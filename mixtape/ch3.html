<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 Potential Outcomes Causal Model | Causal Inference</title>
<meta name="author" content="Scott Cunningham">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.6/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><style>
    @import url('https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&family=Roboto:ital,wght@0,700;1,300&display=swap');
    </style>
<script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/toc.css">
<link rel="stylesheet" href="css/causal_inference_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="&lt;i&gt;The Mixtape&lt;/i&gt;"><span style="font-weight:bold">Causal Inference</span></a>:
        <small class="text-muted"><i>The Mixtape</i></small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="ch1.html"><span class="header-section-number">2</span> Probability and Regression Review</a></li>
<li><a class="" href="ch2.html"><span class="header-section-number">3</span> Directed Acyclic Graphs</a></li>
<li><a class="active" href="ch3.html"><span class="header-section-number">4</span> Potential Outcomes Causal Model</a></li>
<li><a class="" href="ch4.html"><span class="header-section-number">5</span> Matching and Subclassification</a></li>
<li><a class="" href="ch5.html"><span class="header-section-number">6</span> Regression Discontinuity</a></li>
<li><a class="" href="ch6.html"><span class="header-section-number">7</span> Instrumental Variables</a></li>
<li><a class="" href="ch7.html"><span class="header-section-number">8</span> Panel Data</a></li>
<li><a class="" href="ch8.html"><span class="header-section-number">9</span> Difference-in-Differences</a></li>
<li><a class="" href="ch9.html"><span class="header-section-number">10</span> Synthetic Control</a></li>
<li><a class="" href="ch10.html"><span class="header-section-number">11</span> Conclusion</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/scunning1975/mixtape">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ch3" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Potential Outcomes Causal Model<a class="anchor" aria-label="anchor" href="#ch3"><i class="fas fa-link"></i></a>
</h1>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>
<p>Practical questions about causation have been a preoccupation of economists for several centuries. Adam Smith wrote about the causes of the wealth of nations <span class="citation">(Smith <a href="references.html#ref-Smith2003" role="doc-biblioref">2003</a>)</span>. Karl Marx was interested in the transition of society from capitalism to socialism <span class="citation">(Needleman and Needleman <a href="references.html#ref-Needleman1969" role="doc-biblioref">1969</a>)</span>. In the twentieth century the Cowles Commission sought to better understand identifying causal parameters <span class="citation">(Heckman and Vytlacil <a href="references.html#ref-Heckman2007" role="doc-biblioref">2007</a>)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;This brief history will focus on the development of the potential outcomes model. See &lt;span class="citation"&gt;Morgan (&lt;a href="references.html#ref-Morgan1991" role="doc-biblioref"&gt;1991&lt;/a&gt;)&lt;/span&gt; for a more comprehensive history of econometric ideas.&lt;/p&gt;'><sup>50</sup></a> Economists have been wrestling with both the big ideas around causality and the development of useful empirical tools from day one.</p>
<p>We can see the development of the modern concepts of causality in the writings of several philosophers. <span class="citation">Hume (<a href="references.html#ref-Hume1993" role="doc-biblioref">1993</a>)</span> described causation as a sequence of temporal events in which, had the first event not occurred, subsequent ones would not either. For example, he said:</p>
<blockquote>
<p>“We may define a cause to be an object, followed by another, and where all the objects similar to the first are followed by objects similar to the second. Or in other words where, if the first object had not been, the second never had existed.”</p>
</blockquote>
<p><span class="citation">Mill (<a href="references.html#ref-Mill2010" role="doc-biblioref">2010</a>)</span> devised five methods for inferring causation. Those methods were (1) the method of agreement, (2) the method of difference, (3) the joint method, (4) the method of concomitant variation, and (5) the method of residues. The second method, the method of difference, is most similar to the idea of causation as a comparison among counterfactuals. For instance, he wrote:</p>
<blockquote>
<p>“If a person eats of a particular dish, and dies in consequence, that is, would not have died if he had not eaten it, people would be apt to say that eating of that dish was the source of his death.”</p>
</blockquote>
<div id="statistical-inference" class="section level3" number="4.0.1">
<h3>
<span class="header-section-number">4.0.1</span> Statistical inference<a class="anchor" aria-label="anchor" href="#statistical-inference"><i class="fas fa-link"></i></a>
</h3>
<p>A major jump in our understanding of causation occurs coincident with the development of modern statistics. Probability theory and statistics revolutionized science in the nineteenth century, beginning with the field of astronomy. Giuseppe Piazzi, an early nineteenth-century astronomer, discovered the dwarf planet Ceres, located between Jupiter and Mars, in 1801. Piazzi observed it 24 times before it was lost again. Carl Friedrich Gauss proposed a method that could successfully predict Ceres’s next location using data on its prior location. His method minimized the sum of the squared errors; in other words, the ordinary least squares method we discussed earlier. He discovered OLS at age 18 and published his derivation of OLS in 1809 at age 24 <span class="citation">(Gauss <a href="references.html#ref-Gauss1809" role="doc-biblioref">1809</a>)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Around age 20, I finally beat &lt;em&gt;Tomb Raider 2&lt;/em&gt; on the Sony PlayStation. So yeah, I can totally relate to Gauss’s accomplishments at such a young age.&lt;/p&gt;"><sup>51</sup></a> Other scientists who contributed to our understanding of OLS include Pierre-Simon LaPlace and Adrien-Marie Legendre.</p>
<p>The statistician G. Udny Yule made early use of regression analysis in the social sciences. <span class="citation">Yule (<a href="references.html#ref-Yule1899" role="doc-biblioref">1899</a>)</span> was interested in the causes of poverty in England. Poor people depended on either poorhouses or the local authorities for financial support, and Yule wanted to know if public assistance increased the number of paupers, which is a causal question. Yule used least squares regression to estimate the partial correlation between public assistance and poverty. His data was drawn from the English censuses of 1871 and 1881, and I have made his data available at my website for Stata or the Mixtape library for R users. Here’s an example of the regression one might run using these data:
<span class="math display">\[
\text{Pauper}=\alpha+\delta \text{Outrelief}+\beta_1 \text{Old} + \beta_2 \text{Pop} + u
\]</span>
Let’s run this regression using the data.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/yule.do"><code>yule.do</code></a></em></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb21-1"><a href="ch3.html#cb21-1" aria-hidden="true"></a><span class="kw">use</span> https:<span class="co">//github.com/scunning1975/mixtape/raw/master/yule.dta, clear</span></span>
<span id="cb21-2"><a href="ch3.html#cb21-2" aria-hidden="true"></a><span class="kw">regress</span> paup outrelief old pop</span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/yule.R"><code>yule.R</code></a></em></p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haven.tidyverse.org">haven</a></span><span class="op">)</span>

<span class="va">read_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">{</span>
  <span class="va">full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"https://raw.github.com/scunning1975/mixtape/master/"</span>, 
                     <span class="va">df</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/read_dta.html">read_dta</a></span><span class="op">(</span><span class="va">full_path</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">yule</span> <span class="op">&lt;-</span> <span class="fu">read_data</span><span class="op">(</span><span class="st">"yule.dta"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">paup</span> <span class="op">~</span> <span class="va">outrelief</span> <span class="op">+</span> <span class="va">old</span> <span class="op">+</span> <span class="va">pop</span>, <span class="va">.</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">yule</span><span class="op">)</span></code></pre></div>
<p>Each row in this data set is a particular location in England (e.g., Chelsea, Strand). So, since there are 32 rows, that means the data set contains 32 English locations. Each of the variables is expressed as an annual growth rate. As a result, each regression coefficient has elasticity interpretations, with one caveat—technically, as I explained at the beginning of the book, elasticities are actually <em>causal</em> objects, not simply correlations between two variables. And it’s unlikely that the conditions needed to interpret these as causal relationships are met in Yule’s data. Nevertheless, let’s run the regression and look at the results, which I report in Table <a href="ch3.html#tab:yule">4.1</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:yule">Table 4.1: </span> Estimated association between pauperism growth rates and public assistance.</caption>
<tbody>
<tr class="odd">
<td></td>
<td align="center"><em>Dependent variable</em></td>
</tr>
<tr class="even">
<td><strong>Covariates</strong></td>
<td align="center"><strong>Pauperism growth</strong></td>
</tr>
<tr class="odd">
<td>Outrelief</td>
<td align="center">0.752</td>
</tr>
<tr class="even">
<td></td>
<td align="center">(0.135)</td>
</tr>
<tr class="odd">
<td>Old</td>
<td align="center">0.056</td>
</tr>
<tr class="even">
<td></td>
<td align="center">(0.223)</td>
</tr>
<tr class="odd">
<td>Pop</td>
<td align="center"><span class="math inline">\(-0.311\)</span></td>
</tr>
<tr class="even">
<td></td>
<td align="center">(0.067)</td>
</tr>
</tbody>
</table></div>
<p>In words, a 10-percentage-point change in the out-relief growth rate is associated with a 7.5-percentage-point increase in the pauperism growth rate, or an elasticity of 0.75. Yule used his regression to crank out the correlation between out-relief and pauperism, from which he concluded that public assistance increased pauper growth rates.</p>
<p>But what might be wrong with this reasoning? How convinced are you that all backdoor paths between pauperism and out-relief are blocked once you control for two covariates in a cross-sectional database for all of England? Could there be unobserved determinants of both poverty and public assistance? After all, he does not control for any economic factors, which surely affect both poverty and the amount of resources allocated to out-relief. Likewise, he may have the causality backwards—perhaps increased poverty causes communities to increase relief, and not merely the other way around. The earliest adopters of some new methodology or technique are often the ones who get the most criticism, despite being pioneers of the methods themselves. It’s trivially easy to beat up on a researcher from one hundred years ago, working at a time when the alternative to regression was ideological make-believe. Plus he isn’t here to reply. I merely want to note that the naı̈ve use of regression to estimate correlations as a way of making causal claims that inform important policy questions has been the norm for a very long time, and it likely isn’t going away any time soon.</p>
</div>
<div id="physical-randomization" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Physical Randomization<a class="anchor" aria-label="anchor" href="#physical-randomization"><i class="fas fa-link"></i></a>
</h2>
<p>The notion of physical randomization as the foundation of causal inference was in the air in the nineteenth and twentieth centuries, but it was not until <span class="citation">Fisher (<a href="references.html#ref-Fisher1935" role="doc-biblioref">1935</a>)</span> that it crystallized. The first historically recognized randomized experiment had occurred fifty years earlier in psychology <span class="citation">(Peirce and Jastrow <a href="references.html#ref-Peirce1885" role="doc-biblioref">1885</a>)</span>. But interestingly, in that experiment, the reason for randomization was <em>not</em> as the basis for causal inference. Rather, the researchers proposed randomization as a way of fooling subjects in their experiments. <span class="citation">Peirce and Jastrow (<a href="references.html#ref-Peirce1885" role="doc-biblioref">1885</a>)</span> used several treatments, and they used physical randomization so that participants couldn’t guess what would happen next. Unless I’m mistaken, recommending physical randomization of treatments to units as a basis for causal inference is based on <span class="citation">Splawa-Neyman (<a href="references.html#ref-Neyman1923" role="doc-biblioref">1923</a>)</span> and <span class="citation">Fisher (<a href="references.html#ref-Fisher1925" role="doc-biblioref">1925</a>)</span>. More specifically, <span class="citation">Splawa-Neyman (<a href="references.html#ref-Neyman1923" role="doc-biblioref">1923</a>)</span> developed the powerful potential outcomes notation (which we will discuss soon), and while he proposed randomization, it was not taken to be literally necessary until <span class="citation">Fisher (<a href="references.html#ref-Fisher1925" role="doc-biblioref">1925</a>)</span>. <span class="citation">Fisher (<a href="references.html#ref-Fisher1925" role="doc-biblioref">1925</a>)</span> proposed the explicit use of randomization in experimental design for causal inference.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;For more on the transition from &lt;span class="citation"&gt;Splawa-Neyman (&lt;a href="references.html#ref-Neyman1923" role="doc-biblioref"&gt;1923&lt;/a&gt;)&lt;/span&gt; to &lt;span class="citation"&gt;Fisher (&lt;a href="references.html#ref-Fisher1925" role="doc-biblioref"&gt;1925&lt;/a&gt;)&lt;/span&gt;, see &lt;span class="citation"&gt;Rubin (&lt;a href="references.html#ref-Rubin2005" role="doc-biblioref"&gt;2005&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>52</sup></a></p>
<p>Physical randomization was largely the domain of agricultural experiments until the mid-1950s, when it began to be used in medical trials. Among the first major randomized experiments in medicine—in fact, ever attempted—were the Salk polio vaccine field trials. In 1954, the Public Health Service set out to determine whether the Salk vaccine prevented polio. Children in the study were assigned <em>at random</em> to receive the vaccine or a placebo.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;In the placebo, children were injected with a saline solution.&lt;/p&gt;"><sup>53</sup></a> Also, the doctors making the diagnoses of polio did not know whether the child had received the vaccine or the placebo. The polio vaccine trial was called a <em>double-blind, randomized controlled trial</em> because neither the patient nor the administrator of the vaccine knew whether the treatment was a placebo or a vaccine. It was necessary for the field trial to be very large because the rate at which polio occurred in the population was 50 per 100,000. The treatment group, which contained 200,745 individuals, saw 33 polio cases. The control group had 201,229 individuals and saw 115 cases. The probability of seeing such a big difference in rates of polio because of chance alone is about one in a billion. The only plausible explanation, it was argued, was that the polio vaccine caused a reduction in the risk of polio.</p>
<p>A similar large-scale randomized experiment occurred in economics in the 1970s. Between 1971 and 1982, the RAND Corporation conducted a large-scale randomized experiment studying the causal effect of health-care insurance on health-care utilization. For the study, Rand recruited 7,700 individuals younger than age 65. The experiment was somewhat complicated, with multiple treatment arms. Participants were randomly assigned to one of five health insurance plans: free care, three plans with varying levels of cost sharing, and an HMO plan. Participants with cost sharing made fewer physician visits and had fewer hospitalizations than those with free care. Other declines in health-care utilization, such as fewer dental visits, were also found among the cost-sharing treatment groups. Overall, participants in the cost-sharing plans tended to spend less on health because they used fewer services. The reduced use of services occurred mainly because participants in the cost-sharing treatment groups were opting not to initiate care.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;More information about this fascinating experiment can be found in &lt;span class="citation"&gt;Newhouse (&lt;a href="references.html#ref-Newhouse1993" role="doc-biblioref"&gt;1993&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>54</sup></a></p>
<p>But the use of randomized experiments has exploded since that health-care experiment. There have been multiple Nobel Prizes given to those who use them: Vernon Smith for his pioneering of the laboratory experiments in 2002, and more recently, Abhijit Bannerjee, Esther Duflo, and Michael Kremer in 2019 for their leveraging of field experiments at the service of alleviating global poverty.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;If I were a betting man—and I am—then I would bet we see at least one more experimental prize given out. The most likely candidate being John List, for his work using field experiments.&lt;/p&gt;"><sup>55</sup></a> The experimental design has become a hallmark in applied microeconomics, political science, sociology, psychology, and more. But why is it viewed as important? Why is randomization such a key element of this design for isolating causal effects? To understand this, we need to learn more about the powerful notation that <span class="citation">Splawa-Neyman (<a href="references.html#ref-Neyman1923" role="doc-biblioref">1923</a>)</span> developed, called “potential outcomes.”</p>
<div id="potential-outcomes" class="section level3" number="4.1.1">
<h3>
<span class="header-section-number">4.1.1</span> Potential outcomes<a class="anchor" aria-label="anchor" href="#potential-outcomes"><i class="fas fa-link"></i></a>
</h3>
<p>While the potential outcomes notation goes back to <span class="citation">Splawa-Neyman (<a href="references.html#ref-Neyman1923" role="doc-biblioref">1923</a>)</span>, it got a big lift in the broader social sciences with <span class="citation">Rubin (<a href="references.html#ref-Rubin1974" role="doc-biblioref">1974</a>)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Interestingly, philosophy as a field undertakes careful consideration of counterfactuals at the same time as Rubin’s early work with the great metaphysical philosopher David Lewis &lt;span class="citation"&gt;(Lewis &lt;a href="references.html#ref-Lewis1973" role="doc-biblioref"&gt;1973&lt;/a&gt;)&lt;/span&gt;. This stuff was apparently in the air, which makes tracing the causal effect of scientific ideas tough.&lt;/p&gt;'><sup>56</sup></a> As of this book’s writing, potential outcomes is more or less the lingua franca for thinking about and expressing causal statements, and we probably owe <span class="citation">Rubin (<a href="references.html#ref-Rubin1974" role="doc-biblioref">1974</a>)</span> for that as much as anyone.</p>
<p>In the potential outcomes tradition <span class="citation">(Splawa-Neyman <a href="references.html#ref-Neyman1923" role="doc-biblioref">1923</a>; Rubin <a href="references.html#ref-Rubin1974" role="doc-biblioref">1974</a>)</span>, a causal effect is defined as a comparison between two states of the world. Let me illustrate with a simple example. In the first state of the world (sometimes called the “actual” state of the world), a man takes aspirin for his headache and one hour later reports the severity of his headache. In the second state of the world (sometimes called the “counterfactual” state of the world), that same man takes nothing for his headache and one hour later reports the severity of his headache. What was the causal effect of the aspirin? According to the potential outcomes tradition, the causal effect of the aspirin is the difference in the severity of his headache between two states of the world: one where he took the aspirin (the actual state of the world) and one where he never took the aspirin (the counterfactual state of the world). The difference in headache severity between these two states of the world, measured at what is otherwise the same point in time, is the causal effect of aspirin on his headache. Sounds easy!</p>
<p>To even ask questions like this (let alone attempt to answer them) is to engage in storytelling. Humans have always been interested in stories exploring counterfactuals. What if Bruce Wayne’s parents had never been murdered? What if that waitress had won the lottery? What if your friend from high school had never taken that first drink? What if in <em>The Matrix</em> Neo had taken the blue pill? These are fun hypotheticals to entertain, but they are still ultimately storytelling. We need Doctor Strange to give us the Time Stone to answer questions like these.</p>
<p>You can probably see where this is going. The potential outcomes notation expresses causality in terms of counterfactuals, and since counterfactuals do not exist, confidence about causal effects must to some degree be unanswerable. To wonder how life would be different had one single event been different is to indulge in counterfactual reasoning, and counterfactuals are not realized in history because they are hypothetical states of the world. Therefore, if the answer requires data on those counterfactuals, then the question cannot be answered. History is a sequence of observable, <em>factual</em> events, one after another. We don’t know what would have happened had one event changed because we are missing data on the <em>counterfactual outcome</em>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Counterfactual reasoning can be helpful, but it can also be harmful, particularly when it is the source of regret. There is likely a counterfactual version of the sunk-cost fallacy wherein, since we cannot know with certainty what would’ve happened had we made a different decision, we must accept a certain amount of basic uncertainty just to move on and get over it. Ultimately, no one can say that an alternative decision would’ve had a better outcome. You cannot know, and that can be difficult sometimes. It has been and will continue to be, for me at least.&lt;/p&gt;"><sup>57</sup></a> Potential outcomes exist ex ante as a set of possibilities, but once a decision is made, all but one outcome disappears.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;As best I can tell, the philosopher I mentioned earlier, David Lewis, believed that potential outcomes were actually separate worlds—just as real as our world. That means that, according to Lewis, there is a very real, yet inaccessible, world in which Kanye released &lt;em&gt;Yandhi&lt;/em&gt; instead of &lt;em&gt;Jesus Is King&lt;/em&gt;, I find extremely frustrating.&lt;/p&gt;"><sup>58</sup></a></p>
<p>To make this concrete, let’s introduce some notation and more specific concepts. For simplicity, we will assume a <em>binary</em> variable that takes on a value of 1 if a particular unit <span class="math inline">\(i\)</span> receives the <em>treatment</em> and a 0 if it does not.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;A couple of things. First, this analysis can be extended to more than two potential outcomes, but as a lot of this book focuses on program evaluation, I am sticking with just two. Second, the treatment here is any particular intervention that can be manipulated, such as the taking of aspirin or not. In the potential outcomes tradition, manipulation is central to the concept of causality.&lt;/p&gt;"><sup>59</sup></a> Each unit will have two <em>potential outcomes</em>, but only one observed outcome. Potential outcomes are defined as <span class="math inline">\(Y^1_i\)</span> if unit <span class="math inline">\(i\)</span> received the treatment and as <span class="math inline">\(Y^0_i\)</span> if the unit did not. Notice that both potential outcomes have the same <span class="math inline">\(i\)</span> subscript—this indicates two separate states of the world for the exact same person in our example at the exact same moment in time. We’ll call the state of the world where no treatment occurred the <em>control</em> state. Each unit <span class="math inline">\(i\)</span> has exactly two potential outcomes: a potential outcome under a state of the world where the treatment occurred (<span class="math inline">\(Y^1\)</span>) and a potential outcome where the treatment did not occur (<span class="math inline">\(Y^0\)</span>).</p>
<p>Observable or “actual” outcomes, <span class="math inline">\(Y_i\)</span>, are distinct from potential outcomes. First, notice that actual outcomes do not have a superscript. That is because they are not potential outcomes—they are the realized, actual, historical, empirical—however you want to say it—outcomes that unit <span class="math inline">\(i\)</span> experienced. Whereas potential outcomes are hypothetical random variables that differ across the population, observable outcomes are factual random variables. How we get from potential outcomes to actual outcomes is a major philosophical move, but like any good economist, I’m going to make it seem simpler than it is with an equation. A unit’s observable outcome is a function of its potential outcomes determined according to the <em>switching equation</em>:
<span class="math display">\[
Y_i = D_iY^1_i + (1-D_i)Y^0_i
\]</span>
where <span class="math inline">\(D_i\)</span> equals 1 if the unit received the treatment and 0 if it did not. Notice the logic of the equation. When <span class="math inline">\(D_i=1\)</span>, then <span class="math inline">\(Y_i=Y^1_i\)</span> because the second term zeroes out. And when <span class="math inline">\(D_i=0\)</span>, the first term zeroes out and therefore <span class="math inline">\(Y_i=Y^0_i\)</span>. Using this notation, we define the unit-specific treatment effect, or causal effect, as the difference between the two states of the world:
<span class="math display">\[
\delta_i = Y^1_i-Y^0_i
\]</span>
Immediately we are confronted with a problem. If a treatment effect requires knowing two states of the world, <span class="math inline">\(Y^1_i\)</span> and <span class="math inline">\(Y^0_i\)</span>, but by the switching equation we observe only one, then we cannot calculate the treatment effect. Herein lies the fundamental problem of causal inference—<em>certainty</em> around causal effects requires access to data that is and always will be missing.</p>
</div>
<div id="average-treatment-effects" class="section level3" number="4.1.2">
<h3>
<span class="header-section-number">4.1.2</span> Average treatment effects<a class="anchor" aria-label="anchor" href="#average-treatment-effects"><i class="fas fa-link"></i></a>
</h3>
<p>From this simple definition of a treatment effect come three different parameters that are often of interest to researchers. They are all population means. The first is called the <em>average treatment effect</em>:</p>
<p><span class="math display">\[\begin{align}
   ATE &amp; = E[\delta_i] \nonumber      \\
       &amp; = E[Y^1_i - Y^0_i] \nonumber \\
       &amp; = E[Y^1_i] - E[Y^0_i]        
\end{align}\]</span></p>
<p>Notice, as with our definition of individual-level treatment effects, that the average treatment effect requires both potential outcomes for each <span class="math inline">\(i\)</span> unit. Since we only know one of these by the switching equation, the average treatment effect, or the <em>ATE</em>, is inherently unknowable. Thus, the ATE, like the individual treatment effect, is not a quantity that can be calculated. But it can be <em>estimated</em>.</p>
<p>The second parameter of interest is the <em>average treatment effect for the treatment group</em>. That’s a mouthful, but let me explain. There exist two groups of people in this discussion we’ve been having: a treatment group and a control group. The average treatment effect for the treatment group, or <em>ATT</em> for short, is simply that population mean treatment effect for the group of units that had been assigned the treatment in the first place according to the switching equation. Insofar as <span class="math inline">\(\delta_i\)</span> differs across the population, the ATT will likely differ from the ATE. In observational data involving human beings, it almost always will be different from the ATE, and that’s because individuals will be endogenously sorting into some treatment based on the gains they expect from it. Like the ATE, the ATT is unknowable, because like the ATE, it also requires two observations per treatment unit <span class="math inline">\(i\)</span>. Formally we write the ATT as:</p>
<p><span class="math display">\[\begin{align}
   ATT &amp; = E\big[\delta_i\mid D_i=1\big] \nonumber                 
   \\
       &amp; = E\big[Y^1_i - E^0_i\mid D_i = 1\big] \nonumber          
   \\
       &amp; = E\big[Y^1_i\mid D_i=1\big] - E\big[Y^0_i\mid D_i=1\big] 
\end{align}\]</span></p>
<p>The final parameter of interest is called the average treatment effect for the control group, or <em>untreated</em> group. It’s shorthand is <em>ATU</em>, which stands for average treatment effect for the untreated. And like ATT, the ATU is simply the population mean treatment effect for those units who sorted into the control group.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This can happen because of preferences, but it also can happen because of constraints. Utility maximization, remember, is a constrained optimization process, and therefore value and obstacles both play a role in sorting.&lt;/p&gt;"><sup>60</sup></a> Given heterogeneous treatment effects, it’s probably the case that the <span class="math inline">\(ATT\neq ATU\)</span>, especially in an observational setting. The formula for the ATU is as follows:</p>
<p><span class="math display">\[\begin{align}
   ATU &amp; = E\big[\delta_i\mid D_i = 0\big] \nonumber                          
   \\
       &amp; = E\big[Y^1_i - Y^0_i\mid D_i = 0\big] \nonumber                     
   \\
       &amp; =E\big[Y^1_i\mid D_i=0\big]-E\big[Y^0_i\mid D_i=0\big] 
\end{align}\]</span></p>
<p>Depending on the research question, one, or all three, of these parameters is interesting. But the two most common ones of interest are the ATE and the ATT.</p>
</div>
<div id="simple-difference-in-means-decomposition" class="section level3" number="4.1.3">
<h3>
<span class="header-section-number">4.1.3</span> Simple difference in means decomposition<a class="anchor" aria-label="anchor" href="#simple-difference-in-means-decomposition"><i class="fas fa-link"></i></a>
</h3>
<p>This discussion has been somewhat abstract, so let’s be concrete. Let’s assume there are ten patients <span class="math inline">\(i\)</span> who have cancer, and two medical procedures or treatments. There is a surgery intervention, <span class="math inline">\(D_i=1\)</span>, and there is a chemotherapy intervention, <span class="math inline">\(D_i=0\)</span>. Each patient has the following two potential outcomes where a potential outcome is defined as post-treatment life span in years: a potential outcome in a world where they received surgery and a potential outcome where they had instead received chemo. We use the notation <span class="math inline">\(Y^1\)</span> and <span class="math inline">\(Y^0\)</span>, respectively, for these two states of the world.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:po">Table 4.2: </span> Potential outcomes for ten patients receiving surgery <span class="math inline">\(Y^1\)</span> or chemo <span class="math inline">\(Y^0\)</span>.</caption>
<thead><tr class="header">
<th align="left">Patients</th>
<th align="left"><span class="math inline">\(Y^1\)</span></th>
<th align="left"><span class="math inline">\(Y^0\)</span></th>
<th align="left"><span class="math inline">\(\delta\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">7</td>
<td align="left">1</td>
<td align="left">6</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">5</td>
<td align="left">6</td>
<td align="left"><span class="math inline">\(-1\)</span></td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">5</td>
<td align="left">1</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">7</td>
<td align="left">8</td>
<td align="left"><span class="math inline">\(-1\)</span></td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">4</td>
<td align="left">2</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">10</td>
<td align="left">1</td>
<td align="left">9</td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left">1</td>
<td align="left">10</td>
<td align="left"><span class="math inline">\(-9\)</span></td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left">5</td>
<td align="left">6</td>
<td align="left"><span class="math inline">\(-1\)</span></td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="left">3</td>
<td align="left">7</td>
<td align="left"><span class="math inline">\(-4\)</span></td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left">9</td>
<td align="left">8</td>
<td align="left">1</td>
</tr>
</tbody>
</table></div>
<p>We can calculate the average treatment effect if we have this matrix of data, because the average treatment effect is simply the mean difference between columns 2 and 3. That is, <span class="math inline">\(E[Y^1]=5.6\)</span>, and <span class="math inline">\(E[Y^0]=5\)</span>, which means that <span class="math inline">\(ATE=0.6\)</span>. In words, the average treatment effect of surgery across these specific patients is 0.6 additional years (compared to chemo).</p>
<p>But that is just the average. Notice, though: not everyone benefits from surgery. Patient 7, for instance, lives only one additional year post-surgery versus ten additional years post-chemo. But the ATE is simply the average over these heterogeneous treatment effects.</p>
<p>To maintain this fiction, let’s assume that there exists the perfect doctor who knows each person’s potential outcomes and chooses whichever treatment that maximizes a person’s post-treatment life span.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Think of the “perfect doctor” as like a Harry Potter–style Sorting Hat. I first learned of this “perfect doctor” illustration from Rubin himself.&lt;/p&gt;"><sup>61</sup></a> In other words, the doctor chooses to put a patient in surgery or chemotherapy depending on whichever treatment has the longer post-treatment life span. Once he makes that treatment assignment, the doctor observes their post-treatment actual outcome according to the switching equation mentioned earlier.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:o">Table 4.3: </span> Post-treatment observed lifespans in years for surgery <span class="math inline">\(D=1\)</span> versus chemotherapy <span class="math inline">\(D=0\)</span>.</caption>
<thead><tr class="header">
<th align="left">Patients</th>
<th align="left"><span class="math inline">\(Y\)</span></th>
<th align="left"><span class="math inline">\(D\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">7</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">6</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">5</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">8</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">4</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">6 1</td>
<td align="left">0</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">7 1</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left">6</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="left">7</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left">9</td>
<td align="left">1</td>
</tr>
</tbody>
</table></div>
<p>Table <a href="ch3.html#tab:o">4.3</a> shows only the observed outcome for treatment and control group. Table <a href="ch3.html#tab:o">4.3</a> differs from Table <a href="ch3.html#tab:po">4.2</a>, which shows each unit’s potential outcomes. Once treatment has been assigned, we can calculate the average treatment effect for the surgery group (ATT) versus the chemo group (ATU). The ATT equals 4.4, and the ATU equals <span class="math inline">\(-3.2\)</span>. That means that the average post-surgery life span for the surgery group is 4.4 additional years, whereas the average post-surgery life span for the chemotherapy group is 3.2 fewer years.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The reason that the ATU is negative is because the treatment here is the surgery, which did not perform as well as chemotherapy-untreated units. But you could just as easily interpret this as 3.2 &lt;em&gt;additional&lt;/em&gt; years of life if they had received chemo instead of surgery.&lt;/p&gt;"><sup>62</sup></a></p>
<p>Now the ATE is 0.6, which is just a weighted average between the ATT and the ATU.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(ATE = p\times ATT + (1-p)\times ATU = 0.5  \times 4.4 + 0.5\times -3.2 = 0.6.\)&lt;/span&gt;&lt;/p&gt;'><sup>63</sup></a> So we know that the overall effect of surgery is positive, although the effect for some is negative. There exist heterogeneous treatment effects, in other words, but the net effect is positive. What if we were to simply compare the average post-surgery life span for the two groups? This simplistic estimator is called the simple difference in means, and it is an <em>estimate</em> of the ATE equal to
<span class="math display">\[
E\big[Y^1\mid D=1\big] - E\big[Y^0\mid D=0\big]
\]</span>
which can be estimated using samples of data:</p>
<p><span class="math display">\[\begin{align}
SDO &amp;=E\big[Y^1\mid D=1\big] - E\big[Y^0\mid D=0\big] \nonumber
\\
&amp;= \dfrac{1}{N_T} \sum_{i=1}^n \big(y_i\mid d_i=1\big) - \dfrac{1}{N_C} \sum_{i=1}^n \big(y_i\mid d_i=0\big)
\end{align}\]</span></p>
<p>which in this situation is equal to <span class="math inline">\(7-7.4=-0.4\)</span>. That means that the treatment group lives 0.4 fewer years post-surgery than the chemo group when the perfect doctor assigned each unit to its best treatment. While the statistic is true, notice how misleading it is. This statistic without proper qualification could easily be used to claim that, on average, surgery is harmful, when we know that’s not true. It’s biased because the individuals units were optimally sorting into their best treatment option, creating fundamental differences between treatment and control group that are a direct function of the potential outcomes themselves. To make this as clear as I can make it, we will decompose the simple difference in means into three parts. Those three parts are listed below:</p>
<p><span class="math display">\[\begin{align}
    E\big[Y^1\mid D=1\big]-E\big[Y^0\mid D=0\big] &amp; =ATE \nonumber                                              
    \\
                                &amp; + E\big[Y^0\mid D=1\big] - E\big[Y^0\mid D=0\big] \nonumber 
    \\
                                &amp; + (1-\pi)(ATT-ATU)                                          
\end{align}\]</span></p>
<p>To understand where these parts on the right-hand side originate, we need to start over and decompose the parameter of interest, <span class="math inline">\(ATE\)</span>, into its basic building blocks. ATE is equal to the weighted sum of conditional average expectations, <span class="math inline">\(ATT\)</span> and <span class="math inline">\(ATU\)</span>.</p>
<p><span class="math display">\[\begin{align}
   ATE &amp; =\pi ATT+(1-\pi)ATU                                                    
   \\
       &amp; =\pi E\big[Y^1\mid D=1\big]-\pi E\big[Y^0\mid D=1\big]                 
   \\
       &amp; + (1-\pi) E\big[Y^1\mid D=0\big]-(1-\pi) E\big[Y^0\mid D=0\big]        
   \\
       &amp; = \Big\{\pi E\big[Y^1\mid D=1\big]+(1-\pi)E\big[Y^1\mid D=0\big]\Big\} 
   \\
       &amp; -\Big\{\pi E\big[Y^0\mid D=1\big]+(1-\pi) E\big[Y^0\mid D=0\big]\Big\} 
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi\)</span> is the share of patients who received surgery and <span class="math inline">\(1-\pi\)</span> is the share of patients who received chemotherapy. Because the conditional expectation notation is a little cumbersome, let’s exchange each term on the left side, <span class="math inline">\(ATE\)</span>, and right side with some letters. This will make the proof a little less cumbersome:</p>
<p><span class="math display">\[\begin{align}
   E\big[Y^1\mid D=1\big] &amp; = a \\
   E\big[Y^1\mid D=0\big] &amp; = b \\
   E\big[Y^0\mid D=1\big] &amp; = c \\
   E\big[Y^0\mid D=0\big] &amp; = d \\
   ATE  &amp; = e 
\end{align}\]</span></p>
<p>Now that we have made these substitutions, let’s rearrange the letters by redefining ATE as a weighted average of all conditional expectations</p>
<p><span class="math display">\[\begin{align}
   e    &amp; =\big\{\pi{a}+(1-\pi)b\big\}-\big\{\pi{c} + (1-\pi)d\big\}                                                                 
   \\
   e    &amp; =\pi{a}+b-\pi{b}-\pi{c} - d + \pi{d}                                                                                       
   \\
   e    &amp; =\pi{a}+ b-\pi{b}-\pi{c} - d + \pi{d} + (\mathbf{a} - \mathbf{a}) + (\mathbf{c} - \mathbf{c}) + (\mathbf{d} - \mathbf{d})  
   \\
   0    &amp; =e-\pi{a} - b + \pi{b} + \pi{c} + d - \pi{d} - \mathbf{a} + \mathbf{a} - \mathbf{c} + \mathbf{c} - \mathbf{d} + \mathbf{d} 
   \\
   \mathbf{a}-\mathbf{d} &amp; =e-\pi{a} - b + \pi{b} + \pi{c} + d - \pi{d} +\mathbf{a} -\mathbf{c} +\mathbf{c} - \mathbf{d}                              
   \\
   \mathbf{a}-\mathbf{d} &amp; =e + (\mathbf{c} -\mathbf{d}) + \mathbf{a}-\pi{a} - b + \pi{b} -\mathbf{c} + \pi{c} + d - \pi{d}                           
   \\
   \mathbf{a}-\mathbf{d} &amp; =e + (\mathbf{c} -\mathbf{d}) + (1-\pi)a -(1-\pi)b + (1-\pi)d - (1-\pi)c                                                   
   \\
   \mathbf{a}-\mathbf{d} &amp; =e + (\mathbf{c} -\mathbf{d}) + (1-\pi)(a-c) -(1-\pi)(b-d)                                                                 
\end{align}\]</span></p>
<p>Now, substituting our definitions, we get the following:</p>
<p><span class="math display">\[\begin{align}
   E\big[Y^1\mid D=1\big]-E\big[Y^0\mid D=0\big] &amp; = ATE \nonumber                                                       
   \\
                                &amp; + \Big(E\big[Y^0\mid D=1\big] - E\big[Y^0\mid D=0\big]\Big) \nonumber 
   \\
                                &amp; + (1-\pi)(ATT - ATU)                                                  
\end{align}\]</span></p>
<p>And the decomposition ends. Now the fun part—let’s think about what we just made! The left side can be estimated with a sample of data, as both of those potential outcomes become actual outcomes under the switching equation. That’s just the simple difference in mean outcomes. It’s the right side that is more interesting because it tells us what the simple difference in mean outcomes is by definition. Let’s put some labels to it.</p>
<p><span class="math display">\[\begin{align}
\underbrace{\dfrac{1}{N_T} \sum_{i=1}^n \big(y_i\mid d_i=1\big)-\dfrac{1}{N_C}
   \sum_{i=1}^n \big(y_i\mid d_i=0\big)}_{ \text{Simple Difference in Outcomes}}
&amp;= \underbrace{E[Y^1] - E[Y^0]}_{ \text{Average Treatment Effect}}
\\
&amp;+ \underbrace{E\big[Y^0\mid D=1\big] - E\big[Y^0\mid D=0\big]}_{ \text{Selection bias}}
\\
&amp; + \underbrace{(1-\pi)(ATT - ATU)}_{ \text{Heterogeneous treatment effect bias}}
\end{align}\]</span></p>
<p>Let’s discuss each of these in turn. The left side is the simple difference in mean outcomes, and we already know it is equal to <span class="math inline">\(-0.4\)</span>. Since this is a decomposition, it must be the case that the right side also equals <span class="math inline">\(-0.4\)</span>.</p>
<p>The first term is the average treatment effect, which is the parameter of interest, and we know that it is equal to 0.6. Thus, the remaining two terms must be the source of the bias that is causing the simple difference in means to be negative.</p>
<p>The second term is called the <em>selection bias</em>, which merits some unpacking. In this case, the selection bias is the inherent difference between the two groups if both received chemo. Usually, though, it’s just a description of the differences between the two groups if there had never been a treatment in the first place. There are in other words two groups: a surgery group and a chemo group. How do their potential outcomes under control differ? Notice that the first is a counterfactual, whereas the second is an observed outcome according to the switching equation. We can calculate this difference here because we have the complete potential outcomes in Table <a href="ch3.html#tab:po">4.2</a>. That difference is equal to <span class="math inline">\(-4.8\)</span>.</p>
<p>The third term is a lesser-known form of bias, but it’s interesting. Plus, if the focus is the ATE, then it is always present.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Note that &lt;span class="citation"&gt;Angrist and Pischke (&lt;a href="references.html#ref-Angrist2009" role="doc-biblioref"&gt;2009&lt;/a&gt;)&lt;/span&gt; have a slightly different decomposition where the &lt;span class="math inline"&gt;\(SDO=ATT + \text{selection bias}\)&lt;/span&gt;, but that is because their parameter of interest is the ATT, and therefore the third term doesn’t appear.&lt;/p&gt;'><sup>64</sup></a> The <em>heterogeneous treatment effect bias</em> is simply the different returns to surgery for the two groups multiplied by the share of the population that is in the chemotherapy group at all. This final term is <span class="math inline">\(0.5\times (4.4-(-3.2))\)</span> or <span class="math inline">\(3.8\)</span>. Note in case it’s not obvious that the reason <span class="math inline">\(\pi=0.5\)</span> is because 5 out of 10 units are in the chemotherapy group.</p>
<p>Now that we have all three parameters on the right side, we can see why the simple difference in mean outcomes is equal to <span class="math inline">\(-0.4\)</span>.
<span class="math display">\[
-0.4=0.6-4.8+3.8
\]</span>
What I find interesting—hopeful even—in this decomposition is that it shows that a contrast between treatment and control group technically “contains” the parameter of interest. I placed “contains” in quotes because while it is clearly visible in the decomposition, the simple difference in outcomes is ultimately not laid out as the sum of three parts. Rather, the simple difference in outcomes is nothing more than a number. The number is the sum of the three parts, but we cannot calculate each individual part because we do not have data on the underlying counterfactual outcomes needed to make the calculations. The problem is that that parameter of interest has been masked by two forms of bias, the selection bias and the heterogeneous treatment effect bias. If we knew those, we could just subtract them out, but ordinarily we don’t know them. We develop strategies to negate these biases, but we cannot directly calculate them any more than we can directly calculate the ATE, as these biases depend on unobservable counterfactuals.</p>
<p>The problem isn’t caused by assuming heterogeneity either. We can make the strong assumption that treatment effects are constant, <span class="math inline">\(\delta_i = \delta\)</span> <span class="math inline">\(\forall i\)</span>, which will cause <span class="math inline">\(ATU=ATT\)</span> and make <span class="math inline">\(SDO = ATE\)</span> + selection bias. But we’d still have that nasty selection bias screwing things up. One could argue that the entire enterprise of causal inference is about developing a reasonable strategy for negating the role that selection bias is playing in estimated causal effects.</p>
</div>
<div id="independence-assumption" class="section level3" number="4.1.4">
<h3>
<span class="header-section-number">4.1.4</span> Independence assumption<a class="anchor" aria-label="anchor" href="#independence-assumption"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s start with the most credible situation for using <span class="math inline">\(SDO\)</span> to estimate <span class="math inline">\(ATE\)</span>: when the treatment itself (e.g., surgery) has been assigned to patients <em>independent</em> of their potential outcomes. But what does this word “independence” mean anyway? Well, notationally, it means:</p>
<p><span class="math display">\[\begin{align}
   (Y^1,Y^0)\perp \!\!\! \perp D 
\end{align}\]</span></p>
<p>What this means is that surgery was assigned to an individual for reasons that had <em>nothing</em> to do with the gains to surgery.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Why do I say “gains”? Because the gain to surgery is &lt;span class="math inline"&gt;\(Y^1_i - Y^0_i\)&lt;/span&gt;. Thus, if we say it’s independent of gains, we are saying it’s independent of &lt;span class="math inline"&gt;\(Y^1\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(Y^0\)&lt;/span&gt;.&lt;/p&gt;'><sup>65</sup></a> Now in our example, we already know that this is violated because the perfect doctor specifically chose surgery or chemo based on potential outcomes. Specifically, a patient received surgery if <span class="math inline">\(Y^1&gt;Y^0\)</span> and chemo if <span class="math inline">\(Y^1&lt;Y^0\)</span>. Thus, in our case, the perfect doctor ensured that <span class="math inline">\(D\)</span> <em>depended</em> on <span class="math inline">\(Y^1\ and\ Y^0\)</span>. All forms of human-based sorting—probably as a rule to be honest—violate independence, which is the main reason naı̈ve observational comparisons are almost always incapable of recovering causal effects.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This is actually where economics is helpful in my opinion. Economics emphasizes that observed values are equilibria based on agents engaging in constrained optimization and that all but guarantees that independence is violated in observational data. Rarely are human beings making important life choices by flipping coins.&lt;/p&gt;"><sup>66</sup></a></p>
<p>But what if he hadn’t done that? What if he had chosen surgery in such a way that did not depend on <span class="math inline">\(Y^1\)</span> or <span class="math inline">\(Y^0\)</span>? How does one choose surgery independent of the expected gains of the surgery? For instance, maybe he alphabetized them by last name, and the first five received surgery and the last five received chemotherapy. Or maybe he used the second hand on his watch to assign surgery to them: if it was between 1 and 30 seconds, he gave them surgery, and if it was between 31 and 60 seconds, he gave them chemotherapy.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;In &lt;span class="citation"&gt;Craig (&lt;a href="references.html#ref-Craig2006" role="doc-biblioref"&gt;2006&lt;/a&gt;)&lt;/span&gt;, a poker-playing banker used the second hand on his watch as a random number generator to randomly bluff when he had a weak hand.&lt;/p&gt;'><sup>67</sup></a> In other words, let’s say that he chose some method for assigning treatment that did not depend on the values of potential outcomes under either state of the world. What would that mean in this context? Well, it would mean:</p>
<p><span class="math display">\[\begin{align}
   E\big[Y^1\mid D=1\big] - E\big[Y^1\mid D=0\big]=0 \\
   E\big[Y^0\mid D=1\big] - E\big[Y^0\mid D=0\big]=0 
\end{align}\]</span></p>
<p>In other words, it would mean that the mean potential outcome for <span class="math inline">\(Y^1\)</span> or <span class="math inline">\(Y^0\)</span> is the same (in the population) for either the surgery group or the chemotherapy group. This kind of <em>randomization</em> of the treatment assignment would eliminate both the selection bias and the heterogeneous treatment effect bias. Let’s take it in order. The selection bias zeroes out as follows:</p>
<p><span class="math display">\[\begin{align}
   E\big[Y^0\mid D=1\big] - E\big[Y^0\mid D=0\big]=0
\end{align}\]</span></p>
<p>And thus the <span class="math inline">\(SDO\)</span> no longer suffers from selection bias. How does randomization affect heterogeneity treatment bias from the third line? Rewrite definitions for ATT and ATU:</p>
<p><span class="math display">\[\begin{gather}
   ATT = E\big[Y^1\mid D=1\big] - E\big[Y^0\mid D=1\big]
   \\
   ATU = E\big[Y^1\mid D=0\big] - E\big[Y^0\mid D=0\big]
\end{gather}\]</span></p>
<p>Rewrite the third row bias after <span class="math inline">\(1-\pi\)</span>:</p>
<p><span class="math display">\[\begin{align}
   ATT-ATU &amp; =\mathbf{E\big[Y^1\mid D=1\big]}-E\big[Y^0\mid D=1\big]    \\
           &amp; - \mathbf{E\big[Y^1 \mid D=0\big]}+ E\big[Y^0\mid D=0\big] \\
           &amp; = 0                                                        
\end{align}\]</span></p>
<p>If treatment is independent of potential outcomes, then:</p>
<p><span class="math display">\[\begin{align}
   \dfrac{1}{N_T} \sum_{i=1}^n \big(y_i\mid d_i=1\big) - \dfrac{1}{N_C} \sum_{i=1}^n \big(y_i\mid d_i=0\big) &amp; = E[Y^1] - E[Y^0] 
   \\
   SDO                                                                                      &amp; = ATE             
\end{align}\]</span></p>
<p>What’s necessary in this situation is simply (a) data on observable outcomes, (b) data on treatment assignment, and (c) <span class="math inline">\((Y^1,Y^0) \perp \!\!\! \perp D\)</span>. We call (c) the independence assumption. To illustrate that this would lead to the SDO, we use the following Monte Carlo simulation. Note that <span class="math inline">\(ATE\)</span> in this example is equal to 0.6.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/independence.do"><code>independence.do</code></a></em></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb23-1"><a href="ch3.html#cb23-1" aria-hidden="true"></a><span class="kw">clear</span> <span class="ot">all</span></span>
<span id="cb23-2"><a href="ch3.html#cb23-2" aria-hidden="true"></a><span class="kw">program</span> <span class="kw">define</span> gap, rclass</span>
<span id="cb23-3"><a href="ch3.html#cb23-3" aria-hidden="true"></a></span>
<span id="cb23-4"><a href="ch3.html#cb23-4" aria-hidden="true"></a>    <span class="kw">version</span> 14.2</span>
<span id="cb23-5"><a href="ch3.html#cb23-5" aria-hidden="true"></a>    <span class="kw">syntax</span> [, <span class="kw">obs</span>(integer 1) mu(<span class="fu">real</span> 0) sigma(<span class="fu">real</span> 1) ]</span>
<span id="cb23-6"><a href="ch3.html#cb23-6" aria-hidden="true"></a>    <span class="kw">clear</span></span>
<span id="cb23-7"><a href="ch3.html#cb23-7" aria-hidden="true"></a>    <span class="kw">drop</span> <span class="dt">_all</span></span>
<span id="cb23-8"><a href="ch3.html#cb23-8" aria-hidden="true"></a>    <span class="kw">set</span> <span class="kw">obs</span> 10</span>
<span id="cb23-9"><a href="ch3.html#cb23-9" aria-hidden="true"></a>    <span class="kw">gen</span>     y1 = 7 <span class="kw">in</span> 1</span>
<span id="cb23-10"><a href="ch3.html#cb23-10" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 5 <span class="kw">in</span> 2</span>
<span id="cb23-11"><a href="ch3.html#cb23-11" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 5 <span class="kw">in</span> 3</span>
<span id="cb23-12"><a href="ch3.html#cb23-12" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 7 <span class="kw">in</span> 4</span>
<span id="cb23-13"><a href="ch3.html#cb23-13" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 4 <span class="kw">in</span> 5</span>
<span id="cb23-14"><a href="ch3.html#cb23-14" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 10 <span class="kw">in</span> 6</span>
<span id="cb23-15"><a href="ch3.html#cb23-15" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 1 <span class="kw">in</span> 7</span>
<span id="cb23-16"><a href="ch3.html#cb23-16" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 5 <span class="kw">in</span> 8</span>
<span id="cb23-17"><a href="ch3.html#cb23-17" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 3 <span class="kw">in</span> 9</span>
<span id="cb23-18"><a href="ch3.html#cb23-18" aria-hidden="true"></a>    <span class="kw">replace</span> y1 = 9 <span class="kw">in</span> 10</span>
<span id="cb23-19"><a href="ch3.html#cb23-19" aria-hidden="true"></a></span>
<span id="cb23-20"><a href="ch3.html#cb23-20" aria-hidden="true"></a>    <span class="kw">gen</span>     y0 = 1 <span class="kw">in</span> 1</span>
<span id="cb23-21"><a href="ch3.html#cb23-21" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 6 <span class="kw">in</span> 2</span>
<span id="cb23-22"><a href="ch3.html#cb23-22" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 1 <span class="kw">in</span> 3</span>
<span id="cb23-23"><a href="ch3.html#cb23-23" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 8 <span class="kw">in</span> 4</span>
<span id="cb23-24"><a href="ch3.html#cb23-24" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 2 <span class="kw">in</span> 5</span>
<span id="cb23-25"><a href="ch3.html#cb23-25" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 1 <span class="kw">in</span> 6</span>
<span id="cb23-26"><a href="ch3.html#cb23-26" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 10 <span class="kw">in</span> 7</span>
<span id="cb23-27"><a href="ch3.html#cb23-27" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 6 <span class="kw">in</span> 8</span>
<span id="cb23-28"><a href="ch3.html#cb23-28" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 7 <span class="kw">in</span> 9</span>
<span id="cb23-29"><a href="ch3.html#cb23-29" aria-hidden="true"></a>    <span class="kw">replace</span> y0 = 8 <span class="kw">in</span> 10</span>
<span id="cb23-30"><a href="ch3.html#cb23-30" aria-hidden="true"></a>    <span class="kw">drawnorm</span> random</span>
<span id="cb23-31"><a href="ch3.html#cb23-31" aria-hidden="true"></a>    <span class="kw">sort</span> random</span>
<span id="cb23-32"><a href="ch3.html#cb23-32" aria-hidden="true"></a></span>
<span id="cb23-33"><a href="ch3.html#cb23-33" aria-hidden="true"></a>    <span class="kw">gen</span>     <span class="kw">d</span>=1 <span class="kw">in</span> 1/5</span>
<span id="cb23-34"><a href="ch3.html#cb23-34" aria-hidden="true"></a>    <span class="kw">replace</span> <span class="kw">d</span>=0 <span class="kw">in</span> 6/10</span>
<span id="cb23-35"><a href="ch3.html#cb23-35" aria-hidden="true"></a>    <span class="kw">gen</span>     <span class="fu">y</span>=<span class="kw">d</span>*y1 + (1-<span class="kw">d</span>)*y0</span>
<span id="cb23-36"><a href="ch3.html#cb23-36" aria-hidden="true"></a>    <span class="kw">egen</span> sy1 = <span class="kw">mean</span>(<span class="fu">y</span>) <span class="kw">if</span> <span class="kw">d</span>==1</span>
<span id="cb23-37"><a href="ch3.html#cb23-37" aria-hidden="true"></a>    <span class="kw">egen</span> sy0 = <span class="kw">mean</span>(<span class="fu">y</span>) <span class="kw">if</span> <span class="kw">d</span>==0          </span>
<span id="cb23-38"><a href="ch3.html#cb23-38" aria-hidden="true"></a>    <span class="kw">collapse</span> (<span class="kw">mean</span>) sy1 sy0</span>
<span id="cb23-39"><a href="ch3.html#cb23-39" aria-hidden="true"></a>    <span class="kw">gen</span> sdo = sy1 - sy0</span>
<span id="cb23-40"><a href="ch3.html#cb23-40" aria-hidden="true"></a>    <span class="kw">keep</span> sdo</span>
<span id="cb23-41"><a href="ch3.html#cb23-41" aria-hidden="true"></a>    <span class="kw">summarize</span> sdo</span>
<span id="cb23-42"><a href="ch3.html#cb23-42" aria-hidden="true"></a>    <span class="kw">gen</span> <span class="kw">mean</span> = <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb23-43"><a href="ch3.html#cb23-43" aria-hidden="true"></a>    <span class="kw">end</span></span>
<span id="cb23-44"><a href="ch3.html#cb23-44" aria-hidden="true"></a></span>
<span id="cb23-45"><a href="ch3.html#cb23-45" aria-hidden="true"></a><span class="kw">simulate</span> <span class="kw">mean</span>, reps(10000): gap</span>
<span id="cb23-46"><a href="ch3.html#cb23-46" aria-hidden="true"></a>su _sim_1 </span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/independence.R"><code>independence.R</code></a></em></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>

<span class="va">gap</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> 
<span class="op">{</span>
  <span class="va">sdo</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
    y1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">7</span>,<span class="fl">5</span>,<span class="fl">5</span>,<span class="fl">7</span>,<span class="fl">4</span>,<span class="fl">10</span>,<span class="fl">1</span>,<span class="fl">5</span>,<span class="fl">3</span>,<span class="fl">9</span><span class="op">)</span>,
    y0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">6</span>,<span class="fl">1</span>,<span class="fl">8</span>,<span class="fl">2</span>,<span class="fl">1</span>,<span class="fl">10</span>,<span class="fl">6</span>,<span class="fl">7</span>,<span class="fl">8</span><span class="op">)</span>,
    random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>
  <span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">random</span><span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>
      d <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">5</span><span class="op">)</span><span class="op">)</span>,
      y <span class="op">=</span> <span class="va">d</span> <span class="op">*</span> <span class="va">y1</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">d</span><span class="op">)</span> <span class="op">*</span> <span class="va">y0</span>
    <span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
  
  <span class="va">sdo</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sdo</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">-</span><span class="va">sdo</span><span class="op">[</span><span class="fl">6</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span><span class="op">)</span>
  
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">sdo</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu">gap</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sim</span><span class="op">)</span></code></pre></div>
<p>This Monte Carlo runs 10,000 times, each time calculating the average SDO under independence—which is ensured by the random number sorting that occurs. In my running of this program, the ATE is 0.6, and the SDO is on average equal to 0.59088.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Because it’s not seeded, when you run it, your answer will be close but slightly different because of the randomness of the sample drawn.&lt;/p&gt;"><sup>68</sup></a></p>
<p>Before we move on from the SDO, let’s just emphasize something that is often lost on students first learning the independence concept and notation. Independence does not imply that <span class="math inline">\(E[Y^1\mid D=1] - E[Y^0\mid D=0]=0\)</span>. Nor does it imply that <span class="math inline">\(E[Y^1\mid D=1] - E[Y^0\mid D=1]=0\)</span>. Rather, it implies
<span class="math display">\[
E\big[Y^1\mid D=1\big] - E\big[Y^1\mid D=0\big]=0
\]</span>
in a large population.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Here’s a simple way to remember what equality we get with independence. The term before the vertical bar is the same, but the term after the vertical bar is different. So independence guarantees that in the population &lt;span class="math inline"&gt;\(Y^1\)&lt;/span&gt; is the same on average, for each group.&lt;/p&gt;'><sup>69</sup></a> That is, independence implies that the two groups of units, surgery and chemo, have the same potential outcome on average in the population.</p>
<p>How realistic is independence in observational data? Economics—maybe more than any other science—tells us that independence is unlikely to hold observationally. Economic actors are always attempting to achieve some optima. For instance, parents are putting kids in what they perceive to be the best school for them, and that is based on potential outcomes. In other words, people are <em>choosing</em> their interventions, and most likely their decisions are related to the potential outcomes, which makes simple comparisons improper. Rational choice is always pushing against the independence assumption, and therefore simple comparison in means will not approximate the true causal effect. We need unit randomization for simple comparisons to help us understand the causal effects at play.</p>
</div>
<div id="sutva" class="section level3" number="4.1.5">
<h3>
<span class="header-section-number">4.1.5</span> SUTVA<a class="anchor" aria-label="anchor" href="#sutva"><i class="fas fa-link"></i></a>
</h3>
<p>Rubin argues that there are a bundle of assumptions behind this kind of calculation, and he calls these assumptions the <em>stable unit treatment value assumption</em>, or SUTVA for short. That’s a mouthful, but here’s what it means: our potential outcomes framework places limits on us for calculating treatment effects. When those limits do not credibly hold in the data, we have to come up with a new solution. And those limitations are that each unit receives the same sized dose, no spillovers (“externalities”) to other units’ potential outcomes when a unit is exposed to some treatment, and no general equilibrium effects.</p>
<p>First, this implies that the treatment is received in homogeneous doses to all units. It’s easy to imagine violations of this, though—for instance, if some doctors are better surgeons than others. In which case, we just need to be careful what we are and are not defining as the treatment.</p>
<p>Second, this implies that there are no externalities, because by definition, an externality spills over to other untreated units. In other words, if unit 1 receives the treatment, and there is some externality, then unit 2 will have a different <span class="math inline">\(Y^0\)</span> value than if unit 1 had not received the treatment. We are assuming away this kind of spillover. When there are such spillovers, though, such as when we are working with social network data, we will need to use models that can explicitly account for such SUTVA violations, such as that of <span class="citation">Goldsmith-Pinkham and Imbens (<a href="references.html#ref-Pinkham2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>Related to this problem of spillovers is the issue of general equilibrium. Let’s say we are estimating the causal effect of returns to schooling. The increase in college education would in general equilibrium cause a change in relative wages that is different from what happens under partial equilibrium. This kind of scaling-up issue is of common concern when one considers extrapolating from the experimental design to the large-scale implementation of an intervention in some population.</p>
<p><em>Replicating “demand for learning HIV status.”</em> Rebecca Thornton is a prolific, creative development economist. Her research has spanned a number of topics in development and has evaluated critically important questions regarding optimal HIV policy, demand for learning, circumcision, education, and more. Some of these papers have become major accomplishments. Meticulous and careful, she has become a leading expert on HIV in sub-Saharan Africa. I’d like to discuss an ambitious project she undertook as a grad student in rural Malawi concerning whether cash incentives caused people to learn their HIV status and the cascading effect of that learning on subsequent risky sexual behavior <span class="citation">(Thornton <a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span>.</p>
<p>Thornton’s study emerges in a policy context where people believed that HIV testing could be used to fight the epidemic. The idea was simple: if people learned their HIV status, then maybe learning they were infected would cause them to take precautions, thus slowing the rate of infection. For instance, they might seek medical treatment, thus prolonging their life and the quality of life they enjoyed. But upon learning their HIV status, maybe finding out they were HIV-positive would cause them to decrease high-risk behavior. If so, then increased testing could create frictions throughout the sexual network itself that would slow an epidemic. So commonsense was this policy that the assumptions on which it rested were not challenged until <span class="citation">Thornton (<a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span> did an ingenious field experiment in rural Malawi. Her results were, like many studies, a mixture of good news and bad.</p>
<p>Attempting to understand the demand for HIV status, or the effect of HIV status on health behaviors, is generally impossible without an experiment. Insofar as individuals are optimally choosing to learn about their type or engaging in health behaviors, then it is unlikely that knowledge about HIV status is independent of potential outcomes. Almost certainly, it is those very potential outcomes that shape the decisions both to acquire that information and to engage in risky behaviors of any sort. Thus, a field experiment would be needed if we were to test the underlying assumptions behind this commonsense policy to use testing to fight the epidemic.</p>
<p>How did she do this, though? Respondents in rural Malawi were offered a free door-to-door HIV test and randomly assigned no voucher or vouchers ranging from $1–$3. These vouchers were redeemable once they visited a nearby voluntary counseling and testing center (VCT). The most encouraging news was that monetary incentives were highly effective in causing people to seek the results of tests. On average, respondents who received any cash-value voucher were two times as likely to go to the VCT center to get their test results compared to those individuals who received no compensation. How big was this incentive? Well, the average incentive in her experiment was worth about a day’s wage. But she found positive status-seeking behavior even for the smallest incentive, which was worth only one-tenth a day’s wage. Thornton showed that even small monetary nudges could be used to encourage people to learn their HIV type, which has obvious policy implications.</p>
<p>The second part of the experiment threw cold water on any optimism from her first results. Several months after the cash incentives were given to respondents, Thornton followed up and interviewed them about their subsequent health behaviors. Respondents were also given the opportunity to purchase condoms. Using her randomized assignment of incentives for learning HIV status, she was able to isolate the causal effect of learning itself on condom purchase her proxy for engaging in risky sex. She finds that conditional on learning one’s HIV status from the randomized incentives, HIV-positive individuals did increase their condom usage over those HIV-positive individuals who had not learned their results <em>but only in the form of buying two additional condoms</em>. This study suggested that some kinds of outreach, such as door-to-door testing, may cause people to learn their type—particularly when bundled with incentives—but simply having been incentivized to learn one’s HIV status may not itself lead HIV-positive individuals to reduce any engagement in high-risk sexual behaviors, such as having sex without a condom.</p>
<p>Thorton’s experiment was more complex than I am able to represent here, and also, I focus now on only the cash-transfer aspect of the experiment, in the form of vouchers. but I am going to focus purely on her incentive results. But before I do so, let’s take a look at what she found. Table <a href="ch3.html#tab:thornton-main">4.4</a> shows her findings.</p>
<p>Since her project uses randomized assignment of cash transfers for identifying causal effect on learning, she mechanically creates a treatment assignment that is independent of the potential outcomes under consideration. We know this even though we cannot directly test it (i.e., potential outcomes are unseen) because we know how the science works. Randomization, in other words, by design assigns treatment independent of potential outcomes. And as a result, simple differences in means are sufficient for getting basic estimates of causal effects.</p>
<p>But Thornton is going to estimate a linear regression model with controls instead of using a simple difference in means for a few reasons. One, doing so allows her to include a variety of controls that can reduce the residual variance and thus improve the precision of her estimates. This has value because in improving precision, she is able to rule out a broader range of treatment effects that are technically contained by her confidence intervals. Although probably in this case, that’s not terribly important given, as we will see, that her standard errors are miniscule.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:thornton-main">Table 4.4: </span> Impact of Monetary Incentives and Distance on Learning HIV Results <span class="citation">(Thornton <a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span>
</caption>
<thead><tr class="header">
<th></th>
<th align="center"><strong>1</strong></th>
<th align="center"><strong>2</strong></th>
<th align="center"><strong>3</strong></th>
<th align="center"><strong>4</strong></th>
<th align="center"><strong>5</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Any incentive</td>
<td align="center">0.431<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.309<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.219<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.220<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.219 <span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="even">
<td></td>
<td align="center">(0.023)</td>
<td align="center">(0.026)</td>
<td align="center">(0.029)</td>
<td align="center">(0.029)</td>
<td align="center">(0.029)</td>
</tr>
<tr class="odd">
<td>Amount of incentive</td>
<td align="center"></td>
<td align="center">0.091<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.274<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.274<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.273<span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td align="center">(0.012)</td>
<td align="center">(0.036)</td>
<td align="center">(0.035)</td>
<td align="center">(0.036)</td>
</tr>
<tr class="odd">
<td>Amount of incentive<span class="math inline">\(^2\)</span>
</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">
<span class="math inline">\(-0.063\)</span><span class="math inline">\(^{***}\)</span>
</td>
<td align="center">
<span class="math inline">\(-0.063\)</span><span class="math inline">\(^{***}\)</span>
</td>
<td align="center">
<span class="math inline">\(-0.063\)</span><span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">(0.011)</td>
<td align="center">(0.011)</td>
<td align="center">(0.011)</td>
</tr>
<tr class="odd">
<td>HIV</td>
<td align="center">
<span class="math inline">\(-0.055\)</span><span class="math inline">\(^{*}\)</span>
</td>
<td align="center"><span class="math inline">\(-0.052\)</span></td>
<td align="center"><span class="math inline">\(-0.05\)</span></td>
<td align="center">
<span class="math inline">\(-0.058\)</span><span class="math inline">\(^{*}\)</span>
</td>
<td align="center">
<span class="math inline">\(-0.055\)</span><span class="math inline">\(^{*}\)</span>
</td>
</tr>
<tr class="even">
<td></td>
<td align="center">(0.031)</td>
<td align="center">(0.032)</td>
<td align="center">(0.032)</td>
<td align="center">(0.031)</td>
<td align="center">(0.031)</td>
</tr>
<tr class="odd">
<td>Distance (km)</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">
<span class="math inline">\(-0.076\)</span><span class="math inline">\(^{***}\)</span>
</td>
<td align="center"></td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">(0.027)</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Distance<span class="math inline">\(^2\)</span>
</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0.010<span class="math inline">\(^{**}\)</span>
</td>
<td align="center"></td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">(0.005)</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Controls</td>
<td align="center">Yes</td>
<td align="center">Yes</td>
<td align="center">Yes</td>
<td align="center">Yes</td>
<td align="center">Yes</td>
</tr>
<tr class="even">
<td>Sample size</td>
<td align="center">2,812</td>
<td align="center">2,812</td>
<td align="center">2,812</td>
<td align="center">2,812</td>
<td align="center">2,812</td>
</tr>
<tr class="odd">
<td>Average attendance</td>
<td align="center">0.69</td>
<td align="center">0.69</td>
<td align="center">0.69</td>
<td align="center">0.69</td>
<td align="center">0.69</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Columns 1–5 represent OLS coefficients; robust standard errors clustered by village (for 119 villages) with district fixed effects in parentheses. All specifications also include a term for age-squared. “Any incentive” is an indicator if the respondent received any nonzero monetary incentive. “HIV” is an indicator of being HIV positive. “Simulated average distance” is an average distance of respondents’ households to simulated randomized locations of HIV results centers. Distance is measured as a straight-line spherical distance from a respondent’s home to a randomly assigned VCT center from geospatial coordinates and is measured in kilometers. <span class="math inline">\(^{***}\)</span>Significantly different from zero at 99 percent confidence level. <span class="math inline">\(^{**}\)</span> Significantly different from zero at 95 percent confidence level. <span class="math inline">\(^{*}\)</span> Significantly different from zero at 90 percent confidence level.
</p>
<p>But the inclusion of controls has other value. For instance, if assignment was conditional on observables, or if the assignment was done at different times, then including these controls (such as district fixed effects) is technically needed to isolate the causal effects themselves. And finally, regression generates nice standard errors, and maybe for that alone, we should give it a chance.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;She also chose to cluster those standard errors by village for 119 villages. In doing so, she addresses the over-rejection problem that we saw earlier when discussing clustering in the probability and regression chapter.&lt;/p&gt;"><sup>70</sup></a></p>
<p>So what did Thornton find? She uses least squares as her primary model, represented in columns 1–5. The effect sizes that she finds could be described as gigantic. Because only 34 percent of the control group participants went to a center to learn their HIV status, it is impressive that receiving any money caused a 43-percentage-point increase in learning one’s HIV status. Monetary incentives—even very small ones—are enough to push many people over the hump to go collect health data.</p>
<p>Columns 2–5 are also interesting, but I won’t belabor them here. In short, column 2 includes a control for the amount of the incentive, which ranged from US$0 to US$3. This allows us to estimate the linear impact of each additional dollar on learning, which is relatively steep. Columns 3–5 include a quadratic and as a result we see that while each additional dollar increases learning, it does so only at a decreasing rate. Columns 4 and 5 include controls for distance to the VCT center, and as with other studies, distance itself is a barrier to some types of health care <span class="citation">(Lindo et al. <a href="references.html#ref-Lindo2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>Thornton also produces a simple graphic of her results, showing box plots with mean and confidence intervals for the treatment and control group. As we will continually see throughout the book, the best papers estimating causal effects will always summarize their main results in smart and effective pictures, and this study is no exception. As this figure shows, the effects were huge.</p>
<div class="figure">
<span id="fig:thorntonfig"></span>
<img src="graphics/FigA.jpg" alt="Visual representation of cash transfers on learning HIV test results [@Thornton2008]." width="100%"><p class="caption">
Figure 4.1: Visual representation of cash transfers on learning HIV test results <span class="citation">(Thornton <a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span>.
</p>
</div>
<p>While learning one’s own HIV status is important, particularly if it leads to medical care, the gains to policies that nudge learning are particularly higher if they lead to changes in high-risk sexual behavior among HIV-positive individuals. In fact, given the multiplier effects associated with introducing frictions into the sexual network via risk-mitigating behavior (particularly if it disrupts concurrent partnerships), such efforts may be so beneficial that they justify many types of programs that otherwise may not be cost-effective.</p>
<p>Thornton examines in her follow-up survey where she asked all individuals, regardless of whether they learned their HIV status, the effect of a cash transfer on condom purchases. Let’s first see her main results in Figure <a href="ch3.html#fig:thorntoncondomfig">4.2</a>.</p>
<div class="figure">
<span id="fig:thorntoncondomfig"></span>
<img src="graphics/FigC.jpg" alt="Visual representation of cash transfers on condom purchases for HIV positive individuals [@Thornton2008]." width="100%"><p class="caption">
Figure 4.2: Visual representation of cash transfers on condom purchases for HIV positive individuals <span class="citation">(Thornton <a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span>.
</p>
</div>
<p>It is initially encouraging to see that the effects on condom purchases are large for the HIV-positive individuals who, as a result of the incentive, got their test results. Those who bought <em>any</em> condoms increases from a baseline that’s a little over 30 percent to a whopping 80 percent with any incentive. But where things get discouraging is when we examine <em>how many</em> additional condoms this actually entailed. In columns 3 and 4 of Table <a href="ch3.html#tab:thornton-condoms">4.5</a>, we see the problem.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:thornton-condoms">Table 4.5: </span> Reactions to Learning HIV Results among Sexually Active at Baseline <span class="citation">(Thornton <a href="references.html#ref-Thornton2008" role="doc-biblioref">2008</a>)</span>
</caption>
<tbody>
<tr class="odd">
<td align="left"><strong>Dependent variables:</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="left">Got results</td>
<td><span class="math inline">\(-0.022\)</span></td>
<td><span class="math inline">\(-0.069\)</span></td>
<td><span class="math inline">\(-0.193\)</span></td>
<td><span class="math inline">\(-0.303\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td>(0.025)</td>
<td>(0.062)</td>
<td>(0.148)</td>
<td>(0.285)</td>
</tr>
<tr class="even">
<td align="left">Got results <span class="math inline">\(\times\)</span> HIV</td>
<td>0.418<span class="math inline">\(^{***}\)</span>
</td>
<td>0.248</td>
<td>1.778<span class="math inline">\(^{***}\)</span>
</td>
<td>1.689<span class="math inline">\(^{**}\)</span>
</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td>(0.143)</td>
<td>(0.169)</td>
<td>(0.564)</td>
<td>(0.784)</td>
</tr>
<tr class="even">
<td align="left">HIV</td>
<td>
<span class="math inline">\(-0.175\)</span><span class="math inline">\(^{**}\)</span>
</td>
<td><span class="math inline">\(-0.073\)</span></td>
<td><span class="math inline">\(-0.873\)</span></td>
<td><span class="math inline">\(-0.831\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td>(0.085)</td>
<td>(0.123)</td>
<td>(0.275)</td>
<td>(0.375)</td>
</tr>
<tr class="even">
<td align="left">Controls</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td align="left">Sample size</td>
<td>1,008</td>
<td>1,008</td>
<td>1,008</td>
<td>1,008</td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td>0.26</td>
<td>0.26</td>
<td>0.95</td>
<td>0.95</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Sample includes individuals who tested for HIV and have demographic data.
</p>
<p>Now Thornton wisely approaches the question in two ways for the sake of the reader and for the sake of accuracy. She wants to know the effect of getting results, but the results only matter (1) for those who got their status and (2) for those who were HIV-positive. The effects shouldn’t matter if they were HIV-negative. And ultimately that is what she finds, but how is she going to answer the first? Here she examines the effect for those who got their results and who were HIV-positive using an interaction. And that’s column 1: individuals who got their HIV status and who learned they were HIV positive were 41% more likely to buy condoms several months later. This result shrinks, though, once she utilizes the <em>randomization</em> of the incentives in an instrumental variables framework, which we will discuss later in the book. The coefficient is almost cut in half and her confidence intervals are so large that we can’t be sure the effects are nonexistent.</p>
<p>But let’s say that the reason she failed to find an effect on any purchasing behavior is because the sample size is just small enough that to pick up the effect with IV is just asking too much of the data. What if we used something that had a little more information, like number of condoms bought? And that’s where things get pessimistic. Yes, Thornton does find evidence that the HIV-positive individuals were buying more condoms, but when see how many, we learn that it is only around 2 more condoms at the follow-up visit (columns 3–4). And the effect on sex itself (not shown) was negative, small (4% reduction), and not precise enough to say either way anyway.</p>
<p>In conclusion, Thornton’s study is one of those studies we regularly come across in causal inference, a mixture of positive and negative. It’s positive in that nudging people with small incentives leads them to collecting information about their own HIV status. But our enthusiasm is muted when we learn the effect on actual risk behaviors is not very large—a mere two additional condoms bought several months later for the HIV-positive individuals is likely not going to generate large positive externalities unless it falls on the highest-risk HIV-positive individuals.</p>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>
</div>
</div>
<div id="randomization-inference" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Randomization Inference<a class="anchor" aria-label="anchor" href="#randomization-inference"><i class="fas fa-link"></i></a>
</h2>
<p><span class="citation">Athey and Imbens (<a href="references.html#ref-Athey2017d" role="doc-biblioref">2017</a><a href="references.html#ref-Athey2017d" role="doc-biblioref">b</a>)</span>, in their chapter on randomized experiments, note that “in randomization-based inference, uncertainty in estimates arises naturally from the random assignment of the treatments, rather than from hypothesized sampling from a large population” (73). Athey and Imbens are part of a growing trend of economists using randomization-based methods for inferring the probability that an estimated coefficient is not simply a result of change. This growing trend uses randomization-based methods to construct exact <span class="math inline">\(p\)</span>-values that reflect the likelihood that chance could’ve produced the estimate.</p>
<p>Why has randomization inference become so population now? Why not twenty years ago or more? It’s not clear why randomization-based inference has become so popular in recent years, but a few possibilities could explain the trend. It may be the rise in the randomized controlled trials within economics, the availability of large-scale administrative databases that are not samples of some larger population but rather represent “all the data,” or it may be that computational power has improved so much that randomization inference has become trivially simple to implement when working with thousands of observations. But whatever the reason, randomization inference has become a very common way to talk about the uncertainty around one’s estimates.</p>
<p>There are at least three reasons we might conduct randomization inference. First, it may be because we aren’t working with samples, and since standard errors are often justified on the grounds that they reflect sampling uncertainty, traditional methods may not be as meaningful. The core uncertainty within a causal study is not based on sampling uncertainty, but rather on the fact that we do not know the counterfactual <span class="citation">(Abadie, Diamond, and Hainmueller <a href="references.html#ref-Abadie2010" role="doc-biblioref">2010</a>; Abadie et al. <a href="references.html#ref-Abadie2020" role="doc-biblioref">2020</a>)</span>. Second, it may be that we are uncomfortable appealing to the large sample properties of an estimator in a particular setting, such as when we are working with a small number of treatment units. In such situations, maybe assuming the number of units increases to infinity stretches credibility <span class="citation">(Buchmueller, DiNardo, and Valletta <a href="references.html#ref-Buchmueller" role="doc-biblioref">2011</a>)</span>. This can be particularly problematic in practice. <span class="citation">Young (<a href="references.html#ref-Young2019" role="doc-biblioref">2019</a>)</span> shows that in finite samples, it is common for some observations to experience concentrated leverage. Leverage causes standard errors and estimates to become volatile and can lead to overrejection. Randomization inference can be more robust to such outliers. Finally, there seems to be some aesthetic preference for these types of placebo-based inference, as many people find them intuitive. While this is not a sufficient reason to adopt a methodological procedure, it is nonetheless very common to hear someone say that they used randomization inference because it makes sense. I figured it was worth mentioning since you’ll likely run into comments like that as well. But before we dig into it, let’s discuss its history, which dates back to Ronald Fisher in the early twentieth century.</p>
<div id="lady-tasting-tea" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> Lady tasting tea<a class="anchor" aria-label="anchor" href="#lady-tasting-tea"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Fisher (<a href="references.html#ref-Fisher1935" role="doc-biblioref">1935</a>)</span> described a thought experiment in which a woman claims she can discern whether milk or tea was poured first into a cup of tea. While he does not give her name, we now know that the woman in the thought experiment was Muriel Bristol and that the thought experiment in fact did happen.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Apparently, Bristol correctly guessed all four cups of tea.&lt;/p&gt;"><sup>71</sup></a> Muriel Bristol was a PhD scientist back in the days when women rarely were able to become PhD scientists. One day during afternoon tea, Muriel claimed that she could tell whether the milk was added to the cup before or after the tea. Incredulous, Fisher hastily devised an experiment to test her self-proclaimed talent.</p>
<p>The hypothesis, properly stated, is that, given a cup of tea with milk, a woman can discern whether milk or tea was first added to the cup. To test her claim, eight cups of tea were prepared; in four the milk was added first, and in four the tea was added first. How many cups does she have to correctly identify to convince us of her uncanny ability?</p>
<p><span class="citation">Fisher (<a href="references.html#ref-Fisher1935" role="doc-biblioref">1935</a>)</span> proposed a kind of permutation-based inference—a method we now call the Fisher’s exact test. The woman possesses the ability probabilistically, not with certainty, if the likelihood of her guessing all four correctly was sufficiently low. There are <span class="math inline">\(8\times{7}\times{6}\times{5}=1,680\)</span> ways to choose a first cup, a second cup, a third cup, and a fourth cup, in order. There are <span class="math inline">\(4\times{3}\times{2}\times{1}=24\)</span> ways to order four cups. So the number of ways to choose four cups out of eight is <span class="math inline">\(\dfrac{1680}{24}=70\)</span>. Note, the woman performs the experiment by selecting four cups. The probability that she would correctly identify all four cups is <span class="math inline">\(\dfrac{1}{70}\)</span>, which is <span class="math inline">\(p=0.014\)</span>.</p>
<p>Maybe you would be more convinced of this method if you could see a simulation, though. So let’s conduct a simple combination exercise. You can with the following code.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/tea.do"><code>tea.do</code></a></em></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb25-1"><a href="ch3.html#cb25-1" aria-hidden="true"></a><span class="kw">clear</span></span>
<span id="cb25-2"><a href="ch3.html#cb25-2" aria-hidden="true"></a><span class="kw">capture</span> <span class="fu">log</span> <span class="kw">close</span></span>
<span id="cb25-3"><a href="ch3.html#cb25-3" aria-hidden="true"></a></span>
<span id="cb25-4"><a href="ch3.html#cb25-4" aria-hidden="true"></a>* Create the <span class="kw">data</span>. 4 cups with tea, 4 cups with milk.</span>
<span id="cb25-5"><a href="ch3.html#cb25-5" aria-hidden="true"></a></span>
<span id="cb25-6"><a href="ch3.html#cb25-6" aria-hidden="true"></a><span class="kw">set</span> <span class="kw">obs</span> 8</span>
<span id="cb25-7"><a href="ch3.html#cb25-7" aria-hidden="true"></a><span class="kw">gen</span> cup = <span class="dt">_n</span></span>
<span id="cb25-8"><a href="ch3.html#cb25-8" aria-hidden="true"></a></span>
<span id="cb25-9"><a href="ch3.html#cb25-9" aria-hidden="true"></a>* Assume she guesses the first cup (1), then the second cup (2), and so forth</span>
<span id="cb25-10"><a href="ch3.html#cb25-10" aria-hidden="true"></a><span class="kw">gen</span>     guess = 1 <span class="kw">in</span> 1</span>
<span id="cb25-11"><a href="ch3.html#cb25-11" aria-hidden="true"></a><span class="kw">replace</span> guess = 2 <span class="kw">in</span> 2</span>
<span id="cb25-12"><a href="ch3.html#cb25-12" aria-hidden="true"></a><span class="kw">replace</span> guess = 3 <span class="kw">in</span> 3</span>
<span id="cb25-13"><a href="ch3.html#cb25-13" aria-hidden="true"></a><span class="kw">replace</span> guess = 4 <span class="kw">in</span> 4</span>
<span id="cb25-14"><a href="ch3.html#cb25-14" aria-hidden="true"></a><span class="kw">replace</span> guess = 0 <span class="kw">in</span> 5</span>
<span id="cb25-15"><a href="ch3.html#cb25-15" aria-hidden="true"></a><span class="kw">replace</span> guess = 0 <span class="kw">in</span> 6</span>
<span id="cb25-16"><a href="ch3.html#cb25-16" aria-hidden="true"></a><span class="kw">replace</span> guess = 0 <span class="kw">in</span> 7</span>
<span id="cb25-17"><a href="ch3.html#cb25-17" aria-hidden="true"></a><span class="kw">replace</span> guess = 0 <span class="kw">in</span> 8</span>
<span id="cb25-18"><a href="ch3.html#cb25-18" aria-hidden="true"></a><span class="kw">label</span> <span class="kw">variable</span> guess <span class="st">"1: she guesses tea before milk then stops"</span></span>
<span id="cb25-19"><a href="ch3.html#cb25-19" aria-hidden="true"></a></span>
<span id="cb25-20"><a href="ch3.html#cb25-20" aria-hidden="true"></a><span class="kw">tempfile</span> correct</span>
<span id="cb25-21"><a href="ch3.html#cb25-21" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`correct'"</span>, <span class="kw">replace</span></span>
<span id="cb25-22"><a href="ch3.html#cb25-22" aria-hidden="true"></a></span>
<span id="cb25-23"><a href="ch3.html#cb25-23" aria-hidden="true"></a>* <span class="kw">ssc</span> install percom</span>
<span id="cb25-24"><a href="ch3.html#cb25-24" aria-hidden="true"></a>combin cup, <span class="kw">k</span>(4)</span>
<span id="cb25-25"><a href="ch3.html#cb25-25" aria-hidden="true"></a><span class="kw">gen</span> permutation = <span class="dt">_n</span></span>
<span id="cb25-26"><a href="ch3.html#cb25-26" aria-hidden="true"></a><span class="kw">tempfile</span> combo</span>
<span id="cb25-27"><a href="ch3.html#cb25-27" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`combo'"</span>, <span class="kw">replace</span></span>
<span id="cb25-28"><a href="ch3.html#cb25-28" aria-hidden="true"></a></span>
<span id="cb25-29"><a href="ch3.html#cb25-29" aria-hidden="true"></a><span class="kw">destring</span> cup*, <span class="kw">replace</span></span>
<span id="cb25-30"><a href="ch3.html#cb25-30" aria-hidden="true"></a><span class="kw">cross</span> <span class="kw">using</span> <span class="ot">`correct'</span></span>
<span id="cb25-31"><a href="ch3.html#cb25-31" aria-hidden="true"></a><span class="kw">sort</span> permutation cup</span>
<span id="cb25-32"><a href="ch3.html#cb25-32" aria-hidden="true"></a></span>
<span id="cb25-33"><a href="ch3.html#cb25-33" aria-hidden="true"></a><span class="kw">gen</span>     correct = 0</span>
<span id="cb25-34"><a href="ch3.html#cb25-34" aria-hidden="true"></a><span class="kw">replace</span> correct = 1 <span class="kw">if</span> cup_1 == 1 &amp; cup_2 == 2 &amp; cup_3 == 3 &amp; cup_4 == 4</span>
<span id="cb25-35"><a href="ch3.html#cb25-35" aria-hidden="true"></a></span>
<span id="cb25-36"><a href="ch3.html#cb25-36" aria-hidden="true"></a>* Calculation <span class="kw">p</span>-<span class="ot">value</span></span>
<span id="cb25-37"><a href="ch3.html#cb25-37" aria-hidden="true"></a><span class="fu">count</span> <span class="kw">if</span> correct==1</span>
<span id="cb25-38"><a href="ch3.html#cb25-38" aria-hidden="true"></a><span class="kw">local</span> correct <span class="ot">`r(N)'</span></span>
<span id="cb25-39"><a href="ch3.html#cb25-39" aria-hidden="true"></a><span class="fu">count</span></span>
<span id="cb25-40"><a href="ch3.html#cb25-40" aria-hidden="true"></a><span class="kw">local</span> <span class="kw">total</span> <span class="ot">`r(N)'</span></span>
<span id="cb25-41"><a href="ch3.html#cb25-41" aria-hidden="true"></a><span class="kw">di</span> <span class="ot">`correct'</span>/<span class="ot">`total'</span></span>
<span id="cb25-42"><a href="ch3.html#cb25-42" aria-hidden="true"></a><span class="kw">gen</span> pvalue = (<span class="ot">`correct'</span>)/(<span class="ot">`total'</span>)</span>
<span id="cb25-43"><a href="ch3.html#cb25-43" aria-hidden="true"></a>su pvalue</span>
<span id="cb25-44"><a href="ch3.html#cb25-44" aria-hidden="true"></a></span>
<span id="cb25-45"><a href="ch3.html#cb25-45" aria-hidden="true"></a>* pvalue equals 0.014</span>
<span id="cb25-46"><a href="ch3.html#cb25-46" aria-hidden="true"></a> </span>
<span id="cb25-47"><a href="ch3.html#cb25-47" aria-hidden="true"></a><span class="kw">capture</span> <span class="fu">log</span> <span class="kw">close</span></span>
<span id="cb25-48"><a href="ch3.html#cb25-48" aria-hidden="true"></a><span class="kw">exit</span></span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/tea.R"><code>tea.R</code></a></em></p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">utils</span><span class="op">)</span>

<span class="va">correct</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  cup   <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">8</span><span class="op">)</span>,
  guess <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>

<span class="va">combo</span> <span class="op">&lt;-</span> <span class="va">correct</span> <span class="op">%$%</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/combn.html">combn</a></span><span class="op">(</span><span class="va">cup</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">transmute</a></span><span class="op">(</span>
    cup_1 <span class="op">=</span> <span class="va">V1</span>, cup_2 <span class="op">=</span> <span class="va">V2</span>,
    cup_3 <span class="op">=</span> <span class="va">V3</span>, cup_4 <span class="op">=</span> <span class="va">V4</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>permutation <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">70</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">crossing</span><span class="op">(</span><span class="va">.</span>, <span class="va">correct</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">permutation</span>, <span class="va">cup</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>correct <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span><span class="va">cup_1</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">cup_2</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">&amp;</span>
                               <span class="va">cup_3</span> <span class="op">==</span> <span class="fl">3</span> <span class="op">&amp;</span> <span class="va">cup_4</span> <span class="op">==</span> <span class="fl">4</span> <span class="op">~</span> <span class="fl">1</span>,
                             <span class="cn">TRUE</span> <span class="op">~</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">combo</span><span class="op">$</span><span class="va">correct</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">combo</span><span class="op">$</span><span class="va">correct</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">combo</span><span class="op">)</span></code></pre></div>
<p>Notice, we get the same answer either way—0.014. So, let’s return to Dr. Bristol. Either she has no ability to discriminate the order in which the tea and milk were poured, and therefore chose the correct four cups by random chance, or she (like she said) has the ability to discriminate the order in which ingredients were poured into a drink. Since choosing correctly is highly unlikely (1 chance in 70), it is reasonable to believe she has the talent that she claimed all along that she had.</p>
<p>So what exactly have we done? Well, what we have done is provide an exact probability value that the observed phenomenon was merely the product of chance. You can never let the fundamental problem of causal inference get away from you: we never <em>know</em> a causal effect. We only estimate it. And then we rely on other procedures to give us reasons to believe the number we calculated is probably a causal effect. Randomization inference, like all inference, is epistemological scaffolding for a particular kind of belief—specifically, the likelihood that chance created this observed value through a particular kind of procedure.</p>
<p>But this example, while it motivated Fisher to develop this method, is not an experimental design wherein causal effects are estimated. So now I’d like to move beyond it. Here, I hope, the randomization inference procedure will become a more interesting and powerful tool for making credible causal statements.</p>
</div>
<div id="methodology-of-fishers-sharp-null" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> Methodology of Fisher’s sharp null<a class="anchor" aria-label="anchor" href="#methodology-of-fishers-sharp-null"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s discuss more of what we mean by randomization inference in a context that is easier to understand—a literal experiment or quasi-experiment. We will conclude with code that illustrates how we might implement it. The main advantage of randomization inference is that it allows us to make probability calculations revealing whether the data are likely a draw from a truly random distribution or not.</p>
<p>The methodology can’t be understood without first understanding the concept of <em>Fisher’s sharp null</em>. Fisher’s sharp null is a claim we make wherein no unit in our data, when treated, had a causal effect. While that is a subtle concept and maybe not readily clear, it will be much clearer once we work through some examples. The value of Fisher’s sharp null is that it allows us to make an “exact” inference that does not depend on hypothesized distributions (e.g., Gaussian) or large sample approximations. In this sense, it is <em>nonparametric</em>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;I simply mean that the inference does not depend on asymptotics or a type of distribution in the data-generating process.&lt;/p&gt;"><sup>72</sup></a></p>
<p>Some, when first confronted with the concept of randomization inference, think, “Oh, this sounds like bootstrapping,” but the two are in fact completely different. Bootstrapped <em>p</em>-values are random draws from the sample that are then used to conduct inference. This means that bootstrapping is primarily about uncertainty in the observations used in the sample itself. But randomization inference <span class="math inline">\(p\)</span>-values are not about uncertainty in the sample; rather, they are based on uncertainty over <em>which units</em> within a sample are assigned to the treatment itself.</p>
<p>To help you understand randomization inference, let’s break it down into a few methodological steps. You could say that there are six steps to randomization inference: (1) the choice of the sharp null, (2) the construction of the null, (3) the picking of a different treatment vector, (4) the calculation of the corresponding test statistic for that new treatment vector, (5) the randomization over step 3 as you cycle through a number of new treatment vectors (ideally all possible combinations), and (6) the calculation the exact <span class="math inline">\(p\)</span>-value.</p>
</div>
<div id="steps-to-a-p-value" class="section level3" number="4.2.3">
<h3>
<span class="header-section-number">4.2.3</span> Steps to a <span class="roman">p</span> value<a class="anchor" aria-label="anchor" href="#steps-to-a-p-value"><i class="fas fa-link"></i></a>
</h3>
<p>Fisher and Neyman debated about this first step. Fisher’s “sharp” null was the assertion that <em>every single unit</em> had a treatment effect of zero, which leads to an easy statement that the ATE is also zero. Neyman, on the other hand, started at the other direction and asserted that there was no <em>average</em> treatment effect, not that each unit had a zero treatment effect. This is an important distinction. To see this, assume that your treatment effect is a 5, but my treatment effect is <span class="math inline">\(-5\)</span>. Then the <span class="math inline">\(ATE=0\)</span> which was Neyman’s idea. But Fisher’s idea was to say that my treatment effect was zero, and your treatment effect was zero. This is what “sharp” means—it means literally that no single unit has a treatment effect. Let’s express this using potential outcomes notation, which can help clarify what I mean.
<span class="math display">\[
H_0: \delta_i = Y_i^1 - Y_i^0 = 0 \forall i
\]</span>
Now, it may not be obvious how this is going to help us, but consider this—since we know all observed values, if there is no treatment effect, <em>then</em> we also know each unit’s counterfactual. Let me illustrate my point using the example in Table <a href="ch3.html#tab:sharp1">4.6</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp1">Table 4.6: </span> Example of made-up data for 8 people with missing counterfactuals.</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="left"><span class="math inline">\(D\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="left">1</td>
<td align="center">10</td>
<td align="center">.</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="left">1</td>
<td align="center">5</td>
<td align="center">.</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="left">1</td>
<td align="center">16</td>
<td align="center">.</td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="left">1</td>
<td align="center">3</td>
<td align="center">.</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="left">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center">.</td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="left">0</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center">.</td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="left">0</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center">.</td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="left">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">.</td>
</tr>
</tbody>
</table></div>
<p>If you look closely at Table 15, you will see that for each unit, we only observe one potential outcome. But under the sharp null, we can infer the other missing counterfactual. We only have information on observed outcomes based on the switching equation. So if a unit is treated, we know its <span class="math inline">\(Y^1\)</span> but not its <span class="math inline">\(Y^0\)</span>.</p>
<p>The second step is the construction of what is called a “test statistic.” What is this? A test statistic <span class="math inline">\(t(D,Y)\)</span> is simply a known, <em>scalar</em> quantity calculated from the treatment assignments and the observed outcomes. It is often simply nothing more than a measurement of the relationship between the <span class="math inline">\(Y\)</span> values by <span class="math inline">\(D\)</span>. In the rest of this section, we will build out a variety of ways that people construct test statistics, but we will start with a fairly straightforward measurement—the simple difference in mean outcome.</p>
<p>Test statistics ultimately help us distinguish between the sharp null itself and some other hypothesis. And if you want a test statistic with high statistical power, then you need the test statistic to take on “extreme” values (i.e., large in absolute values) when the null is false, and you need for these large values to be unlikely when the null is true.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;It’s kind of interesting what precisely the engine of this method is—it’s actually not designed to pick up small treatment effects because often those small values will be swamped by the randomization process. There’s no philosophical reason to believe, though, that average treatment effects have to be relatively “large.” It’s just that randomization inference &lt;em&gt;does&lt;/em&gt; require that so as to distinguish the true effect from that of the sharp null.&lt;/p&gt;"><sup>73</sup></a></p>
<p>As we said, there are a number of ways to estimate a test statistic, and we will be discussing several of them, but let’s start with the simple difference in mean outcomes. The average values for the treatment group are <span class="math inline">\(34/4\)</span>, the average values for the control group are <span class="math inline">\(30/4\)</span>, and the difference between these two averages is <span class="math inline">\(1\)</span>. So given this <em>particular</em> treatment assignment in our sample—the true assignment, mind you—there is a corresponding test statistic (the simple difference in mean outcomes) that is equal to 1.</p>
<p>Now, what is implied by Fisher’s sharp null is one of the more interesting parts of this method. While historically we do not know each unit’s counterfactual, under the sharp null we <em>do</em> know each unit’s counterfactual. How is that possible? Because if none of the units has nonzero treatment effects, then it must be that each counterfactual is equal to its observed outcome. This means that we can fill in those missing counterfactuals <em>with the observed values</em> (Table <a href="ch3.html#tab:sharp2">4.7</a>).</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp2">Table 4.7: </span> Example of made-up data for 8 people with filled-in counterfactuals according to Fisher’s sharp null hypothesis.</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="left"><span class="math inline">\(D\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="left">1</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="left">1</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="left">1</td>
<td align="center">16</td>
<td align="center"><strong>16</strong></td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="left">1</td>
<td align="center">3</td>
<td align="center"><strong>3</strong></td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="left">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="left">0</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center"><strong>7</strong></td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="left">0</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center"><strong>8</strong></td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="left">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
</tr>
</tbody>
</table></div>
<p>With these missing counterfactuals replaced by the corresponding observed outcome, there’s no treatment effect at the unit level and therefore a zero ATE. So why did we find earlier a simple difference in mean outcomes of 1 if in fact there was no average treatment effect? Simple—it was just noise, pure and simple. It was simply a reflection of some arbitrary treatment assignment under Fisher’s sharp null, and through random chance it just so happens that this assignment generated a test statistic of <span class="math inline">\(1\)</span>.</p>
<p>So, let’s summarize. We have a particular treatment assignment and a corresponding test statistic. If we assume Fisher’s sharp null, that test statistic is simply a draw from some random process. And if that’s true, then we can shuffle the treatment assignment, calculate a new test statistic and ultimately compare this “fake” test statistic with the real one.</p>
<p>The key insight of randomization inference is that under the sharp null, the treatment assignment ultimately does not matter. It explicitly assumes as we go from one assignment to another that the counterfactuals aren’t changing—they are always just equal to the observed outcomes. So the randomization distribution is simply a set of all possible test statistics for each possible treatment assignment vector. The third and fourth steps extend this idea by <em>literally</em> shuffling the treatment assignment and calculating the unique test statistic for each assignment. And as you do this repeatedly (step 5), in the limit you will eventually cycle through all possible combinations that will yield a distribution of test statistics under the sharp null.</p>
<p>Once you have the entire distribution of test statistics, you can calculate the exact <span class="math inline">\(p\)</span>-value. How? Simple—you rank these test statistics, fit the true effect into that ranking, count the number of fake test statistics that dominate the real one, and divide that number by all possible combinations. Formally, that would be this:
<span class="math display">\[
\Pr\Big(t(D,Y)\geq t(D,Y\mid \delta=0)\Big)=
   \dfrac{\sum_{D\in \Omega} I(t(D,Y) \geq t(D,Y)}{K}
\]</span>
Again, we see what is meant by “exact.” These <span class="math inline">\(p\)</span>-values are exact, not approximations. And with a rejection threshold of <span class="math inline">\(\alpha\)</span>—for instance, 0.05—then a randomization inference test will falsely reject the sharp null less than <span class="math inline">\(100 \times \alpha\)</span> percent of the time.</p>
</div>
<div id="example" class="section level3" number="4.2.4">
<h3>
<span class="header-section-number">4.2.4</span> Example<a class="anchor" aria-label="anchor" href="#example"><i class="fas fa-link"></i></a>
</h3>
<p>I think this has been kind of abstract, and when things are abstract, it’s easy to be confused, so let’s work through an example with some new data. Imagine that you work for a homeless shelter with a cognitive behavioral therapy (CBT) program for treating mental illness and substance abuse. You have enough funding to enlist four people into the study, but you have eight residents. Therefore, there are four in treatment and four in control. After concluding the CBT, residents are interviewed to determine the severity of their mental illness symptoms. The therapist records their mental health on a scale of 0 to 20. With the following information, we can both fill in missing counterfactuals so as to satisfy Fisher’s sharp null and calculate a corresponding test statistic based on this treatment assignment. Our test statistic will be the absolute value of the simple difference in mean outcomes for simplicity. The test statistic for this particular treatment assignment is simply <span class="math inline">\(|34/4-30/4|=8.5- 7.5 = 1\)</span>, using the data in Table <a href="ch3.html#tab:sharp3">4.8</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp3">Table 4.8: </span> Self-reported mental health for 8 residents in a homeless shelter (treatment and control).</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="center"><span class="math inline">\(D_1(\$15)\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="center">1</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="center">1</td>
<td align="center">16</td>
<td align="center"><strong>16</strong></td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="center">1</td>
<td align="center">3</td>
<td align="center"><strong>3</strong></td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center"><strong>7</strong></td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="center">0</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center"><strong>8</strong></td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="center">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
</tr>
</tbody>
</table></div>
<p>Now we move to the randomization stage. Let’s shuffle the treatment assignment and calculate the new test statistic for that new treatment vector. Table <a href="ch3.html#tab:sharp4">4.9</a> shows this permutation. But first, one thing. We are going to keep the number of treatment units fixed throughout this example. But if treatment assignment had followed some random process, like the Bernoulli, then the number of treatment units would be random and the randomized treatment assignment would be larger than what we are doing here. Which is right? Neither is right in itself. Holding treatment units fixed is ultimately a reflection of whether it had been fixed in the original treatment assignment. That means that you need to know your data and the process by which units were assigned to treatment to know how to conduct the randomization inference.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp4">Table 4.9: </span> First permutation holding the number of treatment units fixed</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="center"><span class="math inline">\(\widetilde{D_2}\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="center">1</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="center">1</td>
<td align="center">16</td>
<td align="center"><strong>16</strong></td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="center">1</td>
<td align="center">3</td>
<td align="center"><strong>3</strong></td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center"><strong>7</strong></td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="center">0</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center"><strong>8</strong></td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="center">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
</tr>
</tbody>
</table></div>
<p>With this shuffling of the treatment assignment, we can calculate a new test statistic, which is <span class="math inline">\(|36/4 - 28/4|=9-7=2\)</span>. Now before we move on, look at this test statistic: that test statistic of 2 is “fake” because it is not the true treatment assignment. But under the null, the treatment assignment, was already meaningless, since there were no nonzero treatment effects anyway. The point is that even when null of no effect holds, it can and usually will yield a nonzero effect for no other reason than finite sample properties.</p>
<p>Let’s write that number 2 down and do another permutation, by which I mean, let’s shuffle the treatment assignment again. Table <a href="ch3.html#tab:sharp5">4.10</a> shows this second permutation, again holding the number of treatment units fixed at four in treatment and four in control.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp5">Table 4.10: </span> First permutation holding the number of treatment units fixed</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="center"><span class="math inline">\(\widetilde{D_2}\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="center">1</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="center">1</td>
<td align="center">16</td>
<td align="center"><strong>16</strong></td>
<td align="center">16</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="center">1</td>
<td align="center">3</td>
<td align="center"><strong>3</strong></td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center"><strong>7</strong></td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center"><strong>8</strong></td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="center">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
</tr>
</tbody>
</table></div>
<p>The test statistic associated with this treatment assignment is <span class="math inline">\(|36/4-27/4|=9-6.75=2.25\)</span>. Again, 2.25 is a draw from a random treatment assignment where each unit has no treatment effect.</p>
<p>Each time you randomize the treatment assignment, you calculate a test statistic, store that test statistic somewhere, and then go onto the next combination. You repeat this over and over until you have exhausted all possible treatment assignments. Let’s look at the first iterations of this in Table <a href="ch3.html#tab:sharp6">4.11</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:sharp6">Table 4.11: </span> The first few permutations for a randomization of treatment assignments.</caption>
<thead><tr class="header">
<th align="left">Assignment</th>
<th align="center"><span class="math inline">\(D_1\)</span></th>
<th align="center"><span class="math inline">\(D_2\)</span></th>
<th align="center"><span class="math inline">\(D_3\)</span></th>
<th align="center"><span class="math inline">\(D_4\)</span></th>
<th align="center"><span class="math inline">\(D_5\)</span></th>
<th align="center"><span class="math inline">\(D_6\)</span></th>
<th align="center"><span class="math inline">\(D_7\)</span></th>
<th align="center"><span class="math inline">\(D_8\)</span></th>
<th align="center"><span class="math inline">\(\vert T_i \vert\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">True <span class="math inline">\(D\)</span>
</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\widetilde{D_2}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\widetilde{D_3}\)</span></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">2.25</td>
</tr>
<tr class="even">
<td align="left">…</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table></div>
<p>The final step is the calculation of the exact <span class="math inline">\(p\)</span>-value. To do this, we have a couple of options. We can either use software to do it, which is a fine way to do it, or we can manually do it ourselves. And for pedagogical reasons, I am partial to doing this manually. So let’s go.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/ri.do"><code>ri.do</code></a></em></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb27-1"><a href="ch3.html#cb27-1" aria-hidden="true"></a><span class="kw">use</span> https:<span class="co">//github.com/scunning1975/mixtape/raw/master/ri.dta, clear</span></span>
<span id="cb27-2"><a href="ch3.html#cb27-2" aria-hidden="true"></a></span>
<span id="cb27-3"><a href="ch3.html#cb27-3" aria-hidden="true"></a><span class="kw">tempfile</span> ri</span>
<span id="cb27-4"><a href="ch3.html#cb27-4" aria-hidden="true"></a><span class="kw">gen</span> id = <span class="dt">_n</span></span>
<span id="cb27-5"><a href="ch3.html#cb27-5" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`ri'"</span>, <span class="kw">replace</span></span>
<span id="cb27-6"><a href="ch3.html#cb27-6" aria-hidden="true"></a></span>
<span id="cb27-7"><a href="ch3.html#cb27-7" aria-hidden="true"></a>* Create combinations</span>
<span id="cb27-8"><a href="ch3.html#cb27-8" aria-hidden="true"></a>* <span class="kw">ssc</span> install percom</span>
<span id="cb27-9"><a href="ch3.html#cb27-9" aria-hidden="true"></a>combin id, <span class="kw">k</span>(4)</span>
<span id="cb27-10"><a href="ch3.html#cb27-10" aria-hidden="true"></a><span class="kw">gen</span> permutation = <span class="dt">_n</span></span>
<span id="cb27-11"><a href="ch3.html#cb27-11" aria-hidden="true"></a><span class="kw">tempfile</span> combo</span>
<span id="cb27-12"><a href="ch3.html#cb27-12" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`combo'"</span>, <span class="kw">replace</span></span>
<span id="cb27-13"><a href="ch3.html#cb27-13" aria-hidden="true"></a></span>
<span id="cb27-14"><a href="ch3.html#cb27-14" aria-hidden="true"></a>forvalue i =1/4 {</span>
<span id="cb27-15"><a href="ch3.html#cb27-15" aria-hidden="true"></a>    <span class="kw">ren</span> id_<span class="ot">`i'</span> treated<span class="ot">`i'</span></span>
<span id="cb27-16"><a href="ch3.html#cb27-16" aria-hidden="true"></a>}</span>
<span id="cb27-17"><a href="ch3.html#cb27-17" aria-hidden="true"></a></span>
<span id="cb27-18"><a href="ch3.html#cb27-18" aria-hidden="true"></a></span>
<span id="cb27-19"><a href="ch3.html#cb27-19" aria-hidden="true"></a><span class="kw">destring</span> treated*, <span class="kw">replace</span></span>
<span id="cb27-20"><a href="ch3.html#cb27-20" aria-hidden="true"></a><span class="kw">cross</span> <span class="kw">using</span> <span class="ot">`ri'</span></span>
<span id="cb27-21"><a href="ch3.html#cb27-21" aria-hidden="true"></a><span class="kw">sort</span> permutation <span class="bn">name</span></span>
<span id="cb27-22"><a href="ch3.html#cb27-22" aria-hidden="true"></a><span class="kw">replace</span> <span class="kw">d</span> = 1 <span class="kw">if</span> id == treated1 | id == treated2 | id == treated3 | id == treated4</span>
<span id="cb27-23"><a href="ch3.html#cb27-23" aria-hidden="true"></a><span class="kw">replace</span> <span class="kw">d</span> = 0 <span class="kw">if</span> ~(id == treated1 | id == treated2 | id == treated3 | id == treated4)</span>
<span id="cb27-24"><a href="ch3.html#cb27-24" aria-hidden="true"></a></span>
<span id="cb27-25"><a href="ch3.html#cb27-25" aria-hidden="true"></a>* Calculate true effect <span class="kw">using</span> absolute <span class="ot">value</span> <span class="kw">of</span> SDO</span>
<span id="cb27-26"><a href="ch3.html#cb27-26" aria-hidden="true"></a><span class="kw">egen</span>    te1 = <span class="kw">mean</span>(<span class="fu">y</span>) <span class="kw">if</span> <span class="kw">d</span>==1, <span class="kw">by</span>(permutation)</span>
<span id="cb27-27"><a href="ch3.html#cb27-27" aria-hidden="true"></a><span class="kw">egen</span>    te0 = <span class="kw">mean</span>(<span class="fu">y</span>) <span class="kw">if</span> <span class="kw">d</span>==0, <span class="kw">by</span>(permutation)</span>
<span id="cb27-28"><a href="ch3.html#cb27-28" aria-hidden="true"></a></span>
<span id="cb27-29"><a href="ch3.html#cb27-29" aria-hidden="true"></a><span class="kw">collapse</span> (<span class="kw">mean</span>) te1 te0, <span class="kw">by</span>(permutation)</span>
<span id="cb27-30"><a href="ch3.html#cb27-30" aria-hidden="true"></a><span class="kw">gen</span>     ate = te1 - te0</span>
<span id="cb27-31"><a href="ch3.html#cb27-31" aria-hidden="true"></a><span class="kw">keep</span>    ate permutation</span>
<span id="cb27-32"><a href="ch3.html#cb27-32" aria-hidden="true"></a></span>
<span id="cb27-33"><a href="ch3.html#cb27-33" aria-hidden="true"></a><span class="kw">sort</span> ate</span>
<span id="cb27-34"><a href="ch3.html#cb27-34" aria-hidden="true"></a><span class="kw">gen</span> <span class="fu">rank</span> = <span class="dt">_n</span></span>
<span id="cb27-35"><a href="ch3.html#cb27-35" aria-hidden="true"></a>su <span class="fu">rank</span> <span class="kw">if</span> permutation==1</span>
<span id="cb27-36"><a href="ch3.html#cb27-36" aria-hidden="true"></a><span class="kw">gen</span> pvalue = (<span class="ot">`r(mean)'</span>/70)</span>
<span id="cb27-37"><a href="ch3.html#cb27-37" aria-hidden="true"></a><span class="ot">list</span> pvalue <span class="kw">if</span> permutation==1</span>
<span id="cb27-38"><a href="ch3.html#cb27-38" aria-hidden="true"></a>* pvalue equals 0.6</span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/ri.R"><code>ri.R</code></a></em></p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org">magrittr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haven.tidyverse.org">haven</a></span><span class="op">)</span>

<span class="va">read_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">{</span>
  <span class="va">full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"https://raw.github.com/scunning1975/mixtape/master/"</span>, 
                     <span class="va">df</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/read_dta.html">read_dta</a></span><span class="op">(</span><span class="va">full_path</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">ri</span> <span class="op">&lt;-</span> <span class="fu">read_data</span><span class="op">(</span><span class="st">"ri.dta"</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">8</span><span class="op">)</span><span class="op">)</span>

<span class="va">treated</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span>

<span class="va">combo</span> <span class="op">&lt;-</span> <span class="va">ri</span> <span class="op">%$%</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/combn.html">combn</a></span><span class="op">(</span><span class="va">id</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">transmute</a></span><span class="op">(</span>
    treated1 <span class="op">=</span> <span class="va">V1</span>, treated2 <span class="op">=</span> <span class="va">V2</span>,
    treated3 <span class="op">=</span> <span class="va">V3</span>, treated4 <span class="op">=</span> <span class="va">V4</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>permutation <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">70</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">crossing</span><span class="op">(</span><span class="va">.</span>, <span class="va">ri</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">permutation</span>, <span class="va">name</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>d <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span><span class="va">id</span> <span class="op">==</span> <span class="va">treated1</span> <span class="op">|</span> <span class="va">id</span> <span class="op">==</span> <span class="va">treated2</span> <span class="op">|</span>
                         <span class="va">id</span> <span class="op">==</span> <span class="va">treated3</span> <span class="op">|</span> <span class="va">id</span> <span class="op">==</span> <span class="va">treated4</span> <span class="op">~</span> <span class="fl">1</span>,
                       <span class="cn">TRUE</span> <span class="op">~</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span>

<span class="va">te1</span> <span class="op">&lt;-</span> <span class="va">combo</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">permutation</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">d</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>te1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>

<span class="va">te0</span> <span class="op">&lt;-</span> <span class="va">combo</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">permutation</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">d</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>te0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>

<span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html">inner_join</a></span><span class="op">(</span><span class="va">te1</span>, <span class="va">te0</span>, by <span class="op">=</span> <span class="st">"permutation"</span><span class="op">)</span><span class="op">)</span>

<span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html">inner_join</a></span><span class="op">(</span><span class="va">te1</span>, <span class="va">te0</span>, by <span class="op">=</span> <span class="st">"permutation"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>ate <span class="op">=</span> <span class="va">te1</span> <span class="op">-</span> <span class="va">te0</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">permutation</span>, <span class="va">ate</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">ate</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>rank <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">permutation</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">rank</span><span class="op">)</span><span class="op">/</span><span class="va">n</span></code></pre></div>
<p>This program was fairly straightforward because the number of possible combinations was so small. Out of eight observations, then four choose eight equals 70. We just had to manipulate the data to get to that point, but once we did, the actual calculation was straighforward. So we can see that the estimated ATE cannot reject the null in the placebo distribution.</p>
<p>But often the data sets we work with will be much larger than eight observations. In those situations, we cannot use this method, as the sheer volume of combination grows very fast as <span class="math inline">\(n\)</span> increases. We will hold off for now reviewing this inference method when <span class="math inline">\(n\)</span> is too large until we’ve had a chance to cover more ground.</p>
</div>
<div id="other-test-statistics" class="section level3" number="4.2.5">
<h3>
<span class="header-section-number">4.2.5</span> Other test statistics<a class="anchor" aria-label="anchor" href="#other-test-statistics"><i class="fas fa-link"></i></a>
</h3>
<p>Recall that the second step in this methodology was selection of the test statistic.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;For more in-depth discussion of the following issues, I highly recommend the excellent &lt;span class="citation"&gt;Imbens and Rubin (&lt;a href="references.html#ref-Imbens2015" role="doc-biblioref"&gt;2015&lt;/a&gt;)&lt;/span&gt;, chapter 5 in particular.&lt;/p&gt;'><sup>74</sup></a> We chose the simple difference in mean outcomes (or the absolute value of such), which is fine when effects are additive and there are few outliers in the data. But outliers create problems for that test statistic because of the variation that gets introduced in the randomization distribution. So other alternative test statistics become more attractive.</p>
<p>One transformation that handles outliers and skewness more generally is the log transformation. <span class="citation">Imbens and Rubin (<a href="references.html#ref-Imbens2015" role="doc-biblioref">2015</a>)</span> define this as the average difference on a log scale by treatment status, or
<span class="math display">\[
T_{\log} = \bigg| \dfrac{1}{N_T} \sum_{i=1}^N D_i \ln(Y_i) - \dfrac{1}{N_C} \sum_{i=1}^N (1-D_i)\ln(Y_i) \bigg |
\]</span>
This makes sense when the raw data is skewed, which happens for positive values like earnings and in instances when treatment effects are multiplicative rather than additive.</p>
<p>Another test statistic seen is the absolute value in the difference in quantiles. This also protects against outliers and is represented as
<span class="math display">\[
T_{\text{median}}=\Big|\text{median}(Y_T) - \text{median}(Y_C)\Big|
\]</span>
We could look at the median, the 25th quantile, the 75th quantile, or anything along the unit interval.</p>
<p>The issue of outliers also leads us to consider a test statistic that uses ranks rather than differences. This again is useful when there are large numbers of outliers, when outcomes are continuous or data sets are small. Rank statistics transform outcomes to ranks and then conduct analysis on the ranks themselves. The basic idea is to rank the outcomes and then compare the average rank of the treated and control groups. Let’s illustrate this with an example first (Table <a href="ch3.html#tab:rank1">4.12</a>).</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:rank1">Table 4.12: </span> Illustrating ranks using the example data.</caption>
<thead><tr class="header">
<th align="left">Name</th>
<th align="center"><span class="math inline">\(D\)</span></th>
<th align="center"><span class="math inline">\(Y\)</span></th>
<th align="center"><span class="math inline">\(Y^0\)</span></th>
<th align="center"><span class="math inline">\(Y^1\)</span></th>
<th align="center">Rank</th>
<th align="center"><span class="math inline">\(R_i\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Andy</td>
<td align="center">1</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">10</td>
<td align="center">6.5</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="left">Ben</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">5</td>
<td align="center">2.5</td>
<td align="center"><span class="math inline">\(-2\)</span></td>
</tr>
<tr class="odd">
<td align="left">Chad</td>
<td align="center">1</td>
<td align="center">16</td>
<td align="center"><strong>16</strong></td>
<td align="center">16</td>
<td align="center">8</td>
<td align="center">3.5</td>
</tr>
<tr class="even">
<td align="left">Daniel</td>
<td align="center">1</td>
<td align="center">3</td>
<td align="center"><strong>3</strong></td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(-3.5\)</span></td>
</tr>
<tr class="odd">
<td align="left">Edith</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center"><strong>5</strong></td>
<td align="center">2.5</td>
<td align="center"><span class="math inline">\(-1\)</span></td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">7</td>
<td align="center"><strong>7</strong></td>
<td align="center">4</td>
<td align="center"><span class="math inline">\(-0.5\)</span></td>
</tr>
<tr class="odd">
<td align="left">George</td>
<td align="center">0</td>
<td align="center">8</td>
<td align="center">8</td>
<td align="center"><strong>8</strong></td>
<td align="center">5</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="left">Hank</td>
<td align="center">0</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center"><strong>10</strong></td>
<td align="center">6.5</td>
<td align="center">2</td>
</tr>
</tbody>
</table></div>
<p>As before, we only observe one half of the potential outcomes given the switching equation which assigns potential outcomes to actual outcomes. But under Fisher’s sharp null, we can impute the missing counterfactual so as to ensure no treatment effect. To calculate ranks, we simply count the number of units with higher values of <span class="math inline">\(Y\)</span>, including the unit in question. And in instances of ties, we simply take the average over all tied units.</p>
<p>For instance, consider Andy. Andy has a value of <span class="math inline">\(10\)</span>. Andy is as large as himself (1); larger than Ben (2), Daniel (3), Edith (4), Frank (5), and George (6); and tied with Hank (7). Since he is tied with Hank, we average the two, which brings his rank to 6.5. Now consider Ben. Ben has a value of 5. He is as large as himself (1), larger than Daniel (2), and tied with Edith (3). Therefore, we average Edith and himself to get 0.5, bringing us to a rank of 2.</p>
<p>It is common, though, to normalize the ranks to have mean 0, which is done according to the following formula:
<span class="math display">\[
\widetilde{R_i} = \widetilde{R_i}(Y_1, \dots, Y_N) = \sum_{j=1}^N I(Y_j \leq Y_i) - \dfrac{N+1}{2}
\]</span>
This gives us the final column, which we will now use to calculate the test statistic. Let’s use the absolute value of the simple difference in mean outcomes on the normalized rank, which here is
<span class="math display">\[
T_{\text{rank}}=|0-1/4|=1/4
\]</span>
To calculate the exact <span class="math inline">\(p\)</span>-value, we would simply conduct the same randomization process as earlier, only instead of calculating the simple difference in mean outcomes, we would calculate the absolute value of the simpler difference in mean <em>rank</em>.</p>
<p>But all of these test statistics we’ve been discussing have been <em>differences</em> in the outcomes by treatment status. We considered simple differences in averages, simple differences in log averages, differences in quantiles, and differences in ranks. <span class="citation">Imbens and Rubin (<a href="references.html#ref-Imbens2015" role="doc-biblioref">2015</a>)</span> note that there are shortcomings that come from focusing solely on a few features of the data (e.g., skewness), as it can cause us to miss differences in other aspects. This specifically can be problematic if the variance in potential outcomes for the treatment group differs from that of the control group. Focusing only on the simple average differences we discussed may not generate <span class="math inline">\(p\)</span>-values that are “extreme” enough to reject the null even when the null in fact does not hold. So we may be interested in a test statistic that can detect differences in <em>distributions</em> between the treatment and control units. One such test statistic is the Kolmogorov-Smirnov test statistic.</p>
<p>Let’s first define the empirical cumulative distribution function (CDF) as:</p>
<p><span class="math display">\[\begin{align}
   \widehat{F}_C(Y) &amp; =\dfrac{1}{N_C} \sum_{i:D_i=0} 1(Y_i \leq Y)  \\
   \widehat{F}_T(Y) &amp; = \dfrac{1}{N_T} \sum_{i:D_i=1} 1(Y_i \leq Y) 
\end{align}\]</span></p>
<p>If two distributions are the same, then their empirical CDF is the same. But note, empirical CDFs are functions, and test statistics are <em>scalars</em>. So how will we take differences between two functions and turn that into a single scalar quantity? Easy—we will use the <em>maximum</em> difference between the two empirical CDFs. Visually, it will literally be the greatest vertical distance between the two empirical CDFs. That vertical distance will be our test statistic. Formally it is:</p>
<p><span class="math display">\[
T_{KS}=\max \Big|\widehat{F}_T(Y_i) - \widehat{F}_C(Y_i)\Big|
\]</span></p>
<div class="figure">
<span id="fig:unnamed-chunk-42"></span>
<img src="graphics/ks.jpg" alt="Visualization of distributions by treatment status" width="100%"><p class="caption">
Figure 4.3: Visualization of distributions by treatment status
</p>
</div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/ks.do"><code>ks.do</code></a></em></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb29-1"><a href="ch3.html#cb29-1" aria-hidden="true"></a><span class="kw">clear</span></span>
<span id="cb29-2"><a href="ch3.html#cb29-2" aria-hidden="true"></a>input  <span class="kw">d</span> <span class="fu">y</span></span>
<span id="cb29-3"><a href="ch3.html#cb29-3" aria-hidden="true"></a>0    0.22         </span>
<span id="cb29-4"><a href="ch3.html#cb29-4" aria-hidden="true"></a>0   -0.87        </span>
<span id="cb29-5"><a href="ch3.html#cb29-5" aria-hidden="true"></a>0   -2.39        </span>
<span id="cb29-6"><a href="ch3.html#cb29-6" aria-hidden="true"></a>0   -1.79        </span>
<span id="cb29-7"><a href="ch3.html#cb29-7" aria-hidden="true"></a>0    0.37         </span>
<span id="cb29-8"><a href="ch3.html#cb29-8" aria-hidden="true"></a>0   -1.54        </span>
<span id="cb29-9"><a href="ch3.html#cb29-9" aria-hidden="true"></a>0    1.28         </span>
<span id="cb29-10"><a href="ch3.html#cb29-10" aria-hidden="true"></a>0   -0.31        </span>
<span id="cb29-11"><a href="ch3.html#cb29-11" aria-hidden="true"></a>0   -0.74        </span>
<span id="cb29-12"><a href="ch3.html#cb29-12" aria-hidden="true"></a>0    1.72         </span>
<span id="cb29-13"><a href="ch3.html#cb29-13" aria-hidden="true"></a>0    0.38         </span>
<span id="cb29-14"><a href="ch3.html#cb29-14" aria-hidden="true"></a>0   -0.17        </span>
<span id="cb29-15"><a href="ch3.html#cb29-15" aria-hidden="true"></a>0   -0.62        </span>
<span id="cb29-16"><a href="ch3.html#cb29-16" aria-hidden="true"></a>0   -1.10        </span>
<span id="cb29-17"><a href="ch3.html#cb29-17" aria-hidden="true"></a>0    0.30         </span>
<span id="cb29-18"><a href="ch3.html#cb29-18" aria-hidden="true"></a>0    0.15         </span>
<span id="cb29-19"><a href="ch3.html#cb29-19" aria-hidden="true"></a>0    2.30         </span>
<span id="cb29-20"><a href="ch3.html#cb29-20" aria-hidden="true"></a>0    0.19         </span>
<span id="cb29-21"><a href="ch3.html#cb29-21" aria-hidden="true"></a>0   -0.50        </span>
<span id="cb29-22"><a href="ch3.html#cb29-22" aria-hidden="true"></a>0   -0.09        </span>
<span id="cb29-23"><a href="ch3.html#cb29-23" aria-hidden="true"></a>1   -5.13 </span>
<span id="cb29-24"><a href="ch3.html#cb29-24" aria-hidden="true"></a>1   -2.19 </span>
<span id="cb29-25"><a href="ch3.html#cb29-25" aria-hidden="true"></a>1   -2.43 </span>
<span id="cb29-26"><a href="ch3.html#cb29-26" aria-hidden="true"></a>1   -3.83 </span>
<span id="cb29-27"><a href="ch3.html#cb29-27" aria-hidden="true"></a>1    0.50 </span>
<span id="cb29-28"><a href="ch3.html#cb29-28" aria-hidden="true"></a>1   -3.25 </span>
<span id="cb29-29"><a href="ch3.html#cb29-29" aria-hidden="true"></a>1    4.32 </span>
<span id="cb29-30"><a href="ch3.html#cb29-30" aria-hidden="true"></a>1    1.63 </span>
<span id="cb29-31"><a href="ch3.html#cb29-31" aria-hidden="true"></a>1    5.18 </span>
<span id="cb29-32"><a href="ch3.html#cb29-32" aria-hidden="true"></a>1   -0.43 </span>
<span id="cb29-33"><a href="ch3.html#cb29-33" aria-hidden="true"></a>1    7.11 </span>
<span id="cb29-34"><a href="ch3.html#cb29-34" aria-hidden="true"></a>1    4.87 </span>
<span id="cb29-35"><a href="ch3.html#cb29-35" aria-hidden="true"></a>1   -3.10 </span>
<span id="cb29-36"><a href="ch3.html#cb29-36" aria-hidden="true"></a>1   -5.81 </span>
<span id="cb29-37"><a href="ch3.html#cb29-37" aria-hidden="true"></a>1    3.76 </span>
<span id="cb29-38"><a href="ch3.html#cb29-38" aria-hidden="true"></a>1    6.31 </span>
<span id="cb29-39"><a href="ch3.html#cb29-39" aria-hidden="true"></a>1    2.58 </span>
<span id="cb29-40"><a href="ch3.html#cb29-40" aria-hidden="true"></a>1    0.07 </span>
<span id="cb29-41"><a href="ch3.html#cb29-41" aria-hidden="true"></a>1    5.76 </span>
<span id="cb29-42"><a href="ch3.html#cb29-42" aria-hidden="true"></a>1    3.50</span>
<span id="cb29-43"><a href="ch3.html#cb29-43" aria-hidden="true"></a><span class="kw">end</span></span>
<span id="cb29-44"><a href="ch3.html#cb29-44" aria-hidden="true"></a></span>
<span id="cb29-45"><a href="ch3.html#cb29-45" aria-hidden="true"></a><span class="kw">twoway</span> (<span class="kw">kdensity</span> <span class="fu">y</span> <span class="kw">if</span> <span class="kw">d</span>==1) (<span class="kw">kdensity</span> <span class="fu">y</span> <span class="kw">if</span> <span class="kw">d</span>==0, lcolor(<span class="bn">blue</span>) lwidth(medium) lpattern(<span class="kw">dash</span>)), \\\</span>
<span id="cb29-46"><a href="ch3.html#cb29-46" aria-hidden="true"></a><span class="bn">title</span>(Kolmogorov-Smirnov <span class="kw">test</span>) <span class="bn">legend</span>(<span class="kw">order</span>(1 <span class="ot">``Treatment'</span>' 2 <span class="ot">``Control'</span>'))</span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/ks.R"><code>ks.R</code></a></em></p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">stats</span><span class="op">)</span>

<span class="va">tb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  d <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">20</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.22</span>, <span class="op">-</span><span class="fl">0.87</span>, <span class="op">-</span><span class="fl">2.39</span>, <span class="op">-</span><span class="fl">1.79</span>, <span class="fl">0.37</span>, <span class="op">-</span><span class="fl">1.54</span>, 
        <span class="fl">1.28</span>, <span class="op">-</span><span class="fl">0.31</span>, <span class="op">-</span><span class="fl">0.74</span>, <span class="fl">1.72</span>, 
        <span class="fl">0.38</span>, <span class="op">-</span><span class="fl">0.17</span>, <span class="op">-</span><span class="fl">0.62</span>, <span class="op">-</span><span class="fl">1.10</span>, <span class="fl">0.30</span>, 
        <span class="fl">0.15</span>, <span class="fl">2.30</span>, <span class="fl">0.19</span>, <span class="op">-</span><span class="fl">0.50</span>, <span class="op">-</span><span class="fl">0.9</span>,
        <span class="op">-</span><span class="fl">5.13</span>, <span class="op">-</span><span class="fl">2.19</span>, <span class="fl">2.43</span>, <span class="op">-</span><span class="fl">3.83</span>, <span class="fl">0.5</span>, 
        <span class="op">-</span><span class="fl">3.25</span>, <span class="fl">4.32</span>, <span class="fl">1.63</span>, <span class="fl">5.18</span>, <span class="op">-</span><span class="fl">0.43</span>, 
        <span class="fl">7.11</span>, <span class="fl">4.87</span>, <span class="op">-</span><span class="fl">3.10</span>, <span class="op">-</span><span class="fl">5.81</span>, <span class="fl">3.76</span>, 
        <span class="fl">6.31</span>, <span class="fl">2.58</span>, <span class="fl">0.07</span>, <span class="fl">5.76</span>, <span class="fl">3.50</span><span class="op">)</span>
<span class="op">)</span>

<span class="va">kdensity_d1</span> <span class="op">&lt;-</span> <span class="va">tb</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">d</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="va">kdensity_d1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">kdensity_d1</span><span class="op">)</span>

<span class="va">kdensity_d0</span> <span class="op">&lt;-</span> <span class="va">tb</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">d</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="va">kdensity_d0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">kdensity_d0</span><span class="op">)</span>

<span class="va">kdensity_d0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">kdensity_d0</span><span class="op">$</span><span class="va">x</span>, y <span class="op">=</span> <span class="va">kdensity_d0</span><span class="op">$</span><span class="va">y</span>, d <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">kdensity_d1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">kdensity_d1</span><span class="op">$</span><span class="va">x</span>, y <span class="op">=</span> <span class="va">kdensity_d1</span><span class="op">$</span><span class="va">y</span>, d <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>

<span class="va">kdensity</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html">full_join</a></span><span class="op">(</span><span class="va">kdensity_d1</span>, <span class="va">kdensity_d0</span><span class="op">)</span>
<span class="va">kdensity</span><span class="op">$</span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/as_factor.html">as_factor</a></span><span class="op">(</span><span class="va">kdensity</span><span class="op">$</span><span class="va">d</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">kdensity</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">0.3</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>, color <span class="op">=</span> <span class="va">d</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">xlim</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>, <span class="fl">8</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Kolmogorov-Smirnov Test"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_hue.html">scale_color_discrete</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Control"</span>, <span class="st">"Treatment"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>And to calculate the <em>p</em>-value, you repeat what we did in earlier examples. Specifically, drop the treatment variable, re-sort the data, reassign new (fixed) treatment values, calculate <span class="math inline">\(T_{KS}\)</span>, save the coefficient, and repeat a thousand or more times until you have a distribution that you can use to calculate an empirical <span class="math inline">\(p\)</span>-value.</p>
</div>
<div id="randomization-inference-with-large-n" class="section level3" number="4.2.6">
<h3>
<span class="header-section-number">4.2.6</span> Randomization inference with large <span class="math inline">\(n\)</span><a class="anchor" aria-label="anchor" href="#randomization-inference-with-large-n"><i class="fas fa-link"></i></a>
</h3>
<p>What did we do when the number of observations is very large? For instance, Thornton’s total sample was 2,901 participants. Of those, 2,222 received any incentive at all. Wolfram Alpha is an easy to use online calculator for more complicated calculations and easy to use interface. If you go to the website and type “2901 choose 2222” you get the following truncated number of combinations:</p>
<p>6150566109498251513699280333307718471623795043419269261826403
18266385758921095807995693142554352679783785174154933743845244
51166052365151805051778640282428979408776709284871720118822321
8885942515735991356144283120935017438277464692155849858790123
68811156301154026764620799640507224864560706516078004093411306
55445400163121511770007503391790999621671968855397259686031228
687680364730936480933074665307…</p>
<p>Good luck calculating those combinations. So clearly, exact <span class="math inline">\(p\)</span>-values using all of the combinations won’t work. So instead, we are going estimate approximate <span class="math inline">\(p\)</span>-values. To do that, we will need to randomly assign the treatment, estimate a test statistic satisfying the sharp null for that sample, repeating that thousands of times, and then calculate the <span class="math inline">\(p\)</span>-value associated with this treatment assignment based on its ranked position in the distribution.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/thornton_ri.do"><code>thornton_ri.do</code></a></em></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb31-1"><a href="ch3.html#cb31-1" aria-hidden="true"></a><span class="kw">use</span> https:<span class="co">//github.com/scunning1975/mixtape/raw/master/thornton_hiv.dta, clear</span></span>
<span id="cb31-2"><a href="ch3.html#cb31-2" aria-hidden="true"></a></span>
<span id="cb31-3"><a href="ch3.html#cb31-3" aria-hidden="true"></a><span class="kw">tempfile</span> hiv</span>
<span id="cb31-4"><a href="ch3.html#cb31-4" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`hiv'"</span>, <span class="kw">replace</span></span>
<span id="cb31-5"><a href="ch3.html#cb31-5" aria-hidden="true"></a></span>
<span id="cb31-6"><a href="ch3.html#cb31-6" aria-hidden="true"></a>* Calculate true effect <span class="kw">using</span> absolute <span class="ot">value</span> <span class="kw">of</span> SDO</span>
<span id="cb31-7"><a href="ch3.html#cb31-7" aria-hidden="true"></a><span class="kw">egen</span>    te1 = <span class="kw">mean</span>(got) <span class="kw">if</span> any==1</span>
<span id="cb31-8"><a href="ch3.html#cb31-8" aria-hidden="true"></a><span class="kw">egen</span>    te0 = <span class="kw">mean</span>(got) <span class="kw">if</span> any==0</span>
<span id="cb31-9"><a href="ch3.html#cb31-9" aria-hidden="true"></a></span>
<span id="cb31-10"><a href="ch3.html#cb31-10" aria-hidden="true"></a><span class="kw">collapse</span> (<span class="kw">mean</span>) te1 te0</span>
<span id="cb31-11"><a href="ch3.html#cb31-11" aria-hidden="true"></a><span class="kw">gen</span>     ate = te1 - te0</span>
<span id="cb31-12"><a href="ch3.html#cb31-12" aria-hidden="true"></a><span class="kw">keep</span>    ate</span>
<span id="cb31-13"><a href="ch3.html#cb31-13" aria-hidden="true"></a><span class="kw">gen</span> iteration = 1</span>
<span id="cb31-14"><a href="ch3.html#cb31-14" aria-hidden="true"></a></span>
<span id="cb31-15"><a href="ch3.html#cb31-15" aria-hidden="true"></a><span class="kw">tempfile</span> permute1</span>
<span id="cb31-16"><a href="ch3.html#cb31-16" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`permute1'"</span>, <span class="kw">replace</span></span>
<span id="cb31-17"><a href="ch3.html#cb31-17" aria-hidden="true"></a></span>
<span id="cb31-18"><a href="ch3.html#cb31-18" aria-hidden="true"></a>* Create a hundred datasets</span>
<span id="cb31-19"><a href="ch3.html#cb31-19" aria-hidden="true"></a></span>
<span id="cb31-20"><a href="ch3.html#cb31-20" aria-hidden="true"></a><span class="kw">forvalues</span> i = 2/1000 {</span>
<span id="cb31-21"><a href="ch3.html#cb31-21" aria-hidden="true"></a></span>
<span id="cb31-22"><a href="ch3.html#cb31-22" aria-hidden="true"></a><span class="kw">use</span> <span class="st">"`hiv'"</span>, <span class="kw">replace</span></span>
<span id="cb31-23"><a href="ch3.html#cb31-23" aria-hidden="true"></a></span>
<span id="cb31-24"><a href="ch3.html#cb31-24" aria-hidden="true"></a><span class="kw">drop</span> any</span>
<span id="cb31-25"><a href="ch3.html#cb31-25" aria-hidden="true"></a><span class="kw">set</span> <span class="dv">seed</span> <span class="ot">`i'</span></span>
<span id="cb31-26"><a href="ch3.html#cb31-26" aria-hidden="true"></a><span class="kw">gen</span> random_<span class="ot">`i'</span> = runiform()</span>
<span id="cb31-27"><a href="ch3.html#cb31-27" aria-hidden="true"></a><span class="kw">sort</span> random_<span class="ot">`i'</span></span>
<span id="cb31-28"><a href="ch3.html#cb31-28" aria-hidden="true"></a><span class="kw">gen</span> one=<span class="dt">_n</span></span>
<span id="cb31-29"><a href="ch3.html#cb31-29" aria-hidden="true"></a><span class="kw">drop</span> random*</span>
<span id="cb31-30"><a href="ch3.html#cb31-30" aria-hidden="true"></a><span class="kw">sort</span> one</span>
<span id="cb31-31"><a href="ch3.html#cb31-31" aria-hidden="true"></a></span>
<span id="cb31-32"><a href="ch3.html#cb31-32" aria-hidden="true"></a><span class="kw">gen</span>     any = 0</span>
<span id="cb31-33"><a href="ch3.html#cb31-33" aria-hidden="true"></a><span class="kw">replace</span> any = 1 <span class="kw">in</span> 1/2222</span>
<span id="cb31-34"><a href="ch3.html#cb31-34" aria-hidden="true"></a></span>
<span id="cb31-35"><a href="ch3.html#cb31-35" aria-hidden="true"></a>* Calculate <span class="kw">test</span> statistic <span class="kw">using</span> absolute <span class="ot">value</span> <span class="kw">of</span> SDO</span>
<span id="cb31-36"><a href="ch3.html#cb31-36" aria-hidden="true"></a><span class="kw">egen</span>    te1 = <span class="kw">mean</span>(got) <span class="kw">if</span> any==1</span>
<span id="cb31-37"><a href="ch3.html#cb31-37" aria-hidden="true"></a><span class="kw">egen</span>    te0 = <span class="kw">mean</span>(got) <span class="kw">if</span> any==0</span>
<span id="cb31-38"><a href="ch3.html#cb31-38" aria-hidden="true"></a></span>
<span id="cb31-39"><a href="ch3.html#cb31-39" aria-hidden="true"></a><span class="kw">collapse</span> (<span class="kw">mean</span>) te1 te0</span>
<span id="cb31-40"><a href="ch3.html#cb31-40" aria-hidden="true"></a><span class="kw">gen</span>     ate = te1 - te0</span>
<span id="cb31-41"><a href="ch3.html#cb31-41" aria-hidden="true"></a><span class="kw">keep</span>    ate</span>
<span id="cb31-42"><a href="ch3.html#cb31-42" aria-hidden="true"></a></span>
<span id="cb31-43"><a href="ch3.html#cb31-43" aria-hidden="true"></a><span class="kw">gen</span>     iteration = <span class="ot">`i'</span></span>
<span id="cb31-44"><a href="ch3.html#cb31-44" aria-hidden="true"></a><span class="kw">tempfile</span> permute<span class="ot">`i'</span></span>
<span id="cb31-45"><a href="ch3.html#cb31-45" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`permute`i''"</span>, <span class="kw">replace</span></span>
<span id="cb31-46"><a href="ch3.html#cb31-46" aria-hidden="true"></a></span>
<span id="cb31-47"><a href="ch3.html#cb31-47" aria-hidden="true"></a>}</span>
<span id="cb31-48"><a href="ch3.html#cb31-48" aria-hidden="true"></a></span>
<span id="cb31-49"><a href="ch3.html#cb31-49" aria-hidden="true"></a><span class="kw">use</span> <span class="st">"`permute1'"</span>, <span class="kw">replace</span></span>
<span id="cb31-50"><a href="ch3.html#cb31-50" aria-hidden="true"></a><span class="kw">forvalues</span> i = 2/1000 {</span>
<span id="cb31-51"><a href="ch3.html#cb31-51" aria-hidden="true"></a>    <span class="kw">append</span> <span class="kw">using</span> <span class="st">"`permute`i''"</span></span>
<span id="cb31-52"><a href="ch3.html#cb31-52" aria-hidden="true"></a>}</span>
<span id="cb31-53"><a href="ch3.html#cb31-53" aria-hidden="true"></a></span>
<span id="cb31-54"><a href="ch3.html#cb31-54" aria-hidden="true"></a><span class="kw">tempfile</span> final</span>
<span id="cb31-55"><a href="ch3.html#cb31-55" aria-hidden="true"></a><span class="kw">save</span> <span class="st">"`final'"</span>, <span class="kw">replace</span></span>
<span id="cb31-56"><a href="ch3.html#cb31-56" aria-hidden="true"></a></span>
<span id="cb31-57"><a href="ch3.html#cb31-57" aria-hidden="true"></a>* Calculate exact <span class="kw">p</span>-<span class="ot">value</span></span>
<span id="cb31-58"><a href="ch3.html#cb31-58" aria-hidden="true"></a><span class="kw">gsort</span> -ate</span>
<span id="cb31-59"><a href="ch3.html#cb31-59" aria-hidden="true"></a><span class="kw">gen</span> <span class="fu">rank</span> = <span class="dt">_n</span></span>
<span id="cb31-60"><a href="ch3.html#cb31-60" aria-hidden="true"></a>su <span class="fu">rank</span> <span class="kw">if</span> iteration==1</span>
<span id="cb31-61"><a href="ch3.html#cb31-61" aria-hidden="true"></a><span class="kw">gen</span> pvalue = (<span class="ot">`r(mean)'</span>/1000)</span>
<span id="cb31-62"><a href="ch3.html#cb31-62" aria-hidden="true"></a><span class="ot">list</span> <span class="kw">if</span> iteration==1</span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/thornton_ri.R"><code>thornton_ri.R</code></a></em></p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haven.tidyverse.org">haven</a></span><span class="op">)</span>

<span class="va">read_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">{</span>
  <span class="va">full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"https://raw.github.com/scunning1975/mixtape/master/"</span>, 
                     <span class="va">df</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/read_dta.html">read_dta</a></span><span class="op">(</span><span class="va">full_path</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">hiv</span> <span class="op">&lt;-</span> <span class="fu">read_data</span><span class="op">(</span><span class="st">"thornton_hiv.dta"</span><span class="op">)</span>


<span class="co"># creating the permutations</span>

<span class="va">tb</span> <span class="op">&lt;-</span> <span class="cn">NULL</span>

<span class="va">permuteHIV</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span>, <span class="va">random</span> <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">{</span>
  <span class="va">tb</span> <span class="op">&lt;-</span> <span class="va">df</span>
  <span class="va">first_half</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">ceiling</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">tb</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>
  <span class="va">second_half</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">tb</span><span class="op">)</span> <span class="op">-</span> <span class="va">first_half</span>
  
  <span class="kw">if</span><span class="op">(</span><span class="va">random</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">{</span>
    <span class="va">tb</span> <span class="op">&lt;-</span> <span class="va">tb</span> <span class="op">%&gt;%</span>
      <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample_n.html">sample_frac</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
      <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>any <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">first_half</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">second_half</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
  
  <span class="va">te1</span> <span class="op">&lt;-</span> <span class="va">tb</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">any</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">got</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span>na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
  
  <span class="va">te0</span> <span class="op">&lt;-</span> <span class="va">tb</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">any</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">got</span><span class="op">)</span> <span class="op">%&gt;%</span> 
    <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span>na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
  
  <span class="va">ate</span> <span class="op">&lt;-</span>  <span class="va">te1</span> <span class="op">-</span> <span class="va">te0</span>
  
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">ate</span><span class="op">)</span>
<span class="op">}</span>

<span class="fu">permuteHIV</span><span class="op">(</span><span class="va">hiv</span>, random <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="va">iterations</span> <span class="op">&lt;-</span> <span class="fl">1000</span>

<span class="va">permutation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  iteration <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">iterations</span><span class="op">)</span><span class="op">)</span>, 
  ate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">permuteHIV</span><span class="op">(</span><span class="va">hiv</span>, random <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>, <span class="fu">map</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">iterations</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span>, <span class="op">~</span><span class="fu">permuteHIV</span><span class="op">(</span><span class="va">hiv</span>, random <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">)</span>
<span class="op">)</span>

<span class="co">#calculating the p-value</span>

<span class="va">permutation</span> <span class="op">&lt;-</span> <span class="va">permutation</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="op">-</span><span class="va">ate</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>rank <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">iterations</span><span class="op">)</span><span class="op">)</span>

<span class="va">p_value</span> <span class="op">&lt;-</span> <span class="va">permutation</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">iteration</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">rank</span><span class="op">)</span><span class="op">/</span><span class="va">iterations</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:starrandom">Table 4.13: </span> Estimated <span class="math inline">\(p\)</span>-value using different number of trials.</caption>
<thead><tr class="header">
<th align="left">ATE</th>
<th align="center">Iteration</th>
<th align="center">Rank</th>
<th align="center"><span class="math inline">\(p\)</span></th>
<th align="center">No. trials</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">0.45</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.01</td>
<td align="center">100</td>
</tr>
<tr class="even">
<td align="left">0.45</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.002</td>
<td align="center">500</td>
</tr>
<tr class="odd">
<td align="left">0.45</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.001</td>
<td align="center">1000</td>
</tr>
</tbody>
</table></div>
<p>Quite impressive. Table <a href="ch3.html#tab:starrandom">4.13</a> shows Thornton’s experiment under Fisher’s sharp null with between 100 and 1,000 repeated draws yields highly significant <span class="math inline">\(p\)</span>-values. In fact, it is always the highest-ranked ATE in a one-tailed test.</p>
<p>So what I have done here is obtain an approximation of the <span class="math inline">\(p\)</span>-value associated with our test statistic and the sharp null hypothesis. In practice, if the number of draws is large, the <span class="math inline">\(p\)</span>-value based on this random sample will be fairly accurate <span class="citation">(Imbens and Rubin <a href="references.html#ref-Imbens2015" role="doc-biblioref">2015</a>)</span>. I wanted to illustrate this randomization method because in reality this is exactly what you will be doing most of the time since the number of combinations with any reasonably sized data set will be computationally prohibitive.</p>
<p>Now, in some ways, this randomization exercise didn’t reveal a whole lot, and that’s probably because Thornton’s original findings were just so precise to begin with (0.4 with a standard error of 0.02). We could throw atom bombs at this result and it won’t go anywhere. But the purpose here is primarily to show its robustness under different ways of generating those precious <em>p</em>-values, as well as provide you with a map for programming this yourself and for having an arguably separate intuitive way of thinking about significance itself.</p>
</div>
<div id="leverage" class="section level3" number="4.2.7">
<h3>
<span class="header-section-number">4.2.7</span> Leverage<a class="anchor" aria-label="anchor" href="#leverage"><i class="fas fa-link"></i></a>
</h3>
<p>Before we conclude, I’d like to go back to something I said earlier regarding <em>leverage</em>. A recent provocative study by <span class="citation">Young (<a href="references.html#ref-Young2019" role="doc-biblioref">2019</a>)</span> has woken us up to challenges we may face when using traditional inference for estimating the uncertainty of some point estimate, such as robust standard errors. He finds practical problems with our traditional forms of inference, which while previously known, had not been made as salient as they were made by his study. The problem that he highlights is one of concentrated leverage. Leverage is a measure of the degree to which a single observation on the right-hand-side variable takes on extreme values and is influential in estimating the slope of the regression line. A concentration of leverage in even a few observations can make coefficients and standard errors extremely volatile and even bias robust standard errors towards zero, leading to higher rejection rates.</p>
<p>To illustrate this problem, <span class="citation">Young (<a href="references.html#ref-Young2019" role="doc-biblioref">2019</a>)</span> went through a simple exercise. He collected over fifty experimental (lab and field) articles from the American Economic Association’s flagship journals: <em>American Economic Review</em>, <em>American Economic Journal: Applied</em>, and <em>American Economic Journal: Economic Policy</em>. He then reanalyzed these papers, using the authors’ models, by dropping one observation or cluster and reestimating the entire model, repeatedly. What he found was shocking:</p>
<blockquote>
<p>With the removal of just one observation, 35% of 0.01-significant reported results in the average paper can be rendered insignificant at that level. Conversely, 16% of 0.01-insignificant reported results can be found to be significant at that level. (567)</p>
</blockquote>
<p>For evidence to be so dependent on just a few observations creates some doubt about the clarity of our work, so what are our alternatives? The randomization inference method based on Fisher’s sharp null, which will be discussed in this section, can improve upon these problems of leverage, in addition to the aforementioned reasons to consider it. In the typical paper, randomization inference found individual treatment effects that were 13 to 22 percent fewer significant results than what the authors’ own analysis had discovered. Randomization inference, it appears, is somewhat more robust to the presence of leverage in a few observations.</p>
</div>
</div>
<div id="conclusion-2" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-2"><i class="fas fa-link"></i></a>
</h2>
<p>In conclusion, we have done a few things in this chapter. We’ve introduced the potential outcomes notation and used it to define various types of causal effects. We showed that the simple difference in mean outcomes was equal to the sum of the average treatment effect, or the selection bias, and the weighted heterogeneous treatment effect bias. Thus the simple difference-in-mean outcomes estimator is biased unless those second and third terms zero out. One situation in which they zero out is under <em>independence</em> of the treatment, which is when the treatment has been assigned independent of the potential outcomes. When does independence occur? The most commonly confronted situation is under physical randomization of the treatment to the units. Because physical randomization assigns the treatment for reasons that are <em>independent</em> of the potential outcomes, the selection bias zeroes out, as does the heterogeneous treatment effect bias. We now move to discuss a second situation where the two terms zero out: <em>conditional</em> independence.</p>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="ch2.html"><span class="header-section-number">3</span> Directed Acyclic Graphs</a></div>
<div class="next"><a href="ch4.html"><span class="header-section-number">5</span> Matching and Subclassification</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li>
<a class="nav-link" href="#ch3"><span class="header-section-number">4</span> Potential Outcomes Causal Model</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#statistical-inference"><span class="header-section-number">4.0.1</span> Statistical inference</a></li></ul>
</li>
<li>
<a class="nav-link" href="#physical-randomization"><span class="header-section-number">4.1</span> Physical Randomization</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#potential-outcomes"><span class="header-section-number">4.1.1</span> Potential outcomes</a></li>
<li><a class="nav-link" href="#average-treatment-effects"><span class="header-section-number">4.1.2</span> Average treatment effects</a></li>
<li><a class="nav-link" href="#simple-difference-in-means-decomposition"><span class="header-section-number">4.1.3</span> Simple difference in means decomposition</a></li>
<li><a class="nav-link" href="#independence-assumption"><span class="header-section-number">4.1.4</span> Independence assumption</a></li>
<li><a class="nav-link" href="#sutva"><span class="header-section-number">4.1.5</span> SUTVA</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#randomization-inference"><span class="header-section-number">4.2</span> Randomization Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#lady-tasting-tea"><span class="header-section-number">4.2.1</span> Lady tasting tea</a></li>
<li><a class="nav-link" href="#methodology-of-fishers-sharp-null"><span class="header-section-number">4.2.2</span> Methodology of Fisher’s sharp null</a></li>
<li><a class="nav-link" href="#steps-to-a-p-value"><span class="header-section-number">4.2.3</span> Steps to a p value</a></li>
<li><a class="nav-link" href="#example"><span class="header-section-number">4.2.4</span> Example</a></li>
<li><a class="nav-link" href="#other-test-statistics"><span class="header-section-number">4.2.5</span> Other test statistics</a></li>
<li><a class="nav-link" href="#randomization-inference-with-large-n"><span class="header-section-number">4.2.6</span> Randomization inference with large \(n\)</a></li>
<li><a class="nav-link" href="#leverage"><span class="header-section-number">4.2.7</span> Leverage</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conclusion-2"><span class="header-section-number">4.3</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/scunning1975/mixtape/blob/master/03-Potential_Outcomes.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/scunning1975/mixtape/edit/master/03-Potential_Outcomes.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><span style="font-weight:bold">Causal Inference</span></strong>: <i>The Mixtape</i>" was written by Scott Cunningham. It was last built on 2020-12-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
