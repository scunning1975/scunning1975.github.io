<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>7 Instrumental Variables | Causal Inference</title>
<meta name="author" content="Scott Cunningham">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.6/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><style>
    @import url('https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&family=Roboto:ital,wght@0,700;1,300&display=swap');
    </style>
<script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/toc.css">
<link rel="stylesheet" href="css/causal_inference_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="&lt;i&gt;The Mixtape&lt;/i&gt;"><span style="font-weight:bold">Causal Inference</span></a>:
        <small class="text-muted"><i>The Mixtape</i></small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="ch1.html"><span class="header-section-number">2</span> Probability and Regression Review</a></li>
<li><a class="" href="ch2.html"><span class="header-section-number">3</span> Directed Acyclic Graphs</a></li>
<li><a class="" href="ch3.html"><span class="header-section-number">4</span> Potential Outcomes Causal Model</a></li>
<li><a class="" href="ch4.html"><span class="header-section-number">5</span> Matching and Subclassification</a></li>
<li><a class="" href="ch5.html"><span class="header-section-number">6</span> Regression Discontinuity</a></li>
<li><a class="active" href="ch6.html"><span class="header-section-number">7</span> Instrumental Variables</a></li>
<li><a class="" href="ch7.html"><span class="header-section-number">8</span> Panel Data</a></li>
<li><a class="" href="ch8.html"><span class="header-section-number">9</span> Difference-in-Differences</a></li>
<li><a class="" href="ch9.html"><span class="header-section-number">10</span> Synthetic Control</a></li>
<li><a class="" href="ch10.html"><span class="header-section-number">11</span> Conclusion</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/scunning1975/mixtape">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ch6" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Instrumental Variables<a class="anchor" aria-label="anchor" href="#ch6"><i class="fas fa-link"></i></a>
</h1>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="../images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>
<p>Just as Archimedes said, “Give me a fulcrum, and I shall move the world,” you could just as easily say that with a good-enough instrument, you can identify any causal effect. But, while that is hyperbole, for reasons we will soon see, it is nonetheless the case that the instrumental variables (IV) design is potentially one of most important research designs ever devised. It is also unique because it is one of those instances that the econometric estimator was not simply ripped off from statistics (e.g., Eicker-Huber-White standard errors) or imported from some other field (e.g., like regression discontinuity). IV was invented by an economist, and its history is fascinating.</p>
<div id="history-of-instrumental-variables-father-and-son" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> History of Instrumental Variables: Father and Son<a class="anchor" aria-label="anchor" href="#history-of-instrumental-variables-father-and-son"><i class="fas fa-link"></i></a>
</h2>
<p>Philip Wright was born in 1861 and died in 1934. He received his bachelor’s degree from Tufts in 1884 and a master’s degree from Harvard in 1887. His son, Sewall Wright, was born in 1889 when Philip was 28. The family moved from Massachusetts to Galesburg, Illinois, where Philip took a position as professor of mathematics and economics at Lombard College. Philip published numerous articles and books in economics over his career, and he published poetry, too. You can see his vita here at <a href="https://scholar.harvard.edu/files/stock/files/wright_cv.jpg" class="uri">https://scholar.harvard.edu/files/stock/files/wright_cv.jpg</a>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Philip had a passion for poetry, and even published some in his life. He also used his school’s printing press to publish the first book of poems by the great American poet Carl Sandburg.&lt;/p&gt;"><sup>108</sup></a> Sewall attended Lombard College and took his college mathematics courses from his father.</p>
<p>In 1913, Philip took a position at Harvard, and Sewall entered there as a graduate student. Philip would later leave for the Brookings Institute, and Sewall would take his first job in the Department of Zoology at the University of Chicago, where he would eventually be promoted to professor in 1930.</p>
<p>Philip was prolific, which, given his sizable teaching and service requirements, is impressive. He published in top journals such as <em>Quarterly Journal of Economics</em>, <em>Journal of the American Statistical Association</em>, <em>Journal of Political Economy</em>, and <em>American Economic Review</em>. A common theme across many of his publications was the identification problem. He was acutely aware of it and intent on solving it.</p>
<p>In 1928, Philip was writing a book about animal and vegetable oils. The reason? He believed that recent tariff increases were harming international relations. And he wrote about the damage from the tariffs, which had affected animal and vegetable oils. The book, it turns out, would become a classic—not for tariffs or oils, but for being the first proof for the existence of an instrumental variables estimator.</p>
<p>While his father was publishing like a fiend in economics, Sewall Wright was revolutionizing the field of genetics. He invented path analysis, a precursor to Pearl’s directed acyclical graphic models, and he made important contributions to the theory of evolution and genetics. He was a genius. The decision to not follow in the family business (economics) created a bit of tension between the two men, but all evidence suggests that they found each other intellectually stimulating.</p>
<p>In his book on vegetable and oil tariffs, there is an appendix (entitled Appendix B) in which the calculus of an instrumental variables estimator was worked out. Elsewhere, Philip thanked his son for his valuable contributions to what he had written, referring to the path analysis that Sewall had taught him. This path analysis, it turned out, played a key role in Appendix B.</p>
<p>Appendix B showed a solution to the identification problem. So long as the economist is willing to impose some restrictions on the problem, then the system of equations can be identified. Specifically, if there is one instrument for supply, and the supply and demand errors are uncorrelated, then the elasticity of demand can be identified.</p>
<p>But who wrote this Appendix B? Either man could’ve done so. It is a chapter in an economics book, which points to Philip. But it used the path analysis, which points to Sewall. Historians have debated this, even going so far as to accuse Philip of stealing the idea from his son. If Philip stole the idea, by which I mean that when he published Appendix B, he failed to give proper attribution to his son, then it would at the very least have been a strange oversight. In come <span class="citation">Stock and Trebbi (<a href="references.html#ref-Stock2003" role="doc-biblioref">2003</a>)</span> to offer their opinions to this debate over authorship.</p>
<p><span class="citation">Stock and Trebbi (<a href="references.html#ref-Stock2003" role="doc-biblioref">2003</a>)</span> tried to determine the authorship of Appendix B using “stylometric analysis.” Stylometric analysis had been used in other applications, such as to identify the author of the 1996 political novel <em>Primary Colors</em> (Joseph Klein) and the unsigned <em>Federalist Papers</em>. But <span class="citation">Stock and Trebbi (<a href="references.html#ref-Stock2003" role="doc-biblioref">2003</a>)</span> is easily the best application of stylometric analysis in economics.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;But it’s easy to have the best paper on a topic in some field when you’re also the only paper on that topic in that field.&lt;/p&gt;"><sup>109</sup></a></p>
<p>The method is akin to contemporary machine learning methods. The authors collected raw data containing the known original academic writings of each man, plus the first chapter and Appendix B of the book in question. All footnotes, graphs, and figures were excluded. Blocks of 1,000 words were selected from the files. Fifty-four blocks were selected: twenty written by Sewall with certainty, twenty-five by Philip, six from Appendix B, and three from chapter 1. Chapter 1 has always been attributed to Philip, but <span class="citation">Stock and Trebbi (<a href="references.html#ref-Stock2003" role="doc-biblioref">2003</a>)</span> treat the three blocks as unknown to check whether their model is correctly predicting authorship when authorship is already known.</p>
<p>The stylometric indicators that they used included the frequency of occurrence in each block of 70 function words. The list was taken from a separate study. These 70 function words produced 70 numerical variables, each of which is a count, per 1,000 words, of an individual function word in the block. Some words were dropped (e.g., “things” because they occurred only once), leaving 69 function words.</p>
<p>The second set of stylometric indicators, taken from another study, concerned grammatical constructions. <span class="citation">Stock and Trebbi (<a href="references.html#ref-Stock2003" role="doc-biblioref">2003</a>)</span> used 18 grammatical constructions, which were frequency counts. They included things like noun followed by an adverb, total occurrences of prepositions, coordinating conjunction followed by noun, and so on. There was one dependent variable in their analysis, and that was authorship. The independent variables were 87 covariates (69 function word counts and 18 grammatical statistics).</p>
<p>The results of this analysis are absolutely fascinating. For instance, many covariates have very large <span class="math inline">\(t\)</span>-statistics, which would be unlikely if there really were no stylistic differences between the authors and the indicators were independently distributed.</p>
<p>So what do they find? Most interesting is their regression analysis. They write:</p>
<blockquote>
<p>We regressed authorship against an intercept, the first two principal components of the grammatical statistics and the first two principal components of the function word counts, and we attribute authorship depending on whether the predicted value is greater or less than 0.5. (p.191)</p>
</blockquote>
<p>And what did they find? That all of the Appendix B and chapter 1 blocks were assigned to Philip, not Sewall. They did other robustness checks, and all of them still pointed to Philip as the author.</p>
<p>Writing Appendix B and solving the problem that became Appendix B are technically distinct. But I nonetheless love this story for many reasons. First, I love the idea that an econometric estimator as important as instrumental variables has its roots in economics. I’m so accustomed to stories in which the actual econometric estimator was lifted from statistics (Huber-White standard errors) or educational psychology (regression discontinuity) that it’s nice to know economists have added their own designs to the canon. But the other part of the story that I love is the father-son component. It’s encouraging to know that a father and son can overcome differences through intellectual collaborations such as this. Such relationships are important, and tensions, when they arise, should be vigorously pursued until those tensions dissolve if possible. Relationships, and love more generally, matter after all. And Philip and Sewall give a story of that.</p>
</div>
<div id="intuition-of-instrumental-variables" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Intuition of Instrumental Variables<a class="anchor" aria-label="anchor" href="#intuition-of-instrumental-variables"><i class="fas fa-link"></i></a>
</h2>
<div id="canonical-iv-dag" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> Canonical IV DAG<a class="anchor" aria-label="anchor" href="#canonical-iv-dag"><i class="fas fa-link"></i></a>
</h3>
<p>To understand the instrumental variables estimator, it is helpful to start with a DAG that shows a chain of causal effects that contains all the information needed to understand the instrumental variables strategy. First, notice the backdoor path between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>: <span class="math inline">\(D \leftarrow U \rightarrow Y\)</span>. Furthermore, note that <span class="math inline">\(U\)</span> is unobserved by the econometrician, which causes the backdoor path to remain open. If we have this kind of <em>selection on unobservables</em>, then there does not exist a conditioning strategy that will satisfy the backdoor criterion (in our data). But, before we throw up our arms, let’s look at how <span class="math inline">\(Z\)</span> operates through these pathways.</p>
<div class="inline-figure"><img src="causal_inference_mixtape_files/figure-html/iv_dag1-1.png" width="50%" style="display: block; margin: auto;"></div>
<p>First, there is a mediated pathway from <span class="math inline">\(Z\)</span> to <span class="math inline">\(Y\)</span> via <span class="math inline">\(D\)</span>. When <span class="math inline">\(Z\)</span> varies, <span class="math inline">\(D\)</span> varies, which causes <span class="math inline">\(Y\)</span> to change. But, even though <span class="math inline">\(Y\)</span> is varying when <span class="math inline">\(Z\)</span> varies, notice that <span class="math inline">\(Y\)</span> is only varying <em>because</em> <span class="math inline">\(D\)</span> has varied. You sometimes hear people describe this as the “only through” assumption. That is, <span class="math inline">\(Z\)</span> affects <span class="math inline">\(Y\)</span> “only through” <span class="math inline">\(D\)</span>.</p>
<p>Imagine this for a moment though. Imagine <span class="math inline">\(D\)</span> consists of people making choices. Sometimes these choices affect <span class="math inline">\(Y\)</span>, and sometimes these choices are merely correlated with changes in <span class="math inline">\(Y\)</span> due to unobserved changes in <span class="math inline">\(U\)</span>. But along comes some shock, <span class="math inline">\(Z\)</span>, which induces <em>some</em> but not all of the people in <span class="math inline">\(D\)</span> to make different decisions. What will happen?</p>
<p>Well, for one, when those people’s decisions change, <span class="math inline">\(Y\)</span> will change too, because of the causal effect. But all of the correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> in that situation will reflect the causal effect. The reason is that <span class="math inline">\(D\)</span> is a collider along the backdoor path between <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>But I’m not done with this metaphor. Let’s assume that in this <span class="math inline">\(D\)</span> variable, with all these people, only some of the people change their behavior because of <span class="math inline">\(D\)</span>. What then? Well, in that situation, <span class="math inline">\(Z\)</span> is causing a change in <span class="math inline">\(Y\)</span> for just a subset of the population. If the instrument only changes the behavior of women, for instance, then the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> will only reflect the causal effect of women’s choices, not men’s choices.</p>
<p>There are two ideas inherent in the previous paragraph that I want to emphasize. First, if there are heterogeneous treatment effects (e.g., men affect <span class="math inline">\(Y\)</span> differently than women do), then our <span class="math inline">\(Z\)</span> shock only identified some of the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>. And that piece of the causal effect may only be valid for the population of women whose behavior changed in response to <span class="math inline">\(Z\)</span>; it may not be reflective of how men’s behavior would affect <span class="math inline">\(Y\)</span>. And second, if <span class="math inline">\(Z\)</span> is inducing some of the change in <span class="math inline">\(Y\)</span> via only a fraction of the change in <span class="math inline">\(D\)</span>, then it’s almost as though we have less data to identify that causal effect than we really have.</p>
<p>Here we see two of the difficulties in interpreting instrumental variables and identifying a parameter using instrumental variables. Instrumental variables only identify a causal effect for any group of units whose behaviors are changed as a result of the instrument. We call this the causal effect of the <em>complier</em> population; in our example, only women “complied” with the instrument, so we only know its effect for them. And second, instrumental variables are typically going to have larger standard errors, and as such, they will fail to reject in many instances if for no other reason than being underpowered.</p>
<p>Moving along, let’s return to the DAG. Notice that we drew the DAG such that <span class="math inline">\(Z\)</span> is independent of <span class="math inline">\(U\)</span>. You can see this because <span class="math inline">\(D\)</span> is a collider along the <span class="math inline">\(Z \rightarrow D \leftarrow U\)</span> path, which implies that <span class="math inline">\(Z\)</span> and <span class="math inline">\(U\)</span> are independent. This is called the “exclusion restriction,” which we will discuss in more detail later. But briefly, the IV estimator assumes that <span class="math inline">\(Z\)</span> is independent of the variables that determine <span class="math inline">\(Y\)</span> except for <span class="math inline">\(D\)</span>.</p>
<p>Second, <span class="math inline">\(Z\)</span> is correlated with <span class="math inline">\(D\)</span>, and because of its correlation with <span class="math inline">\(D\)</span> (and <span class="math inline">\(D\)</span>’s effect on <span class="math inline">\(Y\)</span>), <span class="math inline">\(Z\)</span> is correlated with <span class="math inline">\(Y\)</span> but only through its effect on <span class="math inline">\(D\)</span>. This relationship between <span class="math inline">\(Z\)</span> and <span class="math inline">\(D\)</span> is called the “first stage” because of the two-stage least squares estimator, which is a kind of IV estimator. The reason it is only correlated with <span class="math inline">\(Y\)</span> via <span class="math inline">\(D\)</span> is because <span class="math inline">\(D\)</span> is a collider along the path <span class="math inline">\(Z\rightarrow D \leftarrow U \rightarrow Y\)</span>.</p>
</div>
<div id="good-instruments-should-feel-weird" class="section level3" number="7.2.2">
<h3>
<span class="header-section-number">7.2.2</span> Good instruments should feel weird<a class="anchor" aria-label="anchor" href="#good-instruments-should-feel-weird"><i class="fas fa-link"></i></a>
</h3>
<p>How do you know when you have a good instrument? One, it will require prior knowledge. I’d encourage you to write down that prior knowledge into a DAG and use it to reflect on the feasibility of your design. As a starting point, you can contemplate identifying a causal effect using IV only if you can theoretically and logically defend the exclusion restriction, since the exclusion restriction is an untestable assumption. That defense requires theory, and since some people aren’t comfortable with theoretical arguments like that, they tend to eschew the use of IV. More and more applied microeconomists are skeptical of IV because they are able to tell limitless stories in which exclusion restrictions do not hold.</p>
<p>But, let’s say you think you do have a good instrument. How might you defend it as such to someone else? A necessary but not sufficient condition for having an instrument that can satisfy the exclusion restriction is if people are confused when you tell them about the instrument’s relationship to the outcome. Let me explain. No one is likely to be confused when you tell them that you think family size will reduce the labor supply of women. They don’t need a Becker model to convince them that women who have more children probably are employed outside the home less often than those with fewer children.</p>
<p>But what would they think if you told them that mothers whose first two children were the same gender were employed outside the home less than those whose two children had a balanced sex ratio? They would probably be confused because, after all, what does the gender composition of one’s first two children have to do with whether a woman works outside the home? That’s a head scratcher. They’re confused because, logically, whether the first two kids are the same gender versus not the same gender doesn’t seem on its face to change the incentives a women has to work outside the home, which is based on reservation wages and market wages. <em>And yet</em>, empirically it is true that if your first two children are a boy, many families will have a third compared to those who had a boy and a girl first. So what gives?</p>
<p>The gender composition of the first two children matters for a family if they have preferences over diversity of gender. Families where the first two children were boys are more likely to try again in the hopes they’ll have a girl. And the same for two girls. Insofar as parents would like to have at least one boy and one girl, then having two boys might cause them to roll the dice for a girl.</p>
<p>And there you see the characteristics of a good instrument. It’s weird to a lay person because a good instrument (two boys) only changes the outcome by first changing some endogenous treatment variable (family size) thus allowing us to identify the causal effect of family size on some outcome (labor supply). And so without knowledge of the endogenous variable, relationships between the instrument and the outcome don’t make much sense. Why? Because the instrument is irrelevant to the determinants of the outcome except for its effect on the endogenous treatment variable. You also see another quality of the instrument that we like, which is that it’s quasi-random.</p>
<p>Before moving along, I’d like to illustrate this “weird instrument” in one more way, using two of my favorite artists: Chance the Rapper and Kanye West. At the start of this chapter, I posted a line from Kanye West’s wonderful song “Ultralight Beam” on the underrated <em>Life of Pablo</em>. On that song, Chance the Rapper sings:</p>
<blockquote>
<p>I made “Sunday Candy,” I’m never going to hell.<br>
I met Kanye West, I’m never going to fail.</p>
</blockquote>
<p>Several years before “Ultralight Beam,” Chance made a song called “Sunday Candy.” It’s a great song and I encourage you to listen to it. But Chance makes a strange argument here on “Ultralight Beam.” He claims that <em>because</em> he made “Sunday Candy,” <em>therefore</em> he won’t go to hell. Now even a religious person will find that perplexing, as there is nothing in Christian theology of eternal damnation that would link making a song to the afterlife. This, I would argue, is a “weird instrument” because without knowing the endogenous variable on the mediated path <span class="math inline">\(SC \rightarrow ? \rightarrow H\)</span>, the two phenomena don’t seem to go together.</p>
<p>But let’s say that I told you that after Chance made “Sunday Candy,” he got a phone call from his old preacher. The preacher loved the song and invited Chance to come sing it at church. And while revisiting his childhood church, Chance had a religious experience that caused him to convert back to Christianity. Now, and only now, does his statement make sense. It isn’t that “Sunday Candy” itself shaped the path of his afterlife, so much as “Sunday Candy” caused a particular event that itself caused his beliefs about the future to change. That the line makes a weird argument is what makes “Sunday Candy” a good instrument.</p>
<p>But let’s take the second line—“I met Kanye West, I’m never going to fail.” Unlike the first line, this is likely not a good instrument. Why? Because I don’t even need to know what variable is along the mediated path <span class="math inline">\(KW \rightarrow ? \rightarrow F\)</span> to doubt the exclusion restriction. If you are a musician, a relationship with Kanye West can possibly make or break your career. Kanye could make your career by collaborating with you on a song or by introducing you to highly talented producers. There is no shortage of ways in which a relationship with Kanye West can cause you to be successful, regardless of whatever unknown endogenous variable we have placed in this mediated path. And since it’s easy to tell a story where knowing Kanye West directly causes one’s success, knowing Kanye West is likely a <em>bad instrument</em>. It simply won’t satisfy the exclusion restriction in this context.</p>
<p>Ultimately, good instruments are jarring precisely because of the exclusion restriction—these two things (gender composition and work) don’t seem to go together. If they did go together, it would likely mean that the exclusion restriction was violated. But if they don’t, then the person is confused, and that is at minimum a possible candidate for a good instrument. This is the commonsense explanation of the “only through” assumption.</p>
</div>
</div>
<div id="homogeneous-treatment-effects" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Homogeneous Treatment Effects<a class="anchor" aria-label="anchor" href="#homogeneous-treatment-effects"><i class="fas fa-link"></i></a>
</h2>
<p>There are two ways to discuss the instrumental variables design: one in a world where the treatment has the same causal effect for everybody (“homogeneous treatment effects”) and one in a world where the treatment effects can differ across the population (“heterogeneous treatment effects”). For homogeneous treatment effects, I will depend on a more traditional approach rather than on potential outcomes notation. When the treatment effect is constant, I don’t feel we need potential outcomes notation as much.</p>
<p>Instrumental variables methods are typically used to address omitted variable bias, measurement error, and simultaneity. For instance, quantity and price is determined by the intersection of supply and demand, so any observational correlation between price and quantity is uninformative about the elasticities associated with supply or demand curves. Philip Wright understood this, which was why he investigated the problem so intensely.</p>
<p>I will assume a homogeneous treatment effect of <span class="math inline">\(\delta\)</span> which is the same for every person. This means that if college caused my wages to increase by 10%, it also caused your wages to increase by 10%. Let’s start by illustrating the problem of omitted variable bias. Assume the classical labor problem where we’re interested in the causal effect of schooling on earnings, but schooling is endogenous because of unobserved ability. Let’s draw a simple DAG to illustrate this setup.</p>
<div class="inline-figure"><img src="causal_inference_mixtape_files/figure-html/iv_dag2-1.png" width="50%" style="display: block; margin: auto;"></div>
<p>We can represent this DAG with a simple regression. Let the true model of earnings be:</p>
<p><span class="math display">\[\begin{align}
   Y_i = \alpha + \delta S_i + \gamma A_i + \varepsilon_i
\end{align}\]</span></p>
<p>where <span class="math inline">\(Y\)</span> is the log of earnings, <span class="math inline">\(S\)</span> is schooling measured in years, <span class="math inline">\(A\)</span> is individual “ability,” and <span class="math inline">\(\varepsilon\)</span> is an error term uncorrelated with schooling or ability. The reason <span class="math inline">\(A\)</span> is unobserved is simply because the surveyor either forgot to collect it or couldn’t collect it and therefore it’s missing from the data set.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Unobserved ability doesn’t mean it’s literally unobserved, in other words. It could be just missing from your data set, and therefore is unobserved &lt;em&gt;to you&lt;/em&gt;.&lt;/p&gt;"><sup>110</sup></a> For instance, the CPS tells us nothing about respondents’ family background, intelligence, motivation, or non-cognitive ability. Therefore, since ability is unobserved, we have the following equation instead:</p>
<p><span class="math display">\[\begin{align}
   Y_i = \alpha + \delta S_i + \eta_i
\end{align}\]</span></p>
<p>where <span class="math inline">\(\eta_i\)</span> is a composite error term equalling <span class="math inline">\(\gamma A_i + \varepsilon_i\)</span>. We assume that schooling is correlated with ability, so therefore it is correlated with <span class="math inline">\(\eta_i\)</span>, making it endogenous in the second, shorter regression. Only <span class="math inline">\(\varepsilon_i\)</span> is uncorrelated with the regressors, and that is by definition.</p>
<p>We know from the derivation of the least squares operator that the estimated value of <span class="math inline">\(\widehat{\delta}\)</span> is:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} = \dfrac{C(Y,S)}{V(S)} = \dfrac{E[YS] - E[Y]E[S]}{V(S)}
\end{align}\]</span></p>
<p>Plugging in the true value of <span class="math inline">\(Y\)</span> (from the longer model), we get the following:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} &amp; = \dfrac{E\big[\alpha S + S^2 \delta + \gamma SA + \varepsilon S\big] - E(S)E\big[\alpha + \delta S + \gamma A + \varepsilon\big]}{V(S)} 
   \\
    &amp; = \dfrac{ \delta E(S^2) - \delta E(S)^2 + \gamma E(AS) - \gamma E(S)E(A) + E(\varepsilon S) - E(S)E(\varepsilon)}{V(S)}                  
   \\
    &amp; = \delta + \gamma \dfrac{C(AS)}{V(S)}                                                                                                    
\end{align}\]</span></p>
<p>If <span class="math inline">\(\gamma&gt;0\)</span> and <span class="math inline">\(C(A,S)&gt;0\)</span>, then <span class="math inline">\(\widehat{\delta}\)</span>, the coefficient on schooling, is upward biased. And that is probably the case given that it’s likely that ability and schooling are positively correlated.</p>
<p>But let’s assume that you have found a really great weird instrument <span class="math inline">\(Z_i\)</span> that causes people to get more schooling but that is independent of student ability and the structural error term. It is independent of ability, which means we can get around the endogeneity problem. And it’s not associated with the other unobserved determinants of earnings, which basically makes it weird. The DAG associated with this set up would look like this:</p>
<div class="inline-figure"><img src="causal_inference_mixtape_files/figure-html/iv_dag3-1.png" width="50%" style="display: block; margin: auto;"></div>
<p>We can use this variable, as I’ll now show, to estimate <span class="math inline">\(\delta\)</span>. First, calculate the covariance of <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>:</p>
<p><span class="math display">\[\begin{align}
   C(Y,Z) &amp; = C(\alpha \delta S+\gamma A+\varepsilon, Z)                                                    \\
          &amp; = E\big[(\alpha+\delta S+\gamma A+\varepsilon),Z] - E(S) E(Z)                                   
   \\
          &amp; =\big\{\alpha E(Z)- \alpha E(Z)\big\} + \delta \big\{E(SZ) - E(S)E(Z)\big\}                     \\
          &amp; \quad + \gamma \big\{E(AZ) - E(A)E(Z)\big\} + \big\{E(\varepsilon Z) - E(\varepsilon)E(Z)\big\} 
   \\
          &amp; =\delta C(S,Z) + \gamma C(A,Z) + C(\varepsilon, Z)                                              
\end{align}\]</span></p>
<p>Notice that the parameter of interest, <span class="math inline">\(\delta\)</span> is on the right side. So how do we isolate it? We can estimate it with the following:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} = \dfrac{C(Y,Z)}{C(S,Z)}
\end{align}\]</span></p>
<p>so long as <span class="math inline">\(C(A,Z)=0\)</span> and <span class="math inline">\(C(\varepsilon,Z)=0\)</span>.</p>
<p>These zero covariances are the statistical truth contained in the IV DAG from earlier. If ability is independent of <span class="math inline">\(Z\)</span>, then this second covariance is zero. And if <span class="math inline">\(Z\)</span> is independent of the structural error term, <span class="math inline">\(\varepsilon\)</span>, then it too is zero. This, you see, is what is meant by the “exclusion restriction”: the instrument must be independent of both parts of the composite error term.</p>
<p>But the exclusion restriction is only a necessary condition for IV to work; it is not a sufficient condition. After all, if all we needed was exclusion, then we could use a random number generator for an instrument. Exclusion is not enough. We also need the instrument to be <em>highly correlated</em> with the endogenous variable schooling <span class="math inline">\(S\)</span>. And the higher the better. We see that here because we are dividing by <span class="math inline">\(C(S,Z)\)</span>, so it necessarily requires that this covariance not be zero.</p>
<p>The numerator in this simple ratio is sometimes called the “reduced form,” while the denominator is called the “first stage.” These terms are somewhat confusing, particularly the former, as “reduced form” means different things to different people. But in the IV terminology, it is that relationship between the instrument and the outcome itself. The first stage is less confusing, as it gets its name from the two-stage least squares estimator, which we’ll discuss next.</p>
<p>When you take the probability limit of this expression, then assuming <span class="math inline">\(C(A,Z)=0\)</span> and <span class="math inline">\(C(\varepsilon , Z)=0\)</span> due to the exclusion restriction, you get
<span class="math display">\[
p\lim\ \widehat{\delta} = \delta
\]</span>
But if <span class="math inline">\(Z\)</span> is not independent of <span class="math inline">\(\eta\)</span> (either because it’s correlated with <span class="math inline">\(A\)</span> or <span class="math inline">\(\varepsilon\)</span>), and if the correlation between <span class="math inline">\(S\)</span> and <span class="math inline">\(Z\)</span> is weak, then <span class="math inline">\(\widehat{\delta}\)</span> becomes severely biased in finite samples.</p>
<div id="two-stage-least-squares" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Two-stage least squares<a class="anchor" aria-label="anchor" href="#two-stage-least-squares"><i class="fas fa-link"></i></a>
</h3>
<p>One of the more intuitive instrumental variables estimators is the two-stage least squares (2SLS). Let’s review an example to illustrate why it is helpful for explaining some of the IV intuition. Suppose you have a sample of data on <span class="math inline">\(Y\)</span>, <span class="math inline">\(S\)</span>, and <span class="math inline">\(Z\)</span>. For each observation <span class="math inline">\(i\)</span>, we assume the data are generated according to:</p>
<p><span class="math display">\[\begin{align}
   Y_i &amp; = \alpha + \delta S_i + \varepsilon_i 
   \\
   S_i &amp; = \gamma + \beta Z_i + \epsilon_i     
\end{align}\]</span></p>
<p>where <span class="math inline">\(C(Z,\varepsilon)=0\)</span> and <span class="math inline">\(\beta \neq 0\)</span>. The former assumption is the exclusion restriction whereas the second assumption is a non-zero first-stage. Now using our IV expression, and using the result that <span class="math inline">\(\sum_{i=1}^n(x_i -\bar{x})=0\)</span>, we can write out the IV estimator as:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} &amp; = \dfrac{C(Y,Z)}{C(S,Z)}                                                                                                                             
   \\
    &amp; = \dfrac{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})(Y_i - \overline{Y}) }{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z}) (S_i - \overline{S})} 
   \\
    &amp; =\dfrac{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})Y_i}{ \dfrac{1}{n} \sum_{i=1}^n (Z_i -\overline{Z})S_i}                                       
\end{align}\]</span></p>
<p>When we substitute the true model for <span class="math inline">\(Y\)</span>, we get the following:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} &amp; =\dfrac{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})\{\alpha + \delta S + \varepsilon \}}{\dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})S_i} \\
    &amp; =\delta + \dfrac{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})\varepsilon_i}{ \dfrac{1}{n} \sum_{i=1}^n (Z_i - \overline{Z})S_i }             
   \\
    &amp; =\delta + \text{``small if $n$ is large''}                                                                                                      
\end{align}\]</span></p>
<p>So, let’s return to our first description of <span class="math inline">\(\widehat{\delta}\)</span> as the ratio of two covariances. With some simple algebraic manipulation, we get the following:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta} &amp; =\dfrac{ C(Y,Z)}{C(S,Z)}                               \\
    &amp; =\dfrac{ \dfrac{C(Z,Y)}{V(Z)} }{\dfrac{ C(Z,S)}{V(Z)}} 
\end{align}\]</span></p>
<p>where the denominator is equal to <span class="math inline">\(\widehat{\beta}\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;That is, &lt;span class="math inline"&gt;\(S_i = \gamma + \beta Z_i + \epsilon_i\)&lt;/span&gt;.&lt;/p&gt;'><sup>111</sup></a> We can rewrite <span class="math inline">\(\widehat{\beta}\)</span> as:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\beta}     &amp; = \dfrac{ C(Z,S)}{V(Z)} 
   \\
   \widehat{\beta}V(Z) &amp; =C(Z,S)                 
\end{align}\]</span></p>
<p>Then we rewrite the IV estimator and make a substitution:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta}_{IV} &amp; =\dfrac{ C(Z,Y)}{C(Z,S)}                                 
   \\
        &amp; =\dfrac{\widehat{\beta}C(Z,Y)}{\widehat{\beta} C(Z,S)}   
   \\
        &amp; =\dfrac{ \widehat{\beta} C(Z,Y)}{\widehat{\beta}^2 V(Z)} 
   \\
        &amp; = \dfrac{C(\widehat{\beta}Z,Y)}{V(\widehat{\beta}Z)}     
\end{align}\]</span></p>
<p>Notice now what is inside the parentheses: <span class="math inline">\(\widehat{\beta}Z\)</span>, which are the fitted values of schooling from the first-stage regression. We are no longer, in other words, using <span class="math inline">\(S\)</span>—we are using its fitted values. Recall that <span class="math inline">\(S=\gamma + \beta Z + \epsilon\)</span>; <span class="math inline">\(\widehat{\delta} = \dfrac{ C(\widehat{\beta}ZY)}{V(\widehat{\beta}Z)}\)</span> and let <span class="math inline">\(\widehat{S} = \widehat{\gamma} + \widehat{\beta}Z\)</span>. Then the two-stage least squares (2SLS) estimator is:</p>
<p><span class="math display">\[\begin{align}
   \widehat{\delta}_{IV} &amp; = \dfrac{ C(\widehat{\beta}Z,Y)}{V(\widehat{\beta}Z)} 
   \\
        &amp; =\dfrac{C(\widehat{S},Y)}{V(\widehat{S})}             
\end{align}\]</span></p>
<p>I will now show that <span class="math inline">\(\widehat{\beta}C(Y,Z)=C(\widehat{S},Y)\)</span>, and leave it to you to show that <span class="math inline">\(V(\widehat{\beta}Z)=V(\widehat{S})\)</span>.</p>
<p><span class="math display">\[\begin{align}
   C(\widehat{S},Y) &amp; = E[\widehat{S}Y] - E[\widehat{S}]E[Y]                                                         
   \\
    &amp; = E\Big(Y[\widehat{\gamma}+\widehat{\beta}Z]\Big) - E(Y)E(\widehat{\gamma} + \widehat{\beta}Z) 
   \\
    &amp; =\widehat{\gamma}E(Y) + \widehat{\beta}E(YZ) - \widehat{\gamma}E(Y) - \widehat{\beta}E(Y)E(Z)  
   \\
    &amp; =\widehat{\beta}\big[E(YZ)-E(Y)E(Z)\big]                                                       
   \\
   C(\widehat{S},Y) &amp; = \widehat{\beta}C(Y,Z)                                                                        
\end{align}\]</span></p>
<p>Now let’s return to something I said earlier—learning 2SLS can help you better understand the intuition of instrumental variables more generally. What does this mean exactly? First, the 2SLS estimator used only the fitted values of the endogenous regressors for estimation. These fitted values were based on all variables used in the model, <em>including the excludable instrument</em>. And as all of these instruments are exogenous in the structural model, what this means is that the fitted values themselves have become exogenous too. Put differently, we are using only the variation in schooling that is <em>exogenous</em>. So that’s kind of interesting, as now we’re back in a world where we are identifying causal effects from exogenous changes in schooling caused by our instrument.</p>
<p>But, now the less-exciting news. This exogenous variation in <span class="math inline">\(S\)</span> driven by the instrument is only a subset of the total variation in schooling. Or put differently, IV reduces the variation in the data, so there is less information available for identification, and what little variation we have left comes from only those units who responded to the instrument in the first place. This, it turns out, will be critical later when we relax the homogeneous treatment effects assumption and allow for heterogeneity.</p>
</div>
</div>
<div id="parental-methamphetamine-abuse-and-foster-care" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Parental Methamphetamine Abuse and Foster Care<a class="anchor" aria-label="anchor" href="#parental-methamphetamine-abuse-and-foster-care"><i class="fas fa-link"></i></a>
</h2>
<p>It’s helpful to occasionally stop and try to think about real-world applications as much as possible; otherwise the estimators feel very opaque and unhelpful. So to illustrate, I’m going to review one of my own papers with Keith Finlay that sought to estimate the effect that parental methamphetamine abuse had on child abuse and foster care admissions <span class="citation">(Cunningham and Finlay <a href="references.html#ref-Cunningham2012" role="doc-biblioref">2012</a>)</span>.</p>
<p>It has been claimed that substance abuse, notably illicit drug use, has a negative impact on parenting, causing neglect, but as these all occur in equilibrium, it’s possible that the correlation is simply reflective of selection bias. Maybe households with parents who abuse drugs would’ve had the same negative outcomes had the parents not used drugs. After all, it’s not like people are flipping coins when deciding to smoke meth. So let me briefly give you some background to the study so that you better understand the data-generating process.</p>
<p>First, methamphetamine is a toxic poison to the mind and body and highly addictive. Some of the symptoms of meth abuse are increased energy and alertness, decreased appetite, intense euphoria, impaired judgment, and psychosis. Second, the meth epidemic in the United States began on the West Coast, before gradually making its way eastward over the 1990s.</p>
<p>We were interested in the impact that this growth in meth abuse was having on children. Observers and law enforcement had commented, without concrete causal evidence, that the epidemic was causing a growth in foster care admissions. But how could we separate correlation from causality? The solution was contained within how meth itself is produced.</p>
<p>Meth is synthesized from a reduction of ephedrine or pseudoephedrine, which is also the active ingredient in many cold medications, such as Sudafed. Without one of these two precursors, it is impossible to produce the kind of meth people abuse. These precursors had supply chains that could be potentially disrupted because of the concentration of pharmaceutical laboratories. In 2004, nine factories manufactured the bulk of the world’s supply of ephedrine and pseudoephedrine. The US Drug Enforcement Agency correctly noted that if it could regulate access to ephedrine and pseudoephedrine, then it could effectively interrupt the production of methamphetamine, and in turn, <em>hypothetically</em> reduce meth abuse and its associated social harms.</p>
<p>So, with input from the DEA, Congress passed the Domestic Chemical Diversion Control Act in August 1995, which provided safeguards by regulating the distribution of products that contained ephedrine as the primary medicinal ingredient. But the new legislation’s regulations applied to ephedrine, not pseudoephedrine, and since the two precursors were nearly identical, traffickers quickly substituted. By 1996, pseudoephedrine was found to be the primary precursor in almost half of meth lab seizures.</p>
<p>Therefore, the DEA went back to Congress, seeking greater control over pseudoephedrine products. And the Comprehensive Methamphetamine Control Act of 1996 went into effect between October and December 1997. This act required distributors of all forms of pseudoephedrine to be subject to chemical registration. <span class="citation">Dobkin and Nicosia (<a href="references.html#ref-Dobkin2009" role="doc-biblioref">2009</a>)</span> argued that these precursor shocks may very well have been the largest supply shocks in the history of drug enforcement.</p>
<p>We placed a Freedom of Information Act request with the DEA requesting all of their undercover purchases and seizures of illicit drugs going back decades. The data included the price of an undercover purchase, the drug’s type, its weight and its purity, as well as the locations in which the purchases occurred. We used these data to construct a price series for meth, heroin, and cocaine. The effect of the two interventions were dramatic. The first supply intervention caused retail (street) prices (adjusted for purity, weight, and inflation) to more than quadruple. The second intervention, while still quite effective at raising relative prices, did not have as large an effect as the first. See Figure <a href="ch6.html#fig:methprice1">7.1</a>.</p>
<div class="figure">
<span id="fig:methprice1"></span>
<img src="graphics/Cunningham_meth1.jpg" alt="Ratio of Median Monthly Expected Retail Prices of Meth, Heroin, and Cocaine Relative to Their Respective Values in 1995, STRIDE 1995--1999. Reprinted from @Cunningham2012." width="100%"><p class="caption">
Figure 7.1: Ratio of Median Monthly Expected Retail Prices of Meth, Heroin, and Cocaine Relative to Their Respective Values in 1995, STRIDE 1995–1999. Reprinted from <span class="citation">Cunningham and Finlay (<a href="references.html#ref-Cunningham2012" role="doc-biblioref">2012</a>)</span>.
</p>
</div>
<p>We showed two other drug prices (cocaine and heroin) in addition to meth because we wanted the reader to understand that the 1995 and 1997 shocks were uniquely impacting meth markets. They did not appear to be common shocks affecting all drug markets, in other words. As a result, we felt more confident that our analysis would be able to isolate the effect of methamphetamine, as opposed to substance abuse more generally. The two interventions simply had no effect on cocaine and heroin prices despite causing a massive shortage of meth and raising its retail price. It wouldn’t have surprised me if disrupting meth markets had caused a shift in demand for cocaine or heroin and in turn caused its prices to change, yet at first glance in the time series, I’m not finding that. Weird.</p>
<p>We are interested in the causal effect of meth abuse on child abuse, and so our first stage is necessarily a proxy for meth abuse—the number of people entering treatment who listed meth as one of the substances they used in their last episode of substance abuse. As I said before, since a picture is worth a thousand words, I’m going to show you pictures of both the first stage and the reduced form. Why do I do this instead of going directly to the tables of coefficients? Because quite frankly, you are more likely to find those estimates believable if you can see evidence for the first stage and the reduced form in the raw data itself.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;I wouldn’t go so far as to say that presenting pictures of the reduced form and first stage is mandatory in the way that many pictures in an RDD are mandatory, but it’s awfully close. Ultimately, seeing is believing.&lt;/p&gt;"><sup>112</sup></a></p>
<div class="figure">
<span id="fig:methprice3"></span>
<img src="graphics/Cunningham_meth3.jpg" alt="Visual representation of the equivalent of the first stage. Reprinted from @Cunningham2012." width="100%"><p class="caption">
Figure 7.2: Visual representation of the equivalent of the first stage. Reprinted from <span class="citation">Cunningham and Finlay (<a href="references.html#ref-Cunningham2012" role="doc-biblioref">2012</a>)</span>.
</p>
</div>
<p>In Figure <a href="ch6.html#fig:methprice3">7.2</a>, we show the first stage. All of these data come from the Treatment Episode Data Set (TEDS), which includes all people going into treatment for substance abuse at federally funded clinics. Patients list the last three substances used in the most recent “episode.” We mark anyone who listed meth, cocaine, or heroin and aggregate by month and state. But first, let’s look at the national aggregate in Figure <a href="ch6.html#fig:methprice3">7.2</a>. You can see evidence for the effect the two interventions had on meth flows, particularly the ephedrine intervention. Self-admitted meth admissions dropped significantly, as did total meth admissions, but there’s no effect on cocaine or heroin. The effect of the pseudoephedrine is not as dramatic, but it appears to cause a break in trend as the growth in meth admissions slows during this period of time. In summary, it appears we have a first stage because, during the interventions, meth admissions declines.</p>
<p>In Figure <a href="ch6.html#fig:methprice2">7.3</a>, we show the reduced form—that is, the effect of the price shocks on foster care admissions. Consistent with what we found in our first-stage graphic, the ephedrine intervention in particular had a profoundly negative effect on foster care admissions. They fell from around 8,000 children removed per month to around 6,000, then began rising again. The second intervention also had an effect, though it appears to be milder. The reason we believe that the second intervention had a more modest effect than the first is because (1) the effect on price was about half the size of the first intervention, and (2) domestic meth production was being replaced by Mexican imports of meth over the late 1990s, and the precursor regulations were not applicable in Mexico. Thus, by the end of the 1990s, domestic meth production played a smaller role in total output, and hence the effect on price and admissions was probably smaller.</p>
<div class="figure">
<span id="fig:methprice2"></span>
<img src="graphics/Cunningham_meth2.jpg" alt="Figure 4 from @Cunningham2012 showing reduced form effect of interventions on children removed from families and placed into foster care. @Cunningham2012" width="100%"><p class="caption">
Figure 7.3: Figure 4 from <span class="citation">Cunningham and Finlay (<a href="references.html#ref-Cunningham2012" role="doc-biblioref">2012</a>)</span> showing reduced form effect of interventions on children removed from families and placed into foster care. <span class="citation">Cunningham and Finlay (<a href="references.html#ref-Cunningham2012" role="doc-biblioref">2012</a>)</span>
</p>
</div>
<p>It’s worth reflecting for a moment on the reduced form. Why would rising retail prices of a pure gram of methamphetamine cause a child <em>not</em> to be placed in foster care? Prices don’t cause child abuse—they’re just nominal pieces of information in the world. The only way in which a higher price for meth could reduce foster care admissions is if parents reduced their consumption of methamphetamine, which in turn caused a reduction in harm to one’s child. This picture is a key piece of evidence for the reader that this is going on.</p>
<p>In Table <a href="ch6.html#tab:meth-table3">7.1</a>, I reproduce our main results from my article with Keith. There are a few pieces of key information that all IV tables should have. First, there is the OLS regression. As the OLS regression suffers from endogeneity, we want the reader to see it so that they have something to compare the IV model to. Let’s focus on column 1, where the dependent variable is total entry into foster care. We find no effect, interestingly, of meth on foster care when we estimate using OLS.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:meth-table3">Table 7.1: </span> Log Latest Entry into Foster Care</caption>
<thead><tr class="header">
<th></th>
<th align="center">Log Latest Entry into Foster Care</th>
<th></th>
<th align="center">Log Latest Entry into Child Neglect</th>
<th></th>
<th align="center">Log Latest Entry into Physical Abuse</th>
<th></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Covariates</strong></td>
<td align="center"><strong>OLS</strong></td>
<td><strong>2SLS</strong></td>
<td align="center"><strong>OLS</strong></td>
<td><strong>2SLS</strong></td>
<td align="center"><strong>OLS</strong></td>
<td><strong>2SLS</strong></td>
</tr>
<tr class="even">
<td>Log self-referred</td>
<td align="center">0.001</td>
<td>1.54<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.03</td>
<td>1.03<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.04</td>
<td>1.49<span class="math inline">\(^{**}\)</span>
</td>
</tr>
<tr class="odd">
<td>Meth treatment rate</td>
<td align="center">(0.02)</td>
<td>(0.59)</td>
<td align="center">(0.02)</td>
<td>(0.41)</td>
<td align="center">(0.03)</td>
<td>(0.62)</td>
</tr>
<tr class="even">
<td>Month-of-year fixed effects</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>State controls</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>State fixed effects</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>State linear time trends</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
<td align="center">Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><strong>First Stage Instrument</strong></td>
<td align="center"></td>
<td></td>
<td align="center"></td>
<td></td>
<td align="center"></td>
<td></td>
</tr>
<tr class="odd">
<td>Price deviation instrument</td>
<td align="center"></td>
<td><span class="math inline">\(-0.0005^{***}\)</span></td>
<td align="center"></td>
<td><span class="math inline">\(-0.0005^{***}\)</span></td>
<td align="center"></td>
<td><span class="math inline">\(-0.0005^{**}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td>(0.0001)</td>
<td align="center"></td>
<td>(0.0001)</td>
<td align="center"></td>
<td>(0.0001)</td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(F\)</span>-statistic for IV in first stage</td>
<td align="center"></td>
<td>17.60</td>
<td align="center"></td>
<td>17.60</td>
<td align="center"></td>
<td>17.60</td>
</tr>
<tr class="even">
<td><span class="math inline">\(N\)</span></td>
<td align="center">1,343</td>
<td>1,343</td>
<td align="center"></td>
<td>1,343</td>
<td align="center"></td>
<td>1,343</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
<em>Notes:</em> Log latest entry into foster care is the natural log of the sum of all new foster care admissions by state, race, and month. Models 3 to 10 denote the flow of children into foster care via a given route of admission denoted by the column heading. Models 11 and 12 use the natural log of the sum of all foster care exits by state, race and month. <span class="math inline">\(^{***}\)</span>, <span class="math inline">\(^{**}\)</span>, and <span class="math inline">\(^{*}\)</span> denote statistical significance at the 1%, 5%, and 10% levels, respectively.
</p>
<p>The second piece of information that one should report in a 2SLS table is the first stage itself. We report the first stage at the bottom of each even-numbered column. As you can see, for each one-unit deviation in price from its long-term trend, meth admissions into treatment (our proxy) fell by <span class="math inline">\(-0.0005\)</span> log points. This is highly significant at the 1% level, but we check for the strength of the instrument using the <span class="math inline">\(F\)</span> statistic <span class="citation">(Staiger and Stock <a href="references.html#ref-Staiger1997" role="doc-biblioref">1997</a>)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;I explain the importance of the &lt;span class="math inline"&gt;\(F\)&lt;/span&gt; statistic later in this chapter, but ordinarily an &lt;span class="math inline"&gt;\(F\)&lt;/span&gt; test on the excludability of the instrument from the first stage is calculated to check for the instrument’s strength.&lt;/p&gt;'><sup>113</sup></a> We have an <span class="math inline">\(F\)</span> statistic of 17.6, which suggests that our instrument is strong enough for identification.</p>
<p>Finally, let’s examine the 2SLS estimate of the treatment effect itself. Notice using only the exogenous variation in log meth admissions, and assuming the exclusion restriction holds in our model, we are able to isolate a causal effect of log meth admissions on log aggregate foster care admissions. As this is a log-log regression, we can interpret the coefficient as an elasticity. We find that a 10% increase in meth admissions for treatment appears to cause around a 15% increase in children being removed from their homes and placed into foster care. This effect is both large and precise. And it was not detectable otherwise (the coefficient was zero).</p>
<p>Why are they being removed? Our data (AFCARS) lists several channels: parental incarceration, child neglect, parental drug use, and physical abuse. Interestingly, we do not find any effect of parental drug use or parental incarceration, which is perhaps counterintuitive. Their signs are negative and their standard errors are large. Rather, we find effects of meth admissions on removals for physical abuse and neglect. Both are elastic (i.e., <span class="math inline">\(\delta &gt;1\)</span>).</p>
<p>What did we learn? First, we learned how a contemporary piece of applied microeconomics goes about using instrumental variables to identify causal effects. We saw the kinds of graphical evidence mustered, the way in which knowledge about the natural experiment and the policies involved helped the authors argue for the exclusion restriction (since it cannot be tested), and the kind of evidence presented from 2SLS, including the first-stage tests for weak instruments. Hopefully seeing a paper at this point was helpful. But the second thing we learned concerned the actual study itself. We learned that for the group of meth users whose behavior was changed as a result of rising real prices of a pure gram of methamphetamine (i.e., the complier subpopulation), their meth use was causing child abuse and neglect so severe that it merited removing their children and placing those children into foster care. If you were only familiar with <span class="citation">Dobkin and Nicosia (<a href="references.html#ref-Dobkin2009" role="doc-biblioref">2009</a>)</span>, who found no effect of meth on crime using county-level data from California and only the 1997 ephedrine shock, you might incorrectly conclude that there are no social costs associated with meth abuse. But, while meth does not appear to cause crime in California, it does appear to harm the children of meth users and places strains on the foster care system.</p>
</div>
<div id="the-problem-of-weak-instruments" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> The Problem of Weak Instruments<a class="anchor" aria-label="anchor" href="#the-problem-of-weak-instruments"><i class="fas fa-link"></i></a>
</h2>
<p>I am not trying to smother you with papers. But before we move back into the technical material itself, I’d like to discuss one more paper. This paper will also help you better understand the weak instrument literature following its publication.</p>
<p>As we’ve said since the beginning, with example after example, there is a very long tradition in labor economics of building models that can credibly identify the returns to schooling. This goes back to <span class="citation">Becker (<a href="references.html#ref-Becker1994" role="doc-biblioref">1994</a>)</span> and the workshop at Columbia that Becker ran for years with Jacob Mincer. This study of the returns to schooling has been an important task given education’s growing importance in the distribution of income and wealth since the latter twentieth century with increasing returns to skill in the marketplace <span class="citation">(Juhn, Murphy, and Pierce <a href="references.html#ref-Juhn1993" role="doc-biblioref">1993</a>)</span>.</p>
<p>One of the more seminal papers in instrumental variables for the modern period is <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span>. Their idea is simple and clever; a quirk in the United States educational system is that a child enters a grade on the basis of his or her birthday. For a long time, that cutoff was late December. If children were born on or before December 31, then they were assigned to the first grade. But if their birthday was on or after January 1, they were assigned to kindergarten. Thus two people—one born on December 31 and one born on January 1—were exogenously assigned different grades.</p>
<p>Now there’s nothing necessarily relevant here because if those children always stay in school for the duration necessary to get a high school degree, then that arbitrary assignment of start date won’t affect high school completion. It’ll only affect <em>when</em> they get that high school degree. But this is where it gets interesting. For most of the twentieth century, the US had compulsory schooling laws that forced a person to remain in high school until age 16. After age 16, one could legally stop going to school. Figure <a href="ch6.html#fig:qob1">7.4</a> explains visually this instrumental variable.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Angrist and Krueger always made such helpful and effective graphics for their studies, and this paper is a great example.&lt;/p&gt;"><sup>114</sup></a></p>
<div class="figure" style="text-align: center">
<span id="fig:qob1"></span>
<img src="causal_inference_mixtape_files/figure-html/qob1-1.png" alt="Compulsory schooling start dates by birthdates." width="100%"><p class="caption">
Figure 7.4: Compulsory schooling start dates by birthdates.
</p>
</div>
<p>Angrist and Krueger had the insight that that small quirk was exogenously assigning more schooling to people born later in the year. The person born in December would reach age 16 with more education than the person born in January, in other words. Thus, the authors uncovered small exogenous variation in schooling. Notice how similar their idea was to regression discontinuity. That’s because IV and RDD are conceptually very similar strategies.</p>
<div class="figure">
<span id="fig:qob2"></span>
<img src="graphics/qob_2.jpg" alt="First stage relationship between quarter of birth and schooling. Reprinted from @Angrist1991." width="100%"><p class="caption">
Figure 7.5: First stage relationship between quarter of birth and schooling. Reprinted from <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span>.
</p>
</div>
<p>Figure 49 shows the first stage, and it is really interesting. Look at all those 3s and 4s at the top of the picture. There’s a clear pattern—those with birthdays in the third and fourth quarter have more schooling on average than do those with birthdays in the first and second quarters. That relationship gets weaker as we move into later cohorts, but that is probably because for later cohorts, the price on higher levels of schooling was rising so much that fewer and fewer people were dropping out before finishing their high school degree.</p>
<div class="figure">
<span id="fig:qob3"></span>
<img src="graphics/qob_3.jpg" alt="Reduced form visualization of the relationship between quarter of birth and log weekly earnings. Reprinted from @Angrist1991." width="100%"><p class="caption">
Figure 7.6: Reduced form visualization of the relationship between quarter of birth and log weekly earnings. Reprinted from <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span>.
</p>
</div>
<p>Figure <a href="ch6.html#fig:qob3">7.6</a> shows the reduced-form relationship between quarter of birth and log weekly earnings.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;I know, I know. No one has ever accused me of being subtle. But it’s an important point—a picture is worth a thousand words. If you can communicate your first stage and reduced form in pictures, you always should, as it will really captivate the reader’s attention and be far more compelling than a simple table of coefficients ever could.&lt;/p&gt;"><sup>115</sup></a> You have to squint a little bit, but you can see the pattern—all along the top of the jagged path are 3s and 4s, and all along the bottom of the jagged path are 1s and 2s. Not always, but it’s correlated.</p>
<p>Remember what I said about how instruments having a certain ridiculousness to them? That is, you know you have a good instrument if the instrument itself doesn’t seem relevant for explaining the outcome of interest because <em>that’s what the exclusion restriction implies</em>. Why would quarter of birth affect earnings? It doesn’t make any obvious, logical sense why it should. But, if I told you that people born later in the year got more schooling than those with less <em>because of compulsory schooling</em>, then the relationship between the instrument and the outcome snaps into place. The only reason we can think of as to why the instrument would affect earnings is if the instrument were operating through schooling. Instruments only explain the outcome, in other words, when you understand their effect on the endogenous variable.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Having said that, &lt;span class="citation"&gt;Buckles and Hungerman (&lt;a href="references.html#ref-Buckles2013" role="doc-biblioref"&gt;2013&lt;/a&gt;)&lt;/span&gt; found that in fact there are systematic differences in individual attributes that are predictors of ability by birth quarter!&lt;/p&gt;'><sup>116</sup></a></p>
<p>Angrist and Krueger use three dummies as their instruments: a dummy for first quarter, a dummy for second quarter, and a dummy for third quarter. Thus, the omitted category is the fourth quarter, which is the group that gets the most schooling. Now ask yourself this: if we regressed years of schooling onto those three dummies, what should the signs and magnitudes be? That is, what would we expect the relationship between the first quarter (compared to the fourth quarter) and schooling? Let’s look at their first-stage results (Table <a href="ch6.html#tab:angrist-qob1">7.2</a>).</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:angrist-qob1">Table 7.2: </span> Quarter of birth and schooling</caption>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center"><strong>Quarter of Birth Effect</strong></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><strong>Outcome variable</strong></td>
<td><strong>Birth Cohort</strong></td>
<td align="center"><strong>I</strong></td>
<td><strong>II</strong></td>
<td><strong>III</strong></td>
</tr>
<tr class="odd">
<td>Total schooling</td>
<td>1930-1939</td>
<td align="center">-0.124</td>
<td>-0.86</td>
<td>-0.015</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.017)</td>
<td>(0.017)</td>
<td>(0.016)</td>
</tr>
<tr class="odd">
<td></td>
<td>1940–1949</td>
<td align="center"><span class="math inline">\(-0.085\)</span></td>
<td><span class="math inline">\(-0.035\)</span></td>
<td><span class="math inline">\(-0.017\)</span></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.012)</td>
<td>(0.012)</td>
<td>(0.011)</td>
</tr>
<tr class="odd">
<td>High school grad</td>
<td>1930-1939</td>
<td align="center"><span class="math inline">\(-0.019\)</span></td>
<td><span class="math inline">\(-0.020\)</span></td>
<td><span class="math inline">\(-0.004\)</span></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.002)</td>
<td>(0.002)</td>
<td>(0.002)</td>
</tr>
<tr class="odd">
<td></td>
<td>1940–1949</td>
<td align="center"><span class="math inline">\(-0.015\)</span></td>
<td><span class="math inline">\(-0.012\)</span></td>
<td><span class="math inline">\(-0.002\)</span></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.001)</td>
<td>(0.001)</td>
<td>(0.001)</td>
</tr>
<tr class="odd">
<td>College grad</td>
<td>1930-1939</td>
<td align="center"><span class="math inline">\(-0.005\)</span></td>
<td>0.003</td>
<td>0.002</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.002)</td>
<td>(0.002)</td>
<td>(0.002)</td>
</tr>
<tr class="odd">
<td></td>
<td>1940–1949</td>
<td align="center"><span class="math inline">\(-0.003\)</span></td>
<td>0.004</td>
<td>0.000</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">(0.002)</td>
<td>(0.002)</td>
<td>(0.002)</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis.
</p>
<p>Table <a href="ch6.html#tab:angrist-qob1">7.2</a> shows the first stage from a regression of the following form:
<span class="math display">\[
S_i=X\pi_{10}+Z_1\pi_{11}+Z_2\pi_{12}+Z_3\pi_{13}+\eta_1
\]</span>
where <span class="math inline">\(Z_i\)</span> is the dummy for the first three quarters, and <span class="math inline">\(\pi_i\)</span> is the coefficient on each dummy. Now we look at what they produced in Table <a href="ch6.html#tab:angrist-qob1">7.2</a>. The coefficients are all <em>negative</em> and significant for the total years of education and the high school graduate dependent variables. Notice, too, that the relationship gets much weaker once we move beyond the groups bound by compulsory schooling: the number of years of schooling for high school students (no effect) and probability of being a college graduate (no effect).</p>
<p>Regarding those college non-results. Ask yourself this question: why should we expect quarter of birth to affect the probability of being a high school graduate but not a college grad? What if we had found quarter of birth predicted high school completion, college completion, post-graduate completion, and total years of schooling beyond high school? Wouldn’t it start to seem like this compulsory schooling instrument was not what we thought it was? After all, this quarter of birth instrument really should only impact <em>high school</em> completion; since it doesn’t bind anyone beyond high school, it shouldn’t affect the number of years beyond high school or college completion probabilities. If it did, we might be skeptical of the whole design. But here it didn’t, which to me makes it even more convincing that they’re identifying a compulsory high school schooling effect.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These kinds of falsifications are extremely common in contemporary applied work. This is because many of the identifying assumptions in any research design are simply untestable. And so the burden of proof is on researchers to convince the reader, oftentimes with intuitive and transparent falsification tests.&lt;/p&gt;"><sup>117</sup></a></p>
<p>Now we look at the second stage for both OLS and 2SLS (which the authors label TSLS, but means the same thing). Table <a href="ch6.html#tab:angrist-qob2">7.3</a> shows these results. The authors didn’t report the first stage in this table because they reported it in the earlier table we just reviewed. For small values, the log approximates a percentage change, so they are finding a 7.1% return for every additional year of schooling, but with 2SLS it’s higher (8.9%). That’s interesting, because if it was merely ability bias, then we’d expect the OLS estimate to be <em>too large</em>, not too small. So something other than mere ability bias must be going on here.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:angrist-qob2">Table 7.3: </span> Effect of schooling on wages using OLS and 2SLS</caption>
<thead><tr class="header">
<th align="left"><strong>Independent variable</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="center"><strong>2SLS</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Years of schooling</td>
<td align="center">0.0711</td>
<td align="center">0.0891</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.0003)</td>
<td align="center">(0.0161)</td>
</tr>
<tr class="odd">
<td align="left">9 Year-of-birth rummies</td>
<td align="center">Yes</td>
<td align="center">Yes</td>
</tr>
<tr class="even">
<td align="left">8 Region-of-residence dummies</td>
<td align="center">No</td>
<td align="center">No</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis. First stage is quarter of birth dummies.
</p>
<p>For whatever it’s worth, I am personally convinced at this point that quarter of birth is a valid instrument and that they’ve identified a causal effect of schooling on earnings, but <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span> want to go further, probably because they want more precision in their estimate. And to get more precision, they load up the first stage with even more instruments. Specifically, they use specifications with 30 dummies (quarter of birth <span class="math inline">\(\times\)</span> year) and 150 dummies (quarter of birth <span class="math inline">\(\times\)</span> state) as instruments. The idea is that the quarter of birth effect may differ by state and cohort.</p>
<p>But at what cost? Many of these instruments are only now weakly correlated with schooling—in some locations, they have almost no correlation, and for some cohorts as well. We got a flavor of that, in fact, in Table <a href="ch6.html#tab:angrist-qob2">7.3</a>, where the later cohorts show less variation in schooling by quarter of birth than the earlier cohorts. What is the effect, then, of reducing the variance in the estimator by loading up the first stage with a bunch of noise?</p>
<p><span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> is a classic work in what is sometimes called the “weak instrument” literature. It’s in this paper that we learn some some very basic problems created by weak instruments, such as the form of 2SLS bias in finite samples. Since <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> focused on the compulsory schooling application that <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span> had done, I will stick with that example throughout. Let’s consider their model with a single endogenous regressor and a simple constant treatment effect. The causal model of interest here is as before:
<span class="math display">\[
y=\beta s + \varepsilon
\]</span>
where <span class="math inline">\(y\)</span> is some outcome and <span class="math inline">\(s\)</span> is some endogenous regressor, such as schooling. Our instrument is <span class="math inline">\(Z\)</span> and the first-stage equation is:
<span class="math display">\[
s=Z' \pi + \eta
\]</span>
Let’s start off by assuming that <span class="math inline">\(\varepsilon\)</span> and <span class="math inline">\(\eta\)</span> are correlated. Then estimating the first equation by OLS would lead to biased results, wherein the OLS bias is:
<span class="math display">\[
E\big[\widehat{\beta}_{OLS}-\beta\big] =
   \dfrac{C(\varepsilon, s)}{V(s)}
\]</span>
We will rename this ratio as <span class="math inline">\(\dfrac{\sigma_{\varepsilon \eta}}{\sigma^2_s}\)</span>. <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> show that the bias of 2SLS centers on the previously defined OLS bias as the weakness of the instrument grows. Following <span class="citation">Angrist and Pischke (<a href="references.html#ref-Angrist2009" role="doc-biblioref">2009</a>)</span>, I’ll express that bias as a function of the first-stage <span class="math inline">\(F\)</span> statistic:
<span class="math display">\[
E\big[\widehat{\beta}_{2SLS}-\beta\big] \approx \dfrac{\sigma_{\varepsilon \eta}}{\sigma_\eta^2} \dfrac{1}{F+1}
\]</span>
where <span class="math inline">\(F\)</span> is the population analogy of the <span class="math inline">\(F\)</span>-statistic for the joint significance of the instruments in the first-stage regression. If the first stage is weak, and <span class="math inline">\(F\rightarrow 0\)</span>, then the bias of 2SLS approaches <span class="math inline">\(\dfrac{\sigma_{\varepsilon \eta}}{\sigma_\eta^2}\)</span>. But if the first stage is very strong, <span class="math inline">\(F \rightarrow \infty\)</span>, then the 2SLS bias goes to 0.</p>
<p>Returning to our rhetorical question from earlier, what was the cost of adding instruments without predictive power? Adding more weak instruments causes the first-stage <span class="math inline">\(F\)</span> statistic to approach zero and increase the bias of 2SLS.</p>
<p><span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> studied this empirically, replicating <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist1991" role="doc-biblioref">1991</a>)</span>, and using simulations. Table <a href="ch6.html#tab:bound-table1">7.4</a> shows what happens once they start adding in controls. Notice that as they do, the <span class="math inline">\(F\)</span> statistic on the excludability of the instruments falls from 13.5 to 4.7 to 1.6. So by the <span class="math inline">\(F\)</span> statistic, they are already running into a weak instrument once they include the 30 quarter of birth <span class="math inline">\(\times\)</span> year dummies, and I think that’s because as we saw, the relationship between quarter of birth and schooling got smaller for the later cohorts.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:bound-table1">Table 7.4: </span> Effect of completed schooling on men’s log weekly wages</caption>
<thead><tr class="header">
<th align="left"><strong>Independent variable</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="left"><strong>2SLS</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="left"><strong>2SLS</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="left"><strong>2SLS</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Years of schooling</td>
<td align="center">0.063</td>
<td align="left">0.142</td>
<td align="center">0.063</td>
<td align="left">0.081</td>
<td align="center">0.063</td>
<td align="left">0.060</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.000)</td>
<td align="left">(0.033)</td>
<td align="center">(0.000)</td>
<td align="left">(0.016)</td>
<td align="center">(0.000)</td>
<td align="left">(0.029)</td>
</tr>
<tr class="odd">
<td align="left">First stage <span class="math inline">\(F\)</span>
</td>
<td align="center"></td>
<td align="left">13.5</td>
<td align="center"></td>
<td align="left">4.8</td>
<td align="center"></td>
<td align="left">1.6</td>
</tr>
<tr class="even">
<td align="left"><em>Excluded instruments</em></td>
<td align="center"></td>
<td align="left"></td>
<td align="center"></td>
<td align="left"></td>
<td align="center"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Quarter of birth</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
</tr>
<tr class="even">
<td align="left">Quarter of birth <span class="math inline">\(\times\)</span> year of birth</td>
<td align="center"></td>
<td align="left">No</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">Number of excluded instruments</td>
<td align="center"></td>
<td align="left">3</td>
<td align="center"></td>
<td align="left">30</td>
<td align="center"></td>
<td align="left">28</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis. First stage is quarter of birth dummies.
</p>
<p>Next, they added in the weak instruments—all 180 of them—which is shown in Table <a href="ch6.html#tab:bound-table2">7.5</a>. And here we see that the problem persists. The instruments are weak, and therefore the bias of the 2SLS coefficient is close to that of the OLS bias.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:bound-table2">Table 7.5: </span> Effect of completed schooling on men’s log weekly wages controlling for state of birth</caption>
<thead><tr class="header">
<th align="left"><strong>Independent variable</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="left"><strong>2SLS</strong></th>
<th align="center"><strong>OLS</strong></th>
<th align="left"><strong>2SLS</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Years of schooling</td>
<td align="center">0.063</td>
<td align="left">0.083</td>
<td align="center">0.063</td>
<td align="left">0.081</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.000)</td>
<td align="left">(0.009)</td>
<td align="center">(0.000)</td>
<td align="left">(0.011)</td>
</tr>
<tr class="odd">
<td align="left">First stage <span class="math inline">\(F\)</span>
</td>
<td align="center"></td>
<td align="left">2.4</td>
<td align="center"></td>
<td align="left">1.9</td>
</tr>
<tr class="even">
<td align="left"><em>Excluded instruments</em></td>
<td align="center"></td>
<td align="left"></td>
<td align="center"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Quarter of birth</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
</tr>
<tr class="even">
<td align="left">Quarter of birth <span class="math inline">\(\times\)</span> year of birth</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">Quarter of birth <span class="math inline">\(\times\)</span> state of birth</td>
<td align="center"></td>
<td align="left">Yes</td>
<td align="center"></td>
<td align="left">Yes</td>
</tr>
<tr class="even">
<td align="left">Number of excluded instruments</td>
<td align="center"></td>
<td align="left">180</td>
<td align="center"></td>
<td align="left">178</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis.
</p>
<p>But the really damning part of the <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> was their simulation. The authors write:</p>
<blockquote>
<p>To illustrate that second-stage results do not give us any indication of the existence of quantitatively important finite-sample biases, we reestimated Table 1, columns (4) and (6) and Table 2, columns (2) and (4), using randomly generated information in place of the actual quarter of birth, following a suggestion by Alan Krueger. The means of the estimated standard errors reporting in the last row are quite close to the actual standard deviations of the 500 estimates for each model. . . . It is striking that the second-stage results reported in Table 3 look quite reasonable even with no information about educational attainment in the simulated instruments. They give no indication that the instruments were randomly generated<span class="math inline">\(\ldots\)</span> On the other hand, the F statistics on the excluded instruments in the first-stage regressions are always near their expected value of essentially 1 and do give a clear indication that the estimates of the second-stage coefficients suffer from finite-sample biases. <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span> (p.448)</p>
</blockquote>
<p>So, what can you do if you have weak instruments? Unfortunately, not a lot. You can use a just-identified model with your strongest IV. Second, you can use a limited-information maximum likelihood estimator (LIML). This is approximately median unbiased for over identified constant effects models. It provides the same asymptotic distribution as 2SLS under homogeneous treatment effects but provides a finite-sample bias reduction.</p>
<p>But, let’s be real for a second. If you have a weak instrument problem, then you only get so far by using LIML or estimating a just-identified model. The real solution for a weak instrument problem is to <em>get better instruments</em>. Under homogeneous treatment effects, you’re always identifying the same effect, so there’s no worry about a complier only parameter. So you should just continue searching for stronger instruments that simultaneously satisfy the exclusion restriction.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Good luck with that. Seriously, good luck because—and I’m going out on a limb here—if you had a better instrument, you’d be using it!&lt;/p&gt;"><sup>118</sup></a></p>
<p>In conclusion, I think we’ve learned a lot about instrumental variables and why they are so powerful. The estimators based on this design are capable of identifying causal effects when your data suffer from selection on unobservables. Since selection on unobservables is believed to be very common, this is a very useful methodology for addressing that. But, that said, we also have learned some of the design’s weaknesses, and hence why some people eschew it. Let’s now move to heterogeneous treatment effects so that we can better understand some limitations a bit better.</p>
</div>
<div id="heterogeneous-treatment-effects" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> Heterogeneous Treatment Effects<a class="anchor" aria-label="anchor" href="#heterogeneous-treatment-effects"><i class="fas fa-link"></i></a>
</h2>
<p>Now we turn to a scenario where we relax the assumption that treatment effects are the same for every unit. This is where the potential outcomes notation comes in handy. Instead, we will allow for each unit to have a unique response to the treatment, or
<span class="math display">\[
Y_i^1 - Y_i^0 = \delta_i
\]</span>
Note that the treatment effect parameter now differs by individual <span class="math inline">\(i\)</span>. We call this heterogeneous treatment effects.</p>
<p>The main questions we have now are: (1) what is IV estimating when we have heterogeneous treatment effects, and (2) under what assumptions will IV identify a causal effect with heterogeneous treatment effects? The reason this matters is that once we introduce heterogeneous treatment effects, we introduce a distinction between the internal validity of a study and its external validity. Internal validity means our strategy identified a causal effect <em>for the population we studied</em>. But external validity means the study’s finding applied to <em>different</em> populations (not in the study). The deal is that under homogeneous treatment effects, there is no tension between external and internal validity because everyone has the same treatment effect. But under heterogeneous treatment effects, there is huge tension; the tension is so great, in fact, that it may even undermine the meaningfulness of the relevance of the estimated causal effect despite an otherwise valid IV design!<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;My hunch is economists’ priors assume heterogeneous treatment effects are the rule and constant treatment effects are the exception, but that many others have the opposite priors. It’s actually not obvious to me there is a reason to have any particular priors, but economists’ training tends to start with heterogeneity.&lt;/p&gt;"><sup>119</sup></a></p>
<p>Heterogeneous treatment effects are built on top of the potential outcomes notation, with a few modifications. Since now we have two arguments—<span class="math inline">\(D\)</span> and <span class="math inline">\(Z\)</span>—we have to modify the notation slightly. We say that <span class="math inline">\(Y\)</span> is a function of <span class="math inline">\(D\)</span> and <span class="math inline">\(Z\)</span> as <span class="math inline">\(Y_i(D_i=0,Z_i=1)\)</span>, which is represented as <span class="math inline">\(Y_i(0,1)\)</span>.</p>
<p>Potential <em>outcomes</em> as we have been using the term refers to the <span class="math inline">\(Y\)</span> variable, but now we have a new potential variable—potential <em>treatment</em> status (as opposed to observed treatment status). Here are the characteristics:</p>
<p><span class="math display">\[\begin{align}
   D_i^1 &amp; =i\text{'s treatment status when }Z_i=1 
   \\
   D_i^0 &amp; =i\text{'s treatment status when }Z_i=0 
\end{align}\]</span></p>
<p>And observed treatment status is based on a treatment status switching equations:</p>
<p><span class="math display">\[\begin{align}
   D_i &amp;=&amp;D_i^0 + (D_i^1 - D_i^0)Z_i \\
   &amp;=&amp;\pi_0 + \pi_1 Z_i + \phi_i
\end{align}\]</span></p>
<p>where <span class="math inline">\(\pi_{0i}=E[D_i^0]\)</span>, <span class="math inline">\(\pi_{1i} = (D_i^1 - D_i^0)\)</span> is the heterogeneous causal effect of the IV on <span class="math inline">\(D_i\)</span>, and <span class="math inline">\(E[\pi_{1i}]=\)</span> the average causal effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(D_i\)</span>.</p>
<p>There are considerably more assumptions necessary for identification once we introduce heterogeneous treatment effects—specifically five assumptions. We now review each of them. And to be concrete, I use repeatedly as an example the effect of military service on earnings using a draft lottery as the instrumental variable <span class="citation">(Angrist <a href="references.html#ref-Angrist1990" role="doc-biblioref">1990</a>)</span>. In that paper, Angrist estimated the returns to military service using as an instrument the person’s draft lottery number. The draft lottery number was generated by a random number generator and if a person’s number was in a particular range, they were drafted, otherwise they weren’t.</p>
<p>First, as before, there is a stable unit treatment value assumption (SUTVA) that states that the potential outcomes for each person <span class="math inline">\(i\)</span> are unrelated to the treatment status of other individuals. The assumption states that if <span class="math inline">\(Z_i=Z_i'\)</span>, then <span class="math inline">\(D_i(Z) = D_i(Z')\)</span>. And if <span class="math inline">\(Z_i=Z_i'\)</span> and <span class="math inline">\(D_i=D_i'\)</span>, then <span class="math inline">\(Y_i(D,Z)=Y_i(D',Z')\)</span>. A violation of SUTVA would be if the status of a person at risk of being drafted was affected by the draft status of others at risk of being drafted. Such spillovers violate SUTVA.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Probably no other identifying assumption is given shorter shrift than SUTVA. Rarely is it mentioned in applied studies, let alone taken seriously.&lt;/p&gt;"><sup>120</sup></a> Not knowing a lot about how that works, I can’t say whether Angrist’s draft study would’ve violated SUTVA. But it seems like he’s safe to me.</p>
<p>Second, there is the independence assumption. The independence assumption is also sometimes called the “as good as random assignment” assumption. It states that the IV is independent of the potential outcomes and potential treatment assignments. Notationally, it is
<span class="math display">\[
\Big\{Y_i(D_i^1,1), Y_i(D_i^0,0),D_i^1,D_i^0\Big\} \perp \!\!\! \perp Z_i
\]</span>
The independence assumption is sufficient for a causal interpretation of the reduced form:</p>
<p><span class="math display">\[\begin{align}
   E\big[Y_i\mid Z_i=1\big]-E\big[Y_i\mid Z_i=0\big] &amp; = E\big[Y_i(D_i^1,1)\mid Z_i=1\mid]- 
   E\big[Y_i(D_i^0,0)\mid Z_i=0\big]
   \\
                                    &amp; = E[Y_i(D_i^1,1)] - E[Y_i(D_i^0,0)]  
\end{align}\]</span></p>
<p>And many people may actually prefer to work just with the instrument and its reduced form because they find independence satisfying and acceptable. The problem, though, is technically the instrument is not the program you’re interested in studying. And there may be many mechanisms leading from the instrument to the outcome that you need to think about (as we will see below). Ultimately, independence is nothing more and nothing less than assuming that the instrument itself is random.</p>
<p>Independence means that the first stage measures the causal effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(D_i\)</span>:</p>
<p><span class="math display">\[\begin{align}
   E\big[D_i\mid Z_i=1\big]-E\big[D_i\mid Z_i=0\big] &amp; = E\big[D_i^1\mid Z_i=1\big] - E\big[D_i^0\mid Z_i=0\big] 
   \\
                                    &amp; = E[D_i^1 - D_i^0]                                        
\end{align}\]</span></p>
<p>An example of this is if Vietnam conscription for military service was based on randomly generated draft lottery numbers. The assignment of draft lottery number was independent of potential earnings or potential military service because it was “as good as random.”</p>
<p>Third, there is the exclusion restriction. The exclusion restriction states that any effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span> must be via the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(D\)</span>. In other words, <span class="math inline">\(Y_i(D_i,Z_i)\)</span> is a function of <span class="math inline">\(D_i\)</span> only. Or formally:
<span class="math display">\[
Y_i(D_i,0) = Y_i(D_i,1)\quad \text{for $D=0,1$}
\]</span>
Again, our Vietnam example. In the Vietnam draft lottery, an individual’s earnings potential as a veteran or a non-veteran are assumed to be the same regardless of draft eligibility status. The exclusion restriction would be violated if low lottery numbers affected schooling by people avoiding the draft. If this was the case, then the lottery number would be correlated with earnings for at least two cases. One, through the instrument’s effect on military service. And two, through the instrument’s effect on schooling. The implication of the exclusion restriction is that a random lottery number (independence) does not therefore imply that the exclusion restriction is satisfied. These are different assumptions.</p>
<p>Fourth is the first stage. IV designs require that <span class="math inline">\(Z\)</span> be correlated with the endogenous variable such that
<span class="math display">\[
E[D_i^1 - D_i^0] \ne 0
\]</span>
<span class="math inline">\(Z\)</span> has to have some statistically significant effect on the average probability of treatment. An example would be having a low lottery number. Does it increase the average probability of military service? If so, then it satisfies the first stage requirement. Note, unlike independence and exclusion, the first stage is testable as it is based solely on <span class="math inline">\(D\)</span> and <span class="math inline">\(Z\)</span>, both of which you have data on.</p>
<p>And finally, there is the monotonicity assumption. This is only strange at first glance but is actually quite intuitive. Monotonicity requires that the instrumental variable (weakly) operate in the same direction on all individual units. In other words, while the instrument may have no effect on some people, all those who are affected are affected in the same direction (i.e., positively or negatively, but not both). We write it out like this:
<span class="math display">\[
\text{Either $\pi_{1i} \geq 0$ for all $i$
       or $\pi_{1i} \leq 0$ for all $i=1,\dots, N$}
\]</span>
What this means, using our military draft example, is that draft eligibility may have no effect on the probability of military service for some people, like patriots, people who love and want to serve their country in the military, but when it does have an effect, it shifts them all into service, or out of service, but not both. The reason we have to make this assumption is that without monotonicity, IV estimators are not guaranteed to estimate a weighted average of the underlying causal effects of the affected group.</p>
<p>If all five assumptions are satisfied, then we have a valid IV strategy. But that being said, while valid, it is not doing what it was doing when we had homogeneous treatment effects. What, then, is the IV strategy estimating under heterogeneous treatment effects? Answer: the local average treatment effect (LATE) of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[\begin{align}
   \delta_{IV,LATE} &amp; =\dfrac{ \text{Effect of $Z$ on $Y$}}{\text{Effect of $Z$ on $D$}} 
   \\
    &amp; =\dfrac{E\big[Y_i(D_i^1,1)-Y_i(D_i^0,0)\big]}{ E[D_i^1 - D_i^0]}   
   \\
    &amp; =E\big[(Y_i^1-Y_i^0)\mid D_i^1-D_i^0=1\big]                        
\end{align}\]</span></p>
<p>The LATE parameter is the average causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> for those whose treatment status was changed by the instrument, <span class="math inline">\(Z\)</span>. We know that because notice the difference in the last line: <span class="math inline">\(D_i^1 - D_i^0\)</span>. So, for those people for whom that is equal to 1, we calculate the difference in potential outcomes. Which means we are only averaging over treatment effects for whom <span class="math inline">\(D_i^1 - D_i^0\)</span>. Hence why the parameter we are estimating is “local.”</p>
<p>How do we interpret Angrist’s estimated causal effect in his Vietnam draft project? Well, IV estimates the average effect of military service on earnings for the subpopulations who enrolled in military service <em>because of the draft</em>. These are specifically only those people, though, who <em>would</em> not have served otherwise. It doesn’t identify the causal effect on patriots who always serve, for instance, because <span class="math inline">\(D_i^1 - D_i^0 = 0\)</span> for patriots. They always serve! <span class="math inline">\(D_i^1=1\)</span> <em>and</em> <span class="math inline">\(D_i^0=1\)</span> for patriots because <em>they’re patriots</em>! It also won’t tell us the effect of military service on those who were exempted from military service for medical reasons because for these people <span class="math inline">\(D_i^1=0\)</span> and <span class="math inline">\(D_i^0=0\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;We have reviewed the properties of IV with heterogeneous treatment effects using a very simple dummy endogeneous variable, dummy IV, and no additional controls example. The intuition of LATE generalizes to most cases where we have continuous endogenous variables and instruments, and additional control variables, as well.&lt;/p&gt;"><sup>121</sup></a></p>
<p>The LATE framework has even more jargon, so let’s review it now. The LATE framework partitions the population of units with an instrument into potentially four mutually exclusive groups. Those groups are:</p>
<ol style="list-style-type: decimal">
<li><p><em>Compliers</em>: This is the subpopulation whose treatment status is affected by the instrument in the correct direction. That is, <span class="math inline">\(D_i^1=1\)</span> and <span class="math inline">\(D_i^0=0\)</span>.</p></li>
<li><p><em>Defiers</em>: This is the subpopulation whose treatment status is affected by the instrument in the wrong direction. That is, <span class="math inline">\(D_i^1=0\)</span> and <span class="math inline">\(D_i^0=1\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These are funny people. If they’re drafted, they dodge the draft. But if they’re not drafted, then they voluntarily enroll. In this context, defiance seems kind of irrational, but that’s not always the case.&lt;/p&gt;"><sup>122</sup></a></p></li>
<li><p><em>Never takers</em>: This is the subpopulation of units that never take the treatment regardless of the value of the instrument. So, <span class="math inline">\(D_i^1=D_i^0=0\)</span>. They simply never take the treatment.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These are draft dodgers. For instance, maybe it’s someone whose doctor gave him a bone-spur diagnosis so he could avoid service.&lt;/p&gt;"><sup>123</sup></a></p></li>
<li><p><em>Always takers</em>: This is the subpopulation of units that always take the treatment regardless of the value of the instrument. So, <span class="math inline">\(D_i^1=D_i^0=1\)</span>. They simply always take the instrument.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;These are our patriots.&lt;/p&gt;"><sup>124</sup></a></p></li>
</ol>
<p>As outlined above, with all five assumptions satisfied, IV estimates the average treatment effect for compliers, which is the parameter we’ve called the local average treatment effect. It’s local in the sense that it is average treatment effect to the compliers only. Contrast this with the traditional IV pedagogy with homogeneous treatment effects. In that situation, compliers have the same treatment effects as non-compliers, so the distinction is irrelevant. Without further assumptions, LATE is not informative about effects on never-takers or always-takers because the instrument does not affect their treatment status.</p>
<p>Does this matter? Yes, absolutely. It matters because in most applications, we would be mostly interested in estimating the average treatment effect on the whole population, but that’s not usually possible with IV.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;This identification of the LATE under heterogeneous treatment effects material was worked out in &lt;span class="citation"&gt;Angrist, Imbens, and Rubin (&lt;a href="references.html#ref-Angrist1996b" role="doc-biblioref"&gt;1996&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>125</sup></a></p>
<p>Now that we have reviewed the basic idea and mechanics of instrumental variables, including some of the more important tests associated with it, let’s get our hands dirty with some data. We’ll work with a couple of data sets now to help you better understand how to implement 2SLS in real data.</p>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="../images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>
</div>
<div id="applications" class="section level2" number="7.7">
<h2>
<span class="header-section-number">7.7</span> Applications<a class="anchor" aria-label="anchor" href="#applications"><i class="fas fa-link"></i></a>
</h2>
<div id="college-in-the-county" class="section level3" number="7.7.1">
<h3>
<span class="header-section-number">7.7.1</span> College in the county<a class="anchor" aria-label="anchor" href="#college-in-the-county"><i class="fas fa-link"></i></a>
</h3>
<p>We will once again look at the returns to schooling since it is such a historically popular topic for causal questions in labor. In this application, we will simply estimate a 2SLS model, calculate the first-stage <em>F</em> statistic, and compare the 2SLS results with the OLS results. I will be keeping it simple, because my goal is just to help the reader become familiarized with the procedure.</p>
<p>The data comes from the NLS Young Men Cohort of the National Longitudinal Survey. This data began in 1966 with 5,525 men aged 14–24 and continued to follow up with them through 1981. These data come from 1966, the baseline survey, and there are a number of questions related to local labor-markets. One of them is whether the respondent lives in the same county as a 4-year (and a 2-year) college.</p>
<p><span class="citation">Card (<a href="references.html#ref-Card1995" role="doc-biblioref">1995</a>)</span> is interested in estimating the following regression equation:
<span class="math display">\[
Y_i=\alpha+\delta S_i + \gamma X_i+\varepsilon_i
\]</span>
where <span class="math inline">\(Y\)</span> is log earnings, <span class="math inline">\(S\)</span> is years of schooling, <span class="math inline">\(X\)</span> is a matrix of exogenous covariates, and <span class="math inline">\(\varepsilon\)</span> is an error term that contains, among other things, unobserved ability. Under the assumption that <span class="math inline">\(\varepsilon\)</span> contains ability, and ability is correlated with schooling, then <span class="math inline">\(C(S,\varepsilon)\neq 0\)</span> and therefore schooling is biased. <span class="citation">Card (<a href="references.html#ref-Card1995" role="doc-biblioref">1995</a>)</span> proposes therefore an instrumental variables strategy whereby he will instrument for schooling with the college-in-the-county dummy variable.</p>
<p>It is worth asking ourselves why the presence of a 4-year college in one’s county would increase schooling. The main reason I can think of is that the presence of the 4-year college increases the likelihood of going to college by lowering the costs, since the student can live at home. This therefore means that we are selecting on a group of compliers whose behavior is affected by the variable. Some kids, in other words, will always go to college regardless of whether a college is in their county, and some will never go despite the presence of the nearby college. But there may exist a group of compliers who go to college only because their county has a college, and if I’m right that this is primarily picking up people going because they can attend while living at home, then it’s necessarily people at some margin who attend only because college became slightly cheaper. This is, in other words, a group of people who are liquidity constrained. And if we believe the returns to schooling for this group are different from those of the always-takers, then our estimates may not represent the ATE. Rather, they would represent the LATE. But in this case, that might actually be an interesting parameter since it gets at the issue of lowering costs of attendance for poorer families.</p>
<p>Here we will do some simple analysis based on <span class="citation">Card (<a href="references.html#ref-Card1995" role="doc-biblioref">1995</a>)</span>.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/card.do"><code>card.do</code></a></em></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb79-1"><a href="ch6.html#cb79-1" aria-hidden="true"></a><span class="kw">use</span> https:<span class="co">//github.com/scunning1975/mixtape/raw/master/card.dta, clear</span></span>
<span id="cb79-2"><a href="ch6.html#cb79-2" aria-hidden="true"></a></span>
<span id="cb79-3"><a href="ch6.html#cb79-3" aria-hidden="true"></a>* OLS estimate <span class="kw">of</span> schooling (educ) <span class="kw">on</span> <span class="fu">log</span> wages</span>
<span id="cb79-4"><a href="ch6.html#cb79-4" aria-hidden="true"></a><span class="kw">reg</span> lwage  educ  exper <span class="bn">black</span> south married smsa</span>
<span id="cb79-5"><a href="ch6.html#cb79-5" aria-hidden="true"></a></span>
<span id="cb79-6"><a href="ch6.html#cb79-6" aria-hidden="true"></a>* 2SLS estimate <span class="kw">of</span> schooling (educ) <span class="kw">on</span> <span class="fu">log</span> wages <span class="kw">using</span> <span class="st">"college in the county"</span> <span class="kw">as</span> an instrument <span class="kw">for</span> schooling</span>
<span id="cb79-7"><a href="ch6.html#cb79-7" aria-hidden="true"></a>ivregress 2sls lwage (educ=nearc4) exper <span class="bn">black</span> south married smsa, first </span>
<span id="cb79-8"><a href="ch6.html#cb79-8" aria-hidden="true"></a></span>
<span id="cb79-9"><a href="ch6.html#cb79-9" aria-hidden="true"></a>* First stage regression <span class="kw">of</span> schooling (educ) <span class="kw">on</span> <span class="ot">all</span> covariates and the college and the county <span class="kw">variable</span></span>
<span id="cb79-10"><a href="ch6.html#cb79-10" aria-hidden="true"></a><span class="kw">reg</span> educ nearc4 exper <span class="bn">black</span> south married smsa</span>
<span id="cb79-11"><a href="ch6.html#cb79-11" aria-hidden="true"></a></span>
<span id="cb79-12"><a href="ch6.html#cb79-12" aria-hidden="true"></a>* <span class="fu">F</span> <span class="kw">test</span> <span class="kw">on</span> the excludability <span class="kw">of</span> college <span class="kw">in</span> the county from the first stage regression.</span>
<span id="cb79-13"><a href="ch6.html#cb79-13" aria-hidden="true"></a><span class="kw">test</span> nearc4</span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/card.R"><code>card.R</code></a></em></p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haven.tidyverse.org">haven</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>

<span class="va">read_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">{</span>
  <span class="va">full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"https://raw.github.com/scunning1975/mixtape/master/"</span>, 
                     <span class="va">df</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/read_dta.html">read_dta</a></span><span class="op">(</span><span class="va">full_path</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">card</span> <span class="op">&lt;-</span> <span class="fu">read_data</span><span class="op">(</span><span class="st">"card.dta"</span><span class="op">)</span>

<span class="co">#Define variable </span>
<span class="co">#(Y1 = Dependent Variable, Y2 = endogenous variable, X1 = exogenous variable, X2 = Instrument)</span>

<span class="kw"><a href="https://rdrr.io/r/base/attach.html">attach</a></span><span class="op">(</span><span class="va">card</span><span class="op">)</span>

<span class="va">Y1</span> <span class="op">&lt;-</span> <span class="va">lwage</span>
<span class="va">Y2</span> <span class="op">&lt;-</span> <span class="va">educ</span>
<span class="va">X1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">exper</span>, <span class="va">black</span>, <span class="va">south</span>, <span class="va">married</span>, <span class="va">smsa</span><span class="op">)</span>
<span class="va">X2</span> <span class="op">&lt;-</span> <span class="va">nearc4</span>

<span class="co">#OLS</span>
<span class="va">ols_reg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y1</span> <span class="op">~</span> <span class="va">Y2</span> <span class="op">+</span> <span class="va">X1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">ols_reg</span><span class="op">)</span>

<span class="co">#2SLS</span>
<span class="va">iv_reg</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/ivreg.html">ivreg</a></span><span class="op">(</span><span class="va">Y1</span> <span class="op">~</span> <span class="va">Y2</span> <span class="op">+</span> <span class="va">X1</span> <span class="op">|</span> <span class="va">X1</span> <span class="op">+</span> <span class="va">X2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">iv_reg</span><span class="op">)</span></code></pre></div>
<p>Our results from this analysis have been arranged into Table <a href="ch6.html#tab:2sls-1">7.6</a>. First, we report our OLS results. For every one year additional of schooling, respondents’ earnings increase by approximately 7.1%. Next we estimated 2SLS using the <code>ivregress 2sls</code> command in Stata. Here we find a much larger return to schooling than we had found using OLS—around 75% larger in fact. But let’s look at the first stage. We find that the college in the county is associated with 0.327 more years of schooling. This is highly significant (<span class="math inline">\(p&lt;0.001\)</span>). The <span class="math inline">\(F\)</span> statistic exceeds 15, suggesting we don’t have a weak instrument problem. The return to schooling associated with this 2SLS estimate is 0.124—that is, for every additional year of schooling, earnings increase by 12.4%. Other covariates are listed if you’re interested in studying them as well.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:2sls-1">Table 7.6: </span> OLS and 2SLS regressions of Log Earnings on Schooling</caption>
<tbody>
<tr class="odd">
<td align="left"><strong>Dependent variable</strong></td>
<td align="center"><strong>OLS</strong></td>
<td align="center"><strong>2SLS</strong></td>
</tr>
<tr class="even">
<td align="left">educ</td>
<td align="center"><span class="math inline">\(0.071^{***}\)</span></td>
<td align="center">0.124<span class="math inline">\(^{**}\)</span>
</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.003)</td>
<td align="center">(0.050)</td>
</tr>
<tr class="even">
<td align="left">exper</td>
<td align="center"><span class="math inline">\(0.034^{***}\)</span></td>
<td align="center">0.056<span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.002)</td>
<td align="center">(0.020)</td>
</tr>
<tr class="even">
<td align="left">black</td>
<td align="center"><span class="math inline">\(-0.166^{***}\)</span></td>
<td align="center"><span class="math inline">\(-0.116^{**}\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.018)</td>
<td align="center">(0.051)</td>
</tr>
<tr class="even">
<td align="left">south</td>
<td align="center"><span class="math inline">\(-0.132^{***}\)</span></td>
<td align="center"><span class="math inline">\(-0.113^{***}\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.015)</td>
<td align="center">(0.023)</td>
</tr>
<tr class="even">
<td align="left">married</td>
<td align="center"><span class="math inline">\(-0.036^{***}\)</span></td>
<td align="center"><span class="math inline">\(-0.032^{***}\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.003)</td>
<td align="center">(0.005)</td>
</tr>
<tr class="even">
<td align="left">smsa</td>
<td align="center"><span class="math inline">\(0.176^{***}\)</span></td>
<td align="center"><span class="math inline">\(0.148^{***}\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.015)</td>
<td align="center">(0.031)</td>
</tr>
<tr class="even">
<td align="left"><strong>First Stage Instrument</strong></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">College in the county</td>
<td align="center"></td>
<td align="center">0.327<span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="even">
<td align="left">Robust standard error</td>
<td align="center"></td>
<td align="center">(0.082)</td>
</tr>
<tr class="odd">
<td align="left">F statistic for IV in first stage</td>
<td align="center"></td>
<td align="center">15.767</td>
</tr>
<tr class="even">
<td align="left">N</td>
<td align="center">3,003</td>
<td align="center">3,003</td>
</tr>
<tr class="odd">
<td align="left">Mean Dependent Variable</td>
<td align="center">6.262</td>
<td align="center">6.262</td>
</tr>
<tr class="even">
<td align="left">Std. Dev. Dependent Variable</td>
<td align="center">0.444</td>
<td align="center">0.444</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis. <span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.10\)</span>, <span class="math inline">\(^{**}\)</span> <span class="math inline">\(p&lt;0.05\)</span>, <span class="math inline">\(^{***}\)</span> <span class="math inline">\(p&lt;0.01\)</span>
</p>
<p>Why would the return to schooling be so much larger for the compliers than for the general population? After all, we showed earlier that if this was simply ability bias, then we’d expect the 2SLS coefficient to be <em>smaller</em> than the OLS coefficient, because ability bias implies that the coefficient on schooling is <em>too large</em>. Yet we’re finding the opposite. So a couple of things it could be. First, it could be that schooling has measurement error. Measurement error would bias the coefficient toward zero, and 2SLS would recover its true value. But I find this explanation to be unlikely, because I don’t foresee people really not knowing with accuracy how many years of schooling they currently have. Which leads us to the other explanation, and that is that compliers have larger returns to schooling. But why would this be the case? Assuming that the exclusion restriction holds, then why would compliers, returns be so much larger? We’ve already established that these people are likely being shifted into more schooling because they live with their parents, which suggests that the college is lowering the marginal cost of going to college. All we are left saying is that for some reason, the higher marginal cost of attending college is causing these people to underinvest in schooling; that in fact their returns are much higher.</p>
</div>
<div id="fulton-fish-markets" class="section level3" number="7.7.2">
<h3>
<span class="header-section-number">7.7.2</span> Fulton Fish Markets<a class="anchor" aria-label="anchor" href="#fulton-fish-markets"><i class="fas fa-link"></i></a>
</h3>
<p>The second exercise that we’ll be doing is based on <span class="citation">Graddy (<a href="references.html#ref-Graddy2006" role="doc-biblioref">2006</a>)</span>. My understanding is that Graddy collected these data herself by recording prices of fish at the actual Fulton Fish Market. I’m not sure if that is true, but I like to believe it’s true. Anyhow, the Fulton Fish Market operated in New York on Fulton Street for 150 years. In November 2005, it moved from Lower Manhattan to a large facility building for the market in the South Bronx. At the time when Graddy (2006) was published, the market was called the New Fulton Fish Market. It’s one of the world’s largest fish markets, second only to the Tsukiji in Tokyo.</p>
<p>Fish are heterogeneous, highly differentiated products. There are anywhere between one hundred and three hundred varieties of fish sold at the market. There are over fifteen varieties of shrimp alone. Within each variety, there’s small fish, large fish, medium fish, fish just caught, fish that have been around a while. There’s so much heterogeneity that customers often want to examine fish personally. You get the picture. This fish market functions just like a two-sided platform matching buyers to sellers, which is made more efficient by the thickness the market produces. It’s not surprising, therefore, that Graddy found the market such an interesting thing to study.</p>
<p>Let’s move to the data. I want us to estimate the price elasticity of demand for fish, which makes this problem much like the problem that Philip Wright faced in that price and quantity are determined simultaneously. The elasticity of demand is a sequence of quantity and price pairs, but with only one pair observed at a given point in time. In that sense, the demand curve is itself a sequence of potential outcomes (quantity) associated with different potential treatments (price). This means the demand curve is itself a real object, but mostly unobserved. Therefore, to trace out the elasticity, we need an instrument that is correlated with supply only. Graddy proposes a few of them, all of which have to do with the weather at sea in the days before the fish arrived to market.</p>
<p>The first instrument is the average maximum wave height in the previous two days. The model we are interested in estimating is:</p>
<p><span class="math display">\[\begin{align}
   Q = \alpha + \delta P + \gamma X + \varepsilon 
\end{align}\]</span></p>
<p>where <span class="math inline">\(Q\)</span> is log quantity of whiting sold in pounds, <span class="math inline">\(P\)</span> is log average daily price per pound, <span class="math inline">\(X\)</span> are day of the week dummies and a time trend, and <span class="math inline">\(\varepsilon\)</span> is the structural error term. Table <a href="ch6.html#tab:2sls-2">7.7</a> presents the results from estimating this equation with OLS (first column) and 2SLS (second column). The OLS estimate of the elasticity of demand is <span class="math inline">\(-0.549\)</span>. It could’ve been anything given price is determined by how many sellers and how many buyers there are at the market on any given day. But when we use the average wave height as the instrument for price, we get a <span class="math inline">\(-0.96\)</span> price elasticity of demand. A 10% increase in the price causes quantity to decrease by 9.6%. The instrument is strong <span class="math inline">\((F&gt;22)\)</span>. For every one-unit increase in the wave-height, price rose 10%.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:2sls-2">Table 7.7: </span> OLS and 2SLS regressions of Log Quantity on Log Price with wave height instrument</caption>
<tbody>
<tr class="odd">
<td align="left"><strong>Dependent variable</strong></td>
<td align="center"><strong>Log(quantity)</strong></td>
<td></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center"><strong>OLS</strong></td>
<td><strong>2SLS</strong></td>
</tr>
<tr class="odd">
<td align="left">Log(Price)</td>
<td align="center"><span class="math inline">\(-0.549^{***}\)</span></td>
<td><span class="math inline">\(-0.960^{**}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.184)</td>
<td>(0.406)</td>
</tr>
<tr class="odd">
<td align="left">Monday</td>
<td align="center"><span class="math inline">\(-0.318\)</span></td>
<td><span class="math inline">\(-0.322\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.227)</td>
<td>(0.225)</td>
</tr>
<tr class="odd">
<td align="left">Tuesday</td>
<td align="center"><span class="math inline">\(-0.684^{***}\)</span></td>
<td><span class="math inline">\(-0.687^{***}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.224)</td>
<td>(0.221)</td>
</tr>
<tr class="odd">
<td align="left">Wednesday</td>
<td align="center"><span class="math inline">\(-0.535^{**}\)</span></td>
<td><span class="math inline">\(-0.520^{**}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.221)</td>
<td>(0.219)</td>
</tr>
<tr class="odd">
<td align="left">Thursday</td>
<td align="center">0.068</td>
<td>0.106</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.221)</td>
<td>(0.222)</td>
</tr>
<tr class="odd">
<td align="left">Time trend</td>
<td align="center"><span class="math inline">\(-0.001\)</span></td>
<td><span class="math inline">\(-0.003\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.003)</td>
<td>(0.003)</td>
</tr>
<tr class="odd">
<td align="left"><em>First Stage Instrument</em></td>
<td align="center"></td>
<td></td>
</tr>
<tr class="even">
<td align="left">Average wave height</td>
<td align="center"></td>
<td><span class="math inline">\(0.103^{***}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Robust standard error</td>
<td align="center"></td>
<td>(0.022)</td>
</tr>
<tr class="even">
<td align="left">F statistic for IV in first stage</td>
<td align="center"></td>
<td>22.638</td>
</tr>
<tr class="odd">
<td align="left">N</td>
<td align="center">97</td>
<td>97</td>
</tr>
<tr class="even">
<td align="left">Mean Dependent Variable</td>
<td align="center">8.086</td>
<td>8.086</td>
</tr>
<tr class="odd">
<td align="left">Std. Dev. Dependent Variable</td>
<td align="center">0.765</td>
<td>0.765</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis. <span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.10\)</span>, <span class="math inline">\(^{**}\)</span> <span class="math inline">\(p&lt;0.05\)</span>, <span class="math inline">\(^{**}\)</span><span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.01\)</span>
</p>
<p>I suppose the question we have to ask ourselves, though, is what exactly is this instrument doing to supply. What are higher waves doing exactly? They are making it more difficult to fish, but are they also changing the composition of the fish caught? If so, then it would seem that the exclusion restriction is violated because that would mean the wave height is directly causing fish composition to change, which will directly determine quantities bought and sold.</p>
<p>Now let’s look at a different instrument: wind speed (Table 59). Specifically, it’s the three-day lagged maximum wind speed. We present these results in Table <a href="ch6.html#tab:2sls-2">7.7</a>. Here we see something we did not see before, which is that this is a weak instrument. The <span class="math inline">\(F\)</span> statistic is less than 10 (approximately 6.5). And correspondingly, the estimated elasticity is twice as large as what we found with wave height. Thus, we know from our earlier discussion of weak instruments that this estimate is likely severely biased, and therefore less reliable than the previous one—even though the previous one itself (1) may not convincingly satisfy the exclusion restriction and (2) is at best a LATE relevant to compliers only. But as we’ve said, if we think that the compliers’ causal effects are similar to that of the broader population, then the LATE may itself be informative and useful.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:2sls-3">Table 7.8: </span> OLS and 2SLS regressions of Log Quantity on Log Price with windspeed instrument.</caption>
<tbody>
<tr class="odd">
<td align="left"><strong>Dependent variable</strong></td>
<td align="center"><strong>Log(quantity)</strong></td>
<td></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center"><strong>OLS</strong></td>
<td><strong>2SLS</strong></td>
</tr>
<tr class="odd">
<td align="left">Log Price</td>
<td align="center"><span class="math inline">\(-0.549^{***}\)</span></td>
<td><span class="math inline">\(-1.960^{**}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.184)</td>
<td>(0.873)</td>
</tr>
<tr class="odd">
<td align="left">Monday</td>
<td align="center"><span class="math inline">\(-0.318\)</span></td>
<td><span class="math inline">\(-0.332\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.227)</td>
<td>(0.281)</td>
</tr>
<tr class="odd">
<td align="left">Tuesday</td>
<td align="center"><span class="math inline">\(-0.684^{***}\)</span></td>
<td><span class="math inline">\(-0.696^{**}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.224)</td>
<td>(0.277)</td>
</tr>
<tr class="odd">
<td align="left">Wednesday</td>
<td align="center"><span class="math inline">\(-0.535^{**}\)</span></td>
<td><span class="math inline">\(-0.482^{*}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.221)</td>
<td>(0.275)</td>
</tr>
<tr class="odd">
<td align="left">Thursday</td>
<td align="center">0.068</td>
<td>0.196</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.221)</td>
<td>(0.285)</td>
</tr>
<tr class="odd">
<td align="left">Time trend</td>
<td align="center"><span class="math inline">\(-0.001\)</span></td>
<td><span class="math inline">\(-0.007\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.003)</td>
<td>(0.005)</td>
</tr>
<tr class="odd">
<td align="left"><em>First Stage Instrument</em></td>
<td align="center"></td>
<td></td>
</tr>
<tr class="even">
<td align="left">Wind Speed</td>
<td align="center"></td>
<td>0.017<span class="math inline">\(^{**}\)</span>
</td>
</tr>
<tr class="odd">
<td align="left">Robust standard error</td>
<td align="center"></td>
<td>(0.007)</td>
</tr>
<tr class="even">
<td align="left">F statistic for IV in first stage</td>
<td align="center"></td>
<td>6.581</td>
</tr>
<tr class="odd">
<td align="left">N</td>
<td align="center">97</td>
<td>97</td>
</tr>
<tr class="even">
<td align="left">Mean Dependent Variable</td>
<td align="center">8.086</td>
<td>8.086</td>
</tr>
<tr class="odd">
<td align="left">Std. Dev. Dependent Variable</td>
<td align="center">0.765</td>
<td>0.765</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis. <span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.10\)</span>, <span class="math inline">\(^{**}\)</span> <span class="math inline">\(p&lt;0.05\)</span>, <span class="math inline">\(^{**}\)</span><span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.01\)</span>
</p>
</div>
</div>
<div id="popular-iv-designs" class="section level2" number="7.8">
<h2>
<span class="header-section-number">7.8</span> Popular IV Designs<a class="anchor" aria-label="anchor" href="#popular-iv-designs"><i class="fas fa-link"></i></a>
</h2>
<p>Instrumental variables is a strategy to adopt when you have a good instrument, and so in that sense, it is a very general design that can be used in just about any context. But over the years, certain types of IV strategies have been used so many times that they constitute their own designs. And from repetition and reflection, we have a better understanding of how these specific IV designs do and do not work. Let’s discuss three such popular designs: the lottery design, the judge fixed effects design, and Bartik instruments.</p>
<div id="lotteries" class="section level3" number="7.8.1">
<h3>
<span class="header-section-number">7.8.1</span> Lotteries<a class="anchor" aria-label="anchor" href="#lotteries"><i class="fas fa-link"></i></a>
</h3>
<p>Previously, we reviewed the use of IV in identifying causal effects when some regressor is endogenous in observational data. But one particular kind of IV application is randomized trials. In many randomized trials, participation is voluntary among those randomly chosen to be in the treatment group. On the other hand, persons in the control group usually don’t have access to the treatment. Only those who are particularly likely to benefit from treatment therefore will probably take up treatment, which almost always leads to positive selection bias. If you compare means between treated and untreated individuals using OLS, you will obtain biased treatment effects even for the randomized trial because of noncompliance. A solution to the problems of least squares in this application is to instrument for Medicaid with whether you were offered treatment and estimate the LATE. Thus even when treatment itself is randomly assigned, it is common for people to use a randomized lottery as an instrument for participation. For a modern example of this, see <span class="citation">Baicker et al. (<a href="references.html#ref-Baicker2013" role="doc-biblioref">2013</a>)</span>, who used the randomized lottery to be enrolled in Oregon’s Medicaid program as an instrument for being on Medicaid. Let’s discuss the Oregon Medicaid studies now, as they are excellent illustrations of the lottery IV design.</p>
<p>What are the effects of expanding access to public health insurance for low-income adults? Are they positive or negative? Are they large or small? Surprisingly, we have not historically had reliable estimates for these very basic questions because we lacked the kind of experiment needed to make claims one way or another. The limited existing evidence was suggestive, with a lot of uncertainty. Observational studies are confounded by selection into health insurance, and the quasi-experimental evidence tended to only focus on the elderly and small children. There has been only one randomized experiment in a developed country, and it was the RAND health insurance experiment in the 1970s. This was an important, expensive, ambitious experiment, but it only randomized cost-sharing—not coverage itself.</p>
<p>But in the 2000s, Oregon chose to expand its Medicaid program for poor adults by making it more generous. Adults aged 19–64 with income less than 100% of the federal poverty line were eligible so long as they weren’t eligible for other similar programs. They also had to be uninsured for fewer than six months and be a legal US resident. The program was called the Oregon Health Plan Standard and it provided comprehensive coverage (but no dental or vision) and minimum cost-sharing. It was similar to other states in payments and management, and the program was closed to new enrollment in 2004.</p>
<p>The expansion is popularly known as the Oregon Medicaid Experiment because the state used a lottery to enroll volunteers. For five weeks, people were allowed to sign up for Medicaid. The state used heavy advertising to make the program salient. There were low barriers to signing up and no eligibility requirements for prescreening. The state in March to October 2008 randomly drew 30,000 people out of a list of 85,000. Those selected were given a chance to apply. If they did apply, then their entire household was enrolled, so long as they returned the application within 45 days. Out of this original 30,000, only 10,000 people were enrolled.</p>
<p>A team of economists became involved with this project early on, out of which several influential papers were written. I’ll now discuss some of the main results from <span class="citation">Finkelstein et al. (<a href="references.html#ref-Finkelstein2012" role="doc-biblioref">2012</a>)</span> and <span class="citation">Baicker et al. (<a href="references.html#ref-Baicker2013" role="doc-biblioref">2013</a>)</span>. The authors of these studies sought to study a broad range of outcomes that might be plausibly affected by health insurance—from financial outcomes, to health-care utilization, to health outcomes. The data needed for these outcomes were meticulously collected from third parties. For instance, the pre-randomization demographic information was available from the lottery sign-up. The state administrative records on Medicaid enrollment were also collected and became the primary measure of a first stage (i.e., insurance coverage). And outcomes were collected from administrative sources (e.g., hospital discharge, mortality, credit), mail surveys, and in-person survey and measurement (e.g., blood samples, body mass index, detailed questionnaires).</p>
<p>The empirical framework in these studies is a straightforward IV design. Sometimes they estimated the reduced form, and sometimes they estimated the full 2SLS model. The two-stages were:</p>
<p><span class="math display">\[\begin{align}
   \text{INSURANCE}_{ihj} &amp; =                                                                                  
   \delta_0+\delta_1\text{ LOTTERY}_{ih} +
   X_{ih}\delta_2 + V_{ih}\delta_3 + \mu_{ihj}
   \\
   y_{ihj}                &amp; =\pi_0+\pi_1 I\widehat{\text{NSURANCE}}_{ih} + X_{ih}\pi_2 + V_{ih}\pi_3 + v_{ihj} 
\end{align}\]</span></p>
<p>where the first equation is the first stage (insurance regressed onto the lottery outcome plus a bunch of covariates), and the second stage regresses individual-level outcomes onto predicted insurance (plus all those controls). We already know that so long as the first stage is strong, then the <em>F</em> statistic will be large, and the finite sample bias lessens.</p>
<p>The effects of winning the lottery had large effects on enrollment. We can see the results of the first stage in Table <a href="ch6.html#tab:lottery-enrollment">7.9</a>. They used different samples, but the effect sizes were similar. Winning the lottery raised the probability of being enrolled on Medicaid by 26% and raised the number of months of being on Medicaid from 3.3 to 4 months.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:lottery-enrollment">Table 7.9: </span> Effect of Lottery on Enrollment</caption>
<thead><tr class="header">
<th align="left">Dependent variable</th>
<th align="center">Full sample</th>
<th align="center">Survey respondents</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Ever on Medicaid</td>
<td align="center">0.256</td>
<td align="center">0.290</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.004)</td>
<td align="center">(0.007)</td>
</tr>
<tr class="odd">
<td align="left">Ever on OHP Standard</td>
<td align="center">0.264</td>
<td align="center">0.302</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.003)</td>
<td align="center">(0.005)</td>
</tr>
<tr class="odd">
<td align="left">Number of months on Medicaid</td>
<td align="center">3.355</td>
<td align="center">3.943</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.045)</td>
<td align="center">(0.09)</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis.
</p>
<p>Across the two papers, the authors looked at the effect of Medicaid’s health insurance coverage on a variety of outcomes including financial health, mortality, and health-care utilization, but I will review only a few here. In Table <a href="ch6.html#tab:lottery-hospital">7.10</a>, the authors present two regression models: column 2 is the intent to treat estimates, which is the reduced form model, and column 3 is the local average treatment effect estimate, which is our full instrumental variables specification. Interestingly, Medicaid increased the number of hospital admissions but had no effect on emergency room visits. The effect on emergency rooms, in fact, is not significant, but the effect on non-emergency-room admissions is positive and significant. This is interesting because it appears that Medicaid is increasing hospital admission without putting additional strain on emergency rooms, which already have scarce resources.</p>
<p>What other kinds of health-care utilization are we observing in Medicaid enrollees? Let’s look at Table <a href="ch6.html#tab:medicaid-health1">7.11</a>, which has five health-care utilization outcomes. Again, I will focus on column 3, which is the LATE estimates. Medicaid enrollees were 34% more likely to have a usual place of care, 28% to have a personal doctor, 24% to complete their health-care needs, 20% more likely to get all needed prescriptions and 14% increased satisfaction with the quality of their care.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:lottery-hospital">Table 7.10: </span> Effect of Medicaid on Hospital admission</caption>
<thead><tr class="header">
<th align="left"><strong>Dependent variable</strong></th>
<th align="center"><strong>ITT</strong></th>
<th align="center"><strong>LATE</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Any hospital admission</td>
<td align="center">0.5%</td>
<td align="center">2.1%</td>
</tr>
<tr class="even">
<td align="left">Hospital admissions through ED</td>
<td align="center">0.2%</td>
<td align="center">0.7%</td>
</tr>
<tr class="odd">
<td align="left">Hospital admissions not through ED</td>
<td align="center">0.4%</td>
<td align="center">1.6%</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Hospital discharge data.
</p>
<p>But Medicaid is not merely a way to increase access to health care; it also functions effectively as health care insurance in the event of catastrophic health events. And one of the most widely circulated results of the experiment was the finding that Medicaid had on financial outcomes. In Table <a href="ch6.html#tab:lottery-credit">7.12</a> we see that one of the main effects was reduction in personal debt (by $390) and reducing debt going to debt collection. The authors also found reductions in out-of-pocket medical expenses, and medical expenses, borrowing money or skipping bills for medical expenses, and whether they refused medical treatment due to medical debt.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:medicaid-health1">Table 7.11: </span> Effect of Medicaid on healthcare Usage</caption>
<thead><tr class="header">
<th align="left"><strong>Dependent variable</strong></th>
<th align="center"><strong>ITT</strong></th>
<th align="center"><strong>LATE</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Have a usual place of care</td>
<td align="center">9.9%</td>
<td align="center">33.9%</td>
</tr>
<tr class="even">
<td align="left">Have a personal doctor</td>
<td align="center">8.1%</td>
<td align="center">28.0%</td>
</tr>
<tr class="odd">
<td align="left">Got all needed healthcare</td>
<td align="center">6.9%</td>
<td align="center">23.9%</td>
</tr>
<tr class="even">
<td align="left">Got all needed prescriptions</td>
<td align="center">5.6%</td>
<td align="center">19.5%</td>
</tr>
<tr class="odd">
<td align="left">Satisfied with quality of care</td>
<td align="center">4.3%</td>
<td align="center">14.2%</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Standard errors in parenthesis.
</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:lottery-credit">Table 7.12: </span> Effect of Medicaid on Hospital admission</caption>
<thead><tr class="header">
<th align="left"><strong>Dependent variable</strong></th>
<th align="center"><strong>ITT</strong></th>
<th align="center"><strong>LATE</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Had a bankruptcy</td>
<td align="center">0.2%</td>
<td align="center">0.9%</td>
</tr>
<tr class="even">
<td align="left">Had a collection</td>
<td align="center"><span class="math inline">\(-1.2\%\)</span></td>
<td align="center"><span class="math inline">\(-4.8\%\)</span></td>
</tr>
<tr class="odd">
<td align="left">Had a medical collection</td>
<td align="center"><span class="math inline">\(-1.6\%\)</span></td>
<td align="center"><span class="math inline">\(-6.4\%\)</span></td>
</tr>
<tr class="even">
<td align="left">Had non-medical collection</td>
<td align="center"><span class="math inline">\(-0.5\%\)</span></td>
<td align="center"><span class="math inline">\(-1.8\%\)</span></td>
</tr>
<tr class="odd">
<td align="left">$ owed medical collection</td>
<td align="center"><span class="math inline">\(-\$99\)</span></td>
<td align="center"><span class="math inline">\(-\$390\)</span></td>
</tr>
</tbody>
</table></div>
<p class="footnote">
Credit records.
</p>
<p>But the effect on health outcomes was a little unclear from this study. The authors find self-reported health outcomes to be improving, as well as a reduction in depression. They also find more healthy physical and mental health days. But the effects are overall small. Furthermore, they ultimately do not find that Medicaid had any effect on mortality—a result we will return to again in the difference-in-differences chapter.</p>
<p>In conclusion, we see a powerful use of IV in the assignment of lotteries to recipients. The lotteries function as instruments for treatment assignment, which can then be used to estimate some local average treatment effect. This is incredibly useful in experimental designs if only because humans often refuse to comply with their treatment assignment or even participate in the experiment altogether!</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:medicaid-health2">Table 7.13: </span> Effect of Medicaid on Hospital admission</caption>
<thead><tr class="header">
<th align="left"><strong>Dependent variable</strong></th>
<th align="center"><strong>ITT</strong></th>
<th align="center"><strong>LATE</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Health good, very good, or excellent</td>
<td align="center">3.9%</td>
<td align="center">13.3%</td>
</tr>
<tr class="even">
<td align="left">Health stable or improving</td>
<td align="center">3.3%</td>
<td align="center">11.3%</td>
</tr>
<tr class="odd">
<td align="left">Depression screen NEGATIVE</td>
<td align="center">2.3%</td>
<td align="center">7.8%</td>
</tr>
<tr class="even">
<td align="left">CDC healthy days (physical)</td>
<td align="center">0.381</td>
<td align="center">1.31</td>
</tr>
<tr class="odd">
<td align="left">CDC healthy days (mental)</td>
<td align="center">0.603</td>
<td align="center">2.08</td>
</tr>
</tbody>
</table></div>
</div>
<div id="judge-fixed-effects" class="section level3" number="7.8.2">
<h3>
<span class="header-section-number">7.8.2</span> Judge fixed effects<a class="anchor" aria-label="anchor" href="#judge-fixed-effects"><i class="fas fa-link"></i></a>
</h3>
<p>A second IV design that has become extremely popular in recent years is the “judge fixed effects” design. You may also hear it called the “leniency design,” but because the applications so often involve judges, it seems the former name has stuck. A search on Google Scholar for the term yields over 70 hits, with over 50 since 2018 alone.</p>
<p>The concept of the judge fixed effects design is that there exists a narrow pipeline through which all individuals must pass, numerous randomly assigned decision-makers blocking the individuals’ passage who assign a treatment to the individuals and discretion among the decision-makers. When all three are there, you probably have the makings of a judge fixed effects design. The reason the method is called the judge fixed effects design is because it has traditionally exploited a feature in American jurisprudence where jurisdictions will randomly assign judges to defendants. In Harris County, Texas, for instance, they used to use a bingo machine to assign defendants to one of dozens of courts <span class="citation">(Mueller-Smith <a href="references.html#ref-Mike2015" role="doc-biblioref">2015</a>)</span>.</p>
<div class="figure">
<span id="fig:seth-judges"></span>
<img src="graphics/scottjudges.jpg" alt="Randomized judge assignment. Although justice is supposedly blind, judges are complex bundles of characteristics that affect their judgments. Artwork by Seth." width="100%"><p class="caption">
Figure 7.7: Randomized judge assignment. Although justice is supposedly blind, judges are complex bundles of characteristics that affect their judgments. Artwork by Seth.
</p>
</div>
<p>The first paper to recognize that there were systematic differences in judge sentencing behavior was an article by <span class="citation">Gaudet, Harris, and John (<a href="references.html#ref-Gaudet1933" role="doc-biblioref">1933</a>)</span>. The authors were interested in better understanding what, other than guilt, determined the sentencing outcomes of defendants. They decided to focus on the judge in part because judges were being randomly rotated to defendants. And since they were being “by chance” rotated to defendants, in a large sample, the characteristics of the defendants should’ve remained approximately the same across all judges. Any differences in sentencing outcomes, therefore, wouldn’t be because of the underlying charge or even the defendant’s guilt, but rather, would be connected to the judge. See Figure <a href="ch6.html#fig:seth-judges">7.7</a> for a beautiful drawing of this identification strategy based on over 7,000 hand collected cases showing systematic differences in judge sentencing behavior.</p>
<div class="figure">
<span id="fig:gaudet1"></span>
<img src="graphics/percentages.jpg" alt="Variation in judge sentencing outcomes. This figure originally appeared in @Gaudet1933. Reprinted by special permission of Northwestern University Pritzker School of Law, *Journal of Criminal Law and Criminology*" width="100%"><p class="caption">
Figure 7.8: Variation in judge sentencing outcomes. This figure originally appeared in <span class="citation">Gaudet, Harris, and John (<a href="references.html#ref-Gaudet1933" role="doc-biblioref">1933</a>)</span>. Reprinted by special permission of Northwestern University Pritzker School of Law, <em>Journal of Criminal Law and Criminology</em>
</p>
</div>
<p>Figure <a href="ch6.html#fig:gaudet1">7.8</a> is a pretty typical graphic for any paper on judge fixed effects showing the variation in the judge’s propensities; it’s just kind of interesting that it appears from the very beginning back in 1933. And as you can see in Figure <a href="ch6.html#fig:gaudet1">7.8</a>, there is weirdly enough a lot of variation in the sentencing propensities across the six judges. Judge 2 imposed imprisonment in only 33.6% of his cases, whereas Judge 4 imposed imprisonment in a whopping 57.7%. And since they are all seeing on average the same defendants, it can’t be that Judge 4 is simply seeing worse cases. Rather, there appears to be something systematic, like a tendency for certain judges to always judge defendants more harshly. But why are they like this? <span class="citation">Gaudet, Harris, and John (<a href="references.html#ref-Gaudet1933" role="doc-biblioref">1933</a>)</span> offer the following conjecture:</p>
<blockquote>
<p>Perhaps the most interesting thing to be noticed in these graphs is the fact that the sentencing tendency of the judge seems to be fairly well determined before he sits on the bench. In other words what determines whether a judge will be severe or lenient is to be found in the environment to which the judge has been subjected previous to his becoming an administrator of sentences.</p>
</blockquote>
<p>But the main takeaway is that the authors were the first to discover that the leniency or severity of the judge, and not merely the defendant’s own guilt, plays a significant role apparently in the final determination of a case against the defendant. The authors write:</p>
<blockquote>
<p>The authors wish to point out that these results tend to show that some of our previous studies in the fields of criminology and penology are based upon very unreliable evidence if our results are typical of sentencing tendencies. In other words, what type of sentence received by a prisoner may be either an indication of the seriousness of his crime or of the severity of the judge. (p.815)</p>
</blockquote>
<p>The next mention of the explicit judge fixed effects design is in the <span class="citation">Imbens and Angrist (<a href="references.html#ref-Imbens1994" role="doc-biblioref">1994</a>)</span> article decomposing IV into the LATE parameter using potential outcomes notation. At the conclusion of their article, they provide three examples of IV designs that may or may not fit the five identifying assumptions of IV that I discussed earlier. They write:</p>
<blockquote>
<p>Example 2 (Administrative Screening): Suppose applicants for a social program are screened by two officials. The two officials are likely to have different admission rates, even if the stated admission criteria are identical. Since the identity of the official is probably immaterial to the response, it seems plausible that Condition 1 <em>independence</em> is satisfied. The instrument is binary so Condition 3 is trivially satisfied. However, Condition 2 <em>monotonicity</em> requires that if official <span class="math inline">\(A\)</span> accepts applicants with probability <span class="math inline">\(P(0)\)</span>, and official B accepts people with probability <span class="math inline">\((P1)&gt;P(0)\)</span>, official B must accept <em>any</em> applicant who would have been accepted by official <span class="math inline">\(A\)</span>. This is unlikely to hold if admission is based on a number of criteria. Therefore, in this example we <em>cannot</em> use Theorem 1 to identify a local average treatment effect nonparametrically despite the presence of an instrument satisfying Condition 1 <em>independence</em>. (p.472)</p>
</blockquote>
<p>While the first time we see the method used for any type of empirical identification is <span class="citation">Waldfogel (<a href="references.html#ref-Waldfogel1995" role="doc-biblioref">1995</a>)</span>, the first explicit IV strategy is a paper ten years later by <span class="citation">Kling (<a href="references.html#ref-Kling2006" role="doc-biblioref">2006</a>)</span>, who used randomized judge assignment with judge propensities to instrument for incarceration length. He then linked defendants to employment and earnings records, which he then used to estimate the causal effect of incarceration on labor-market outcomes. He ultimately finds no adverse effects on labor-market consequences from longer sentences in the two states he considers.</p>
<p>But this question was revisited by <span class="citation">Mueller-Smith (<a href="references.html#ref-Mike2015" role="doc-biblioref">2015</a>)</span>, who used Harris County, Texas, for his location. Harris County has dozens of courts and defendants are randomly assigned to one of them. Mueller-Smith linked defendant outcomes to a variety of labor-market and criminal outcomes, and came to the opposite conclusion as <span class="citation">Kling (<a href="references.html#ref-Kling2006" role="doc-biblioref">2006</a>)</span>. <span class="citation">Mueller-Smith (<a href="references.html#ref-Mike2015" role="doc-biblioref">2015</a>)</span> finds that incarceration generates net increases in the frequency and severity of recidivism, worsens labor-market outcomes, and increases defendant’s dependence on public assistance.</p>
<p>Judicial severity causing adverse consequences on defendants is practically a hallmark of the judge fixed effects literature. Just to name a few such examples, there is the finding that less allowance of Chapter 13 bankruptcy worsens future financial events <span class="citation">(Dobbie, Goldsmith-Pinkham, and Yang <a href="references.html#ref-Dobbie2017" role="doc-biblioref">2017</a>)</span>, racial bias among bail judges <span class="citation">(Arnold, Dobbie, and Yang <a href="references.html#ref-Dobbie2018" role="doc-biblioref">2018</a>)</span>, pretrial detention having higher rates of guilty pleas, conviction, recidivism, and worsened labor-market outcomes <span class="citation">(Leslie and Pope <a href="references.html#ref-Leslie2018" role="doc-biblioref">2018</a>; Dobbie, Goldin, and Yang <a href="references.html#ref-Dobbie2018b" role="doc-biblioref">2018</a>; Stevenson <a href="references.html#ref-Stevenson2018" role="doc-biblioref">2018</a>)</span>, juvenile incarceration worsening high school outcomes and adult recidivism rates <span class="citation">(Aizer and Doyle <a href="references.html#ref-Aizer2015" role="doc-biblioref">2015</a>)</span>, foster care raising juvenile delinquency, teen pregnancy, and worsening future employment <span class="citation">(Doyle <a href="references.html#ref-Doyle2007" role="doc-biblioref">2007</a>)</span>, foster care increasing adult crime <span class="citation">(Doyle <a href="references.html#ref-Doyle2008" role="doc-biblioref">2008</a>)</span>, and countless others. But there are a few exceptions. For instance, <span class="citation">Norris, Pecenco, and Weaver (<a href="references.html#ref-Norris2020" role="doc-biblioref">2020</a>)</span> find beneficial effects to children when the marginal siblings and parents are incarcerated.</p>
<p>The three main identifying assumptions that should be on the researcher’s mind when attempting to implement a judge fixed effects design are the independence assumption, exclusion restriction, and the monotonicity assumption. Let’s discuss them each at a time because, in some scenarios, one of these may be more credible than the other.</p>
<p>The independence assumption seems to be satisfied in many cases because the administrators in question are literally being randomly assigned to individual cases. As such, our instrument—which is sometimes modeled as the average propensity of the judge excluding the case in question or simply as a series of judge fixed effects (which, as I’ll mention in a moment, turns out to be equivalent)—easily passes the independence test. But it’s possible that strategic behavior on the part of the defendant in response to the strictness of the judge they were assigned can undermine the otherwise random assignment. Consider something that <span class="citation">Gaudet, Harris, and John (<a href="references.html#ref-Gaudet1933" role="doc-biblioref">1933</a>)</span> observed in their original study regarding the dynamics of the courtroom when randomly assigned a severe judge:</p>
<blockquote>
<p>The individual tendencies in the sentencing tendencies of judges are evidently recognized by many who are accustomed to observe this sentencing. The authors have been told by several lawyers that some recidivists know the sentencing tendencies of judges so well that the accused will frequently attempt to choose which judge is to sentence them, and further, some lawyers say that they are frequently able to do this. It is said to be done in this way. If the prisoner sees that he is going to be sentenced by Judge X, whom he believes to be severe in his sentencing tendency, he will change his plea from “Guilty” to “Non Vult” or from “Non Vult” to “Not Guilty,” etc. His hope is that in this way the sentencing will be postponed and hence he will probably be sentenced by another judge. (p.812)</p>
</blockquote>
<p>There are several approaches one can take to assessing independence. First, checking for balance on pre-treatment covariates is an absolute must. Insofar as this is a randomized experiment, then all observable and unobservable characteristics will be distributed equally across the judges. While we cannot check for balance on unobservables, we can check for balance on observables. Most papers of which I am aware check for covariate balance, usually before doing any actual analysis.</p>
<p>Insofar as you suspect endogenous sorting, you might simply use the original assignment, not the final assignment, for identification. This is because in most cases, we will know the initial judge assignment was random. But this approach may not be feasible in many settings if initial judge or court assignment is not available. Nevertheless, endogenous sorting in response to the severity of the judge could undermine the design by introducing a separate mechanism by which the instrument impacts the final decision (via sorting into the lenient judge’s courtroom if possible), and the researcher should attempt to ascertain through conversations with administrators the degree to which this practically occurs in the data.</p>
<p>The violation of exclusion is more often the worry, though, and really should be evaluated case by case. For instance, in <span class="citation">Dobbie, Goldin, and Yang (<a href="references.html#ref-Dobbie2018b" role="doc-biblioref">2018</a>)</span>, the authors are focused on pretrial detention. But pretrial detention is determined by bail set by judges who do not themselves have any subsequent interaction with the next level’s randomized judge, and definitely don’t have any interaction with the defendant upon the judicial ruling and punishment rendered. So in this case, it does seem like <span class="citation">Dobbie, Goldin, and Yang (<a href="references.html#ref-Dobbie2018b" role="doc-biblioref">2018</a>)</span> might have a more credible argument that exclusion holds.</p>
<p>But consider a situation where a defendant is randomly assigned a severe judge. In expectation, if the case goes to trial, the defendant faces a higher expected penalty even given a fixed probability of conviction across any judge for no other reason than that the stricter judge will likely choose a harsher penalty and thus drive up the expected penalty. Facing this higher expected penalty, the defense attorney and defendant might decide to accept a lesser plea in response to the judge’s anticipated severity, which would violate exclusion since exclusion requires the instrument effect the outcome only through the judge’s decision (sentence).</p>
<p>But even if exclusion can be defended, in many situations monotonicity becomes the more difficult case to make for this design. It was explicitly monotonicity that made <span class="citation">Imbens and Angrist (<a href="references.html#ref-Imbens1994" role="doc-biblioref">1994</a>)</span> skeptical that judge fixed effects could be used to identify the local average treatment effect. This is because the instrument is required to weakly operate the same across all defendants. Either a judge is strict or she isn’t, but she can’t be both in different circumstances. Yet humans are complex bundles of thoughts and experiences, and those biases may operate in non-transitive ways. For instance, a judge may be lenient, except when the defendant is black or if the offense is a drug charge, in which case they switch and become strict. <span class="citation">Mueller-Smith (<a href="references.html#ref-Mike2015" role="doc-biblioref">2015</a>)</span> attempted to overcome potential violations of exclusion and monotonicity through a parametric strategy of simultaneously instrumenting for all observed sentencing dimensions and thus allowing the instruments’ effect on sentencing outcomes to be heterogeneous in defendant traits and crime characteristics.</p>
<p>Formal solutions to querying the plausibility of these assumptions have appeared in recent years, though. <span class="citation">Frandsen, Lefgren, and Leslie (<a href="references.html#ref-Frandsen2019" role="doc-biblioref">2019</a>)</span> propose a test for exclusion and monotonicity based on relaxing the monotonicity assumption. This test requires that the average treatment effect among individuals who violate monotonicity be identical to the average treatment effect among some subset of individuals who satisfy it. Their test simultaneously tests for exclusion and monotonicity, so one cannot be sure which violation is driving the test’s result unless theoretically one rules out one of the two using a priori information. Their proposed test is based on two observations: that the average outcomes, conditional on judge assignment, should fit a continuous function of judge propensities, and secondly, the slope of that continuous function should be bounded in magnitude by the width of the outcome variable’s support. The test itself is relatively straightforward and simply requires examining whether observed outcomes averaged by judges are consistent with such a function. We can see a picture of what it looks like to pass this test in the top panel of Figure <a href="ch6.html#fig:emily1">7.9</a> versus the bottom panel, which fails the test.</p>
<div class="figure">
<span id="fig:emily1"></span>
<img src="graphics/emily1.jpg" alt="Average outcomes as a function of judge propensities. Reprinted from @Frandsen2019." width="100%"><p class="caption">
Figure 7.9: Average outcomes as a function of judge propensities. Reprinted from <span class="citation">Frandsen, Lefgren, and Leslie (<a href="references.html#ref-Frandsen2019" role="doc-biblioref">2019</a>)</span>.
</p>
</div>
<p>While the authors have made available code and documentation that can be used to implement this test,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;See Emily Leslie’s website &lt;a href="https://sites.google.com/view/emilycleslie/home/research" class="uri"&gt;https://sites.google.com/view/emilycleslie/home/research&lt;/a&gt; to download the Stata ado package.&lt;/p&gt;'><sup>126</sup></a> it is not currently available in R and therefore will not be reviewed here.</p>
<p>In this section, I’d like to accomplish two things. First, I’d like to review an interesting new paper by Megan Stevenson that examined how cash bail affected case outcomes <span class="citation">(Stevenson <a href="references.html#ref-Stevenson2018" role="doc-biblioref">2018</a>)</span>. As this is an important policy question, I felt it would be good to review this excellent study. But the second purpose of this section is to replicate her main results so that the reader can see exactly how to implement this instrumental variables strategy.</p>
<p>As with most judge fixed effects papers, Stevenson is working with administrative data for a large city. Large cities are probably the best context due to the large samples which can help ameliorate the finite sample bias of IV. Fortunately, these data are often publicly available and need only be scraped from court records that are in many locations posted online. <span class="citation">Stevenson (<a href="references.html#ref-Stevenson2018" role="doc-biblioref">2018</a>)</span> focuses on Philadelphia, where the natural experiment is the random assignment of bail judges (“magistrates”) who unsurprisingly differ widely in their propensity to set bail at affordable levels. In other words, bail judges differ systematically in the price they set for bail, and given a downward-sloping demand curve, more severe judges setting expensive bails will see more defendants unable to pay their bail. As a result, they are forced to remain in detention prior to the trial.</p>
<p>Using a variety of IV estimators, <span class="citation">Stevenson (<a href="references.html#ref-Stevenson2018" role="doc-biblioref">2018</a>)</span> finds that an increase in randomized pretrial detention leads to a 13% increase in the likelihood of receiving a conviction. She argues that this is caused by an increase in guilty pleas among defendants who otherwise would have been acquitted or had their charges dropped—a particularly problematic mechanism, if true. Pretrial detention also led to a 42% increase in the length of the incarceration sentence and a 41% increase in the amount of non-bail fees owed. This provides support for idea that cash bail contributes to a cycle of poverty in which defendants unable to pay their court fees end up trapped in the penal system through higher rates of guilt, higher court fees, and likely higher rates of reoffending <span class="citation">(Dobbie, Goldin, and Yang <a href="references.html#ref-Dobbie2018b" role="doc-biblioref">2018</a>)</span>.</p>
<p>One might think that the judge fixed effects design is a “just identified” model. Can’t we just use as our instrument the average strictness for each judge (excluding the defendant’s own case)? Then we have just one instrument for our one endogenous variable, and 2SLS seems like a likely candidate, right? After all, that one instrument would be unique to each individual because each individual would have a unique judge and a unique average strictness if average strictness was calculated as the mean of all judge sentencing excluding the individual under consideration.</p>
<p>The problem is that this is still just a high-dimension instrument. The correct specification is to use the actual judge fixed effects, and depending on your application you may have anywhere from eight (as in Stevenson’s case) to hundreds of judges. Insofar as some of these are weak, which they probably will be, you run into a typical kind of overidentification problem where in finite samples you begin moving the point estimates back to centering on the OLS bias as I discussed earlier. This issue is still being resolved by econometricians and is likely to be an active area of research going forward. Some solutions may be to use high-dimension reduction techniques such as LASSO <span class="citation">(Gilchrist and Sands <a href="references.html#ref-Gilchrist2016" role="doc-biblioref">2016</a>)</span>, instrument selection <span class="citation">(Donald and Newey <a href="references.html#ref-Donald2001" role="doc-biblioref">2001</a>)</span>, or perhaps combining individual judges with similar strictness into only one instrument.</p>
<p>Stevenson’s data contains 331,971 observations and eight randomly assigned bail judges. Like many papers in the judge fixed effects literature, she uses the jackknife instrumental variables estimator (JIVE) <span class="citation">(Angrist, Imbens, and Krueger <a href="references.html#ref-Angrist1999c" role="doc-biblioref">1999</a>)</span>. While 2SLS is the most commonly used IV estimator in applied microeconomics applications, it suffers from finite sample problems when there are weak instruments and the use of many instruments as we showed with the discussion of <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-Bound1995" role="doc-biblioref">1995</a>)</span>. <span class="citation">Angrist, Imbens, and Krueger (<a href="references.html#ref-Angrist1999c" role="doc-biblioref">1999</a>)</span> proposed an estimator that attempts to eliminate the finite-sample bias of 2SLS called JIVE.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Best name for an estimator ever.&lt;/p&gt;"><sup>127</sup></a> These aren’t perfect, as their distributions are larger than that of the 2SLS estimator, but they may have an advantage when there are several instruments and some of which are weak (as is likely to occur with judge fixed effects).</p>
<p>JIVE is popularly known as a “leave one out” estimator. <span class="citation">Angrist, Imbens, and Krueger (<a href="references.html#ref-Angrist1999c" role="doc-biblioref">1999</a>)</span> suggest using all observations in this estimator except for the <span class="math inline">\(i\)</span> unit. This is the nice feature for judge fixed effects because ideally the instrument is the mean strictness of the judge <em>in all other cases</em>, excluding the particular defendant’s case. So JIVE is nice both for its handling of the finite sample bias, and for its construction of the theoretical instrument more generally.</p>
<p>Given the econometrics of judge fixed effects with its many instruments is potentially the frontier of econometrics, my goal here will be somewhat backwards looking. We will simply run through some simple exercises using JIVE so that you can see how historically researchers are estimating their models.</p>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/Do/bail.do"><code>bail.do</code></a></em></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode stata"><code class="sourceCode stata"><span id="cb81-1"><a href="ch6.html#cb81-1" aria-hidden="true"></a><span class="kw">use</span> https:<span class="co">//github.com/scunning1975/mixtape/raw/master/judge_fe.dta, clear</span></span>
<span id="cb81-2"><a href="ch6.html#cb81-2" aria-hidden="true"></a> </span>
<span id="cb81-3"><a href="ch6.html#cb81-3" aria-hidden="true"></a><span class="kw">global</span> judge_pre judge_pre_1 judge_pre_2 judge_pre_3 judge_pre_4 judge_pre_5 judge_pre_6 judge_pre_7 judge_pre_8</span>
<span id="cb81-4"><a href="ch6.html#cb81-4" aria-hidden="true"></a><span class="kw">global</span> demo <span class="bn">black</span> age male <span class="bn">white</span> </span>
<span id="cb81-5"><a href="ch6.html#cb81-5" aria-hidden="true"></a><span class="kw">global</span> <span class="kw">off</span>      fel mis <span class="kw">sum</span> F1 F2 F3 <span class="fu">F</span> M1 M2 M3 M </span>
<span id="cb81-6"><a href="ch6.html#cb81-6" aria-hidden="true"></a><span class="kw">global</span> prior priorCases priorWI5 prior_felChar  prior_guilt onePrior threePriors</span>
<span id="cb81-7"><a href="ch6.html#cb81-7" aria-hidden="true"></a><span class="kw">global</span> control2     <span class="fu">day</span> day2 day3  bailDate t1 t2 t3 t4 t5 t6</span>
<span id="cb81-8"><a href="ch6.html#cb81-8" aria-hidden="true"></a></span>
<span id="cb81-9"><a href="ch6.html#cb81-9" aria-hidden="true"></a></span>
<span id="cb81-10"><a href="ch6.html#cb81-10" aria-hidden="true"></a>* Naive OLS</span>
<span id="cb81-11"><a href="ch6.html#cb81-11" aria-hidden="true"></a>* minimum controls</span>
<span id="cb81-12"><a href="ch6.html#cb81-12" aria-hidden="true"></a><span class="kw">reg</span> guilt jail3 <span class="ot">$control2</span>, <span class="kw">robust</span></span>
<span id="cb81-13"><a href="ch6.html#cb81-13" aria-hidden="true"></a>* maximum controls</span>
<span id="cb81-14"><a href="ch6.html#cb81-14" aria-hidden="true"></a><span class="kw">reg</span> guilt jail3 possess robbery DUI1st drugSell aggAss <span class="ot">$demo</span> <span class="ot">$prior</span> <span class="ot">$off</span>  <span class="ot">$control2</span> , <span class="kw">robust</span></span>
<span id="cb81-15"><a href="ch6.html#cb81-15" aria-hidden="true"></a></span>
<span id="cb81-16"><a href="ch6.html#cb81-16" aria-hidden="true"></a></span>
<span id="cb81-17"><a href="ch6.html#cb81-17" aria-hidden="true"></a>* First stage</span>
<span id="cb81-18"><a href="ch6.html#cb81-18" aria-hidden="true"></a><span class="kw">reg</span> jail3 <span class="ot">$judge_pre</span> <span class="ot">$control2</span>, <span class="kw">robust</span></span>
<span id="cb81-19"><a href="ch6.html#cb81-19" aria-hidden="true"></a><span class="kw">reg</span> jail3 possess robbery DUI1st drugSell aggAss <span class="ot">$demo</span> <span class="ot">$prior</span> <span class="ot">$off</span>  <span class="ot">$control2</span> <span class="ot">$judge_pre</span>, <span class="kw">robust</span></span>
<span id="cb81-20"><a href="ch6.html#cb81-20" aria-hidden="true"></a></span>
<span id="cb81-21"><a href="ch6.html#cb81-21" aria-hidden="true"></a></span>
<span id="cb81-22"><a href="ch6.html#cb81-22" aria-hidden="true"></a></span>
<span id="cb81-23"><a href="ch6.html#cb81-23" aria-hidden="true"></a>** Instrumental variables estimation</span>
<span id="cb81-24"><a href="ch6.html#cb81-24" aria-hidden="true"></a>* 2sls main results</span>
<span id="cb81-25"><a href="ch6.html#cb81-25" aria-hidden="true"></a>* minimum controls</span>
<span id="cb81-26"><a href="ch6.html#cb81-26" aria-hidden="true"></a>ivregress 2sls guilt (jail3= <span class="ot">$judge_pre</span>) <span class="ot">$control2</span>, <span class="kw">robust</span> first</span>
<span id="cb81-27"><a href="ch6.html#cb81-27" aria-hidden="true"></a>* maximum controls</span>
<span id="cb81-28"><a href="ch6.html#cb81-28" aria-hidden="true"></a>ivregress 2sls guilt (jail3= <span class="ot">$judge_pre</span>) possess robbery DUI1st drugSell aggAss <span class="ot">$demo</span> <span class="ot">$prior</span> <span class="ot">$off</span> <span class="ot">$control2</span> , <span class="kw">robust</span> first</span>
<span id="cb81-29"><a href="ch6.html#cb81-29" aria-hidden="true"></a></span>
<span id="cb81-30"><a href="ch6.html#cb81-30" aria-hidden="true"></a>* JIVE main results</span>
<span id="cb81-31"><a href="ch6.html#cb81-31" aria-hidden="true"></a>* minimum controls</span>
<span id="cb81-32"><a href="ch6.html#cb81-32" aria-hidden="true"></a>jive guilt (jail3= <span class="ot">$judge_pre</span>) <span class="ot">$control2</span>, <span class="kw">robust</span></span>
<span id="cb81-33"><a href="ch6.html#cb81-33" aria-hidden="true"></a>* maximum controls</span>
<span id="cb81-34"><a href="ch6.html#cb81-34" aria-hidden="true"></a>jive guilt (jail3= <span class="ot">$judge_pre</span>) possess robbery DUI1st drugSell aggAss <span class="ot">$demo</span> <span class="ot">$prior</span> <span class="ot">$off</span> <span class="ot">$control2</span> , <span class="kw">robust</span></span></code></pre></div>
<p><em><a href="https://github.com/scunning1975/mixtape/blob/master/R/bail.R"><code>bail.R</code></a></em></p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haven.tidyverse.org">haven</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">estimatr</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/sgaure/lfe">lfe</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">SteinIV</span><span class="op">)</span>

<span class="va">read_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">{</span>
  <span class="va">full_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"https://raw.github.com/scunning1975/mixtape/master/"</span>, 
                     <span class="va">df</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://haven.tidyverse.org/reference/read_dta.html">read_dta</a></span><span class="op">(</span><span class="va">full_path</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">judge</span> <span class="op">&lt;-</span> <span class="fu">read_data</span><span class="op">(</span><span class="st">"judge_fe.dta"</span><span class="op">)</span>

<span class="co">#grouped variable names from the data set</span>
<span class="va">judge_pre</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">starts_with</a></span><span class="op">(</span><span class="st">"judge_"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">.</span>, <span class="va">.</span> <span class="op">!=</span> <span class="st">"judge_pre_8"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="co"># remove one for colinearity</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">.</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span>

<span class="va">demo</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">black</span>, <span class="va">age</span>, <span class="va">male</span>, <span class="va">white</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">.</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span>

<span class="va">off</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">fel</span>, <span class="va">mis</span>, <span class="va">sum</span>, <span class="va">F1</span>, <span class="va">F2</span>, <span class="va">F3</span>, <span class="va">M1</span>, <span class="va">M2</span>, <span class="va">M3</span>, <span class="va">M</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">.</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span>

<span class="va">prior</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">priorCases</span>, <span class="va">priorWI5</span>, <span class="va">prior_felChar</span>, 
         <span class="va">prior_guilt</span>, <span class="va">onePrior</span>, <span class="va">threePriors</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">.</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span>

<span class="va">control2</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bailDate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">bailDate</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">day</span>, <span class="va">day2</span>, <span class="va">bailDate</span>, 
         <span class="va">t1</span>, <span class="va">t2</span>, <span class="va">t3</span>, <span class="va">t4</span>, <span class="va">t5</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="co"># all but one time period for colinearity</span>
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">.</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span>

<span class="co">#formulas used in the OLS</span>
<span class="va">min_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"guilt ~ jail3 + "</span>, <span class="va">control2</span><span class="op">)</span><span class="op">)</span>
<span class="va">max_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"guilt ~ jail3 + possess + robbery + DUI1st + drugSell + aggAss"</span>,
                                <span class="va">demo</span>, <span class="va">prior</span>, <span class="va">off</span>, <span class="va">control2</span>, sep <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span>

<span class="co">#max variables and min variables</span>
<span class="va">min_ols</span> <span class="op">&lt;-</span> <span class="fu">lm_robust</span><span class="op">(</span><span class="va">min_formula</span>, data <span class="op">=</span> <span class="va">judge</span><span class="op">)</span>
<span class="va">max_ols</span> <span class="op">&lt;-</span> <span class="fu">lm_robust</span><span class="op">(</span><span class="va">max_formula</span>, data <span class="op">=</span> <span class="va">judge</span><span class="op">)</span>

<span class="co">#--- Instrumental Variables Estimations</span>
<span class="co">#-- 2sls main results</span>
<span class="co">#- Min and Max Control formulas</span>
<span class="va">min_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"guilt ~ "</span>, <span class="va">control2</span>, <span class="st">" | 0 | (jail3 ~ 0 +"</span>, <span class="va">judge_pre</span>, <span class="st">")"</span><span class="op">)</span><span class="op">)</span>
<span class="va">max_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"guilt ~"</span>, <span class="va">demo</span>, <span class="st">"+ possess +"</span>, <span class="va">prior</span>, <span class="st">"+ robbery +"</span>, 
                                <span class="va">off</span>, <span class="st">"+ DUI1st +"</span>, <span class="va">control2</span>, <span class="st">"+ drugSell + aggAss | 0 | (jail3 ~ 0 +"</span>, <span class="va">judge_pre</span>, <span class="st">")"</span><span class="op">)</span><span class="op">)</span>
<span class="co">#2sls for min and max</span>
<span class="va">min_iv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lfe/man/felm.html">felm</a></span><span class="op">(</span><span class="va">min_formula</span>, data <span class="op">=</span> <span class="va">judge</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">min_iv</span><span class="op">)</span>
<span class="va">max_iv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lfe/man/felm.html">felm</a></span><span class="op">(</span><span class="va">max_formula</span>, data <span class="op">=</span> <span class="va">judge</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">max_iv</span><span class="op">)</span>



<span class="co">#-- JIVE main results</span>
<span class="co">#- minimum controls</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">guilt</span><span class="op">)</span>

<span class="va">X_min</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bailDate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">bailDate</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">jail3</span>, <span class="va">day</span>, <span class="va">day2</span>, <span class="va">t1</span>, <span class="va">t2</span>, <span class="va">t3</span>, <span class="va">t4</span>, <span class="va">t5</span>, <span class="va">bailDate</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">.</span>,<span class="op">~</span><span class="va">.</span><span class="op">)</span>

<span class="va">Z_min</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bailDate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">bailDate</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">judge_pre_8</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">starts_with</a></span><span class="op">(</span><span class="st">"judge_pre"</span><span class="op">)</span>, <span class="va">day</span>, <span class="va">day2</span>, <span class="va">t1</span>, <span class="va">t2</span>, <span class="va">t3</span>, <span class="va">t4</span>, <span class="va">t5</span>, <span class="va">bailDate</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">.</span>,<span class="op">~</span><span class="va">.</span><span class="op">)</span>

<span class="fu">jive.est</span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, X <span class="op">=</span> <span class="va">X_min</span>, Z <span class="op">=</span> <span class="va">Z_min</span><span class="op">)</span>

<span class="co">#- maximum controls</span>
<span class="va">X_max</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bailDate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">bailDate</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">jail3</span>, <span class="va">white</span>, <span class="va">age</span>, <span class="va">male</span>, <span class="va">black</span>,
         <span class="va">possess</span>, <span class="va">robbery</span>, <span class="va">prior_guilt</span>,
         <span class="va">prior_guilt</span>, <span class="va">onePrior</span>, <span class="va">priorWI5</span>, <span class="va">prior_felChar</span>, <span class="va">priorCases</span>,
         <span class="va">DUI1st</span>, <span class="va">drugSell</span>, <span class="va">aggAss</span>, <span class="va">fel</span>, <span class="va">mis</span>, <span class="va">sum</span>,
         <span class="va">threePriors</span>,
         <span class="va">F1</span>, <span class="va">F2</span>, <span class="va">F3</span>,
         <span class="va">M</span>, <span class="va">M1</span>, <span class="va">M2</span>, <span class="va">M3</span>,
         <span class="va">day</span>, <span class="va">day2</span>, <span class="va">bailDate</span>, 
         <span class="va">t1</span>, <span class="va">t2</span>, <span class="va">t3</span>, <span class="va">t4</span>, <span class="va">t5</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">.</span>,<span class="op">~</span><span class="va">.</span><span class="op">)</span>

<span class="va">Z_max</span> <span class="op">&lt;-</span> <span class="va">judge</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bailDate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">bailDate</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">judge_pre_8</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">starts_with</a></span><span class="op">(</span><span class="st">"judge_pre"</span><span class="op">)</span>, <span class="va">white</span>, <span class="va">age</span>, <span class="va">male</span>, <span class="va">black</span>,
         <span class="va">possess</span>, <span class="va">robbery</span>, <span class="va">prior_guilt</span>,
         <span class="va">prior_guilt</span>, <span class="va">onePrior</span>, <span class="va">priorWI5</span>, <span class="va">prior_felChar</span>, <span class="va">priorCases</span>,
         <span class="va">DUI1st</span>, <span class="va">drugSell</span>, <span class="va">aggAss</span>, <span class="va">fel</span>, <span class="va">mis</span>, <span class="va">sum</span>,
         <span class="va">threePriors</span>,
         <span class="va">F1</span>, <span class="va">F2</span>, <span class="va">F3</span>,
         <span class="va">M</span>, <span class="va">M1</span>, <span class="va">M2</span>, <span class="va">M3</span>,
         <span class="va">day</span>, <span class="va">day2</span>, <span class="va">bailDate</span>, 
         <span class="va">t1</span>, <span class="va">t2</span>, <span class="va">t3</span>, <span class="va">t4</span>, <span class="va">t5</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">.</span>,<span class="op">~</span><span class="va">.</span><span class="op">)</span>

<span class="fu">jive.est</span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, X <span class="op">=</span> <span class="va">X_max</span>, Z <span class="op">=</span> <span class="va">Z_max</span><span class="op">)</span></code></pre></div>
<p>These results are pretty interesting. Notice that if we just were to examine this using OLS, you’d conclude there was actually no connection between pre-trial detention and a guilty plea. It was either zero using only time controls, or it raised the probability 3% with our fuller set of controls (mainly demographic controls, prior offenses, and the characteristics of the offense itself). But, when we use IV with the binary judge fixed effects as instruments, the effects change a lot. We end up with estimates ranging from 15 to 21%, and of these probably we should be more focused on JIVE because of its advantages, as previously mentioned. You can examine the strength of the instruments yourself by regressing detention onto the binary instruments to see just how strong the instruments are, but they are very strong. All but two are statistically significant at the 1% level. Of the other two, one has a <em>p</em>-value of 0.076 and the other is weak <span class="math inline">\((p&lt;0.25)\)</span>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:jive1">Table 7.14: </span> OLS and IV Estimates of Detention on Guilty Plea</caption>
<thead><tr class="header">
<th align="left">Model:</th>
<th align="center">OLS</th>
<th></th>
<th align="center">2SLS</th>
<th></th>
<th align="center">JIVE</th>
<th></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Detention</td>
<td align="center">-0.001</td>
<td>0.029<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.151<span class="math inline">\(^{**}\)</span>
</td>
<td>0.186<span class="math inline">\(^{***}\)</span>
</td>
<td align="center">0.162<span class="math inline">\(^{**}\)</span>
</td>
<td>0.212<span class="math inline">\(^{***}\)</span>
</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">(0.002)</td>
<td>(0.002)</td>
<td align="center">(0.065)</td>
<td>(0.064)</td>
<td align="center">(0.070)</td>
<td>(0.076)</td>
</tr>
<tr class="odd">
<td align="left">N</td>
<td align="center">331,971</td>
<td>331,971</td>
<td align="center">331,971</td>
<td>331,971</td>
<td align="center">331,971</td>
<td>331,971</td>
</tr>
<tr class="even">
<td align="left">Mean guilt</td>
<td align="center">0.49</td>
<td>0.49</td>
<td align="center">0.49</td>
<td>0.49</td>
<td align="center">0.49</td>
<td>0.49</td>
</tr>
</tbody>
</table></div>
<p class="footnote">
First model includes controls for time; second model controls for characteristics of the defendant. Outcome is guilty plea. Heteroskedastic robust standard errors in parenthesis. <span class="math inline">\(^{*}\)</span> <span class="math inline">\(p&lt;0.10\)</span>, <span class="math inline">\(^{**}\)</span> <span class="math inline">\(p&lt;0.05\)</span>, <span class="math inline">\(^{***}\)</span> <span class="math inline">\(p&lt;0.01\)</span>
</p>
<p>The judge fixed effects design is a very popular form of instrumental variables. It is used whenever there exists a wheel of randomly assigned decision makers assigning a treatment of some kind to other people. Important questions and answers in the area of criminal justice have been examined using this design. When linked with external administrative data sources, researchers have been able to more carefully evaluate the causal effect of criminal justice interventions on long-term outcomes. But the procedure has uniquely sensitive identifying assumptions related to independence, exclusion, and monotonicity that must be carefully contemplated before going forward with the design. Nevertheless, when those assumptions can be credibly defended, it is a powerful estimator of local average treatment effects.</p>
</div>
<div id="bartik-instruments" class="section level3" number="7.8.3">
<h3>
<span class="header-section-number">7.8.3</span> Bartik instruments<a class="anchor" aria-label="anchor" href="#bartik-instruments"><i class="fas fa-link"></i></a>
</h3>
<p>Bartik instruments, also known as shift-share instruments, were named after Timothy Bartik, who used them in a careful study of regional labor-markets <span class="citation">(Bartik <a href="references.html#ref-Bartik1991" role="doc-biblioref">1991</a>)</span>. Both Bartik’s book and the instrument received wider attention the following year with <span class="citation">Blanchard and Katz (<a href="references.html#ref-Blanchard1992" role="doc-biblioref">1992</a>)</span>. It has been particularly influential in the areas of migration and trade, as well as labor, public, and several other fields. A simple search for the phrase “Bartik instrument” on Google Scholar reveals almost five hundred cites at the time of this writing.</p>
<p>But just as Stigler’s law of eponymy promises <span class="citation">(Stigler <a href="references.html#ref-Stigler1980" role="doc-biblioref">1980</a>)</span>, Bartik instruments do not originate with <span class="citation">Bartik (<a href="references.html#ref-Bartik1991" role="doc-biblioref">1991</a>)</span>. <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> notes that traces of it can be found as early as <span class="citation">Perloff (<a href="references.html#ref-Perloff1957" role="doc-biblioref">1957</a>)</span> who showed that industry shares could be used to predict income levels. <span class="citation">Freeman (<a href="references.html#ref-Freeman1980" role="doc-biblioref">1980</a>)</span> also used the change in industry composition as an instrument for labor demand. But due to Bartik’s careful empirical analysis using the instrument combined with his detailed exposition of the logic of how the national growth shares created variation in labor-market demand in Appendix 4 of his book, the design has been named after him.</p>
<p>OLS estimates of the effect of employment growth rates on labor-market outcomes are likely hopelessly biased since labor-market outcomes are simultaneously determined by labor supply and labor demand. Bartik therefore suggested using IV to resolve the issue and in Appendix 4 describes the ideal instrument.</p>
<blockquote>
<p>Obvious candidates for instruments are variables shifting MSA labor demand. In this book, only one type of demand shifter is used to form instrumental variables: the share effect from a shift-share analysis of each metropolitan area and year-to-year employment change. A shift-share analysis decomposes MSA growth into three components: a national growth component, which calculates what growth would have occurred if all industries in the MSA had grown at the all-industry national average; a share component, which calculates what extra growth would have occurred if each industry in the MSA had grown at that industry’s national average; and a shift component, which calculates the extra growth that occurs because industries grow at different rates locally than they do nationally. <span class="citation">(Bartik <a href="references.html#ref-Bartik1991" role="doc-biblioref">1991</a>)</span>(p.202)</p>
</blockquote>
<p>Summarizing all of this, the idea behind a Bartik instrument is to measure the change in a region’s labor demand due to changes in the national demand for different industries’ products.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="citation"&gt;Goldsmith-Pinkham, Sorkin, and Swift (&lt;a href="references.html#ref-Pinkham2020" role="doc-biblioref"&gt;2020&lt;/a&gt;)&lt;/span&gt; note that many instruments have Bartik features. They describe an instrument as “Bartik-like” if it uses the inner product structure of the endogenous variable to construct an instrument.&lt;/p&gt;'><sup>128</sup></a> To make this concrete, let’s assume that we are interested in estimating the following wage equation:</p>
<p><span class="math display">\[\begin{align}
   Y_{l,t} = \alpha + \delta I_{l,t} + \rho X_{l,t} + \varepsilon_{l,t}
\end{align}\]</span></p>
<p>where <span class="math inline">\(Y_{l,t}\)</span> is log wages in location <span class="math inline">\(l\)</span> (e.g., Detroit) in time period <span class="math inline">\(t\)</span> (e.g., 2000) among native workers, <span class="math inline">\(I_{l,t}\)</span> are immigration flows in region <span class="math inline">\(l\)</span> at time period <span class="math inline">\(t\)</span> and <span class="math inline">\(X_{l,t}\)</span> are controls that include region and time fixed effects, among other things. The parameter <span class="math inline">\(\delta\)</span> as elsewhere is some average treatment effect of the immigration flows’ effect on native wages. The problem is that it is almost certainly the case that immigration flows are highly correlated with the disturbance term such as the time-varying characteristics of location <span class="math inline">\(l\)</span> (e.g., changing amenities) <span class="citation">(Sharpe <a href="references.html#ref-Sharpe2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>The Bartik instrument is created by interacting initial “shares” of geographic regions, prior to the contemporaneous immigration flow, with national growth rates. The deviations of a region’s growth from the US national average are explained by deviations in the growth prediction variable from the US national average. And deviations of the growth prediction variables from the US national average are due to the shares because the national growth effect for any particular time period is the same for all regions. We can define the Bartik instrument as follows:</p>
<p><span class="math display">\[\begin{align}
   {B}_{l,t} = \sum_{k=1}^K z_{l,k,t^0} m_{k,t}
\end{align}\]</span></p>
<p>where <span class="math inline">\(z_{l,k,t^0}\)</span> are the “initial” <span class="math inline">\(t^0\)</span> share of immigrants from source country <span class="math inline">\(k\)</span> (e.g., Mexico) in location <span class="math inline">\(l\)</span> (e.g., Detroit) and <span class="math inline">\(m_{k,t}\)</span> is the change in immigration from country <span class="math inline">\(k\)</span> (e.g., Mexico) into the US as a whole. The first term is the share variable and the second term is the shift variable. The predicted flow of immigrants, <span class="math inline">\({B}\)</span>, into destination <span class="math inline">\(l\)</span> (e.g., Detroit) is then just a weighted average of the national inflow rates from each country in which weights depend on the initial distribution of immigrants.</p>
<p>Once we have constructed our instrument, we have a two-stage least squares estimator that first regresses the endogenous <span class="math inline">\(I_{l,t}\)</span> onto the controls and our Bartik instrument. Using the fitted values from that regression, we then regress <span class="math inline">\(Y_{l,t}\)</span> onto <span class="math inline">\(\widehat{I}_{l,t}\)</span> to recover the impact of immigration flows onto log wages.</p>
</div>
<div id="shifts-vs-shares" class="section level3" number="7.8.4">
<h3>
<span class="header-section-number">7.8.4</span> Shifts vs Shares<a class="anchor" aria-label="anchor" href="#shifts-vs-shares"><i class="fas fa-link"></i></a>
</h3>
<p>I’d like to now turn to the identifying assumptions that are unique to this design. There are two perspectives as to what is needed to leverage a Bartik design to identify a causal effect and they separately address the roles of the exogeneity of the shares versus the shifts. Which perspective you take will depend on the ex ante plausibility of certain assumptions. They will also depend on different tools.</p>
<p><span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> explain the shares perspective. They show that while the shifts affect the strength of the first stage, it is actually the initial shares that provide the exogenous variation. They write that “the Bartik instrument is ‘equivalent’ to using local industry shares as instruments, and so the exogeneity condition should be interpreted in terms of the shares.” Insofar as a researcher’s application is exploiting differential exogenous exposure to common shocks, industry specific shocks, or a two-industry scenario, then it is likely that the source of exogeneity comes from the initial shares and not the shifts. This is a type of strict exogeneity assumption where the initial shares are exogenous conditional on observables, such as location fixed effects. What this means in practice is that the burden is on the researcher to argue why they believe the initial shares are indeed exogenous.</p>
<p>But while exogenous shares are sufficient, it turns out they are not necessary for identification of causal effects. Temporal shocks may provide exogeous sources of variation. <span class="citation">Borusyak, Hull, and Jaravel (<a href="references.html#ref-Hull2019" role="doc-biblioref">2019</a>)</span> explain the shifts perspective. They show that exogenous independent shocks to many industries allow a Bartik design to identify causal effects regardless of whether the shares are exogenous so long as the shocks are uncorrelated with the bias of the shares. Otherwise, it may be the shock itself that is creating exogenous variation, in which case the focus on excludability moves away from the initial shares and more towards the national shocks themselves <span class="citation">(Borusyak, Hull, and Jaravel <a href="references.html#ref-Hull2019" role="doc-biblioref">2019</a>)</span>. The authors write:</p>
<blockquote>
<p>Ultimately, the plausibility of our exogenous shocks framework, as with the alternative framework of <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> based on exogenous shares, depends on the shift-share IV application. We encourage practitioners to use shift-share instruments based on an <em>a priori</em> argument supporting the plausibility of either one of these approaches; various diagnostics and tests of the framework that is most suitable for the setting may then be applied. While <span class="citation">Borusyak, Hull, and Jaravel (<a href="references.html#ref-Hull2019" role="doc-biblioref">2019</a>)</span> develops such procedures for the “shocks” view, <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> provide different tools for the “shares” view.</p>
</blockquote>
<p>Insofar as we think about the initial shares as the instruments, and not the shocks, then we are in a world in which those initial shares are measuring differential exogenous exposures to some common shock. As the shares are equilibrium values, based on past labor supply and demand, it may be tough to justify why we should consider them exogenous to the structural unobserved determinants of some future labor-market outcome. But it turns out that that is not the critical piece. A valid Bartik design can be valid even if the shares are correlated indirectly with the levels of the outcomes; they just can’t be correlated with the differential changes associated with the national shock itself, which is a subtle but distinct point.</p>
<p>One challenge with Bartik instruments is the sheer number of shifting values. For instance, there are almost four hundred different industries in the United States. Multiplied over many time periods and the exclusion restriction becomes a bit challenging to defend. <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> provide several suggestions for evaluating the central identifying assumption in this design. For instance, if there is a pre-period, then ironically this design begins to resemble the difference-in-differences design that we will discuss in a subsequent chapter. In that case, we might test for placebos, pre-trends, and so forth.</p>
<p>Another possibility is based on the observation that the Bartik instrument is simply a specific combination of many instruments. In that sense, it bears some resemblance to the judge fixed effects design from earlier in which the judge’s propensity was itself a specific combination of many binary fixed effects. With many instruments, other options become available. If the researcher is willing to assume a null of constant treatment effects, then overidentification tests are an option. But overidentification tests can fail if there is treatment heterogeneity as opposed to exclusion not holding. Similar to <span class="citation">Borusyak, Hull, and Jaravel (<a href="references.html#ref-Hull2019" role="doc-biblioref">2019</a>)</span>, insofar as one is willing to assume cross-sectional heterogeneity in which treatment effects are constant within a location only, then <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> provides some diagnostic aids to help evaluate the plausibility of the design itself.</p>
<p>A second result in <span class="citation">Goldsmith-Pinkham, Sorkin, and Swift (<a href="references.html#ref-Pinkham2020" role="doc-biblioref">2020</a>)</span> is a decomposition of the Bartik estimator into a weighted combination of estimates where each share is an instrument. These weights, called Rotemberg weights, sum to one, and the authors note that higher valued weights indicate that those instruments are responsible for more of the identifying variation in the design itself. These weights provide insight into which of the shares get more weight in the overall estimate, which helps clarify which industry shares should be scrutinized. If regions with high weights pass some basic specification tests, then confidence in the overall identification strategy is more defensible.</p>
</div>
</div>
<div id="conclusion-5" class="section level2" number="7.9">
<h2>
<span class="header-section-number">7.9</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-5"><i class="fas fa-link"></i></a>
</h2>
<p>In conclusion, instrumental variables are a powerful design for identifying causal effects when your data suffer from selection on unobservables. But even with that in mind, it has many limitations that have in the contemporary period caused many applied researchers to eschew it. First, it only identifies the LATE under heterogeneous treatment effects, and that may or may not be a policy relevant variable. Its value ultimately depends on how closely the compliers’ average treatment effect resembles that of the other subpopulations. Second, unlike RDD, which has only one main identifying assumption (the continuity assumption), IV has up to five assumptions! Thus, you can immediately see why people find IV estimation less credible—not because it fails to identify a causal effect, but rather because it’s harder and harder to imagine a pure instrument that satisfies all five conditions.</p>
<p>But all this is to say, IV is an important strategy and sometimes the opportunity to use it will come along, and you should be prepared for when that happens by understanding it and how to implement it in practice. And where can the best instruments be found? <span class="citation">Angrist and Krueger (<a href="references.html#ref-Angrist2001" role="doc-biblioref">2001</a>)</span> note that the best instruments come from in-depth knowledge of the institutional details of some program or intervention. The things you spend your life studying will in time reveal good instruments. Rarely will you find them from simply downloading a new data set, though. Intimate familiarity is how you find instrumental variables, and there is, alas, no shortcut to achieving that.</p>
<div class="cover-box">
<div class="row">
    <div class="col-xs-8 col-md-4 cover-img">
        <a href="https://www.amazon.com/dp/0300251688"><img src="../images/cover.jpg" alt="Buy Today!"></a>
    </div>
    
    <div class="col-xs-12 col-md-8 cover-text-box">
            <h2> 
                Causal Inference: 
                <br><span style="font-style: italic; font-weight:bold; font-size: 20px;">The Mixtape.</span>
            </h2> 
            
        <div class="cover-text">
            <p>Buy the print version today:</p>
            
            <div class="chips">
                <a href="https://www.amazon.com/dp/0300251688" class="app-chip"> 
                    <i class="fab fa-amazon" aria-hidden="true"></i> Buy from Amazon 
                </a>
    
                <a href="https://yalebooks.yale.edu/book/9780300251685/causal-inference" class="app-chip"> 
                    <i class="fas fa-book" aria-hidden="true"></i> Buy from Yale Press 
                </a>
            </div>
        </div>
    </div>
</div>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="ch5.html"><span class="header-section-number">6</span> Regression Discontinuity</a></div>
<div class="next"><a href="ch7.html"><span class="header-section-number">8</span> Panel Data</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ch6"><span class="header-section-number">7</span> Instrumental Variables</a></li>
<li><a class="nav-link" href="#history-of-instrumental-variables-father-and-son"><span class="header-section-number">7.1</span> History of Instrumental Variables: Father and Son</a></li>
<li>
<a class="nav-link" href="#intuition-of-instrumental-variables"><span class="header-section-number">7.2</span> Intuition of Instrumental Variables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#canonical-iv-dag"><span class="header-section-number">7.2.1</span> Canonical IV DAG</a></li>
<li><a class="nav-link" href="#good-instruments-should-feel-weird"><span class="header-section-number">7.2.2</span> Good instruments should feel weird</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#homogeneous-treatment-effects"><span class="header-section-number">7.3</span> Homogeneous Treatment Effects</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#two-stage-least-squares"><span class="header-section-number">7.3.1</span> Two-stage least squares</a></li></ul>
</li>
<li><a class="nav-link" href="#parental-methamphetamine-abuse-and-foster-care"><span class="header-section-number">7.4</span> Parental Methamphetamine Abuse and Foster Care</a></li>
<li><a class="nav-link" href="#the-problem-of-weak-instruments"><span class="header-section-number">7.5</span> The Problem of Weak Instruments</a></li>
<li><a class="nav-link" href="#heterogeneous-treatment-effects"><span class="header-section-number">7.6</span> Heterogeneous Treatment Effects</a></li>
<li>
<a class="nav-link" href="#applications"><span class="header-section-number">7.7</span> Applications</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#college-in-the-county"><span class="header-section-number">7.7.1</span> College in the county</a></li>
<li><a class="nav-link" href="#fulton-fish-markets"><span class="header-section-number">7.7.2</span> Fulton Fish Markets</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#popular-iv-designs"><span class="header-section-number">7.8</span> Popular IV Designs</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#lotteries"><span class="header-section-number">7.8.1</span> Lotteries</a></li>
<li><a class="nav-link" href="#judge-fixed-effects"><span class="header-section-number">7.8.2</span> Judge fixed effects</a></li>
<li><a class="nav-link" href="#bartik-instruments"><span class="header-section-number">7.8.3</span> Bartik instruments</a></li>
<li><a class="nav-link" href="#shifts-vs-shares"><span class="header-section-number">7.8.4</span> Shifts vs Shares</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conclusion-5"><span class="header-section-number">7.9</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/scunning1975/mixtape/blob/master/06-Instrumental_Variables.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/scunning1975/mixtape/edit/master/06-Instrumental_Variables.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><span style="font-weight:bold">Causal Inference</span></strong>: <i>The Mixtape</i>" was written by Scott Cunningham. It was last built on 2020-12-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
