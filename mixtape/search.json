[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"\nonline version Causal Inference: MixtapeCausal inference encompasses tools allow social scientists determine causes . messy world, causal inference helps establish causes effects actions studied—example, impact (lack thereof) increases minimum wage employment, effects early childhood education incarceration later life, influence economic growth introducing malaria nets developing regions. Scott Cunningham introduces students practitioners methods necessary arrive meaningful answers questions causation, using range modeling techniques coding instructions R Stata programming languages.Buy print version today:  Buy Amazon   Buy Yale Press ","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Buy print version today:path economics linear. didn’t major economics, instance. didn’t even take economics course college. majored English, Pete’s sake. ambition become poet. became intrigued idea humans can form plausible beliefs causal effects even without randomized experiment. Twenty-five years ago, wouldn’t clue sentence even meant, let alone experiment. get ? Maybe like know got point felt needed write book. TL;DR version followed windy path English causal inference.1 First, fell love economics. fell love empirical research. noticed growing interest causal inference happening entire time. let tell longer version.majored English University Tennessee Knoxville graduated serious ambition become professional poet. , successful writing poetry college, quickly realized finding road success beyond point probably realistic. newly married, baby way, working qualitative research analyst market research. Slowly, stopped writing poetry altogether.2My job qualitative research analyst eye opening, part first exposure empiricism. job “grounded theory”—kind inductive approach generating explanations human behavior based observations. running focus groups conducting -depth interviews, well ethnographic methods. approached project opportunity understand people things (even buy detergent pick cable provider). job inspired develop theories human behavior, didn’t provide way falsifying theories.lacked background social sciences, spend evenings downloading reading articles Internet. don’t remember ended , one night University Chicago Law Economics working paper series website speech Gary Becker caught eye. Nobel Prize acceptance speech economics applies human behavior (Becker 1993), reading changed life. thought economics stock markets banks read speech. didn’t know economics engine one use analyze human behavior. overwhelmingly exciting, seed planted.wasn’t read article crime Lott Mustard (1997) became truly enamored economics. idea empirical component economists sought estimate causal effects quantitative data. coauthor paper David Mustard, associate professor economics University Georgia, one Gary Becker’s former students. decided wanted study Mustard, applied University Georgia’s doctoral program economics. moved Athens, Georgia, wife, Paige, infant son, Miles, started classes fall 2002.passing first-year comprehensive exams, took Mustard’s labor economics field class learned variety topics shape interests years. topics included returns education, inequality, racial discrimination, crime, many fascinating topics labor. read many, many empirical papers class, afterwards knew need strong background econometrics kind research cared . fact, decided make econometrics main field study. led work Christopher Cornwell, econometrician labor economist Georgia. learned lot Chris, econometrics research . became mentor, coauthor, close friend.Econometrics difficult. won’t even pretend good . took econometrics courses offered University Georgia, . included classes covering topics like probability statistics, cross-sections, panel data, time series, qualitative dependent variables. passed field exam econometrics, struggled understand econometrics deep level. saying goes, see forest trees. Something just wasn’t clicking.noticed something, though, writing third chapter dissertation hadn’t noticed . third chapter investigation effect abortion legalization cohort’s future sexual behavior (Cunningham Cornwell 2013). revisiting Donohue Levitt (2001). One books read preparation study Levine (2004), addition reviewing theory empirical studies abortion little table explaining difference--differences identification strategy. University Georgia traditional econometrics pedagogy, field courses theoretical (e.g., public economics, industrial organization), never really heard phrase “identification strategy,” let alone “causal inference.” Levine’s simple difference--differences table reason opened eyes. saw econometric modeling used isolate causal effects treatment, led change approach empirical problems.","code":""},{"path":"introduction.html","id":"what-is-causal-inference","chapter":"1 Introduction","heading":"1.1 What Is Causal Inference?","text":"first job graduate school assistant professor Baylor University Waco, Texas, still work live today. restless second got . feel econometrics indispensable, yet missing something. ? theory causality. orbiting theory ever since seeing difference--differences table Levine (2004). needed . , desperate, always want learn something new—developed course causality force learn things didn’t know.named course Causal Inference Research Design taught first time Baylor master’s students 2010. time, couldn’t really find example sort class looking , cobbled together patchwork ideas several disciplines authors, like labor economics, public economics, sociology, political science, epidemiology, statistics. name . class wasn’t pure econometrics course; rather, applied empirical class taught variety contemporary research designs, difference--differences, filled empirical replications readings, built robust theory causality found Donald Rubin’s work well work Judea Pearl. book class fact similar one another.3So define causal inference? Causal inference leveraging theory deep knowledge institutional details estimate impact events choices given outcome interest. new field; humans obsessing causality since antiquity. new progress believe ’ve made estimating causal effects inside outside laboratory. date beginning new, modern causal inference Fisher (1935), Haavelmo (1943), Rubin (1974). connect work early pioneers like John Snow. give lot credit numerous highly creative labor economists late 1970s late 1990s whose ambitious research agendas created revolution economics continues day. even make argument owe Cowles Commission, Philip Sewall Wright, computer scientist Judea Pearl.however date emergence, causal inference now matured distinct field, surprisingly, ’re starting see treatments . ’s sometimes reviewed lengthy chapter “program evaluation” econometrics textbooks (Wooldridge 2010), even given entire book-length treatments. name just textbooks growing area, ’s Angrist Pischke (2009), Morgan Winship (2014), Imbens Rubin (2015), probably half dozen others, mention numerous, lengthy treatments specific strategies, found Angrist Krueger (2001) Imbens Lemieux (2008). market quietly adding books articles identifying causal effects data time.Causal Inference: Mixtape exist? Well, put bluntly, readable introductory book programming examples, data, detailed exposition didn’t exist one. book effort fill hole, believe researchers really need guide takes knowing almost nothing causal inference place competency. Competency sense conversant literate designs can . Competency sense can take data, write code , using theoretical contextual knowledge, implement reasonable design one projects. book helps someone , book value, can hope .books like? ones inspired book? don’t just keep using ? classes, mainly relied Morgan Winship (2014), Angrist Pischke (2009), well library theoretical empirical articles. books opinion definitive classics. didn’t satisfy needs, result, constantly jumping material. books awesome quite right either. Imbens Rubin (2015) cover potential outcomes model, experimental design, matching instrumental variables, directed acyclic graphical models (DAGs), regression discontinuity, panel data, synthetic control. Morgan Winship (2014) cover DAGs, potential outcomes model, instrumental variables, light touch regression discontinuity panel data tastes. also don’t cover synthetic control, called important innovation causal inference last 15 years Athey Imbens (2017a). Angrist Pischke (2009) close need include anything synthetic control graphical models find critically useful. maybe importantly, Imbens Rubin (2015), Angrist Pischke (2009), Morgan Winship (2014) provide practical programming guidance, believe replication coding gain knowledge areas.4This book written different people mind. written first foremost practitioners, includes easy--download data sets programs. ’s made several efforts review papers well replicate models much possible. want readers understand field, important, want feel empowered can use tools answer research questions.Another person mind experienced social scientist wants retool. Maybe people theoretical bent background, maybe ’re people simply holes human capital. book, hope, can help guide modern theories causality common social sciences, well provide calculus directed acyclic graphical models can help connect knowledge theory estimation. DAGs particular valuable group, think.third group ’m focusing nonacademic person industry, media, think tanks, like. Increasingly, knowledge causal inference expected throughout professional world. longer simply something academics sit around debate. crucial knowledge making business decisions well interpreting policy.Finally, book written people early careers, undergraduates, graduate students, newly minted PhDs. hope book can give jump start don’t meander, like many us , somewhat labyrinthine path methods.","code":""},{"path":"introduction.html","id":"do-not-confuse-correlation-with-causality","chapter":"1 Introduction","heading":"1.2 Do Not Confuse Correlation with Causality","text":"common days hear someone say “correlation mean causality.” Part purpose book help readers able understand exactly correlations, particularly observational data, unlikely reflective causal relationship. rooster crows, sun soon rises, know rooster didn’t cause sun rise. rooster eaten farmer’s cat, sun still risen. Yet often people make kind mistake naively interpreting simple correlations.\nFigure 1.1: correlation doesn’t mean causality. Artwork Seth.\nweirdly enough, sometimes causal relationships two things yet observable correlation. Now definitely strange. can one thing cause another thing without discernible correlation two things? Consider example, illustrated Figure 1.1. sailor sailing boat across lake windy day. wind blows, counters turning rudder way exactly offset force wind. Back forth moves rudder, yet boat follows straight line across lake. kindhearted yet naive person knowledge wind boats might look woman say, “Someone get sailor new rudder! broken!” thinks see relationship movement rudder direction boat.fact see relationship mean isn’t one? Just observable relationship mean causal one. Imagine instead perfectly countering wind turning rudder, instead flipped coin—heads turns rudder left, tails turns rudder right. think man seen sailing boat according coin flips? randomly moved rudder windy day, see sailor zigzagging across lake. see relationship movement randomized able see otherwise? sailor endogenously moving rudder response unobserved wind. , relationship rudder boat’s direction canceled—even though causal relationship two.sounds like silly example, fact serious versions . Consider central bank reading tea leaves discern recessionary wave forming. Seeing evidence recession emerging, bank enters open-market operations, buying bonds pumping liquidity economy. Insofar actions done optimally, open-market operations show relationship whatsoever actual output. fact, ideal, banks may engage aggressive trading order stop recession, unable see evidence working even though !Human beings engaging optimal behavior main reason correlations almost never reveal causal relationships, rarely human beings acting randomly. see, presence randomness crucial identifying causal effect.Buy print version today:","code":""},{"path":"introduction.html","id":"optimization-makes-everything-endogenous","chapter":"1 Introduction","heading":"1.3 Optimization Makes Everything Endogenous","text":"Certain presentations causal inference methodologies sometimes described atheoretical, opinion, practitioners seem comfortable flying blind, actual methods employed causal designs always deeply dependent theory local institutional knowledge. firm belief, emphasize book, without prior knowledge, estimated causal effects rarely, ever, believable. Prior knowledge required order justify claim causal finding. economic theory also highlights causal inference necessarily thorny task. Let explain.’s broadly thought two types data. ’s experimental data non-experimental data. latter also sometimes called observational data. Experimental data collected something akin laboratory environment. traditional experiment, researcher participates actively process recorded. ’s difficult obtain data like social sciences due feasibility, financial cost, moral objections, although common now case. Examples include Oregon Medicaid Experiment, RAND health insurance experiment, field experiment movement inspired Esther Duflo, Michael Kremer, Abhijit Banerjee, John List, many others.Observational data usually collected surveys retrospective manner, -product business activity (“big data”). many observational studies, collect data happened previously, opposed collecting data happens, though increased use web scraping, may possible get observational data closer exact moment action occurred. regardless timing, researcher passive actor processes creating data . observes actions results position interfere environment units consideration exist. common form data many us ever work .Economic theory tells us suspicious correlations found observational data. observational data, correlations almost certainly reflecting causal relationship variables endogenously chosen people making decisions thought best. pursuing goal facing constraints, chose certain things created spurious correlation things. see problem reflected potential outcomes model : correlation, order measure causal effect, must based choice made independent potential outcomes consideration. Yet person making choice based thinks best, necessarily based potential outcomes, correlation remotely satisfy conditions need order say causal. put bluntly can, economic theory says choices endogenous, therefore since , correlations choices outcomes aggregate rarely, ever, represent causal effect.Now veering realm epistemology. Identifying causal effects involves assumptions, also requires particular kind belief work scientists. Credible valuable research requires believe important work correctly try achieve certain outcome (e.g., confirmation bias, statistical significance, asterisks). foundations scientific knowledge scientific methodologies. True scientists collect evidence order prove want true others want believe. form deception manipulation called propaganda, propaganda science. Rather, scientific methodologies devices forming particular kind belief. Scientific methodologies allow us accept unexpected, sometimes undesirable, answers. process oriented, outcome oriented. without values, causal methodologies also believable.","code":""},{"path":"introduction.html","id":"example-identifying-price-elasticity-of-demand","chapter":"1 Introduction","heading":"1.4 Example: Identifying Price Elasticity of Demand","text":"One cornerstones scientific methodologies empirical analysis.5 empirical analysis, mean use data test theory estimate relationship variables. first step conducting empirical economic analysis careful formulation question like answer. cases, like develop test formal economic model describes mathematically certain relationship, behavior, process interest. models valuable insofar describe phenomena interest make falsifiable (testable) predictions. prediction falsifiable insofar can evaluate, potentially reject, prediction data.6 model framework describe relationships interested , intuition results, hypotheses like test.7After specified model, turn called econometric model, can estimated directly data. One clear issue immediately face regarding functional form model, describe relationships variables interested equation. Another important issue deal variables directly reasonably observed researcher, measured well, play important role model.generically important contribution understanding causal inference notion comparative statics. Comparative statics theoretical descriptions causal effects contained within model. kinds comparative statics always based  idea ceteris paribus—“else constant.” trying describe causal effect intervention, instance, always assuming relevant variables model changing. changing, correlated variable interest confound estimation.8To illustrate idea, let’s begin basic economic model: supply demand equilibrium problems creates estimating price elasticity demand. Policy-makers business managers natural interest learning price elasticity demand knowing enables firms maximize profits governments choose optimal taxes, whether restrict quantity altogether (Becker, Grossman, Murphy 2006). problem observe demand curves, demand curves theoretical objects. specifically, demand curve collection paired potential outcomes price quantity. observe price quantity equilibrium values, potential price potential quantities along entire demand curve. tracing potential outcomes along demand curve can calculate elasticity.\nFigure 1.2: Wright’s graphical demonstration identification problem. Figure Wright, P. G. (1928). Tariff Animal Vegetable Oils.\nsee , consider graphic Philip Wright’s Appendix B (Wright 1928), ’ll discuss greater detail later (Figure 1.2). price elasticity demand ratio percentage changes quantity price single demand curve. Yet, shifts supply demand, sequence quantity price pairs emerges history reflect neither demand curve supply curve. fact, connecting points reflect meaningful useful object.price elasticity demand solution following equation:\\[\n\\epsilon = \\frac{\\partial \\log Q}{\\partial \\log P}\n\\]example, change \\(P\\) exogenous. instance, holds supply fixed, prices goods fixed, income fixed, preferences fixed, input costs fixed, . order estimate price elasticity demand, need changes \\(P\\) completely utterly independent otherwise normal determinants supply determinants demand. Otherwise get shifts either supply demand, creates new pairs data correlation \\(P\\) \\(Q\\) measure elasticity demand.problem elasticity important object, need know , therefore need solve problem. given theoretical object, must write econometric model starting point. One possible example econometric model linear demand function:\\[\n\\log Q_d = \\alpha+\\delta \\log P+\\gamma X + u\n\\]\\(\\alpha\\) intercept, \\(\\delta\\) elasticity demand, \\(X\\) matrix factors determine demand like prices goods income, \\(\\gamma\\) coefficient relationship \\(X\\) \\(Q_d\\), \\(u\\) error term.9Foreshadowing content mixtape, need two things estimate price elasticity demand. First, need numerous rows data price quantity. Second, need variation price imaginary data set independent \\(u\\). call kind independence exogeneity. Without , recover price elasticity demand, therefore decision requires information based stabs dark.","code":""},{"path":"introduction.html","id":"conclusion","chapter":"1 Introduction","heading":"1.5 Conclusion","text":"book introduction research designs can recover causal effects. just importantly, provides hands-practice implement designs. Implementing designs means writing code type software. chosen illustrate designs using two popular software languages: Stata (commonly used economists) R (commonly used everyone else).book contains numerous empirical exercises illustrated Stata R programs. exercises either simulations (don’t need external data) exercises requiring external data. data needed latter made available Github. Stata examples download files usually start program using following command: use https://github.com/scunning1975/mixtape/raw/master/DATAFILENAME.DTA, DATAFILENAME.DTA name particular data set.R users, somewhat different process load data memory. effort organize clean code, students Hugo Sant’Anna Terry Tsai created function simplify data download process. partly based library called haven, package reading data files. secondly based set commands create function download data directly Github.10Some readers may familiar either Stata R nonetheless wish follow along. encourage use opportunity invest learning one languages. beyond scope book provide introduction languages, fortunately, numerous resources online. instance, Christopher Baum written excellent introduction Stata https://fmwww.bc.edu/GStat/docs/StataIntro.pdf. Stata popular among microeconomists, given amount coauthoring involved modern economic research, argument made investing solely ability solve basic coordination problems potential coauthors. downside Stata proprietary must purchased. people, may simply big barrier—especially anyone simply wanting follow along book. R hand open-source free. Tutorials Basic R can found https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf, introduction Tidyverse (used throughout R programming) can found https://r4ds..co.nz. Using time learn R likely well worth time.Perhaps already know R want learn Stata. perhaps know Stata want learn R. book may helpful way sets code put sequence accomplish basic tasks. , said, many situations, although tried best reconcile results Stata R, always able . Ultimately, Stata R different programming languages sometimes yield different results different optimization procedures simply programs built slightly differently. discussed occasionally articles authors attempt better understand accounts differing results. always able fully reconcile different results, offer two programs simply alternative approaches. ultimately responsible anything using either language research. leave ultimately understand method estimating procedure contained within given software package.conclusion, simply finding association two variables might suggestive causal effect, also might . Correlation doesn’t mean causation unless key assumptions hold. start digging causal methodologies , though, need lay foundation statistics regression modeling. Buckle ! going fun.Buy print version today:","code":""},{"path":"ch1.html","id":"ch1","chapter":"2 Probability and Regression Review","heading":"2 Probability and Regression Review","text":"Buy print version today:","code":""},{"path":"ch1.html","id":"basic-probability-theory","chapter":"2 Probability and Regression Review","heading":"2.1 Basic probability theory","text":"practice, causal inference based statistical models range simple extremely advanced. building models requires rudimentary knowledge probability theory, let’s begin definitions. random process process can repeated many times different outcomes time. sample space set possible outcomes random process. distinguish discrete continuous random processes Table 1 . Discrete processes produce, integers, whereas continuous processes produce fractions well.Table 2.1:  Examples Discrete Continuous Random ProcessesWe define independent events two ways. first refers logical independence. instance, two events occur reason believe two events affect . assumed affect , logical fallacy called post hoc ergo propter hoc, Latin “, therefore .” fallacy recognizes temporal ordering events sufficient able say first thing caused second.second definition independent event statistical independence. ’ll illustrate latter example idea sampling without replacement. Let’s use randomly shuffled deck cards example. deck 52 cards, probability first card ace?\n\\[ \n\\Pr(\\text{Ace}) =\\dfrac{\\text{Count Aces}}{\\text{Sample Space}}=\\dfrac{4}{52}=\n   \\dfrac{1}{13}=0.077\n\\]\n52 possible outcomes sample space, set possible outcomes random process. 52 possible outcomes, concerned frequency ace occurring. four aces deck, \\(\\dfrac{4}{52}=0.077\\).Assume first card ace. Now ask question . shuffle deck, probability next card drawn also ace? longer \\(\\dfrac{1}{13}\\) sample replacement. sampled without replacement. Thus new probability \n\\[ \n\\Pr\\Big(\\text{Ace}\\mid\\text{Card }1 =\\text{Ace}\\Big) =\n   \\dfrac{3}{51}= 0.059\n\\]\nsampling without replacement, two events—ace \\(\\text{Card }1\\) ace \\(\\text{Card }2\\) \\(\\text{Card }1\\) ace—aren’t independent events. make two events independent, put ace back shuffle deck. two events, \\(\\) \\(B\\), independent :\n\\[ \n\\Pr(\\mid B)=\\Pr()\n\\]\nexample two independent events rolling 5 one die rolled 3 another die. two events independent, probability rolling 5 always 0.17 regardless rolled first die.11But want know probability event occurring requires multiple events first occur? instance, let’s say ’re talking Cleveland Cavaliers winning NBA championship. 2016, Golden State Warriors 3–1 best--seven playoff. happen Warriors lose playoff? Cavaliers win three row. instance, find probability, take product marginal probabilities, \\(\\Pr(\\cdot)^n\\), \\(\\Pr(\\cdot)\\) marginal probability one event occurring, \\(n\\) number repetitions one event. unconditional probability Cleveland win 0.5, game independent, probability Cleveland come back 3–1 deficit product game’s probability winning:\n\\[ \n\\text{Win probability} =\\Pr\\big(W,W,W\\big)= (0.5)^3= 0.125\n\\]\nAnother example may helpful. Texas Hold’em poker, player dealt two cards facedown. holding two kind, say two “pocket.” , probability dealt pocket aces? ’s \\(\\dfrac{4}{52}\\times\\dfrac{3}{51}=0.0045\\). ’s right: ’s \\(0.45\\%\\).Let’s formalize ’ve saying generalized case. independent events, calculate joint probabilities, multiply marginal probabilities:\n\\[ \n\\Pr(,B)=\\Pr()\\Pr(B)\n\\]\n\\(\\Pr(,B)\\) joint probability \\(\\) \\(B\\) occurring, \\(\\Pr()\\) marginal probability \\(\\) event occurring.Now, slightly difficult application. probability rolling 7 using two six-sided dice, probability rolling 3? answer , let’s compare two probabilities. ’ll use table help explain intuition. First, let’s look ways get 7 using two six-sided dice. 36 total possible outcomes \\((6^2=36)\\) rolling two dice. Table 2.2 see six different ways roll 7 using two dice. probability rolling 7 \\(6/36=16.67\\)%. Next, let’s look ways roll 3 using two six-sided dice. Table 2.3 shows two ways get 3 rolling two six-sided dice. probability rolling 3 \\(2/36=5.56\\)%. , , probabilities rolling 7 rolling 3 different.Table 2.2:  Total number ways get 7 two six-sided dice.Table 2.3:  Total number ways get 3 using two six-sided dice.","code":""},{"path":"ch1.html","id":"events-and-conditional-probability","chapter":"2 Probability and Regression Review","heading":"2.2 Events and conditional probability","text":"First, talk three ways representing probability, ’d like introduce new terminology concepts: events conditional probabilities. Let \\(\\) event. let \\(B\\) event. two events, four possibilities.B: B occur.B: B occur.\\(\\sim\\) B: occur, B occurs.\\(\\sim\\) B: occur, B occurs.\\(\\sim\\) B: occurs, B occur.\\(\\sim\\) B: occurs, B occur.\\(\\sim\\) \\(\\sim\\) B: Neither B occurs.\\(\\sim\\) \\(\\sim\\) B: Neither B occurs.’ll use couple different examples illustrate represent probability.","code":""},{"path":"ch1.html","id":"probability-tree","chapter":"2 Probability and Regression Review","heading":"2.3 Probability tree","text":"Let’s think situation trying get driver’s license. Suppose order get driver’s license, pass written exam driving exam. However, fail written exam, ’re allowed take driving exam. can represent two events probability tree.Probability trees intuitive easy interpret.12 First, see probability passing written exam 0.75 probability failing exam 0.25. Second, every branching node, can see probabilities associated given branch summing 1.0. joint probabilities also summing 1.0. called law total probability equal sum joint probability B\\(_n\\) events occurring:\n\\[ \n\\Pr()=\\sum_n Pr(\\cup B_n)\n\\]also see concept conditional probability driver’s license tree. instance, probability failing driving exam, conditional passed written exam, represented \\(\\Pr(\\text{Fail} \\mid \\text{Pass})=0.45\\).","code":""},{"path":"ch1.html","id":"venn-diagrams-and-sets","chapter":"2 Probability and Regression Review","heading":"2.4 Venn diagrams and sets","text":"second way represent multiple events occurring Venn diagram. Venn diagrams first conceived John Venn 1880. used teach elementary set theory, well express set relationships probability statistics. example involve two sets, \\(\\) \\(B\\).University Texas’s football coach razor’s edge athletic director regents season. several mediocre seasons, future school jeopardy. Longhorns don’t make great bowl game, likely won’t rehired. , likely rehired. Let’s discuss elementary set theory using coach’s situation guiding example. , let’s remind terms. \\(\\) \\(B\\) events, \\(U\\) universal set \\(\\) \\(B\\) subsets. Let \\(\\) probability Longhorns get invited great bowl game \\(B\\) probability coach rehired. Let \\(\\Pr()=0.6\\) let \\(\\Pr(B)=0.8\\). Let probability \\(\\) \\(B\\) occur \\(\\Pr(,B)=0.5\\).Note, \\(+\\sim =U\\), \\(\\sim \\) complement \\(\\). complement means everything universal set . said B. sum \\(B\\) \\(\\sim B=U\\). Therefore:\n\\[ \n+{\\sim} =B+ {\\sim} B\n\\]can rewrite following definitions:\\[\\begin{align}\n   & = B+{\\sim} B - {\\sim} \\\\\n   B & = +{\\sim} - {\\sim} B \n\\end{align}\\]Whenever want describe set events either \\(\\) \\(B\\) occur, : \\(\\cup B\\). pronounced “\\(\\) union \\(B\\),” means new set contains every element \\(\\) every element \\(B\\). element either set \\(\\) set \\(B\\), , also new union set. whenever want describe set events occurred together—joint set—’s \\(\\cap B\\), pronounced “\\(\\) intersect \\(B\\).” new set contains every element \\(\\) \\(B\\) sets. , things inside \\(\\) \\(B\\) get added new set.Now let’s look closely relationship involving set .\\[\\begin{align}\n   =\\cup B+\\cup{\\sim} B\n\\end{align}\\]Notice saying: two ways identify \\(\\) set. First, can look instances \\(\\) occurs \\(B\\). rest \\(\\) \\(B\\)? Well, ’s \\(\\cup B\\) situation, covers rest \\(\\) set.similar style reasoning can help understand following expression.\n\\[ \n\\cap B=\\cup{\\sim}B+\\sim \\cup B+\\cup B\n\\]\nget \\(\\) intersect \\(B\\), need three objects: set \\(\\) units outside \\(B\\), set \\(B\\) units outside \\(\\), joint set. get , \\(\\cap B\\).Now just simple addition find missing values. Recall \\(\\) team making playoffs \\(\\Pr()=0.6\\). \\(B\\) probability coach rehired, \\(\\Pr(B)=0.8\\). Also, \\(\\Pr(,B)=0.5\\), probability \\(\\) \\(B\\) occurring. :\\[\\begin{align}\n                & = \\cup B+\\cup{\\sim}B \\\\\n   \\cup{\\sim}B  & = - \\cup B           \\\\\n   \\Pr(, \\sim B) & = \\Pr() - Pr(,B)       \\\\\n   \\Pr(,\\sim B)  & = 0.6 - 0.5              \\\\\n   \\Pr(,\\sim B)  & = 0.1                    \n\\end{align}\\]working sets, important understand probability calculated considering share set (example \\(\\)) made subset (example \\(\\cup B\\)). write probability \\(\\cup B\\) occurs , regards \\(U\\). ask question “share due \\(\\cup B\\)?” Notice, , need :\\[\\begin{align}\n   ? & = \\cup B \\div \\\\\n   ? & = 0.5 \\div 0.6    \\\\\n   ? & = 0.83            \n\\end{align}\\]left intentionally undefined left side focus calculation . now let’s define wanting calculate: world \\(\\) occurred, probability \\(B\\) also occur? :\\[\\begin{align}\n   \\Pr(B \\mid )  & = \\dfrac{\\Pr(,B)}{\\Pr()}= \\dfrac{0.5}{0.6}=0.83 \\\\\n   \\Pr(\\mid B) & = \\dfrac{\\Pr(,B)}{\\Pr(B)}= \\dfrac{0.5}{0.8}=0.63 \n\\end{align}\\]\nNotice, conditional probabilities easy see Venn diagram. essentially asking percentage subset—e.g., \\(\\Pr()\\)—due joint set, example, \\(\\Pr(,B)\\). reasoning reasoning used define concept conditional probability.","code":""},{"path":"ch1.html","id":"contingency-tables","chapter":"2 Probability and Regression Review","heading":"2.5 Contingency tables","text":"Another way can represent events contingency table. Contingency tables also sometimes called twoway tables. Table 2.4 example contingency table. continue example worried Texas coach.Table 2.4:  Two way contingency table.Recall \\(\\Pr()=0.6\\), \\(\\Pr(B)=0.8\\), \\(Pr(,B)=0.5\\). Note calculate conditional probabilities, must know frequency element question (e.g., \\(\\Pr(,B)\\)) relative larger event (e.g., \\(\\Pr()\\)). want know conditional probability \\(B\\) given \\(\\), ’s:\n\\[ \n\\Pr(B\\mid )=\\dfrac{\\Pr(,B)}{\\Pr()}=\\dfrac{0.5}{0.6}=0.83\n\\]\nnote knowing frequency \\(\\cup B\\) world \\(B\\) occurs ask following:\n\\[ \n\\Pr(\\mid B)=\\dfrac{\\Pr(,B)}{\\Pr(B)}= \\dfrac{0.5}{0.8}=0.63\n\\], can use done far write definition joint probability. Let’s start definition conditional probability first. Given two events, \\(\\) \\(B\\):\\[\\begin{align}\n   \\Pr(\\mid B) & =\\dfrac{\\Pr(,B)}{\\Pr(B)} \\tag{2.1} \\\\\n   \\Pr(B\\mid ) & =\\dfrac{\\Pr(B,)}{\\Pr()} \\tag{2.2} \\\\\n   \\Pr(,B)     & =\\Pr(B,) \\tag{2.3}                 \\\\\n   \\Pr()       & =\\Pr(,\\sim B)+\\Pr(,B)                    \n   \\tag{2.4}\n   \\\\\n   \\Pr(B)       & =\\Pr(,B)+\\Pr(\\sim , B)                   \n   \\tag{2.5}\n\\end{align}\\]\nUsing equations (2.1) (2.2), can simply write definition joint probabilities.\n\\[\\begin{align}\n   \\Pr(,B) = \\Pr(\\mid B) \\Pr(B) \\tag{2.6}\\\\\n   \\Pr(B,) = \\Pr(B \\mid ) \\Pr() \\tag{2.7}\n\\end{align}\\]\nformula joint probability. Given equation (2.3), using definitions \\((\\Pr(,B\\) \\(\\Pr(B,))\\), can also rearrange terms, make substitution, rewrite :\n\\[\\begin{align}\n   \\Pr(\\mid B)\\Pr(B) & = \\Pr(B\\mid )\\Pr()                  \n   \\\\\n   \\Pr(\\mid B)       & = \\dfrac{\\Pr(B\\mid ) \\Pr()}{\\Pr(B)} \n\\end{align}\\]\n\\tag{2.8}Equation (2.8) sometimes called naive version Bayes’s rule. now decompose equation fully, though, substituting equation (2.5) equation (2.8).\\[\\begin{align}\n   \\Pr(\\mid B)=\\dfrac{\\Pr(B\\mid )\\Pr()}{\\Pr(,B)+ \\Pr(\\sim ,B)} \\tag{2.9}\n\\end{align}\\]\nSubstituting equation (2.6) denominator equation (2.9) yields:\\[\\begin{align}\n   \\Pr(\\mid B)=\\dfrac{\\Pr(B\\mid )\\Pr()}{\\Pr(B\\mid )\\Pr()+\\Pr(\\sim , B)} \\tag{2.10}\n\\end{align}\\]\nFinally, note using definition joint probability, \\(\\Pr(B,\\sim )= \\Pr(B\\mid\\sim )\\Pr(\\sim )\\), substitute denominator equation (2.10) get:\\[\\begin{align}\n   \\Pr(\\mid B)=\\dfrac{\\Pr(B\\mid )\\Pr()}{\\Pr(B\\mid )\\Pr()+\\Pr(B\\mid \\sim )\\Pr(\\sim )} \\tag{2.11}\n\\end{align}\\]’s mouthful substitutions, equation (2.11) mean? Bayesian decomposition version Bayes’s rule. Let’s use example Texas making great bowl game. \\(\\) Texas making great bowl game, \\(B\\) coach getting rehired. \\(\\cap B\\) joint probability events occur. can make calculation using contingency tables. questions : Texas coach rehired, ’s probability Longhorns made great bowl game? formally, \\(\\Pr(\\mid B)\\). can use Bayesian decomposition find probability.\\[\\begin{align}\n   \\Pr(\\mid B) & = \\dfrac{\\Pr(B\\mid )\\Pr()}{\\Pr(B\\mid )\\Pr()+\\Pr(B\\mid \\sim )\\Pr(\\sim )} \n   \\\\\n                & =\\dfrac{0.83\\cdot 0.6}{0.83\\cdot 0.6+0.75\\cdot 0.4}                           \n   \\\\\n                & =\\dfrac{0.498}{0.498+0.3}                                                     \\\\\n                & =\\dfrac{0.498}{0.798}                                                         \\\\\n   \\Pr(\\mid B) & =0.624                                                                        \n\\end{align}\\]\nCheck contingency table using definition joint probability:\\[\\begin{align}\n   \\Pr(\\mid B)=\\dfrac{\\Pr(,B)}{\\Pr(B)}= \\dfrac{0.5}{0.8}=0.625\n\\end{align}\\]\n, coach rehired, 63 percent chance made great bowl game.13","code":""},{"path":"ch1.html","id":"monty-hall-example","chapter":"2 Probability and Regression Review","heading":"2.6 Monty Hall example","text":"Let’s use different example, Monty Hall example. fun one, people find itcounterintuitive. even used stump mathematicians statisticians.14 Bayes’s rule makes answer clear—clear, fact, ’s somewhat surprising Bayes’s rule actually controversial (Mcgrayne 2012).Let’s assume three closed doors: door 1 \\((D_1)\\), door 2 \\((D_2)\\), door 3 \\((D_3)\\). Behind one doors million dollars. Behind two doors goat. Monty Hall, game-show host example, asks contestants pick door. pick door, opens door picked, opens one doors reveal goat. asks contestant, “like switch doors?”common response Monty Hall’s offer say makes sense change doors, ’s equal chance million dollars behind either door. Therefore, switch? ’s 50–50 chance ’s behind door picked ’s 50–50 chance ’s behind remaining door, makes rational sense switch. Right? Yet, little intuition tell ’s right answer, seem Monty Hall opened third door, made statement. exactly say?Let’s formalize problem using probability notation. Assume chose door 1, \\(D_1\\). probability \\(D_1\\) million dollars made choice \\(\\Pr(D_1=1 \\text{ million})=\\dfrac{1}{3}\\). call event \\(A_1\\). probability \\(D_1\\) million dollars start game \\(\\dfrac{1}{3}\\) sample space 3 doors, one million dollars behind . Thus, \\(\\Pr(A_1)=\\dfrac{1}{3}\\). Also, law total probability, \\(\\Pr(\\sim A_1)=\\dfrac{2}{3}\\). Let’s say Monty Hall opened door 2, \\(D_2\\), reveal goat. asked, “like change door number 3?”need know probability door 3 million dollars compare Door 1’s probability. call opening door 2 event \\(B\\). call probability million dollars behind door \\(\\), \\(A_i\\). now write question just asked formally decompose using Bayesian decomposition. ultimately interested knowing probability door 1 million dollars (event \\(A_1\\)) given Monty Hall opened door 2 (event \\(B\\)), conditional probability question. Let’s write conditional probability using Bayesian decomposition equation (2.11).\\[\\begin{align}\n   \\small\n   \\Pr(A_1 \\mid B)=\\dfrac{\\Pr(B\\mid A_1) \\Pr(A_1)}{\\Pr(B\\mid A_1) \\Pr(A_1)+\\Pr(B\\mid A_2) \\Pr(A_2)+\\Pr(B\\mid A_3) \\Pr(A_3)}\\\\\n   \\tag{2.12}\n\\end{align}\\]basically two kinds probabilities right side equation. ’s marginal probability million dollars behind given door, \\(\\Pr(A_i)\\). ’s conditional probability Monty Hall open door 2 given million dollars behind door \\(A_i\\), \\(\\Pr(B\\mid A_i)\\).marginal probability door \\(\\) million dollars behind without additional information \\(\\dfrac{1}{3}\\). call prior probability, prior belief. may also called unconditional probability.conditional probability, \\(\\Pr(B|A_i)\\), requires little careful thinking. Take first conditional probability, \\(\\Pr(B\\mid A_1)\\). door 1 million dollars behind , ’s probability Monty Hall open door 2?Let’s think second conditional probability: \\(\\Pr(B\\mid A_2)\\). money behind door 2, ’s probability Monty Hall open door 2?last conditional probability, \\(\\Pr(B\\mid A_3)\\). world money behind door 3, ’s probability Monty Hall open door 2?conditional probabilities requires thinking carefully feasibility events question. Let’s examine easiest question: \\(\\Pr(B\\mid A_2)\\). money behind door 2, likely Monty Hall open door, door 2? Keep mind: game show. gives idea game-show host behave. think Monty Hall open door million dollars behind ? makes sense think ’d ever open door actually money behind —always open door goat. don’t think ’s opening doors goats? Let’s see happens take intuition logical extreme conclude Monty Hall never opens door million dollars. opens door door goat. assumption, can proceed estimate \\(\\Pr(A_1\\mid B)\\) substituting values \\(\\Pr(B\\mid A_i)\\) \\(\\Pr(A_i)\\) right side equation (2.12).\\(\\Pr(B\\mid A_1)\\)? , world chosen door 1, money behind door 1, probability open door 2? two doors open money behind door 1—open either door 2 door 3, goat behind . \\(\\Pr(B\\mid A_1)=0.5\\).second conditional probability, \\(\\Pr(B\\mid A_2)\\)? money behind door 2, ’s probability open ? assumption never opens door million dollars, know probability 0.0. finally, third probability, \\(\\Pr(B\\mid A_3)\\)? probability opens door 2 given money behind door 3? Now consider one carefully—contestant already chosen door 1, can’t open one. can’t open door 3, money behind . door, therefore, open door 2. Thus, probability 1.0. Furthermore, marginal probabilities, \\(\\Pr(A_i)\\), equal 1/3, allowing us solve conditional probability left side substitution, multiplication, division.\\[\\begin{align}\n   \\Pr(A_1\\mid B) & = \\dfrac{\\dfrac{1}{2}\\cdot                       \n   \\dfrac{1}{3}}{\\dfrac{1}{2}\\cdot\n   \\dfrac{1}{3}+0\\cdot\\dfrac{1}{3}+1.0 \\cdot \\dfrac{1}{3}}\n   \\\\\n                  & =\\dfrac{\\dfrac{1}{6}}{\\dfrac{1}{6}+\\dfrac{2}{6}} \n   \\\\\n                  & = \\dfrac{1}{3}                                   \n\\end{align}\\]\nAha. Now isn’t just little bit surprising? probability contestant chose correct door \\(\\dfrac{1}{3}\\), just Monty Hall opened door 2.probability door 3, door ’re holding, million dollars? beliefs likelihood changed now door 2 removed equation? Let’s crank Bayesian decomposition see whether learned anything.\\[\\begin{align}\n   \\Pr(A_3\\mid B) & = \\dfrac{ \\Pr(B\\mid A_3)\\Pr(A_3) }{ \\Pr(B\\mid A_3)\\Pr(A_3)+\\Pr(B\\mid A_2)\\Pr(A_2)+ \\Pr(B\\mid A_1)\\Pr(A_1) }      \n   \\\\\n                  & = \\dfrac{ 1.0 \\cdot \\dfrac{1}{3} }{ 1.0 \\cdot \\dfrac{1}{3}+0 \\cdot \\dfrac{1}{3}+\\dfrac{1}{2} \\cdot \\dfrac{1}{3}} \n   \\\\\n                  & = \\dfrac{2}{3}                                                                                                   \n\\end{align}\\]Interestingly, beliefs door originally chose haven’t changed, beliefs door changed. prior probability, \\(\\Pr(A_3)=\\dfrac{1}{3}\\), increased process called updating new probability \\(\\Pr(A_3\\mid B)=\\dfrac{2}{3}\\). new conditional probability called posterior probability, posterior belief. simply means witnessed \\(B\\), learned information allowed form new belief door money might behind.mentioned footnote 14 regarding controversy around vos Sant’s correct reasoning need switch doors, deductions based Bayes’s rule often surprising even smart people—probably lack coherent ways correctly incorporate information probabilities. Bayes’s rule shows us way logical accurate. besides insightful, Bayes’s rule also opens door different kind reasoning cause effect. Whereas book estimating effects known causes, Bayes’s rule reminds us can form reasonable beliefs causes known effects.","code":""},{"path":"ch1.html","id":"summation-operator","chapter":"2 Probability and Regression Review","heading":"2.7 Summation operator","text":"tools use reason causality rest atop bedrock probabilities. often working mathematical tools concepts statistics expectations probabilities. One common tools use book linear regression model, can dive , build simple notation.15 ’ll begin summation operator. Greek letter \\(\\Sigma\\) (capital Sigma) denotes summation operator. Let \\(x_1, x_2, \\ldots, x_n\\) sequence numbers. can compactly write sum numbers using summation operator :\\[\\begin{align}\n   \\sum_{=1}^nx_i \\equiv x_1+x_2+\\ldots+x_n\n\\end{align}\\]\nletter \\(\\) called index summation. letters, \\(j\\) \\(k\\), sometimes used indices summation. subscript variable simply represents specific value random variable, \\(x\\). numbers 1 \\(n\\) lower limit upper limit, respectively, summation. expression \\(\\Sigma_{=1}^nx_i\\) can stated words “sum numbers \\(x_i\\) values \\(\\) 1 \\(n\\).” example can help clarify:\\[\\begin{align}\n\\sum_{=6}^9 x_i= x_6+x_7+x_8+x_9\n\\end{align}\\]\nsummation operator three properties. first property called constant rule. Formally, :\n\\[ \n\\text{constant }\n   c{:}\\quad \\sum_{=1}^nc=nc\n\\]\nLet’s consider example. Say given:\n\\[ \n\\sum_{=1}^35=(5+5+5)=3 \\cdot 5=15\n\\]\nsecond property summation operator :\n\\[ \n\\sum_{=1}^ncx_i=c\\sum_{=1}^nx_i\n\\]\nlet’s use example. Say given:\\[\\begin{align}\n   \\sum_{=1}^3 5x_i & =5x_1+5x_2+5x_3   \n   \\\\\n    & =5 (x_1+x_2+x_3)  \n   \\\\\n    & =5\\sum_{=1}^3x_i \n\\end{align}\\]\ncan apply properties get following third property:\\[\\begin{align}\n   \\text{constant $$ $b$:}\\quad \\sum_{=1}^n(ax_i+by_i) =\\sum_{=1}^n x_i + b\\sum_{j=1}^n y_i\n\\end{align}\\]\nleaving summation operator, useful also note things properties operator. First, summation ratio ratio summations .\\[\\begin{align}\n   \\sum_i^n \\dfrac{x_i}{y_i} \\ne \\dfrac{ \\sum_{=1}^n x_i}{\\sum_{=1}^ny_i}\n\\end{align}\\]\nSecond, summation squared variable equal squaring summation.\\[\\begin{align}\n   \\sum_{=1}^nx_i^2 \\ne\n   \\bigg(\\sum_{=1}^nx_i \\bigg)^2\n\\end{align}\\]can use summation indicator make number calculations, repeatedly course book. instance, can use summation operator calculate average:\n\\[\\begin{align}\n   \\overline{x} & = \\dfrac{1}{n} \\sum_{=1}^n x_i \n   \\\\\n& =\\dfrac{x_1+x_2+\\dots+x_n}{n}   \n\\end{align}\\]\n\\(\\overline{x}\\) average (mean) random variable \\(x_i\\). Another calculation can make random variable’s deviations mean. sum deviations mean always equal 0:\n\\[ \n\\sum_{=1}^n (x_i - \\overline{x})=0\n\\]\ncan see Table 2.5.Table 2.5:  Sum deviations equalling zeroConsider sequence two numbers {\\(y_1, y_2, \\ldots, y_n\\)} {\\(x_1, x_2, \\ldots, x_n\\)}. Now can consider double summations possible values \\(x\\)’s \\(y\\)’s. example, consider case \\(n=m=2\\). , \\(\\sum_{=1}^2\\sum_{j=1}^2x_iy_j\\) equal \\(x_1y_1+x_1y_2+x_2y_1+x_2y_2\\). \\[\\begin{align}\n   x_1y_1+x_1y_2+x_2y_1+x_2y_2\n     & = x_1(y_1+y_2)+x_2(y_1+y_2)                     \\\\\n     & = \\sum_{=1}^2x_i(y_1+y_2)                      \\\\\n     & = \\sum_{=1}^2x_i \\bigg( \\sum_{j=1}^2y_j \\bigg) \\\\\n     & = \\sum_{=1}^2 \\bigg( \\sum_{j=1}^2x_iy_j \\bigg) \\\\\n     & = \\sum_{=1}^2 \\sum_{j=1}^2x_iy_j               \n\\end{align}\\]\nOne result useful throughout book :\\[ \n\\sum_{=1}^n(x_i - \\overline{x})^2=\\sum_{=1}^n x_i^2 - n(\\overline{x})^2 \\tag{2.13}\n\\]overly long, step--step proof . Note summation index suppressed first line easier reading.\\[\\begin{align}\n   \\sum_{=1}^n(x_i-\\overline{x})^2 & =                                                                                               \n   \\sum_{=1}^n (x_i^2-2x_i\\overline{x}+\\overline{x}^2)\n   \\\\\n            & = \\sum x_i^2 - 2\\overline{x} \\sum x_i +n\\overline{x}^2                                          \\\\\n            & = \\sum x_i^2 - 2 \\dfrac{1}{n} \\sum x_i \\sum x_i +n\\overline{x}^2                                \\\\\n            & = \\sum x_i^2 +n\\overline{x}^2 - \\dfrac{2}{n} \\bigg (\\sum x_i \\bigg )^2                          \\\\\n            & = \\sum x_i^2+n\\bigg (\\dfrac{1}{n} \\sum x_i \\bigg)^2 - 2n \\bigg (\\dfrac{1}{n} \\sum x_i \\bigg )^2 \\\\\n            & = \\sum x_i^2 - n \\bigg (\\dfrac{1}{n} \\sum x_i \\bigg )^2                                         \\\\\n            & = \\sum x_i^2 - n \\overline{x}^2                                                                 \n\\end{align}\\]\ngeneral version result :\n\\[\\begin{align}\n   \\sum_{=1}^n(x_i-\\overline{x})(y_i-\\overline{y}) & = \\sum_{=1}^n x_i(y_i - \\overline{y})   \n   \\\\\n            & = \\sum_{=1}^n (x_i - \\overline{x})y_i   \n   \\\\\n            & = \\sum_{=1}^n x_iy_i - n(\\overline{xy}) \n   \\\\\n    \\tag{2.14}\n\\end{align}\\]:\n\\[ \n\\sum_{=1}^n (x_i -\\overline{x})(y_i - \\overline{y})= \\sum_{=1}^n x_i(y_i - \\overline{y})=\\sum_{=1}^n (x_i - \\overline{x})y_i=\\sum_{=1}^n x_iy_i - n(\\overline{x}\\overline{y}) \\tag{2.15}\n\\]","code":""},{"path":"ch1.html","id":"expected-value","chapter":"2 Probability and Regression Review","heading":"2.8 Expected value","text":"expected value random variable, also called expectation sometimes population mean, simply weighted average possible values variable can take, weights given probability value occurring population. Suppose variable \\(X\\) can take values \\(x_1, x_2, \\ldots, x_k\\), probability \\(f(x_1), f(x_2), \\ldots, f(x_k)\\), respectively. define expected value \\(X\\) :\n\\[\\begin{align}\n       E(X) & = x_1f(x_1)+x_2f(x_2)+\\dots+x_kf(x_k) \\\\\n            & = \\sum_{j=1}^k x_jf(x_j)              \n   \\end{align}\\]\nLet’s look numerical example. \\(X\\) takes values \\(-1\\), 0, 2, probabilities 0.3, 0.3, 0.4, respectively.16 expected value \\(X\\) equals:\\[\\begin{align}\n   E(X) & = (-1)(0.3)+(0)(0.3)+(2)(0.4) \n   \\\\\n        & = 0.5                         \n\\end{align}\\]\nfact, take expectation function variable, , \\(X^2\\). Note \\(X^2\\) takes values 1, 0, 4, probabilities 0.3, 0.3, 0.4. Calculating expected value \\(X^2\\) therefore :\\[\\begin{align}\n   E(X^2) & = (-1)^2(0.3)+(0)^2(0.3)+(2)^2(0.4) \n   \\\\\n          & = 1.9                               \n\\end{align}\\]first property expected value constant \\(c\\), \\(E(c)=c\\). second property two constants \\(\\) \\(b\\), \\(E(aX+ b)=E(aX)+E(b)=aE(X)+b\\). third property numerous constants, \\(a_1, \\dots, a_n\\) many random variables, \\(X_1, \\dots, X_n\\), following true:\\[\\begin{align}\n   E(a_1X_1+\\dots+a_nX_n)=a_1E(X_1)+\\dots+a_nE(X_n)\n\\end{align}\\]\ncan also express using expectation operator:\\[\\begin{align}\n   E\\bigg(\\sum_{=1}^na_iX_i\\bigg)=\\sum_{=1}a_iE(X_i)\n\\end{align}\\]\nspecial case \\(a_i=1\\), \\[\\begin{align}\n   E\\bigg(\\sum_{=1}^nX_i\\bigg)=\\sum_{=1}^nE(X_i)\n\\end{align}\\]","code":""},{"path":"ch1.html","id":"variance","chapter":"2 Probability and Regression Review","heading":"2.9 Variance","text":"expectation operator, \\(E(\\cdot)\\), population concept. refers whole group interest, just sample available us. meaning somewhat similar average random variable population. additional properties expectation operator can explained assuming two random variables, \\(W\\)  \\(H\\).\\[\\begin{align}\n   E(aW+b)             & = aE(W)+b\\ \\text{constants $$, $b$} \n   \\\\\n   E(W+H)              & = E(W)+E(H)                                  \\\\\n   E\\Big(W - E(W)\\Big) & = 0                                          \n\\end{align}\\]\nConsider variance random variable, \\(W\\):\\[\\begin{align}\n   V(W)=\\sigma^2=E\\Big[\\big(W-E(W)\\big)^2\\Big]\\ \\text{population}\n\\end{align}\\]\ncan show\n\\[ \nV(W)=E(W^2) - E(W)^2 \\tag{2.16}\n\\]\ngiven sample data, can estimate variance following calculation:\\[\\begin{align}\n   \\widehat{S}^2=(n-1)^{-1}\\sum_{=1}^n(x_i - \\overline{x})^2\n\\end{align}\\]\ndivide \\(n\\ -\\ 1\\) making degree--freedom adjustment estimating mean. large samples, degree--freedom adjustment practical effect value \\(S^2\\) \\(S^2\\) average (degree freedom correction) sum squared deviations mean.17A properties variance. First, variance line :\n\\[ \n   V(aX+b)=^2V(X) \\tag{2.17}\n\\]variance constant 0 (.e., \\(V(c)=0\\) constant, \\(c\\)). variance sum two random variables equal :\n\\[ \nV(X+Y)=V(X)+V(Y)+2\\Big(E(XY) - E(X)E(Y)\\Big) \\tag{2.18}\n\\]\ntwo variables independent, \\(E(XY)=E(X)E(Y)\\) \\(V(X+Y)\\) equal sum \\(V(X)+V(Y)\\).","code":""},{"path":"ch1.html","id":"covariance","chapter":"2 Probability and Regression Review","heading":"2.10 Covariance","text":"last part equation (2.18) called covariance. covariance measures amount linear dependence two random variables. represent \\(C(X,Y)\\) operator. expression \\(C(X,Y)>0\\) indicates two variables move direction, whereas \\(C(X,Y)<0\\) indicates move opposite directions. Thus can rewrite equation (2.18) :\\[\\begin{align}\n   V(X+Y)=V(X)+V(Y)+2C(X,Y)\n\\end{align}\\]\n’s tempting say zero covariance means two random variables unrelated, incorrect. nonlinear relationship. definition covariance \n\\[ \nC(X,Y)=E(XY) - E(X)E(Y) \\tag{2.19}\n\\]\nsaid, \\(X\\) \\(Y\\) independent, \\(C(X,Y)=0\\) population. covariance two linear functions :\\[\\begin{align}\n   C(a_1+b_1X, a_2+b_2Y)=b_1b_2C(X,Y)\n\\end{align}\\]\ntwo constants, \\(a_1\\) \\(a_2\\), zero mean difference equals 0.Interpreting magnitude covariance can tricky. , better served looking correlation. define correlation follows. Let \\(W=\\dfrac{X-E(X)}{\\sqrt{V(X)}}\\) \\(Z=\\dfrac{Y - E(Y)}{\\sqrt{V(Y)}}\\). :\n\\[ \n\\text{Corr}(W,Z)=\\dfrac{C(X,Y)}{\\sqrt{V(X)V(Y)}} \\tag{2.20}\n\\]\ncorrelation coefficient bounded \\(-1\\) 1. positive (negative) correlation indicates variables move (opposite) ways. closer coefficient 1 \\(-1\\), stronger linear relationship .","code":""},{"path":"ch1.html","id":"population-model","chapter":"2 Probability and Regression Review","heading":"2.11 Population model","text":"begin cross-sectional analysis. assume can collect random sample population interest. Assume two variables, \\(x\\) \\(y\\), want see \\(y\\) varies changes \\(x\\).18There three questions immediately come . One, \\(y\\) affected factors \\(x\\)? handle ? Two, functional form connecting two variables? Three, interested causal effect \\(x\\) \\(y\\), can distinguish mere correlation? Let’s start specific model.\n\\[ \ny=\\beta_0+\\beta_1x+u\n   \\tag{2.21}\n\\]\nmodel assumed hold population. Equation (2.21) defines linear bivariate regression model. models concerned capturing causal effects, terms left side usually thought effect, terms right side thought causes.Equation (2.21) explicitly allows factors affect \\(y\\) including random variable called error term, \\(u\\). equation also explicitly models functional form assuming \\(y\\) linearly dependent \\(x\\). call \\(\\beta_0\\) coefficient intercept parameter, call \\(\\beta_1\\) coefficient slope parameter. describe population, goal empirical work estimate values. never directly observe parameters, data (emphasize throughout book). can , though, estimate parameters using data assumptions. , need credible assumptions accurately estimate parameters data. return point later. simple regression framework, unobserved variables determine \\(y\\) subsumed error term \\(u\\).First, make simplifying assumption without loss generality. Let expected value \\(u\\) zero population. Formally:\n\\[ \nE(u)=0 \\tag{2.22}\n\\]\n\\(E(\\cdot)\\) expected value operator discussed earlier. normalize \\(u\\) random variable 0, consequence. ? presence \\(\\beta_0\\) (intercept term) always allows us flexibility. average \\(u\\) different 0—instance, say ’s \\(\\alpha_0\\)—adjust intercept. Adjusting intercept effect \\(\\beta_1\\) slope parameter, though. instance:\\[\\begin{align}\n   y=(\\beta_0+\\alpha_0)+\\beta_1x+(u-\\alpha_0)\n\\end{align}\\]\n\\(\\alpha_0=E(u)\\). new error term \\(u-\\alpha_0\\), new intercept term \\(\\beta_0+ \\alpha_0\\). two terms changed, notice change: slope, \\(\\beta_1\\).","code":""},{"path":"ch1.html","id":"mean-independence","chapter":"2 Probability and Regression Review","heading":"2.12 Mean independence","text":"assumption meshes well elementary treatment statistics involves mean error term “slice” population determined values \\(x\\):\n\\[ \nE(u\\mid x)=E(u)\\ \\text{values $x$} \\tag{2.23}\n\\]\n\\(E(u\\mid x)\\) means “expected value \\(u\\) given \\(x\\).” equation (2.23) holds, say \\(u\\) mean independent \\(x\\).example might help . Let’s say estimating effect schooling wages, \\(u\\) unobserved ability. Mean independence requires \\(E(\\text{ability}\\mid x=8)=E(\\text{ability}\\mid x=12)=E(\\text{ability}\\mid x=16)\\) average ability different portions population eighth-grade education, twelfth-grade education, college education. people choose much schooling invest based unobserved skills attributes, equation 2.27 likely violated—least example.let’s say willing make assumption. combining new assumption, \\(E(u\\mid x)=E(u)\\) (nontrivial assumption make), \\(E(u)=0\\) (normalization trivial assumption), get following new assumption:\n\\[ \nE(u\\mid x)=0,\\ \\text{values $x$} \\tag{2.24}\n\\]\nEquation (2.24) called zero conditional mean assumption key identifying assumption regression models. conditional expected value linear operator, \\(E(u\\mid x)=0\\) implies \\[\\begin{align}\n   E(y\\mid x)=\\beta_0+\\beta_1x\n\\end{align}\\]\nshows population regression function linear function \\(x\\), Angrist Pischke (2009) call conditional expectation function.19 relationship crucial intuition parameter, \\(\\beta_1\\), causal parameter.Buy print version today:","code":""},{"path":"ch1.html","id":"ordinary-least-squares","chapter":"2 Probability and Regression Review","heading":"2.13 Ordinary least squares","text":"Given data \\(x\\) \\(y\\), can estimate population parameters, \\(\\beta_0\\) \\(\\beta_1\\)? Let pairs \\(\\big\\{(x_i,\\ \\textrm{}\\ y_i): =1,2,\\dots,n \\big\\}\\) random samples size population. Plug observation population equation:\\[\\begin{align}\n   y_i=\\beta_0+\\beta_1x_i+u_i\n\\end{align}\\]\n\\(\\) indicates particular observation. observe \\(y_i\\) \\(x_i\\) \\(u_i\\). just know \\(u_i\\) . use two population restrictions discussed earlier:\\[\\begin{align}\n   E(u)       & =0  \\\\\n   E(u\\mid x) & = 0 \n\\end{align}\\]\nobtain estimating equations \\(\\beta_0\\) \\(\\beta_1\\). talked first condition already. second one, though, means mean value \\(x\\) change different slices error term. independence assumption implies \\(E(xu)=0\\), get \\(E(u)=0\\), \\(C(x,u)=0\\). Notice \\(C(x,u)=0\\), implies \\(x\\) \\(u\\) independent.20 Next plug \\(u\\), equal \\(y-\\beta_0-\\beta_1x\\):\\[\\begin{align}\n   E(y-\\beta_0-\\beta_1x)           & =0 \\\\\n   \\Big(x[y-\\beta_0-\\beta_1x]\\Big) & =0 \n\\end{align}\\]\ntwo conditions population effectively determine \\(\\beta_0\\) \\(\\beta_1\\). , note notation population concepts. don’t access populations, though sample counterparts:\\[\\begin{align}\n   \\dfrac{1}{n}\\sum_{=1}^n\\Big(y_i-\\widehat{\\beta_0}-\\widehat{\\beta_1}x_i\\Big) & =0 \\tag{2.25} \\\\\n   \\dfrac{1}{n}\\sum_{=1}^n\n   \\Big(x_i\\Big[y_i-\\widehat{\\beta_0}-\\widehat{\\beta_1}x_i\n   \\Big]\\Big)         & =0                \n   \\tag{2.26}\n\\end{align}\\]\n\\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\) estimates data.21 two linear equations two unknowns \\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\). Recall properties summation operator work following sample properties two equations. begin equation (2.25) pass summation operator .\\[\\begin{align}\n   \\dfrac{1}{n}\\sum_{=1}^n\\Big(y_i-\\widehat{\\beta_0}-\\widehat{\\beta_1}x_i\\Big) & = \\dfrac{1}{n}\\sum_{=1}^n(y_i) - \\dfrac{1}{n}\\sum_{=1}^n\\widehat{\\beta_0} - \\dfrac{1}{n}\\sum_{=1}^n\\widehat{\\beta_1}x_i \\\\\n    & = \\dfrac{1}{n}\\sum_{=1}^n y_i - \\widehat{\\beta_0} - \\widehat{\\beta_1} \\bigg( \\dfrac{1}{n}\\sum_{=1}^n x_i \\bigg)          \\\\\n    & = \\overline{y} - \\widehat{\\beta_0} - \\widehat{\\beta_1} \\overline{x}                                                        \n\\end{align}\\]\n\\(\\overline{y}=\\dfrac{1}{n}\\sum_{=1}^n y_i\\) average \\(n\\) numbers \\(\\{y_i:1,\\dots,n\\}\\). emphasis call \\(\\overline{y}\\) sample average. already shown first equation equals zero (equation (2.25)), implies \\(\\overline{y}=\\widehat{\\beta_0}+\\widehat{\\beta_1} \\overline{x}\\). now use equation write intercept terms slope:\\[\\begin{align}\n   \\widehat{\\beta_0}=\\overline{y}-\\widehat{\\beta_1} \\overline{x}\n\\end{align}\\]\nnow plug \\(\\widehat{\\beta_0}\\) second equation, \\(\\sum_{=1}^n x_i (y_i-\\widehat{\\beta_0} - \\widehat{\\beta_1}x_i)=0\\). gives us following (simple algebraic manipulation):\\[\\begin{align}\n   \\sum_{=1}^n x_i\\Big[y_i-(\\overline{y}- \\widehat{\\beta_1} \\overline{x})-\\widehat{\\beta_1} x_i\\Big] & =0                                                                   \n   \\\\\n   \\sum_{=1}^n x_i(y_i-\\overline{y})       & = \\widehat{\\beta_1} \\bigg[ \\sum_{=1}^n x_i(x_i- \\overline{x})\\bigg] \n\\end{align}\\]\nequation solve is22\\[\\begin{align}\n   \\sum_{=1}^n (x_i-\\overline{x}) (y_i- \\overline{y})=\\widehat{\\beta_1} \\bigg[ \\sum_{=1}^n (x_i - \\overline{x})^2 \\bigg]\n\\end{align}\\]\n\\(\\sum_{=1}^n(x_i-\\overline{x})^2\\ne0\\), can write:\n\\[\\begin{align}\n       \\widehat{\\beta}_1 & =                                                                        \n       \\dfrac{\\sum_{=1}^n (x_i-\\overline{x})\n       (y_i-\\overline{y})}{\\sum_{=1}^n(x_i-\\overline{x})^2 }\n       \\\\\n & =\\dfrac{\\text{Sample covariance}(x_i,y_i) }{\\text{Sample variance}(x_i)} \n   \\end{align}\\]previous formula \\(\\widehat{\\beta}_1\\) important shows us take data compute slope estimate. estimate, \\(\\widehat{\\beta}_1\\), commonly referred ordinary least squares (OLS) slope estimate. can computed whenever sample variance \\(x_i\\) isn’t 0. words, can computed \\(x_i\\) constant across values \\(\\). intuition variation \\(x\\) permits us identify impact \\(y\\). also means, though, determine slope relationship observe sample everyone years schooling, whatever causal variable interested .calculated \\(\\widehat{\\beta}_1\\), can compute intercept value, \\(\\widehat{\\beta}_0\\), \\(\\widehat{\\beta}_0=\\overline{y} - \\widehat{\\beta}_1\\overline{x}\\). OLS intercept estimate calculated using sample averages. Notice straightforward \\(\\widehat{\\beta}_0\\) linear \\(\\widehat{\\beta}_1\\). computers statistical programming languages software, let computers calculations even \\(n\\) small, calculations quite tedious.candidate estimates, \\(\\widehat{\\beta}_0, \\widehat{\\beta}_1\\), define fitted value \\(\\) :\\[\\begin{align}\n   \\widehat{y_i}=\\widehat{\\beta}_0+\\widehat{\\beta}_1x_i\n\\end{align}\\]\nRecall \\(=\\{1, \\ldots, n\\}\\), \\(n\\) equations. value predict \\(y_i\\) given \\(x=x_i\\). prediction error \\(y\\ne y_i\\). call mistake residual, use \\(\\widehat{u_i}\\) notation . residual equals:\\[\\begin{align}\n   \\widehat{u_i} & = y_i-\\widehat{y_i}                          \n   \\\\\n   \\widehat{u_i} & = y_i-\\widehat{\\beta_0}-\\widehat{\\beta_1}x_i \n\\end{align}\\]\nresidual error term represented \\({u}\\), important know differences. residual prediction error based fitted \\(\\widehat{y}\\) actual \\(y\\). residual therefore easily calculated sample data. \\(u\\) without hat error term, definition unobserved researcher. Whereas residual appear data set generated steps regression manipulation, error term never appear data set. determinants outcome captured model. crucial distinction, strangely enough subtle even seasoned researchers struggle express .Suppose measure size mistake, \\(\\), squaring . Squaring , , eliminate negative values mistake everything positive value. becomes useful summing mistakes don’t want positive negative values cancel one another . let’s : square mistake add get \\(\\sum_{=1}^n \\widehat{u_i}^2\\):\\[\\begin{align}\n   \\sum_{=1}^n \\widehat{u_i}^2 & =\\sum_{=1}^n (y_i - \\widehat{y_i})^2                                 \\\\\n        & = \\sum_{=1}^n \\Big(y_i-\\widehat{\\beta_0}-\\widehat{\\beta_1}x_i\\Big)^2 \n\\end{align}\\]\nequation called sum squared residuals residual \\(\\widehat{u_i}=y_i-\\widehat{y}\\). residual based estimates slope intercept. can imagine number estimates values. goal minimize sum squared residuals choosing \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta_1}\\)? Using calculus, can shown solutions problem yield parameter estimates obtained .numbers \\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\) given data set, write OLS regression line:\n\\[ \n\\widehat{y}=\\widehat{\\beta_0}+\\widehat{\\beta_1}x\n\\]\nLet’s consider short simulation.ols.dools.RLet’s look output . First, summarize data, ’ll see fitted values produced using Stata’s Predict command manually using Generate command. wanted reader chance better understand , ways. second, let’s look data paste top estimated coefficients, y-intercept slope \\(x\\) Figure 2.1. estimated coefficients close hard coded values built data-generating process.\nFigure 2.1: Graphical representation bivariate regression \\(y\\) \\(x\\)\nestimated coefficients OLS regression line, can predict \\(y\\) (outcome) (sensible) value \\(x\\). plug certain values \\(x\\), can immediately calculate \\(y\\) probably error. value OLS lies large error : OLS minimizes error linear function. fact, best guess \\(y\\) linear estimators minimizes prediction error. ’s always prediction error, words, estimator, OLS least worst.Notice intercept predicted value \\(y\\) \\(x=0\\). sample, value \\(-0.0750109\\).23 slope allows us predict changes \\(y\\) reasonable change \\(x\\) according :\\[\\begin{align}\n   \\Delta \\widehat{y}=\\widehat{\\beta}_1 \\Delta x\n\\end{align}\\]\n\\(\\Delta x=1\\), \\(x\\) increases one unit, \\(\\Delta \\widehat{y}=5.598296\\) numerical example \\(\\widehat{\\beta}_1=5.598296\\).Now calculated \\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\), get OLS fitted values plugging \\(x_i\\) following equation \\(=1,\\dots,n\\):\\[\\begin{align}\n   \\widehat{y_i}=\\widehat{\\beta}_0+\\widehat{\\beta}_1x_i\n\\end{align}\\]\nOLS residuals also calculated :\\[\\begin{align}\n   \\widehat{u_i}=y_i - \\widehat{\\beta}_0 - \\widehat{\\beta}_1 x_i\n\\end{align}\\]\nresiduals different 0 (.e., lie regression line). can see Figure 2.1. positive, negative. positive residual indicates regression line (hence, predicted values) underestimates true value \\(y_i\\). residual negative, regression line overestimates true value.Recall defined fitted value \\(\\widehat{y_i}\\) residual, \\(\\widehat{u_i}\\), \\(y_i - \\widehat{y_i}\\). Notice scatter-plot relationship residuals fitted values created spherical pattern, suggesting correlated (Figure 2.2). mechanical—least squares produces residuals uncorrelated fitted values. ’s magic , just least squares.\nFigure 2.2: Distribution residuals around regression line\n","code":"set seed 1 \nclear \nset obs 10000 \ngen x = rnormal() \ngen u  = rnormal() \ngen y  = 5.5*x + 12*u \nreg y x \npredict yhat1 \ngen yhat2 = -0.0750109  + 5.598296*x // Compare yhat1 and yhat2\nsum yhat* \npredict uhat1, residual \ngen uhat2=y-yhat2 \nsum uhat* \ntwoway (lfit y x, lcolor(black) lwidth(medium)) (scatter y x, mcolor(black) ///\nmsize(tiny) msymbol(point)), title(OLS Regression Line) \nrvfplot, yline(0) \nlibrary(tidyverse)\n\nset.seed(1)\ntb <- tibble(\n  x = rnorm(10000),\n  u = rnorm(10000),\n  y = 5.5*x + 12*u\n) \n\nreg_tb <- tb %>% \n  lm(y ~ x, .) %>%\n  print()\n\nreg_tb$coefficients\n\ntb <- tb %>% \n  mutate(\n    yhat1 = predict(lm(y ~ x, .)),\n    yhat2 = 0.0732608 + 5.685033*x, \n    uhat1 = residuals(lm(y ~ x, .)),\n    uhat2 = y - yhat2\n  )\n\nsummary(tb[-1:-3])\n\ntb %>% \n  lm(y ~ x, .) %>% \n  ggplot(aes(x=x, y=y)) + \n  ggtitle(\"OLS Regression Line\") +\n  geom_point(size = 0.05, color = \"black\", alpha = 0.5) +\n  geom_smooth(method = lm, color = \"black\") +\n  annotate(\"text\", x = -1.5, y = 30, color = \"red\", \n           label = paste(\"Intercept = \", -0.0732608)) +\n  annotate(\"text\", x = 1.5, y = -30, color = \"blue\", \n           label = paste(\"Slope =\", 5.685033))"},{"path":"ch1.html","id":"algebraic-properties-of-ols","chapter":"2 Probability and Regression Review","heading":"2.14 Algebraic Properties of OLS","text":"Remember obtained \\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\)? intercept included, :\\[\\begin{align}\n   \\sum_{=1}^n\\Big(y_i-\\widehat{\\beta}_0 -\\widehat{\\beta}_1x_i\\Big) =0\n\\end{align}\\]\nOLS residual always adds zero, construction.\n\\[ \n\\sum_{=1}^n \\widehat{u_i}=0\n   \\tag{2.27}\n\\]\nSometimes seeing believing, let’s look together. Type following Stata verbatim.ols2.dools2.ROutput can summarized following table (Table 2.6).Table 2.6:  Simulated data showing sum residuals equals zeroNotice difference \\(u\\), \\(\\widehat{y}\\), \\(\\widehat{u}\\) columns. sum ten lines, neither error term fitted values \\(y\\) sum zero. residuals sum zero. , said, one algebraic properties OLS—coefficients optimally chosen ensure residuals sum zero.\\(y_i=\\widehat{y_i}+\\widehat{u_i}\\) definition (can also see Table 6), can take sample average sides:\\[\\begin{align}\n   \\dfrac{1}{n} \\sum_{=1}^n y_i=\\dfrac{1}{n} \\sum_{=1}^n \\widehat{y_i}+\\dfrac{1}{n} \\sum_{=1}^n \\widehat{u_i}\n\\end{align}\\]\n\\(\\overline{y}=\\overline{\\widehat{y}}\\) residuals sum zero. Similarly, way obtained estimates yields\\[\\begin{align}\n   \\sum_{=1}^n x_i \\Big(y_i-\\widehat{\\beta}_0 - \\widehat{\\beta}_1 x_i\\Big)=0\n\\end{align}\\]\nsample covariance (therefore sample correlation) explanatory variables residuals always zero (see Table 2.6).\\[\\begin{align}\n   \\sum_{=1}^n x_i \\widehat{u_i}=0\n\\end{align}\\]\n\\(\\widehat{y_i}\\) linear functions \\(x_i\\), fitted values residuals uncorrelated (see Table 2.6):\\[\\begin{align}\n   \\sum_{=1}^n \\widehat{y_i} \\widehat{u_i}=0 \\tag{2.28}\n\\end{align}\\]\nproperties hold construction. words, \\(\\widehat{\\beta}_0\\) \\(\\widehat{\\beta}_1\\) selected make true.24A third property plug average \\(x\\), predict sample average \\(y\\). , point \\((\\overline{x}, \\overline{y})\\) OLS regression line, :\\[\\begin{align}\n   \\overline{y}=\\widehat{\\beta}_0+\\widehat{\\beta}_1 \\overline{x}\n\\end{align}\\]","code":"clear \nset seed 1234\nset obs 10\ngen x = 9*rnormal() \ngen u  = 36*rnormal() \ngen y  = 3 + 2*x + u\nreg y x\npredict yhat\npredict residuals, residual\nsu residuals\nlist\ncollapse (sum) x u y yhat residuals\nlist\nlibrary(tidyverse)\n\nset.seed(1)\n\ntb <- tibble(\n  x = 9*rnorm(10),\n  u = 36*rnorm(10),\n  y = 3 + 2*x + u,\n  yhat = predict(lm(y ~ x)),\n  uhat = residuals(lm(y ~ x))\n)\n\nsummary(tb)\ncolSums(tb)"},{"path":"ch1.html","id":"goodness-of-fit","chapter":"2 Probability and Regression Review","heading":"2.15 Goodness-of-fit","text":"observation, write\\[\\begin{align}\n   y_i=\\widehat{y_i}+\\widehat{u_i}\n\\end{align}\\]\nDefine total sum squares (SST), explained sum squares (SSE), residual sum squares (SSR) \\[\\begin{align}\n   SST & = \\sum_{=1}^n (y_i - \\overline{y})^2 \\tag{2.29}           \n   \\\\\n   SSE & = \\sum_{=1}^n (\\widehat{y_i} - \\overline{y})^2 \\tag{2.30} \n   \\\\\n   SSR & = \\sum_{=1}^n \\widehat{u_i}^2                                 \n   \\tag{2.31}\n\\end{align}\\]\nsample variances divided \\(n-1\\).25 \\(\\dfrac{SST}{n-1}\\) sample variance \\(y_i\\), \\(\\dfrac{SSE}{n-1}\\) sample variance \\(\\widehat{y_i}\\), \\(\\dfrac{SSR}{n-1}\\) sample variance \\(\\widehat{u_i}\\). simple manipulation rewrite equation (2.29):\\[\\begin{align}\n   SST & = \\sum_{=1}^n (y_i - \\overline{y})^2                                               \n   \\\\\n       & = \\sum_{=1}^n \\Big[ (y_i - \\widehat{y_i}) - (\\widehat{y_i} - \\overline{y}) \\Big]^2 \n   \\\\\n       & = \\sum_{=1}^n \\Big[ \\widehat{u_i} - (\\widehat{y_i} - \\overline{y})\\Big]^2          \n\\end{align}\\]\nSince equation (2.28) shows fitted values uncorrelated residuals, can write following equation:\\[\\begin{align}\n   SST=SSE+SSR\n\\end{align}\\]\nAssuming \\(SST>0\\), can define fraction total variation \\(y_i\\) explained \\(x_i\\) (OLS regression line) \\[\\begin{align}\n   R^2=\\dfrac{SSE}{SST}=1-\\dfrac{SSR}{SST}\n\\end{align}\\]\ncalled R-squared regression. can shown equal square correlation \\(y_i\\) \\(\\widehat{y_i}\\). Therefore \\(0\\leq R^2 \\leq 1\\). R-squared zero means linear relationship \\(y_i\\) \\(x_i\\), \\(R\\)-squared one means perfect linear relationship (e.g., \\(y_i=x_i+2\\)). \\(R^2\\) increases, \\(y_i\\) closer closer falling OLS regression line.encourage fixate \\(R\\)-squared research projects aim estimate causal effect, though. ’s useful summary measure, tell us causality. Remember, aren’t trying explain variation \\(y\\) trying estimate causal effect. \\(R^2\\) tells us much variation \\(y_i\\) explained explanatory variables. interested causal effect single variable, \\(R^2\\) irrelevant. causal inference, need equation (2.24).","code":""},{"path":"ch1.html","id":"expected-value-of-ols","chapter":"2 Probability and Regression Review","heading":"2.16 Expected value of OLS","text":"now, motivated simple regression using population model. analysis purely algebraic, based sample data. residuals always average zero apply OLS sample, regardless underlying model. job gets tougher. Now study statistical properties OLS estimator, referring population model assuming random sampling.26The field mathematical statistics concerned questions. estimators behave across different samples data? average, instance, get right answer repeatedly sample? need find expected value OLS estimators—effect, average outcome across possible random samples—determine whether right, average. leads naturally characteristic called unbiasedness, desirable estimators.\n\\[ \nE(\\widehat{\\beta})=\\beta \\tag{2.32}\n\\]\nRemember, objective estimate \\(\\beta_1\\), slope \\({population}\\) parameter describes relationship \\(y\\) \\(x\\). estimate, \\(\\widehat{\\beta_1}\\), estimator parameter obtained specific sample. Different samples generate different estimates (\\(\\widehat{\\beta_1}\\)) “true” (unobserved) \\(\\beta_1\\). Unbiasedness means take many random samples \\(Y\\) want population compute estimate time, average estimates equal \\(\\beta_1\\).several assumptions required OLS unbiased. first assumption called linear parameters. Assume population model\\[\\begin{align}\n   y=\\beta_0+\\beta_1 x+u\n\\end{align}\\]\n\\(\\beta_0\\) \\(\\beta_1\\) unknown population parameters. view \\(x\\) \\(u\\) outcomes random variables generated data-generating process. Thus, since \\(y\\) function \\(x\\) \\(u\\), random, \\(y\\) also random. Stating assumption formally shows goal estimate \\(\\beta_0\\) \\(\\beta_1\\).second assumption random sampling. random sample size \\(n\\), \\(\\{ (x_i, y_i){:} =1, \\dots, n\\}\\), following population model. know use data estimate \\(\\beta_0\\) \\(\\beta_1\\) OLS. \\(\\) draw population, can write, \\(\\):\\[\\begin{align}\n   y_i=\\beta_0+\\beta_1x_i+u_i\n\\end{align}\\]\nNotice \\(u_i\\) unobserved error observation \\(\\). residual compute data.third assumption called sample variation explanatory variable. , sample outcomes \\(x_i\\) value. saying sample variance \\(x\\) zero. practice, assumption . \\(x_i\\) value (.e., constant), learn \\(x\\) affects \\(y\\) population. Recall OLS covariance \\(y\\) \\(x\\) divided variance \\(x\\), \\(x\\) constant, dividing zero, OLS estimator undefined.fourth assumption assumptions start real teeth. called zero conditional mean assumption probably critical assumption causal inference. population, error term zero mean given value explanatory variable:\\[\\begin{align}\n   E(u\\mid x)=E(u)=0\n\\end{align}\\]\nkey assumption showing OLS unbiased, zero value importance assume \\(E(u\\mid x)\\) change \\(x\\). Note can compute OLS estimates whether assumption holds, even underlying population model., show \\(\\widehat{\\beta_1}\\) unbiased estimate \\(\\beta_1\\) (equation (2.32))? need show four assumptions just outlined, expected value \\(\\widehat{\\beta_1}\\), averaged across random samples, center true value \\(\\beta_1\\). subtle yet critical concept. Unbiasedness context means repeatedly sample data population run regression new sample, average estimated coefficients equal true value \\(\\beta_1\\). discuss answer series steps.Step 1: Write formula \\(\\widehat{\\beta_1}\\). convenient use \\(\\dfrac{C(x,y)}{V(x)}\\) form:\\[\\begin{align}\n   \\widehat{\\beta_1}=\\dfrac{\\sum_{=1}^n (x_i - \\overline{x})y_i}{\\sum_{=1}^n (x_i - \\overline{x})^2}\n\\end{align}\\]\nLet’s get rid notational clutter defining \\(\\sum_{=1}^n (x_i - \\overline{x})^2=SST_x\\) (.e., total variation \\(x_i\\)) rewrite :\\[\\begin{align}\n   \\widehat{\\beta_1}=\\dfrac{ \\sum_{=1}^n (x_i - \\overline{x})y_i}{SST_x}\n\\end{align}\\]Step 2: Replace \\(y_i\\) \\(y_i= \\beta_0+\\beta_1 x_i+u_i\\), uses first linear assumption fact sampled data (second assumption). numerator becomes:\\[\\begin{align}\n   \\sum_{=1}^n (x_i - \\overline{x})y_i & =\\sum_{=1}^n (x_i - \\overline{x})(\\beta_0+\\beta_1 x_i+u_i)                                                                  \n   \\\\\n                & = \\beta_0 \\sum_{=1}^n (x_i - \\overline{x})+\\beta_1 \\sum_{=1}^n (x_i - \\overline{x})x_i+\\sum_{=1}^n (x_i+\\overline{x}) u_i \n   \\\\\n                & =0+\\beta_1 \\sum_{=1}^n (x_i - \\overline{x})^2+ \\sum_{=1}^n (x_i - \\overline{x})u_i                                         \n   \\\\\n                & = \\beta_1 SST_x+\\sum_{=1}^n (x_i - \\overline{x}) u_i                                                                        \n\\end{align}\\]\nNote, used \\(\\sum_{=1}^n (x_i-\\overline{x})=0\\) \\(\\sum_{=1}^n (x_i - \\overline{x})x_i=\\sum_{=1}^n (x_i - \\overline{x})^2\\) .27We shown :\\[\\begin{align}\n   \\widehat{\\beta_1} & = \\dfrac{ \\beta_1 SST_x+ \\sum_{=1}^n (x_i - \\overline{x})u_i }{SST_x} \\nonumber \\\\\n    & = \\beta_1+\\dfrac{ \\sum_{=1}^n (x_i - \\overline{x})u_i }{SST_x}                  \n\\end{align}\\]\nNote last piece slope coefficient OLS regression \\(u_i\\) \\(x_i\\), \\(\\): \\(1, \\dots, n\\).28 regression \\(u_i\\) observed. Now define \\(w_i=\\dfrac{(x_i - \\overline{x})}{SST_x}\\) following:\\[\\begin{align}\n   \\widehat{\\beta_1}=\\beta_1+\\sum_{=1}^n w_i u_i\n\\end{align}\\]\nshowed us following: First, \\(\\widehat{\\beta_1}\\) linear function unobserved errors, \\(u_i\\). \\(w_i\\) functions \\(\\{ x_1, \\dots, x_n \\}\\). Second, random difference \\(\\beta_1\\) estimate , \\(\\widehat{\\beta_1}\\), due linear function unobservables.Step 3: Find \\(E(\\widehat{\\beta_1})\\). random sampling assumption zero conditional mean assumption, \\(E(u_i \\mid x_1, \\dots, x_n)=0\\), means conditional \\(x\\) variables:\\[\\begin{align}\n   E\\big(w_iu_i\\mid x_1, \\dots, x_n\\big) =\n   w_i E\\big(u_i \\mid x_1, \\dots, x_n\\big)=0\n\\end{align}\\]\n\\(w_i\\) function \\(\\{x_1, \\dots, x_n\\}\\). true population \\(u\\) \\(x\\) correlated.Now can complete proof: conditional \\(\\{x_1, \\dots, x_n\\}\\),\\[\\begin{align}\n   E(\\widehat{\\beta_1}) & = E \\bigg(\\beta_1+\\sum_{=1}^n w_i u_i \\bigg) \\\\\n    & =\\beta_1+\\sum_{=1}^n E(w_i u_i)              \\\\\n    & = \\beta_1+\\sum_{=1}^n w_i E(u_i)             \\\\\n    & =\\beta_1 +0                                   \\\\\n    & =\\beta_1                                      \n\\end{align}\\]\nRemember, \\(\\beta_1\\) fixed constant population. estimator, \\(\\widehat{\\beta_1}\\), varies across samples random outcome: collect data, know \\(\\widehat{\\beta_1}\\) . four aforementioned assumptions, \\(E(\\widehat{\\beta_0})=\\beta_0\\) \\(E(\\widehat{\\beta_1})=\\beta_1\\).find helpful concrete work exercises like . let’s visualize . Let’s create Monte Carlo simulation. following population model:\\[\\begin{align}\ny=3+2x+u \\tag{2.33}\n\\end{align}\\]\n\\(x\\sim Normal(0,9)\\), \\(u\\sim Normal(0,36)\\). Also, \\(x\\) \\(u\\) independent. following Monte Carlo simulation estimate OLS sample data 1,000 times. true \\(\\beta\\) parameter equals 2. average \\(\\widehat{\\beta}\\) equal use repeated sampling?ols3.dools3.RTable 2.7:  Monte Carlo simulation OLS.Table 2.7 gives us mean value \\(\\widehat{\\beta-1}\\) 1,000 repetitions (repeated sampling). results differ mine randomness involved simulation. results similar shown . sample different estimated slope, average \\(\\widehat{\\beta-1}\\) samples 1.998317, close true value 2 (see equation (2.33)). standard deviation estimator 0.0398413, close standard error recorded regression .29 Thus, see estimate mean value coefficient repeated sampling, standard error standard deviation repeated estimation. can see distribution coefficient estimates Figure 2.3.\nFigure 2.3: Distribution coefficients Monte Carlo simulation.\nproblem , don’t know kind sample . one “almost exactly 2” samples, one “pretty different 2” samples? can never know whether close population value. hope sample “typical” produces slope estimate close \\(\\widehat{\\beta_1}\\), can’t know. Unbiasedness property procedure rule. property estimate . example, say estimated 8.2% return schooling. tempting say 8.2% unbiased estimate return schooling, ’s technically incorrect. rule used get \\(\\widehat{\\beta_1}=0.082\\) unbiased (believe \\(u\\) unrelated schooling), actual estimate .","code":"clear all \nprogram define ols, rclass \nversion 14.2 \nsyntax [, obs(integer 1) mu(real 0) sigma(real 1) ] \n\n    clear \n    drop _all \n    set obs 10000 \n    gen x = 9*rnormal()  \n    gen u  = 36*rnormal()  \n    gen y  = 3 + 2*x + u \n    reg y x \n    end \n\nsimulate beta=_b[x], reps(1000): ols \nsu \nhist beta\nlibrary(tidyverse)\n\nlm <- lapply(\n  1:1000,\n  function(x) tibble(\n    x = 9*rnorm(10000),\n    u = 36*rnorm(10000),\n    y = 3 + 2*x + u\n  ) %>% \n    lm(y ~ x, .)\n)\n\nas_tibble(t(sapply(lm, coef))) %>%\n  summary(x)\n\nas_tibble(t(sapply(lm, coef))) %>% \n  ggplot()+\n  geom_histogram(aes(x), binwidth = 0.01)"},{"path":"ch1.html","id":"law-of-iterated-expectations","chapter":"2 Probability and Regression Review","heading":"2.17 Law of iterated expectations","text":"conditional expectation function (CEF) mean outcome \\(y\\) covariate \\(x\\) held fixed. Let’s focus intently function.30 Let’s get notation syntax way. noted earlier, write CEF \\(E(y_i\\mid x_i)\\). Note CEF explicitly function \\(x_i\\). \\(x_i\\) random, CEF random—although sometimes work particular values \\(x_i\\), like \\(E(y_i\\mid x_i=8\\text{ years schooling})\\) \\(E(y_i\\mid x_i=\\text{Female})\\). treatment variables, CEF takes two values: \\(E(y_i\\mid d_i=0)\\) \\(E(y_i\\mid d_i= 1)\\). special cases .important complement CEF law iterated expectations (LIE). law says unconditional expectation can written unconditional average CEF. words, \\(E(y_i)=E \\{E(y_i\\mid x_i)\\}\\). fairly simple idea: want know unconditional expectation random variable \\(y\\), can simply calculate weighted sum conditional expectations respect covariate \\(x\\). Let’s look example. Let’s say average grade-point females 3.5, average GPA males 3.2, half population female, half male. :\\[\\begin{align}\n   E[GPA] & = E \\big\\{E(GPA_i\\mid \\text{Gender}_i) \\big\\} \n   \\\\\n          & =(0.5 \\times 3.5)+(3.2 \\times 0.5)            \n   \\\\\n          & = 3.35                                        \n\\end{align}\\]\nprobably use LIE time didn’t even know . proof complicated. Let \\(x_i\\) \\(y_i\\) continuously distributed. joint density defined \\(f_{xy}(u,t)\\). conditional distribution \\(y\\) given \\(x=u\\) defined \\(f_y(t\\mid x_i=u)\\). marginal densities \\(g_y(t)\\) \\(g_x(u)\\).\\[\\begin{align}\n   E \\{E(y\\mid x)\\} & = \\int E(y\\mid x=u) g_x(u) du                                            \\\\\n    & = \\int \\bigg[ \\int tf_{y\\mid x} (t\\mid x=u) dt \\bigg] g_x(u) du          \\\\\n    & = \\int \\int t f_{y\\mid x} (t\\mid x=u) g_x(u) du dt                       \\\\\n    & = \\int t \\bigg[ \\int f_{y\\mid x} (t\\mid x=u) g_x(u) du \\bigg] dt \\text{} \\\\\n    & = \\int t [ f_{x,y}du] dt                                                 \\\\\n    & = \\int t g_y(t) dt                                                       \\\\\n    & =E(y)                                                                    \n\\end{align}\\]\nCheck easy proof . first line uses definition expectation. second line uses definition conditional expectation. third line switches integration order. fourth line uses definition joint density. fifth line replaces prior line subsequent expression. sixth line integrates joint density support x equal marginal density \\(y\\). restating law iterated expectations: \\(E(y_i)= E\\{E(y\\mid x_i)\\}\\).","code":""},{"path":"ch1.html","id":"cef-decomposition-property","chapter":"2 Probability and Regression Review","heading":"2.18 CEF decomposition property","text":"first property CEF discuss CEF decomposition property. power LIE comes way breaks random variable two pieces—CEF residual special properties. CEF decomposition property states \n\\[ \ny_i=E(y_i\\mid x_i)+\\varepsilon_i\\\n\\]() \\(\\varepsilon_i\\) mean independent \\(x_i\\), ,\\[ \nE(\\varepsilon_i\\mid x_i)=0\n\\](ii) \\(\\varepsilon_i\\) correlated function \\(x_i\\).theorem says random variable \\(y_i\\) can decomposed piece explained \\(x_i\\) (CEF) piece left orthogonal function \\(x_i\\). ’ll prove () part first. Recall \\(\\varepsilon_i=y_i - E(y_i\\mid x_i)\\) make substitution second line .\\[\\begin{align}\n   E(\\varepsilon_i\\mid x_i)\n     & =E\\Big(y_i- E(y_i\\mid x_i)\\mid x_i\\Big) \n   \\\\\n     & =E(y_i\\mid x_i) - E(y_i\\mid x_i)        \n   \\\\\n     & = 0                                     \n\\end{align}\\]second part theorem states \\(\\varepsilon_i\\) uncorrelated function \\(x_i\\). Let \\(h(x_i)\\) function \\(x_i\\). \\(E( h(x_i) \\varepsilon_i)=E \\{ h(x_i) E(\\varepsilon_i\\mid x_i)\\}\\) second term interior product equal zero mean independence.31","code":""},{"path":"ch1.html","id":"cef-prediction-property","chapter":"2 Probability and Regression Review","heading":"2.19 CEF prediction property","text":"second property CEF prediction property. states \\(E(y_i\\mid x_i)=\\arg\\min_{m(x_i)}E[(y-m(x_i))^2]\\), \\(m(x_i)\\) function \\(x_i\\). words, states CEF minimum mean squared error \\(y_i\\) given \\(x_i\\). adding \\(E(y_i\\mid x_i) - E(y_i\\mid x_i)=0\\) right side get\n\\[ \n\\Big[y_i-m(x_i)\\Big]^2=\\Big[\\big(y_i-E[y_i\\mid x_i]\\big)\n   +\\big(E(y_i\\mid x_i)- m(x_i)\\big)\\Big]^2\n\\]\npersonally find easier follow simpler notation. replace expression following terms:\n\\[ \n(-b+b-c)^2\n\\]\nDistribute terms, rearrange , replace terms original values get following:\\[\\begin{align}\n   \\arg\\min \\Big(y_i- E(y_i\\mid x_i)\\Big)^2 & + 2\\Big(E(y_i\\mid x_i)- m(x_i)\\Big)\\times \n   \\Big(y_i - E(y_i\\mid x_i)\\Big)\\\\\n    & +\\Big(E(y_i\\mid x_i)+m(x_i)\\Big)^2        \n\\end{align}\\]Now minimize function respect \\(m(x_i)\\). minimizing function respect \\(m(x_i)\\), note first term \\((y_i-E(y_i\\mid x_i))^2\\) doesn’t matter depend \\(m(x_i)\\). zero . second third terms, though, depend \\(m(x_i)\\). rewrite \\(2(E (y_i\\mid x_i)-m(x_i))\\) \\(h(x_i)\\). Also set \\(\\varepsilon_i\\) equal \\([y_i-E(y_i\\mid x_i)]\\) substitute\n\\[ \n\\arg\\min\\varepsilon_i^2+h(x_i)\\varepsilon_i+ \\Big[ E(y_i\\mid x_i)+m(x_i)\\Big]^2\n\\]\nNow minimizing function setting equal zero get\n\\[ \nh'(x_i)\\varepsilon_i\n\\]\nequals zero decomposition property.","code":""},{"path":"ch1.html","id":"anova-theory","chapter":"2 Probability and Regression Review","heading":"2.20 ANOVA theory","text":"final property CEF discuss analysis variance theorem, ANOVA. According theorem, unconditional variance random variable equal variance conditional expectation plus expectation conditional variance, \n\\[ \nV(y_i)=V\\Big[E(y_i\\mid x_i)\\Big]+\n   E\\Big[V(y_i\\mid x_i)\\Big]\n\\]\n\\(V\\) variance \\(V(y_i\\mid x_i)\\) conditional variance.","code":""},{"path":"ch1.html","id":"linear-cef-theorem","chapter":"2 Probability and Regression Review","heading":"2.21 Linear CEF theorem","text":"probably know now, use least squares applied work extremely common. ’s regression several justifications. discussed one—unbiasedness certain assumptions error term. ’d like present slightly different arguments. Angrist Pischke (2009) argue linear regression may useful even underlying CEF linear, regression good approximation CEF. keep open mind break little bit .Angrist Pischke (2009) give several arguments using regression, linear CEF theorem probably easiest. Let’s assume sure CEF linear. ? Well, CEF linear, linear CEF theorem states population regression equal linear CEF. CEF linear, population regression equals , course use population regression estimate CEF. need proof just easily considered common sense, provide one. \\(E(y_i\\mid x_i)\\) linear, \\(E(y_i\\mid x_i)= x'\\widehat{\\beta}\\) vector \\(\\widehat{\\beta}\\). decomposition property, get:\n\\[ \nE\\Big(x(y-E(y\\mid x)\\Big)=E\\Big(x(y-x'\\widehat{\\beta})\\Big)=0\n\\]\nsolve , get \\(\\widehat{\\beta}=\\beta\\). Hence \\(E(y\\mid x)=x'\\beta\\).","code":""},{"path":"ch1.html","id":"best-linear-predictor-theorem","chapter":"2 Probability and Regression Review","heading":"2.22 Best linear predictor theorem","text":"linear theorems worth bringing context. instance, recall CEF minimum mean squared error predictor \\(y\\) given \\(x\\) class functions, according CEF prediction property. Given , population regression function best can class linear functions.32","code":""},{"path":"ch1.html","id":"regression-cef-theorem","chapter":"2 Probability and Regression Review","heading":"2.23 Regression CEF theorem","text":"now like cover one attribute regression. function \\(X\\beta\\) provides minimum mean squared error linear approximation CEF. ,\n\\[ \n\\beta=\\arg\\min_b E\\Big\\{\\big[E(y_i\\mid x_i) - x_i'b\\big]^2 \\Big\\}\n\\]\n? Let’s try back second, though, get big picture, linear theorems can leave reader asking, “?” ’m telling want present argument regression appealing; even though ’s linear, can still justified CEF isn’t. since don’t know certainty CEF linear, actually nice argument least consider. Regression ultimately nothing crank turning data estimates, ’m saying crank produces something desirable even bad situations. Let’s look little bit crank, though, reviewing another theorem become popularly known regression anatomy theorem.","code":""},{"path":"ch1.html","id":"regression-anatomy-theorem","chapter":"2 Probability and Regression Review","heading":"2.24 Regression anatomy theorem","text":"addition discussion CEF regression theorems, now dissect regression . discuss regression anatomy theorem. regression anatomy theorem based earlier work Frisch Waugh (1933) Lovell (1963).33 find theorem intuitive think specific example offer data visualization. opinion, theorem helps us interpret individual coefficients multiple linear regression model. Say interested causal effect family size labor supply. want regress labor supply family size:\\[\\begin{align}\n   Y_i=\\beta_0+\\beta_1 X_i+u_i\n\\end{align}\\]\n\\(Y\\) labor supply, \\(X\\) family size.family size truly random, number kids family uncorrelated unobserved error term.34 implies regress labor supply family size, estimate, \\(\\widehat{\\beta}_1\\), can interpreted causal effect family size labor supply. just plot regression coefficient scatter plot showing \\(\\) pairs data; slope coefficient best linear fit data data cloud. Furthermore, randomized number children, slope also tell us average causal effect family size labor supply.likely, family size isn’t random, many people choose number children family—instead , say, flipping coin. interpret \\(\\widehat{\\beta}_1\\) family size random? Often, people choose family size according something akin optimal stopping rule. People pick many kids , , stop . instances, may even attempt pick gender. choices based variety unobserved observed economic factors may associated one’s decision enter labor market. words, using language ’ve using now, ’s unlikely \\(E(u\\mid X)=E(u)=0\\).let’s say reason think number kids family conditionally random. make tractable sake pedagogy, let’s say particular person’s family size good randomly chosen condition race age.35 unrealistic, include illustrate important point regarding multivariate regressions. assumption true, write following equation:\\[\\begin{align}\n   Y_i=\\beta_0+\\beta_1 X_i+\\gamma_1 R_i+\\gamma_2A_i+u_i\n\\end{align}\\]\n\\(Y\\) labor supply, \\(X\\) number kids, \\(R\\) race, \\(\\) age, \\(u\\) population error term.want estimate average causal effect family size labor supply, need two things. First, need sample data containing four variables. Without four variables, estimate regression model. Second, need number kids, \\(X\\), randomly assigned given set race age.Now, interpret \\(\\widehat{\\beta}_1\\)? might visualize coefficient given six dimensions data? regression anatomy theorem tells us coefficient estimate actually means also lets us visualize data two dimensions.explain intuition regression anatomy theorem, let’s write population model multiple variables. Assume main multiple regression model interest K covariates. can write :\n\\[ \ny_i=\\beta_0+\\beta_1 x_{1i}+\\dots+\\beta_k x_{ki}+ \\dots+\\beta_K x_{Ki}+e_i\n\\]\nNow assume auxiliary regression variable \\(x_{1i}\\) regressed remaining independent variables:\n\\[ \nx_{1i}=\\gamma_0+\\gamma_{k-1}x_{k-1i}+ \\gamma_{k+1}x_{k+1i}+\\dots+\\gamma_Kx_{Ki}+f_i\n\\]\n\\(\\tilde{x}_{1i}=x_{1i} - \\widehat{x}_{1i}\\) residual auxiliary regression. parameter \\(\\beta_1\\) can rewritten :\n\\[ \n\\beta_1=\\dfrac{C(y_i,\\tilde{x}_i)}{V(\\tilde{x}_i)}\n\\]\nNotice see coefficient estimate scaled covariance, , covariance respect outcome residual auxiliary regression, scale variance residual.prove theorem, note \\(E[\\tilde{x}_{ki}]=E[x_{ki}] - E[\\widehat{x}_{ki}]=E[f_i]\\), plug \\(y_i\\) residual \\(\\tilde{x}_{ki}\\) \\(x_{ki}\\) auxiliary regression covariance \\(\\mathop{\\mathrm{cov}}(y_i,x_{ki})\\):\\[\\begin{align}\n   \\beta_k & = \\dfrac{\\mathop{\\mathrm{cov}}( \\beta_0+\\beta_1 x_{1i}+\\dots+ \\beta_kx_{ki}+\\dots+\\beta_Kx_{Ki}+e_i, \\tilde{x}_{ki})}{\\mathop{\\mathrm{var}}(\\tilde{x}_{ki})} \n   \\\\\n           & = \\dfrac{\\mathop{\\mathrm{cov}}(\\beta_0+\\beta_1 x_{1i}+\\dots+\\beta_k x_{ki}+\\dots+\\beta_K x_{Ki}+e_i, f_i)}{\\mathop{\\mathrm{var}}(f_i)}                       \n\\end{align}\\]Since construction \\(E[f_i]=0\\), follows term \\(\\beta_0 E[f_i]=0\\). Since \\(f_i\\) linear combination independent variables exception \\(x_{ki}\\), must \\[\\begin{align}\n   \\beta_1E[f_ix_{1i}]=\\dots=\\beta_{k-1}E[f_ix_{k-1i}]= \\beta_{k+1} E[f_ix_{k+1i}]=\\dots=\\beta_K E[f_ix_{Ki}]=0\n\\end{align}\\]Consider now term \\(E[e_if_i]\\). can written \\[\\begin{align}\n   E[e_if_i] & = E[e_if_i]                               \\\\\n             & = E[e_i \\tilde{x}_{ki}]                   \\\\\n             & = E\\Big[e_i(x_{ki}-\\widehat{x}_{ki})\\Big] \\\\\n             & = E[e_ix_{ki}]-E[e_i\\tilde{x}_{ki}]       \n\\end{align}\\]Since \\(e_i\\) uncorrelated independent variable, also uncorrelated \\(x_{ki}\\). Accordingly, \\(E[e_ix_{ki}]=0\\). regard second term subtraction, substituting predicted value \\(x_{ki}\\) auxiliary regression, get\n\\[ \nE[e_i\\tilde{x}_{ki}]=E\\Big[e_i(\\widehat{\\gamma}_0+ \\widehat{\\gamma}_1x_{1i}+\\dots+ \\widehat{\\gamma}_{k-1i}+ \\widehat{\\gamma}_{k+1}x_{k+1i}+\\dots+ \\widehat{x}_Kx_{Ki})\\Big]\n\\], since \\(e_i\\) uncorrelated independent variable, expected value terms equal zero. follows \\(E[e_if_i]=0\\).remaining term, , \\([\\beta_kx_{ki}f_i]\\), equals \\(E[\\beta_kx_{ki}\\tilde{x}_{ki}]\\), since \\(f_i=\\tilde{x}_{ki}\\). term \\(x_{ki}\\) can substituted rewriting auxiliary regression model, \\(x_{ki}\\), \\[\\begin{align}\n   x_{ki}=E[x_{ki}\\mid X_{-k}]+\\tilde{x}_{ki}\n\\end{align}\\]gives\\[\\begin{align}\n   E[\\beta_{k}x_{ki}\\tilde{x}_{ki}] & = \\beta_k E\\Big[\\tilde{x}_{ki} ( E[x_{ki}\\mid X_{-k}]+ \\tilde{x}_{ki})\\Big]         \n   \\\\\n            & = \\beta_k \\Big\\{ E[\\tilde{x}_{ki}^2]+ E[(E[x_{ki}\\mid x_{-k}]\\tilde{x}_{ki})]\\Big\\} \n   \\\\\n            & = \\beta_{k}\\mathop{\\mathrm{var}}(\\tilde{x}_{ki})                                                     \n\\end{align}\\]follows directly orthogonality \\(E[x_{ki}\\mid X_{-k}]\\) \\(\\tilde{x}_{ki}\\). previous derivations finally get\n\\[ \n\\mathop{\\mathrm{cov}}(y_i,\\tilde{x}_{ki})=\\beta_k\\mathop{\\mathrm{var}}(\\tilde{x}_{ki})\n\\]\ncompletes proof.find helpful visualize things. Let’s look example Stata using popular automobile data set. ’ll show :reganat.doreganat.RLet’s walk regression output ’ve reproduced Table 2.8 well nice visualization slope parameters ’ll call short bivariate regression longer multivariate regression. short regression price car length yields coefficient 57.20 length. every additional inch, car $57 expensive, shown upward-sloping, dashed line Figure 2.4. slope line 57.20.Table 2.8:  Regression estimates automobile price length characteristics.\nFigure 2.4: Regression anatomy display.\neventually become second nature talk including variables right side regression “controlling ” variables. regression anatomy exercise, hope give different interpretation ’re fact “control ” variables regression. First, notice coefficient length changed signs increased magnitude controlled variables. Now, effect length \\(-94.5\\). appears length confounded several variables, conditioned , longer cars actually cheaper. can see visual representation Figure 2.4, multivariate slope negative.exactly going visualization? Well, one, condensed number dimensions (variables) four two. regression anatomy process described earlier. Basically, ran auxiliary regression, used residuals , calculated slope coefficient \\(\\dfrac{\\mathop{\\mathrm{cov}}(y_i,\\tilde{x}_i)}{\\mathop{\\mathrm{var}}{(\\tilde{x}_i)}}\\). allowed us show scatter plots auxiliary residuals paired outcome observations slice slope (Figure 2.4). Notice useful way preview multidimensional correlation two variables multivariate regression. Notice solid black line negative slope bivariate regression positive. regression anatomy theorem shows two estimators—one multivariate OLS bivariate regression price residual—identical.","code":"ssc install reganat, replace\nsysuse auto.dta, replace\nregress price length\nregress price length weight headroom mpg\nreganat price length weight headroom mpg, dis(length) biline\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\n\nauto <- read_data(\"auto.dta\") %>% \n  mutate(length = length - mean(length))\n\nlm1 <- lm(price ~ length, auto)\nlm2 <- lm(price ~ length + weight + headroom + mpg, auto)\n\n\ncoef_lm1 <- lm1$coefficients\ncoef_lm2 <- lm2$coefficients\nresid_lm2 <- lm2$residuals \n\ny_single <- tibble(price = coef_lm1[1] + coef_lm1[2]*auto$length, \n                   length = auto$length)\n\ny_multi <- tibble(price = coef_lm1[1] + coef_lm2[2]*auto$length, \n                  length = auto$length)\n\n\nggplot(auto) + \n  geom_point(aes(x = length, y = price)) +\n  geom_smooth(aes(x = length, y = price), data = y_multi, color = \"blue\") +\n  geom_smooth(aes(x = length, y = price), data = y_single, color=\"red\")"},{"path":"ch1.html","id":"variance-of-the-ols-estimators","chapter":"2 Probability and Regression Review","heading":"2.25 Variance of the OLS estimators","text":"less summarizes want discuss regarding linear regression. zero conditional mean assumption, epistemologically infer rule used produce coefficient regression sample unbiased. ’s nice tells us good reason believe result. now need build epistemological justification capture inherent uncertainty sampling process . added layer uncertainty often called inference. Let’s turn now.Remember simulation ran earlier resampled population estimated regression coefficients thousand times? produced histogram 1,000 estimates Figure 2.3. mean coefficients around 1.998, close true effect 2 (hard-coded data-generating process). standard deviation around 0.04. means , basically, repeated sampling population, got different estimates. average estimates close true effect, spread standard deviation 0.04. concept spread repeated sampling probably useful thing keep mind move section.four assumptions discussed earlier, OLS estimators unbiased. assumptions sufficient tell us anything variance estimator . assumptions help inform beliefs estimated coefficients, average, equal parameter values . speak intelligently variance estimator, need measure dispersion sampling distribution estimators. ’ve saying, leads us variance ultimately standard deviation. characterize variance OLS estimators four assumptions. now, ’s easiest introduce assumption simplifies calculations. ’ll keep assumption ordering ’ve using call fifth assumption.fifth assumption homoskedasticity constant variance assumption. assumption stipulates population error term, \\(u\\), variance given value explanatory variable, \\(x\\). Formally, :\n\\[ \nV(u\\mid x)=\\sigma^2\n\\]\nfirst learning material, always unusually hard time wrapping head around \\(\\sigma^2\\). Part humanities background; didn’t really appreciation random variables dispersed. wasn’t used taking lot numbers trying measure distances , things slow click. ’re like , try . Think \\(\\sigma^2\\) just positive number like 2 8. number measuring spreading underlying errors . words, variance errors conditional explanatory variable simply finite, positive number. number measuring variance stuff \\(x\\) influence value \\(y\\) . assume zero conditional mean assumption, whenever assume homoskedasticity, can also write:\n\\[ \nE(u^2\\mid x)=\\sigma^2=E(u^2)\n\\]\nNow, first, fourth, fifth assumptions, can write:\n\\[\\begin{align}\n       E(y\\mid x) & = \\beta_0+\\beta_1 x \\\\\n       V(y\\mid x) & = \\sigma^2          \n   \\end{align}\\]\naverage, expected, value \\(y\\) allowed change \\(x\\), errors homoskedastic, variance change \\(x\\). constant variance assumption may realistic; must determined case--case basis.Theorem: Sampling variance OLS. assumptions 1 2, get:\\[\\begin{align}\n   V(\\widehat{\\beta_1}\\mid x)&=\\dfrac{\\sigma^2}{\\sum_{=1}^n (x_i-\\overline{x})^2}\\\\\n   &= \\dfrac{ \\sigma^2}{SST_x}\n\\end{align}\\]\\[   \n   V(\\widehat{\\beta_0}\\mid x)=\n   \\dfrac{\\sigma^2\\left(\\dfrac{1}{n} \\sum_{=1}^n x_i^2\\right)}{SST_x}\n\\]\nshow , write, ,\n\\[ \n\\widehat{\\beta_1}=\\beta_1+ \\sum_{=1}^n w_i u_i\n\\]\n\\(w_i=\\dfrac{(x_i-\\overline{x})}{SST_x}\\). treating nonrandom derivation. \\(\\beta_1\\) constant, affect \\(V(\\widehat{\\beta_1})\\). Now, need use fact , uncorrelated random variables, variance sum sum variances. \\(\\{ u_i: =1, \\dots, n \\}\\) actually independent across \\(\\) uncorrelated. Remember: know \\(x\\), know \\(w\\). :\\[\\begin{align}\n   V(\\widehat{\\beta_1}\\mid x) & =\\mathop{\\mathrm{Var\\,}}(\\beta_1+ \\sum_{=1}^n w_i u_i\\mid x)    \n   \\\\\n      & = \\mathop{\\mathrm{Var\\,}}\\bigg(\\sum_{=1}^n w_i u_i\\mid x\\bigg) \n   \\\\\n      & = \\sum_{=1}^n\\mathop{\\mathrm{Var\\,}}(w_i u_i\\mid x)            \n   \\\\\n      & = \\sum_{=1}^n w_i^2\\mathop{\\mathrm{Var\\,}}(u_i\\mid x)          \n   \\\\\n      & = \\sum_{=1}^n w_i^2\\sigma^2                  \n   \\\\\n      & = \\sigma^2 \\sum_{=1}^n w_i^2                 \n\\end{align}\\]\npenultimate equality condition used fifth assumption variance \\(u_i\\) depend \\(x_i\\). Now :\\[\\begin{align}\n   \\sum_{=1}^n w_i^2 & = \\sum_{=1}^n                                          \n   \\dfrac{(x_i-\\overline{x})^2}{SST_x^2}\\\\\n    & =\\dfrac{ \\sum_{=1}^n (x_i - \\overline{x})^2}{ SST_x^2} \\\\\n    & = \\dfrac{ SST_x}{SST_x^2}                               \\\\\n    & = \\dfrac{1}{SST_x}                                      \n\\end{align}\\]\nshown:\n\\[ \nV(\\widehat{\\beta_1})=\\dfrac{\\sigma^2}{SST_x}\n\\]\ncouple points. First, “standard” formula variance OLS slope estimator. valid fifth assumption, homoskedastic errors, doesn’t hold. homoskedasticity assumption needed, words, derive standard formula. homoskedasticity assumption used show unbiasedness OLS estimators. requires first four assumptions.Usually, interested \\(\\beta_1\\). can easily study two factors affect variance: numerator denominator.\n\\[ \nV(\\widehat{\\beta_1})=\\dfrac{ \\sigma^2}{SST_x}\n\\]\nerror variance increases—, \\(\\sigma^2\\) increases—variance estimator. “noise” relationship \\(y\\) \\(x\\) (.e., larger variability \\(u\\)), harder learn something \\(\\beta_1\\). contrast, variation \\(\\{x_i\\}\\) good thing. \\(SST_x\\) rises, \\(V(\\widehat{\\beta_1}) \\downarrow\\).Notice \\(\\dfrac{ SST_x}{n}\\) sample variance \\(x\\). can think getting close population variance \\(x\\), \\(\\sigma_x^2\\), \\(n\\) gets large. means:\n\\[ \nSST_x \\approx n\\sigma_x^2\n\\]\nmeans \\(n\\) grows, \\(V(\\widehat{\\beta_1})\\) shrinks rate \\(\\dfrac{1}{n}\\). data good thing: shrinks sampling variance estimators.standard deviation \\(\\widehat{\\beta_1}\\) square root variance. :\n\\[ \nsd(\\widehat{\\beta_1})=\\dfrac{ \\sigma}{\\sqrt{SST_x}}\n\\]\nturns measure variation appears confidence intervals test statistics.Next look estimating error variance. formula, \\(V(\\widehat{\\beta_1})= \\dfrac{\\sigma^2}{SST_x}\\), can compute \\(SST_x\\) \\(\\{x_i: =1, \\dots, n\\}\\). need estimate \\(\\sigma^2\\). Recall \\(\\sigma^2=E(u^2)\\). Therefore, observe sample errors, \\(\\{u_i: =1, \\dots, n\\}\\), unbiased estimator \\(\\sigma^2\\) sample average:\n\\[ \n\\dfrac{1}{n} \\sum_{=1}^n u_i^2\n\\]\nisn’t estimator can compute data observe, \\(u_i\\) unobserved. replacing \\(u_i\\) “estimate,” OLS residual \\(\\widehat{u_i}\\)?\\[\\begin{align}\n   u_i           & = y_i - \\beta_0 - \\beta_1 x_i                    \n   \\\\\n   \\widehat{u_i} & = y_i - \\widehat{\\beta_0} - \\widehat{\\beta_1}x_i \n\\end{align}\\]\nWhereas \\(u_i\\) computed, \\(\\widehat{u_i}\\) can computed data depends estimators, \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta_1}\\). , except sheer coincidence, \\(u_i\\ne\\widehat{u_i}\\) \\(\\).\\[\\begin{align}\n   \\widehat{u_i} & = y_i-\\widehat{\\beta_0} - \\widehat{\\beta_1}x_i                     \n   \\\\\n                 & =(\\beta_0+\\beta_1x_i+u_i)-\\widehat{\\beta_0} - \\widehat{\\beta_1}x_i \n   \\\\\n                 & =u_i-(\\widehat{\\beta_0}-\\beta_0)-(\\widehat{\\beta_1}                \n   -\\beta_1)x_i\n\\end{align}\\]\nNote \\(E(\\widehat{\\beta_0})=\\beta_0\\) \\(E(\\widehat{\\beta_1})=\\beta_1\\), estimators almost always differ population values sample. estimator \\(\\sigma^2\\)?\n\\[ \n\\dfrac{1}{n} \\sum_{=1}^n \\widehat{u_i}^2= \\dfrac{1}{n}SSR\n\\]\ntrue estimator easily computed data OLS. turns , estimator slightly biased: expected value little less \\(\\sigma^2\\). estimator account two restrictions residuals used obtain \\(\\widehat{\\beta_0}\\) \\(\\widehat{\\beta_1}\\):\\[\\begin{align}\n   \\sum_{=1}^n \\widehat{u_i}=0 \\\\\n   \\sum_{=1}^n x_i \\widehat{u_i}=0\n\\end{align}\\]\nrestriction unobserved errors. unbiased estimator, therefore, \\(\\sigma^2\\) uses degrees--freedom adjustment. residuals \\(n-2\\), \\(n\\), degrees freedom. Therefore:\n\\[ \n\\widehat{\\sigma}^2=\\dfrac{1}{n-2} SSR\n\\]now propose following theorem. unbiased estimator \\(\\sigma^2\\) first five assumptions :\n\\[ \nE(\\widehat{\\sigma}^2)=\\sigma^2\n\\]\nsoftware packages, regression output include:\\[\\begin{align}\n   \\widehat{\\sigma} & = \\sqrt{\\widehat{\\sigma}^2} \n   \\\\\n    & = \\sqrt{\\dfrac{SSR}{(n-2)}} \n\\end{align}\\]\nestimator \\(sd(u)\\), standard deviation population error. One small glitch \\(\\widehat{\\sigma}\\) unbiased \\(\\sigma\\).36 matter purposes: \\(\\widehat{\\sigma}\\) called standard error regression, means estimate standard deviation error regression. software package Stata calls root mean squared error.Given \\(\\widehat{\\sigma}\\), can now estimate \\(sd(\\widehat{\\beta_1})\\) \\(sd(\\widehat{\\beta_0})\\). estimates called standard errors \\(\\widehat{\\beta_j}\\). use lot. Almost regression packages report standard errors column next coefficient estimates. can just plug \\(\\widehat{\\sigma}\\) \\(\\sigma\\):\n\\[ \nse(\\widehat{\\beta_1})= \\dfrac{\\widehat{\\sigma}}{\\sqrt{SST_x}}\n\\]\nnumerator denominator computed data. reasons see, useful report standard errors corresponding coefficient, usually parentheses.","code":""},{"path":"ch1.html","id":"robust-standard-errors","chapter":"2 Probability and Regression Review","heading":"2.26 Robust standard errors","text":"realistic variance errors slices explanatory variable, \\(x\\)? short answer probably unrealistic. Heterogeneity just something ’ve come accept rule, exception, anything, opting believing homoskedasticity, opting . can just take given errors never homoskedastic move forward solution.isn’t completely bad news, unbiasedness regressions based repeated sampling never depended assuming anything variance errors. four assumptions, particularly zero conditional mean assumption, guaranteed central tendency coefficients repeated sampling equal true parameter, book causal parameter. problem spread coefficients. Without homoskedasticity, OLS longer minimum mean squared errors, means estimated standard errors biased. Using sampling metaphor, , distribution coefficients probably larger thought. Fortunately, solution. Let’s write variance equation heterogeneous variance terms:\n\\[ \n\\mathop{\\mathrm{Var\\,}}(\\widehat{\\beta_1})=\\dfrac{\\sum_{=1}^n (x_i - \\overline{x})^2 \\sigma_i^2}{SST_x^2}\n\\]\nNotice \\(\\) subscript \\(\\sigma_i^2\\) term; means variance constant. \\(\\sigma_i^2=\\sigma^2\\) \\(\\), formula reduces usual form, \\(\\dfrac{\\sigma^2}{SST_x^2}\\). isn’t true, problem called heteroskedastic errors. valid estimator Var(\\(\\widehat{\\beta_1}\\)) heteroskedasticity form (including homoskedasticity) \n\\[ \n\\mathop{\\mathrm{Var\\,}}(\\widehat{\\beta_1})=\\dfrac{\\sum_{=1}^n (x_i - \\overline{x})^2 \\widehat{u_i}^2}{SST_x^2}\n\\]\neasily computed data OLS regression. Friedhelm Eicker, Peter J. Huber, Halbert White thank solution (White (1980)).37 solution heteroskedasticity goes several names, common “robust” standard error.","code":""},{"path":"ch1.html","id":"cluster-robust-standard-errors","chapter":"2 Probability and Regression Review","heading":"2.27 Cluster robust standard errors","text":"People try scare challenging constructed standard errors. Heteroskedastic errors, though, aren’t thing worried comes inference. phenomena affect observations individually, affect groups observations involve individuals. affect individuals within group common way. Say want estimate effect class size student achievement, know exist unobservable things (like teacher) affect students equally. can commit independence unobservables across classes, individual student unobservables correlated within class, situation need cluster standard errors. dive example, ’d like start simulation illustrate problem.baseline simulation, let’s begin simulating nonclustered data analyze least squares estimates nonclustered data. help firm understanding problems occur least squares data clustered.38cluster1.docluster1.RAs can see Figure 2.5, least squares estimate centered true population parameter.\nFigure 2.5: Distribution least squares estimator 1,000 random draws.\nSetting significance level 5%, incorrectly reject null \\(\\beta_1=0\\) 5% time simulations. let’s check confidence intervals. can seen Figure 2.6, 95% 95% confidence intervals contain true value \\(\\beta_1\\), zero. words, means incorrectly reject null 5% time.\nFigure 2.6: Distribution 95% confidence intervals coloring showing incorrectly rejecting null.\nhappens use least squares clustered data? see , let’s resimulate data observations longer independent draws given cluster observations.cluster2.docluster2.R\nFigure 2.7: Distribution least squares estimator 1,000 random draws.\ncan seen Figure 2.7, least squares estimate narrower spread estimates data isn’t clustered. see bit clearly, let’s look confidence intervals .cluster3.docluster3.R\nFigure 2.8: Distribution 1,000 95% confidence intervals dashed region representing estimates incorrectly reject null.\nFigure 2.8 shows distribution 95% confidence intervals least squares estimates. can seen, much larger number estimates incorrectly rejected null hypothesis data clustered. standard deviation estimator shrinks clustered data, causing us reject null incorrectly often. can ?cluster4.docluster4.RNow case, notice included “, cluster(cluster_ID)” syntax regression command. dive syntax , let’s look confidence intervals changed. Figure 2.9 shows distribution 95% confidence intervals , , darkest region represents estimates incorrectly rejected null. Now, observations whose errors correlated within cluster, find estimating model using least squares leads us back situation type error decreased considerably.\nFigure 2.9: Distribution 1,000 95% confidence intervals cluster robust least squares regression dashed region representing estimates incorrectly reject null.\nleads us natural question: adjustment estimator’s variance caused type error decrease much? Whatever ’s , sure seems working! Let’s dive adjustment example. Consider following model:\n\\[ \ny_{ig}=x_{ig}'\\beta+u_{ig}\\quad \\text{$1, \\dots, G$}\n\\]\n\n\\[ \nE[u_{ig}u_{jg}']\n\\]\nequals zero \\(g=g'\\) equals \\(\\sigma_{(ij)g}\\) \\(g\\ne g'\\).Let’s stack data cluster first.\n\\[ \ny_g=x_g' \\beta+u_g\n\\]\nOLS estimator still \\(\\widehat{\\beta}= E[X'X]^{-1}X'Y\\). just stacked data, doesn’t affect estimator . change variance.\n\\[ \nV(\\beta)=E\\Big[[X'X]^{-1}X' \\Omega X[X'X]^{-1}\\Big]\n\\]\nmind, can now write variance-covariance matrix clustered data \n\\[ \n\\widehat{V}(\\widehat{\\beta})=[X'X]^{-1}\n   \\left[ \\sum_{=1}^G x'_g \\widehat{u}_g \\widehat{u}_g'\\right][X'X]^{-1}\n\\]Adjusting clustered data quite common applied work given ubiquity clustered data first place. ’s absolutely essential working panel contexts, repeated cross-sections like difference--differences design. also turns important experimental design, often, treatment higher level aggregation microdata . real world, though, can never assume errors independent draws distribution. need know variables constructed first place order choose correct error structure calculating standard errors. aggregate variables, like class size, ’ll need cluster level. treatment occurred state level, ’ll need cluster level. ’s large literature available looks even complex error structures, multi-way clustering (Cameron, Gelbach, Miller 2011).even concept sample basis standard errors may shifting. ’s becoming increasingly less case researchers work random samples; likely working administrative data containing population , thus concept sampling uncertainty becomes strained.39 instance, Manski Pepper (2018) wrote “random sampling assumptions …natural considering states counties units observation.” although metaphor superpopulation may useful extending classical uncertainty concepts, ubiquity digitized administrative data sets led econometricians statisticians think uncertainty ways.New work Abadie et al. (2020) explores sampling-based concepts standard error may right way think uncertainty context causal inference, call design-based uncertainty. work many ways anticipates next two chapters direct reference concept counterfactual. Design-based uncertainty reflection knowing values occurred intervention different counterfactual. Abadie et al. (2020) derive standard errors design-based uncertainty, opposed sampling-based uncertainty. luck , standard errors usually smaller.Let’s now move fundamental concepts causality used applied work try develop tools understand counterfactuals causality work together.Buy print version today:","code":"clear all\nset seed 20140\n* Set the number of simulations\nlocal n_sims  = 1000\nset obs `n_sims'\n\n* Create the variables that will contain the results of each simulation\ngenerate beta_0 = .\ngenerate beta_0_l = .\ngenerate beta_0_u = .\ngenerate beta_1 = .\ngenerate beta_1_l = .\ngenerate beta_1_u = .\n\n\n* Provide the true population parameters\nlocal beta_0_true = 0.4\nlocal beta_1_true = 0\nlocal rho = 0.5\n\n* Run the linear regression 1000 times and save the parameters beta_0 and beta_1\nquietly {\n    forvalues i = 1(1) `n_sims' {\n        preserve  \n        clear\n        set obs 100\n        generate x = rnormal(0,1)\n        generate e = rnormal(0, sqrt(1 - `rho'))\n        generate y = `beta_0_true' + `beta_1_true'*x + e\n        regress y x\n        local b0 = _b[_cons]\n        local b1 = _b[x]\n        local df = e(df_r)\n        local critical_value = invt(`df', 0.975)\n        restore\n        replace beta_0 = `b0' in `i'\n        replace beta_0_l = beta_0 - `critical_value'*_se[_cons] \n        replace beta_0_u = beta_0 + `critical_value'*_se[_cons] \n        replace beta_1 = `b1' in `i'\n        replace beta_1_l = beta_1 - `critical_value'*_se[x] \n        replace beta_1_u = beta_1 + `critical_value'*_se[x] \n        \n    }\n}\ngen false = (beta_1_l > 0 )\nreplace false = 2 if beta_1_u < 0\nreplace false = 3 if false == 0\ntab false\n\n* Plot the parameter estimate\nhist beta_1, frequency addplot(pci 0 0 100 0) title(\"Least squares estimates of non-clustered data\") subtitle(\" Monte Carlo simulation of the slope\") legend(label(1 \"Distribution of least squares estimates\") label(2 \"True population parameter\")) xtitle(\"Parameter estimate\") \n\nsort beta_1\ngen int sim_ID = _n\ngen beta_1_True = 0\n* Plot of the Confidence Interval\ntwoway rcap beta_1_l beta_1_u sim_ID if beta_1_l > 0 | beta_1_u < 0  , horizontal lcolor(pink) || || ///\nrcap beta_1_l beta_1_u sim_ID if beta_1_l < 0 & beta_1_u > 0 , horizontal ysc(r(0)) || || ///\nconnected sim_ID beta_1 || || ///\nline sim_ID beta_1_True, lpattern(dash) lcolor(black) lwidth(1) ///  \ntitle(\"Least squares estimates of non-clustered data\") subtitle(\" 95% Confidence interval of the slope\") ///\nlegend(label(1 \"Missed\") label(2 \"Hit\") label(3 \"OLS estimates\") label(4 \"True population parameter\")) xtitle(\"Parameter estimates\") ///\nytitle(\"Simulation\")\n#- Analysis of Clustered Data\n#- Courtesy of Dr. Yuki Yanai, \n#- http://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html\n\nlibrary('arm')\nlibrary('mvtnorm')\nlibrary('lme4')\nlibrary('multiwayvcov')\nlibrary('clusterSEs')\nlibrary('ggplot2')\nlibrary('dplyr')\nlibrary('haven')\n\ngen_cluster <- function(param = c(.1, .5), n = 1000, n_cluster = 50, rho = .5) {\n  # Function to generate clustered data\n  # Required package: mvtnorm\n  \n  # individual level\n  Sigma_i <- matrix(c(1, 0, 0, 1 - rho), ncol = 2)\n  values_i <- rmvnorm(n = n, sigma = Sigma_i)\n  \n  # cluster level\n  cluster_name <- rep(1:n_cluster, each = n / n_cluster)\n  Sigma_cl <- matrix(c(1, 0, 0, rho), ncol = 2)\n  values_cl <- rmvnorm(n = n_cluster, sigma = Sigma_cl)\n  \n  # predictor var consists of individual- and cluster-level components\n  x <- values_i[ , 1] + rep(values_cl[ , 1], each = n / n_cluster)\n  \n  # error consists of individual- and cluster-level components\n  error <- values_i[ , 2] + rep(values_cl[ , 2], each = n / n_cluster)\n  \n  # data generating process\n  y <- param[1] + param[2]*x + error\n  \n  df <- data.frame(x, y, cluster = cluster_name)\n  return(df)\n}\n\n# Simulate a dataset with clusters and fit OLS\n# Calculate cluster-robust SE when cluster_robust = TRUE\ncluster_sim <- function(param = c(.1, .5), n = 1000, n_cluster = 50,\n                        rho = .5, cluster_robust = FALSE) {\n  # Required packages: mvtnorm, multiwayvcov\n  df <- gen_cluster(param = param, n = n , n_cluster = n_cluster, rho = rho)\n  fit <- lm(y ~ x, data = df)\n  b1 <- coef(fit)[2]\n  if (!cluster_robust) {\n    Sigma <- vcov(fit)\n    se <- sqrt(diag(Sigma)[2])\n    b1_ci95 <- confint(fit)[2, ]\n  } else { # cluster-robust SE\n    Sigma <- cluster.vcov(fit, ~ cluster)\n    se <- sqrt(diag(Sigma)[2])\n    t_critical <- qt(.025, df = n - 2, lower.tail = FALSE)\n    lower <- b1 - t_critical*se\n    upper <- b1 + t_critical*se\n    b1_ci95 <- c(lower, upper)\n  }\n  return(c(b1, se, b1_ci95))\n}\n\n# Function to iterate the simulation. A data frame is returned.\nrun_cluster_sim <- function(n_sims = 1000, param = c(.1, .5), n = 1000,\n                            n_cluster = 50, rho = .5, cluster_robust = FALSE) {\n  # Required packages: mvtnorm, multiwayvcov, dplyr\n  df <- replicate(n_sims, cluster_sim(param = param, n = n, rho = rho,\n                                      n_cluster = n_cluster,\n                                      cluster_robust = cluster_robust))\n  df <- as.data.frame(t(df))\n  names(df) <- c('b1', 'se_b1', 'ci95_lower', 'ci95_upper')\n  df <- df %>% \n    mutate(id = 1:n(),\n           param_caught = ci95_lower <= param[2] & ci95_upper >= param[2])\n  return(df)\n}\n\n# Distribution of the estimator and confidence intervals\nsim_params <- c(.4, 0)   # beta1 = 0: no effect of x on y\nsim_nocluster <- run_cluster_sim(n_sims = 10000, param = sim_params, rho = 0)\nhist_nocluster <- ggplot(sim_nocluster, aes(b1)) +\n  geom_histogram(color = 'black') +\n  geom_vline(xintercept = sim_params[2], color = 'red')\nprint(hist_nocluster)\n\nci95_nocluster <- ggplot(sample_n(sim_nocluster, 100),\n                         aes(x = reorder(id, b1), y = b1, \n                             ymin = ci95_lower, ymax = ci95_upper,\n                             color = param_caught)) +\n  geom_hline(yintercept = sim_params[2], linetype = 'dashed') +\n  geom_pointrange() +\n  labs(x = 'sim ID', y = 'b1', title = 'Randomly Chosen 100 95% CIs') +\n  scale_color_discrete(name = 'True param value', labels = c('missed', 'hit')) +\n  coord_flip()\nprint(ci95_nocluster)\n\nsim_nocluster %>% summarize(type1_error = 1 - sum(param_caught)/n())clear all\nset seed 20140\nlocal n_sims = 1000\nset obs `n_sims'\n\n* Create the variables that will contain the results of each simulation\ngenerate beta_0 = .\ngenerate beta_0_l = .\ngenerate beta_0_u = .\ngenerate beta_1 = .\ngenerate beta_1_l = .\ngenerate beta_1_u = .\n\n\n* Provide the true population parameters\nlocal beta_0_true = 0.4\nlocal beta_1_true = 0\nlocal rho = 0.5\n\n* Simulate a linear regression. Clustered data (x and e are clustered)\n\n\nquietly {\nforvalues i = 1(1) `n_sims' {\n    preserve\n    clear\n    set obs 50\n    \n    * Generate cluster level data: clustered x and e\n    generate int cluster_ID = _n\n    generate x_cluster = rnormal(0,1)\n    generate e_cluster = rnormal(0, sqrt(`rho'))\n    expand 20\n    bysort cluster_ID : gen int ind_in_clusterID = _n\n\n    * Generate individual level data\n    generate x_individual = rnormal(0,1)\n    generate e_individual = rnormal(0,sqrt(1 - `rho'))\n\n    * Generate x and e\n    generate x = x_individual + x_cluster\n    generate e = e_individual + e_cluster\n    generate y = `beta_0_true' + `beta_1_true'*x + e\n    \n* Least Squares Estimates\n    regress y x\n    local b0 = _b[_cons]\n    local b1 = _b[x]\n    local df = e(df_r)\n    local critical_value = invt(`df', 0.975)\n    * Save the results\n    restore\n    replace beta_0 = `b0' in `i'\n    replace beta_0_l = beta_0 - `critical_value'*_se[_cons]\n    replace beta_0_u = beta_0 + `critical_value'*_se[_cons]\n    replace beta_1 = `b1' in `i'\n    replace beta_1_l = beta_1 - `critical_value'*_se[x]\n    replace beta_1_u = beta_1 + `critical_value'*_se[x]\n}\n}\n\ngen false = (beta_1_l > 0 )\nreplace false = 2 if beta_1_u < 0\nreplace false = 3 if false == 0\ntab false\n\n* Plot the parameter estimate\nhist beta_1, frequency addplot(pci 0 0 100 0) title(\"Least squares estimates of clustered Data\") subtitle(\" Monte Carlo simulation of the slope\") legend(label(1 \"Distribution of least squares estimates\") label(2 \"True population parameter\")) xtitle(\"Parameter estimate\")\n#- Analysis of Clustered Data - part 2\n#- Courtesy of Dr. Yuki Yanai, \n#- http://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html\n\nlibrary('arm')\nlibrary('mvtnorm')\nlibrary('lme4')\nlibrary('multiwayvcov')\nlibrary('clusterSEs')\nlibrary('ggplot2')\nlibrary('dplyr')\nlibrary('haven')\n\n#Data with clusters\nsim_params <- c(.4, 0)   # beta1 = 0: no effect of x on y\nsim_cluster_ols <- run_cluster_sim(n_sims = 10000, param = sim_params)\nhist_cluster_ols <- hist_nocluster %+% sim_cluster_ols\nprint(hist_cluster_ols)sort beta_1\ngen int sim_ID = _n\ngen beta_1_True = 0\n\n* Plot of the Confidence Interval\ntwoway rcap beta_1_l beta_1_u sim_ID if beta_1_l > 0 | beta_1_u < 0  , horizontal lcolor(pink) || || ///\nrcap beta_1_l beta_1_u sim_ID if beta_1_l < 0 & beta_1_u > 0 , horizontal ysc(r(0)) || || ///\nconnected sim_ID beta_1 || || ///\nline sim_ID beta_1_True, lpattern(dash) lcolor(black) lwidth(1) ///  \ntitle(\"Least squares estimates of clustered data\") subtitle(\" 95% Confidence interval of the slope\") ///\nlegend(label(1 \"Missed\") label(2 \"Hit\") label(3 \"OLS estimates\") label(4 \"True population parameter\")) xtitle(\"Parameter estimates\") ///\nytitle(\"Simulation\")\n#- Analysis of Clustered Data - part 3\n#- Courtesy of Dr. Yuki Yanai, \n#- http://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html\n\nlibrary('arm')\nlibrary('mvtnorm')\nlibrary('lme4')\nlibrary('multiwayvcov')\nlibrary('clusterSEs')\nlibrary('ggplot2')\nlibrary('dplyr')\nlibrary('haven')\n\n#Confidence interval\nci95_cluster_ols <- ci95_nocluster %+% sample_n(sim_cluster_ols, 100)\nprint(ci95_cluster_ols)\n\nsim_cluster_ols %>% summarize(type1_error = 1 - sum(param_caught)/n())* Robust Estimates\nclear all\nlocal n_sims = 1000\nset obs `n_sims'\n\n* Create the variables that will contain the results of each simulation\ngenerate beta_0_robust = .\ngenerate beta_0_l_robust = .\ngenerate beta_0_u_robust = .\ngenerate beta_1_robust = .\ngenerate beta_1_l_robust = .\ngenerate beta_1_u_robust = .\n\n* Provide the true population parameters\nlocal beta_0_true = 0.4\nlocal beta_1_true = 0\nlocal rho = 0.5\n\nquietly {\nforvalues i = 1(1) `n_sims' {\n    preserve\n    clear\n    set obs 50\n    \n    * Generate cluster level data: clustered x and e\n    generate int cluster_ID = _n\n    generate x_cluster = rnormal(0,1)\n    generate e_cluster = rnormal(0, sqrt(`rho'))\n    expand 20\n    bysort cluster_ID : gen int ind_in_clusterID = _n\n\n    * Generate individual level data\n    generate x_individual = rnormal(0,1)\n    generate e_individual = rnormal(0,sqrt(1 - `rho'))\n\n    * Generate x and e\n    generate x = x_individual + x_cluster\n    generate e = e_individual + e_cluster\n    generate y = `beta_0_true' + `beta_1_true'*x + e\n    regress y x, cl(cluster_ID)\n    local b0_robust = _b[_cons]\n    local b1_robust = _b[x]\n    local df = e(df_r)\n    local critical_value = invt(`df', 0.975)\n    * Save the results\n    restore\n    replace beta_0_robust = `b0_robust' in `i'\n    replace beta_0_l_robust = beta_0_robust - `critical_value'*_se[_cons]\n    replace beta_0_u_robust = beta_0_robust + `critical_value'*_se[_cons]\n    replace beta_1_robust = `b1_robust' in `i'\n    replace beta_1_l_robust = beta_1_robust - `critical_value'*_se[x]\n    replace beta_1_u_robust = beta_1_robust + `critical_value'*_se[x]\n\n}\n}\n\n* Plot the histogram of the parameters estimates of the robust least squares\ngen false = (beta_1_l_robust > 0 )\nreplace false = 2 if beta_1_u_robust < 0\nreplace false = 3 if false == 0\ntab false\n\n* Plot the parameter estimate\nhist beta_1_robust, frequency addplot(pci 0 0 110 0) title(\"Robust least squares estimates of clustered data\") subtitle(\" Monte Carlo simulation of the slope\") legend(label(1 \"Distribution of robust least squares estimates\") label(2 \"True population parameter\")) xtitle(\"Parameter estimate\")\n\nsort beta_1_robust\ngen int sim_ID = _n\ngen beta_1_True = 0\n\n* Plot of the Confidence Interval\ntwoway rcap beta_1_l_robust beta_1_u_robust sim_ID if beta_1_l_robust > 0 | beta_1_u_robust < 0, horizontal lcolor(pink) || || rcap beta_1_l_robust beta_1_u_robust sim_ID if beta_1_l_robust < 0 & beta_1_u_robust > 0 , horizontal ysc(r(0)) || || connected sim_ID beta_1_robust || || line sim_ID beta_1_True, lpattern(dash) lcolor(black) lwidth(1) title(\"Robust least squares estimates of clustered data\") subtitle(\" 95% Confidence interval of the slope\") legend(label(1 \"Missed\") label(2 \"Hit\") label(3 \"Robust estimates\") label(4 \"True population parameter\")) xtitle(\"Parameter estimates\") ytitle(\"Simulation\")\n#- Analysis of Clustered Data - part 4\n#- Courtesy of Dr. Yuki Yanai, \n#- http://yukiyanai.github.io/teaching/rm1/contents/R/clustered-data-analysis.html\n\nlibrary('arm')\nlibrary('mvtnorm')\nlibrary('lme4')\nlibrary('multiwayvcov')\nlibrary('clusterSEs')\nlibrary('ggplot2')\nlibrary('dplyr')\nlibrary('haven')\n\n#clustered robust\nsim_params <- c(.4, 0)   # beta1 = 0: no effect of x on y\nsim_cluster_robust <- run_cluster_sim(n_sims = 10000, param = sim_params,\n                                      cluster_robust = TRUE)\n\nhist_cluster_robust <- hist_nocluster %+% sim_cluster_ols\nprint(hist_cluster_robust)\n\n#Confidence Intervals\nci95_cluster_robust <- ci95_nocluster %+% sample_n(sim_cluster_robust, 100)\nprint(ci95_cluster_robust)\n\nsim_cluster_robust %>% summarize(type1_error = 1 - sum(param_caught)/n())"},{"path":"ch2.html","id":"ch2","chapter":"3 Directed Acyclic Graphs","heading":"3 Directed Acyclic Graphs","text":"Buy print version today:history graphical causal modeling goes back early twentieth century Sewall Wright, one fathers modern genetics son economist Philip Wright. Sewall developed path diagrams genetics, Philip, believed, adapted econometric identification (Matsueda 2012).40But despite promising start, use graphical modeling causal inference largely ignored economics profession, exceptions (Heckman Pinto 2015; Imbens 2019). revitalized purpose causal inference computer scientist Turing Award winner Judea Pearl adapted work artificial intelligence. explained mangum opus, general theory causal inference expounds usefulness directed graph notation (Pearl 2009). Since graphical models immensely helpful designing credible identification strategy, chosen include consideration. Let’s review graphical models, one Pearl’s contributions theory causal inference.41","code":""},{"path":"ch2.html","id":"introduction-to-dag-notation","chapter":"3 Directed Acyclic Graphs","heading":"3.1 Introduction to DAG Notation","text":"Using directed acyclic graphical (DAG) notation requires -front statements. first thing notice DAG notation, causality runs one direction. Specifically, runs forward time. cycles DAG. show reverse causality, one need create multiple nodes, likely two versions node separated time index. Similarly, simultaneity, supply demand models, straightforward DAGs (Heckman Pinto 2015). handle either simultaneity reverse causality, recommended take completely different approach problem one presented chapter. Third, DAGs explain causality terms counterfactuals. , causal effect defined comparison two states world—one state actually happened intervention took value another state didn’t happen (“counterfactual”) intervention.Think DAG like graphical representation chain causal effects. causal effects based underlying, unobserved structured process, one economist might call equilibrium values system behavioral equations, nothing model world. captured efficiently using graph notation, nodes arrows. Nodes represent random variables, random variables assumed created data-generating process.42 Arrows represent causal effect two random variables moving intuitive direction arrow. direction arrow captures direction causality.Causal effects can happen two ways. can either direct (e.g., \\(D \\rightarrow Y\\)), can mediated third variable (e.g., \\(D \\rightarrow X \\rightarrow Y\\)). mediated third variable, capturing sequence events originating \\(D\\), may may important depending question ’re asking.DAG meant describe causal relationships relevant effect \\(D\\) \\(Y\\). makes DAG distinctive explicit commitment causal effect pathway complete commitment lack causal pathway represented missing arrows. words, DAG contain arrows connecting variables choices exclude arrows. lack arrow necessarily means think relationship data—one strongest beliefs can hold. complete DAG direct causal effects among variables graph well common causes pair variables graph.point, may wondering DAG comes . ’s excellent question. may question. DAG supposed theoretical representation state---art knowledge phenomena ’re studying. ’s expert say thing , expertise comes variety sources. Examples include economic theory, scientific models, conversations experts, observations experiences, literature reviews, well intuition hypotheses.included material book found DAGs useful understanding critical role prior knowledge plays identifying causal effects. reasons . One, found DAGs helpful communicating research designs estimators reason pictures speak thousand words. , experience, especially true instrumental variables, intuitive DAG representation. Two, concepts backdoor criterion collider bias, well-designed DAG can help develop credible research design identifying causal effects intervention. bonus, also think DAG provides bridge various empirical schools, structural reduced form groups. finally, DAGs drive home point assumptions necessary identification causal effects, economists hammering years (Wolpin 2013).","code":""},{"path":"ch2.html","id":"a-simple-dag","chapter":"3 Directed Acyclic Graphs","heading":"3.1.1 A simple DAG","text":"Let’s begin simple DAG illustrate basic ideas. expand build slightly complex ones later.DAG, three random variables: \\(X\\), \\(D\\), \\(Y\\). direct path \\(D\\) \\(Y\\), represents causal effect. path represented \\(D \\rightarrow Y\\). also second path \\(D\\) \\(Y\\) called backdoor path. backdoor path \\(D \\leftarrow X \\rightarrow Y\\). direct path causal effect, backdoor path causal. Rather, process creates spurious correlations \\(D\\) \\(Y\\) driven solely fluctuations \\(X\\) random variable.idea backdoor path one important things can learn DAG. similar notion omitted variable bias represents variable determines outcome treatment variable. Just controlling variable like regression creates omitted variable bias, leaving backdoor open creates bias. backdoor path \\(D \\leftarrow X \\rightarrow Y\\). therefore call \\(X\\) confounder jointly determines \\(D\\) \\(Y\\), confounds ability discern effect \\(D\\) \\(Y\\) naı̈ve comparisons.Think backdoor path like : Sometimes \\(D\\) takes different values, \\(Y\\) takes different values \\(D\\) causes \\(Y\\). sometimes \\(D\\) \\(Y\\) take different values \\(X\\) takes different values, bit correlation \\(D\\) \\(Y\\) purely spurious. existence two causal pathways contained within correlation \\(D\\) \\(Y\\).Let’s look second DAG, subtly different first. previous example, \\(X\\) observed. know observed direct edges \\(X\\) \\(D\\) \\(Y\\) solid lines. sometimes exists confounder unobserved, , represent direct edges dashed lines. Consider following DAG:, \\(U\\) noncollider along backdoor path \\(D\\) \\(Y\\), unlike , \\(U\\) unobserved researcher. exists, may simply missing data set. situation, two pathways \\(D\\) \\(Y\\). ’s direct pathway, \\(D \\rightarrow Y\\), causal effect, ’s backdoor pathway, \\(D \\leftarrow U \\rightarrow Y\\). since \\(U\\) unobserved, backdoor pathway open.Let’s now move another example, one slightly realistic. classical question labor economics whether college education increases earnings. According Becker human capital model (Becker 1994), education increases one’s marginal product, since workers paid marginal product competitive markets, education also increases earnings. college education random; optimally chosen given individual’s subjective preferences resource constraints. represent following DAG. always, let \\(D\\) treatment (e.g., college education) \\(Y\\) outcome interest (e.g., earnings). Furthermore, let \\(PE\\) parental education, \\(\\) family income, \\(B\\) unobserved background factors, genetics, family environment, mental ability.DAG telling story. one things like DAGs invite everyone listen story together. interpretation story told. person background. ’s contained data sets, measures things like intelligence, contentiousness, mood stability, motivation, family dynamics, environmental factors—hence, unobserved picture. environmental factors likely correlated parent child therefore subsumed variable \\(B\\).Background causes child’s parent choose optimal level education, choice also causes child choose level education variety channels. First, shared background factors, \\(B\\). background factors cause child choose level education, just parent . Second, ’s direct effect, perhaps simple modeling achievement setting expectations, kind peer effect. third, ’s effect parental education family earnings, \\(\\), turn affects much schooling child receives. Family earnings may affect child’s future earnings bequests transfers, well external investments child’s productivity.simple story tell, DAG tells well, want alert attention subtle points contained DAG. DAG actually telling two stories. telling happening, telling happening. instance, notice \\(B\\) direct effect child’s earnings except effect schooling. realistic, though? Economists long maintained unobserved ability determines much schooling child gets directly affects child’s future earnings, insofar intelligence motivation can influence careers. DAG, relationship background earnings, assumption. free call foul assumption think background factors affect schooling child’s productivity, affect wages. think arrow \\(B\\) \\(Y\\)? draw one rewrite backdoor paths \\(D\\) \\(Y\\).Now DAG, ? like list direct indirect paths (.e., backdoor paths) \\(D\\) \\(Y\\). , better sense problems . :\\(D \\rightarrow Y\\) (causal effect education earnings)\\(D \\rightarrow Y\\) (causal effect education earnings)\\(D \\leftarrow \\rightarrow Y\\) (backdoor path 1)\\(D \\leftarrow \\rightarrow Y\\) (backdoor path 1)\\(D \\leftarrow PE \\rightarrow \\rightarrow Y\\) (backdoor path 2)\\(D \\leftarrow PE \\rightarrow \\rightarrow Y\\) (backdoor path 2)\\(D \\leftarrow B \\rightarrow PE \\rightarrow \\rightarrow Y\\) (backdoor path 3)\\(D \\leftarrow B \\rightarrow PE \\rightarrow \\rightarrow Y\\) (backdoor path 3)four paths \\(D\\) \\(Y\\): one direct causal effect (arguably important one want know return schooling) three backdoor paths. since none variables along backdoor paths collider, backdoors paths open. problem, though, open backdoor paths create systematic independent correlations \\(D\\) \\(Y\\). Put different way, presence open backdoor paths introduces bias comparing educated less-educated workers.","code":""},{"path":"ch2.html","id":"colliding","chapter":"3 Directed Acyclic Graphs","heading":"3.1.2 Colliding","text":"collider? ’s unusual term, one may never seen , let’s introduce another example. ’m going show collider graphically using simple DAG, ’s easy thing see slightly complicated phenomenon explain. let’s work new DAG. Pay careful attention directions arrows, changed., let’s list paths \\(D\\) \\(Y\\):\\(D \\rightarrow Y\\) (causal effect \\(D\\) \\(Y\\))\\(D \\rightarrow Y\\) (causal effect \\(D\\) \\(Y\\))\\(D \\rightarrow X \\leftarrow Y\\) (backdoor path 1)\\(D \\rightarrow X \\leftarrow Y\\) (backdoor path 1)Just like last time, two ways get \\(D\\) \\(Y\\). can get \\(D\\) \\(Y\\) using direct (causal) path, \\(D \\rightarrow Y\\). can use backdoor path, \\(D \\rightarrow X \\leftarrow Y\\). something different backdoor path; see ? time \\(X\\) two arrows pointing , away . two variables cause third variable along path, call third variable “collider.” Put differently, \\(X\\) collider along backdoor path \\(D\\) causal effects \\(Y\\) collide \\(X\\). ? makes collider special? Colliders special part appear along backdoor path, backdoor path closed simply presence. Colliders, left alone, always close specific backdoor path.","code":""},{"path":"ch2.html","id":"backdoor-criterion","chapter":"3 Directed Acyclic Graphs","heading":"3.1.3 Backdoor criterion","text":"care open backdoor paths create systematic, noncausal correlations causal variable interest outcome trying study. regression terms, open backdoor paths introduce omitted variable bias, know, bias bad flips sign entirely. goal, , close backdoor paths. can close otherwise open backdoor paths, can isolate causal effect \\(D\\) \\(Y\\) using one research designs identification strategies discussed book. close backdoor path?two ways close backdoor path. First, confounder created open backdoor path, can close path conditioning confounder. Conditioning requires holding variable fixed using something like subclassification, matching, regression, another method. equivalent “controlling ” variable regression. second way close backdoor path appearance collider along backdoor path. Since colliders always close backdoor paths, conditioning collider always opens backdoor path, choosing ignore colliders part overall strategy estimate causal effect . conditioning collider, closed backdoor path takes closer larger ambition isolate causal effect.backdoor paths closed, say come research design satisfies backdoor criterion. satisfied backdoor criterion, effect isolated causal effect. let’s formalize : set variables \\(X\\) satisfies backdoor criterion DAG \\(X\\) blocks every path confounders contain arrow \\(D\\) \\(Y\\). Let’s review original DAG involving parental education, background earnings.minimally sufficient conditioning strategy necessary achieve backdoor criterion control \\(\\), \\(\\) appeared noncollider along every backdoor path (see earlier). might literally simpler run following regression:\n\\[\nY_i = \\alpha + \\delta D_i + \\beta I_i + \\varepsilon_i\n\\]\nsimply conditioning \\(\\), estimated \\(\\widehat{\\delta}\\) takes causal interpretation.43But maybe hearing story, studying reviewing literature economic theory surrounding , skeptical DAG. Maybe DAG really bothered moment saw produce skeptical \\(B\\) relationship \\(Y\\) except \\(D\\) \\(PE\\). skepticism leads believe direct connection \\(B\\) \\(Y\\), merely one mediated education.Note including new backdoor path created problem conditioning strategy longer satisfies backdoor criterion. Even controlling \\(\\), still exist spurious correlations \\(D\\) \\(Y\\) due \\(D \\leftarrow B \\rightarrow Y\\) backdoor path. Without information nature \\(B \\rightarrow Y\\) \\(B \\rightarrow D\\), say much partial correlation \\(D\\) \\(Y\\). just legally allowed interpret \\(\\widehat{\\delta}\\) regression causal effect \\(D\\) \\(Y\\).","code":""},{"path":"ch2.html","id":"more-examples-of-collider-bias","chapter":"3 Directed Acyclic Graphs","heading":"3.1.4 More examples of collider bias","text":"issue conditioning collider important, know problem ? data set comes flag saying “collider” “confounder.” Rather, way know whether satisfied backdoor criterion DAG, DAG requires model. requires -depth knowledge data-generating process variables DAG, also requires ruling pathways. way rule pathways logic models. way avoid —empirical work requires theory guide . Otherwise, know ’ve conditioned collider noncollider? Put differently, identify treatment effects without making assumptions.earlier DAG collider bias, conditioned variable \\(X\\) collider—specifically, descendent \\(D\\) \\(Y\\). just one example collider. Oftentimes, colliders enter system subtle ways. Let’s consider following scenario: , let \\(D\\) \\(Y\\) child schooling child future earnings. time introduce three new variables—\\(U1\\), father’s unobserved genetic ability; \\(U2\\), mother’s unobserved genetic ability; \\(\\), joint family income. Assume \\(\\) observed \\(U_i\\) unobserved parents.Notice DAG several backdoor paths \\(D\\) \\(Y\\). follows:\\(D \\leftarrow U2 \\rightarrow Y\\)\\(D \\leftarrow U2 \\rightarrow Y\\)\\(D \\leftarrow U1 \\rightarrow Y\\)\\(D \\leftarrow U1 \\rightarrow Y\\)\\(D \\leftarrow U1 \\rightarrow \\leftarrow U2 \\rightarrow Y\\)\\(D \\leftarrow U1 \\rightarrow \\leftarrow U2 \\rightarrow Y\\)\\(D \\leftarrow U2 \\rightarrow \\leftarrow U1 \\rightarrow Y\\)\\(D \\leftarrow U2 \\rightarrow \\leftarrow U1 \\rightarrow Y\\)Notice, first two open-backdoor paths, , closed, \\(U1\\) \\(U2\\) observed. controlled \\(\\) anyway? Controlling \\(\\) makes matters worse, opens third fourth backdoor paths, \\(\\) collider along . appear conditioning strategy meet backdoor criterion DAG. strategy controlling \\(\\) actually make matters worse. Collider bias difficult concept understand first, ’ve included couple examples help sort .Buy print version today:","code":""},{"path":"ch2.html","id":"discrimination-and-collider-bias","chapter":"3 Directed Acyclic Graphs","heading":"3.1.5 Discrimination and collider bias","text":"Let’s examine real-world example around problem gender discrimination labor-markets. common hear occupation characteristics job conditioned , wage disparity genders disappears gets smaller. instance, critics claimed Google systematically underpaid female employees. Google responded data showed take “location, tenure, job role, level performance” consideration, women’s pay basically identical men. words, controlling characteristics job, women received pay.one ways gender discrimination creates gender disparities earnings occupational sorting? discrimination happens via occupational match, naïve contrasts wages gender controlling occupation characteristics likely understate presence discrimination marketplace. Let illustrate DAG based simple occupational sorting model unobserved heterogeneity.Notice fact effect female gender earnings; women assumed productivity identical men. Thus, control discrimination, ’d get coefficient zero example women , initially, just productive men.44But example, aren’t interested estimating effect female earnings; interested estimating effect discrimination . Now can see several noticeable paths discrimination earnings. follows:\\(D \\rightarrow O \\rightarrow Y\\)\\(D \\rightarrow O \\rightarrow Y\\)\\(D \\rightarrow O \\leftarrow \\rightarrow Y\\)\\(D \\rightarrow O \\leftarrow \\rightarrow Y\\)first path backdoor path; rather, path whereby discrimination mediated occupation discrimination effect earnings. imply women discriminated , turn affects jobs hold, result holding marginally worse jobs, women paid less. second path relates channel slightly complicated. path, unobserved ability affects jobs people get earnings.let’s say regress \\(Y\\) onto \\(D\\), discrimination variable. yields total effect discrimination weighted sum direct effect discrimination earnings mediated effect discrimination earnings occupational sorting. say want control occupation want compare men women similar jobs. Well, controlling occupation regression closes mediation channel, opens second channel. ? \\(D \\rightarrow O \\leftarrow \\rightarrow Y\\) collider \\(O\\). control occupation, open second path. closed colliders close backdoor paths, since conditioned , actually opened instead. reason merely control occupation. control ironically introduces new patterns bias.45What needed control occupation ability, since ability unobserved, , therefore possess identification strategy satisfies backdoor criterion. Let’s now look code illustrate DAG.46collider_discrimination.docollider_discrimination.RThis simulation hard-codes data-generating process represented previous DAG. Notice ability random draw standard normal distribution. Therefore independent female preferences. last two generated variables: heterogeneous occupations corresponding wages. Occupations increasing unobserved ability decreasing discrimination. Wages decreasing discrimination increasing higher-quality jobs higher ability. Thus, know discrimination exists simulation hard-coding way negative coefficients occupation wage processes.regression coefficients three regressions end code presented Table 3.1. First note simply regress wages onto gender, get large negative effect, combination direct effect discrimination earnings indirect effect via occupation. run regression Google others recommend wherein control occupation, sign gender changes. becomes positive! know wrong hard-coded effect gender \\(-1\\)! problem occupation collider. caused ability discrimination. control occupation, open backdoor path discrimination earnings spurious strong perverts entire relationship. control occupation ability can isolate direct causal effect gender wages.Table 3.1:  Regressions illustrating confounding bias simulated gender disparity","code":"clear all \nset obs 10000 \n\n* Half of the population is female. \ngenerate female = runiform()>=0.5 \n\n* Innate ability is independent of gender. \ngenerate ability = rnormal() \n\n* All women experience discrimination. \ngenerate discrimination = female \n\n* Data generating processes\ngenerate occupation = (1) + (2)*ability + (0)*female + (-2)*discrimination + rnormal() \ngenerate wage = (1) + (-1)*discrimination + (1)*occupation + 2*ability + rnormal() \n\n* Regressions\nregress wage female \nregress wage female occupation \nregress wage female occupation ability\nlibrary(tidyverse)\nlibrary(stargazer)\n\ntb <- tibble(\n  female = ifelse(runif(10000)>=0.5,1,0),\n  ability = rnorm(10000),\n  discrimination = female,\n  occupation = 1 + 2*ability + 0*female - 2*discrimination + rnorm(10000),\n  wage = 1 - 1*discrimination + 1*occupation + 2*ability + rnorm(10000) \n)\n\nlm_1 <- lm(wage ~ female, tb)\nlm_2 <- lm(wage ~ female + occupation, tb)\nlm_3 <- lm(wage ~ female + occupation + ability, tb)\n\nstargazer(lm_1,lm_2,lm_3, type = \"text\", \n          column.labels = c(\"Biased Unconditional\", \n                            \"Biased\",\n                            \"Unbiased Conditional\"))"},{"path":"ch2.html","id":"sample-selection-and-collider-bias","chapter":"3 Directed Acyclic Graphs","heading":"3.1.6 Sample selection and collider bias","text":"Bad controls kind collider bias afraid , though. Collider bias can also baked directly sample sample collider. ’s doubt strange concept imagine, funny illustration clarify mean.2009 CNN blog post reported Megan Fox, starred movie Transformers, voted worst attractive actress 2009 survey movie stars (Piazza 2009). implication taken talent beauty negatively correlated. ? might ? independent reality negatively correlated sample movie stars collider bias? even possible?47To illustrate, generate data based follow- ing DAG:Let’s illustrate simple program.moviestar.domoviestar.RFigure 3.1 shows output simulation. bottom left panel shows scatter plot talent beauty. Notice two variables independent, random draws standard normal distribution, creating oblong data cloud. “movie star” top 85th percentile distribution linear combination talent beauty, sample consists people whose combined score top right portion joint distribution. frontier negative slope upper right portion data cloud, creating negative correlation observations movie-star sample. Likewise, collider bias created negative correlation talent beauty non-movie-star sample well. Yet know fact relationship two variables. kind sample selection creates spurious correlations. random sample full population sufficient show relationship two variables, splitting sample movie stars , introduce spurious correlations two variables interest.\nFigure 3.1: Top left figure: Non-star sample scatter plot beauty (vertical axis) talent (horizontal axis). Top right right figure: Star sample scatter plot beauty talent. Bottom left figure: Entire (stars non-stars combined) sample scatter plot beauty talent.\n","code":"clear all \nset seed 3444 \n\n* 2500 independent draws from standard normal distribution \nset obs 2500 \ngenerate beauty=rnormal() \ngenerate talent=rnormal() \n\n* Creating the collider variable (star) \ngen score=(beauty+talent) \negen c85=pctile(score), p(85)   \ngen star=(score>=c85) \nlabel variable star \"Movie star\" \n\n* Conditioning on the top 15\\% \ntwoway (scatter beauty talent, mcolor(black) msize(small) msymbol(smx)), ytitle(Beauty) xtitle(Talent) subtitle(Aspiring actors and actresses) by(star, total)\nlibrary(tidyverse)\n\nset.seed(3444)\n\nstar_is_born <- tibble(\n  beauty = rnorm(2500),\n  talent = rnorm(2500),\n  score = beauty + talent,\n  c85 = quantile(score, .85),\n  star = ifelse(score>=c85,1,0)\n)\n\nstar_is_born %>% \n  lm(beauty ~ talent, .) %>% \n  ggplot(aes(x = talent, y = beauty)) +\n  geom_point(size = 0.5, shape=23) + xlim(-4, 4) + ylim(-4, 4)\n\nstar_is_born %>% \n  filter(star == 1) %>% \n  lm(beauty ~ talent, .) %>% \n  ggplot(aes(x = talent, y = beauty)) +\n  geom_point(size = 0.5, shape=23) + xlim(-4, 4) + ylim(-4, 4)\n\nstar_is_born %>% \n  filter(star == 0) %>% \n  lm(beauty ~ talent, .) %>% \n  ggplot(aes(x = talent, y = beauty)) +\n  geom_point(size = 0.5, shape=23) + xlim(-4, 4) + ylim(-4, 4)"},{"path":"ch2.html","id":"collider-bias-and-police-use-of-force","chapter":"3 Directed Acyclic Graphs","heading":"3.1.7 Collider bias and police use of force","text":"’ve known problems nonrandom sample selection decades (Heckman 1979). DAGs may still useful helping spot might otherwise subtle cases conditioning colliders (Elwert Winship 2014). given ubiquitous rise researcher access large administrative databases, ’s also likely sort theoretically guided reasoning needed help us determine whether databases rife collider bias. contemporary debate help illustrate mean.Public concern police officers systematically discriminating minorities reached breaking point led emergence Black Lives Matter movement. “Vigilante justice” episodes George Zimmerman’s killing teenage Trayvon Martin, well police killings Michael Brown, Eric Garner, countless others, served catalysts bring awareness perception African Americans face enhanced risks shootings. Fryer (2019) attempted ascertain degree racial bias use force police. perhaps one important questions policing book’s publication.several critical empirical challenges studying racial biases police use force, though. main problem data police-citizen interactions conditional interaction already occurred. data generated function earlier police-citizen interactions. sense, can say data endogenous. Fryer (2019) collected several databases hoped help us better understand patterns. Two public-use data sets—New York City Stop Frisk database Police-Public Contact Survey. former New York Police Department contained data police stops questioning pedestrians; police wanted , frisk weapons contraband. latter survey civilians describing interactions police, including use force.two data sets administrative. first compilation event summaries dozen large cities large counties across United States incidents officer discharged weapon civilian. second random sample police-civilian interactions Houston Police Department. accumulation databases evidence gigantic empirical task. instance, Fryer (2019) notes Houston data based arrest narratives ranged two one hundred pages length. arrest narratives, team researchers collected almost three hundred variables relevant police use force incident. world now live, though. Administrative databases can accessed easily ever, helping break open black box many opaque social processes.facts important note. First, using stop--frisk data, Fryer finds blacks Hispanics 50 percent likely interaction police raw data. racial difference survives conditioning 125 baseline characteristics, encounter characteristics, civilian behavior, precinct, year fixed effects. full model, blacks 21 percent likely whites involved interaction police weapon drawn (statistically significant). racial differences show Police-Public Contact Survey well, racial differences considerably larger. first thing note actual stop appears larger minorities, come back momentarily.Things become surprising Fryer moves rich administrative data sources. finds conditional police interaction, racial differences officer-involved shootings. fact, controlling suspect demographics, officer demographics, encounter characteristics, suspect weapon, year fixed effects, blacks 27 percent less likely shot police nonblack non-Hispanics. coefficient significant, shows across alternative specifications cuts data. Fryer simply unable data find evidence racial discrimination officer-involved shootings.One main strengths Fryer’s study shoe leather used accumulate needed data sources. Without data, one study question whether police shoot minorities shoot whites. extensive coding information narratives also strength, afforded Fryer ability control observable confounders. study without issues cause skeptic take issue. Perhaps police departments willing cooperate study kind ones least racial bias, instance. words, maybe departments racial bias begin .48 perhaps sinister explanation exists, records unreliable administrators scrub data racially motivated shootings handing Fryer altogether.like discuss innocent possibility, one requires conspiracy theories yet basic problem fact worrisome. Perhaps administrative datasource endogenous conditioning collider. , administrative data may racial bias baked start. Let explain DAG.Fryer showed minorities likely stopped using stop--frisk data Police-Public Contact Survey. know already \\(D \\rightarrow M\\) pathway exists. fact, robust correlation across multiple studies. Minorities likely encounter police. Fryer’s study introduces extensive controls nature interaction, time day, hundreds factors ’ve captured \\(X\\). Controlling \\(X\\) allows Fryer shut backdoor path.notice \\(M\\)—stop . administrative data conditional stop. Fryer (2019) acknowledges outset: “Unless otherwise noted, results conditional interaction. Understanding potential selection police data sets due bias police interacts difficult endeavor” (3). Yet DAG shows police stop people believe suspicious use force people find suspicious, conditioning stop equivalent conditioning collider. opens \\(D \\rightarrow M \\leftarrow U \\rightarrow Y\\) mediated path, introduces spurious patterns data , depending signs causal associations, may distort true relationship police racial differences shootings.Dean Knox, Lowe, Jonathan Mummolo talented team political scientists study policing, among things. produced study revisited Fryer’s question opinion yielded new clues role racial bias police use force challenges using administrative data sources . consider Knox, Lowe, Mummolo (2020) one methodologically helpful studies understanding problem attempting solve . study widely read every applied researcher whose day job involves working proprietary administrative data sets, DAG may fact general problem. , administrative data sources already select samples, depending study question, may constitute collider problem sort described DAG. authors develop bias correction procedure places bounds severity selection problems. using bounding approach, find even lower-bound estimates incidence police violence civilians much five times higher traditional approach ignores sample selection problem altogether.incorrect say sample selection problems unknown without DAGs. ’ve known limited solutions since least Heckman (1979). tried show general. atheoretical approach empiricism simply fail. even “big data” solve . Causal inference solved data, argue next chapter. Causal inference requires knowledge behavioral processes structure equilibria world. Without , one hope devise credible identification strategy. even data substitute deep institutional knowledge phenomenon ’re studying. , strangely enough, even includes behavioral processes generated samples ’re using first place. simply must take seriously behavioral theory behind phenomenon ’re studying hope obtain believable estimates causal effects. DAGs helpful tool wrapping head around expressing problems.","code":""},{"path":"ch2.html","id":"conclusion-1","chapter":"3 Directed Acyclic Graphs","heading":"3.1.8 Conclusion","text":"conclusion, DAGs powerful tools.49 helpful clarifying relationships variables guiding research design shot identifying causal effect. two concepts discussed chapter—backdoor criterion collider bias—two things wanted bring attention. since DAGs based counterfactual forms reasoning, fit well potential outcomes model discuss next chapter.Buy print version today:","code":""},{"path":"ch3.html","id":"ch3","chapter":"4 Potential Outcomes Causal Model","heading":"4 Potential Outcomes Causal Model","text":"Buy print version today:Practical questions causation preoccupation economists several centuries. Adam Smith wrote causes wealth nations (Smith 2003). Karl Marx interested transition society capitalism socialism (Needleman Needleman 1969). twentieth century Cowles Commission sought better understand identifying causal parameters (Heckman Vytlacil 2007).50 Economists wrestling big ideas around causality development useful empirical tools day one.can see development modern concepts causality writings several philosophers. Hume (1993) described causation sequence temporal events , first event occurred, subsequent ones either. example, said:“may define cause object, followed another, objects similar first followed objects similar second. words , first object , second never existed.”Mill (2010) devised five methods inferring causation. methods (1) method agreement, (2) method difference, (3) joint method, (4) method concomitant variation, (5) method residues. second method, method difference, similar idea causation comparison among counterfactuals. instance, wrote:“person eats particular dish, dies consequence, , died eaten , people apt say eating dish source death.”","code":""},{"path":"ch3.html","id":"statistical-inference","chapter":"4 Potential Outcomes Causal Model","heading":"4.0.1 Statistical inference","text":"major jump understanding causation occurs coincident development modern statistics. Probability theory statistics revolutionized science nineteenth century, beginning field astronomy. Giuseppe Piazzi, early nineteenth-century astronomer, discovered dwarf planet Ceres, located Jupiter Mars, 1801. Piazzi observed 24 times lost . Carl Friedrich Gauss proposed method successfully predict Ceres’s next location using data prior location. method minimized sum squared errors; words, ordinary least squares method discussed earlier. discovered OLS age 18 published derivation OLS 1809 age 24 (Gauss 1809).51 scientists contributed understanding OLS include Pierre-Simon LaPlace Adrien-Marie Legendre.statistician G. Udny Yule made early use regression analysis social sciences. Yule (1899) interested causes poverty England. Poor people depended either poorhouses local authorities financial support, Yule wanted know public assistance increased number paupers, causal question. Yule used least squares regression estimate partial correlation public assistance poverty. data drawn English censuses 1871 1881, made data available website Stata Mixtape library R users. ’s example regression one might run using data:\n\\[\n\\text{Pauper}=\\alpha+\\delta \\text{Outrelief}+\\beta_1 \\text{Old} + \\beta_2 \\text{Pop} + u\n\\]\nLet’s run regression using data.yule.doyule.REach row data set particular location England (e.g., Chelsea, Strand). , since 32 rows, means data set contains 32 English locations. variables expressed annual growth rate. result, regression coefficient elasticity interpretations, one caveat—technically, explained beginning book, elasticities actually causal objects, simply correlations two variables. ’s unlikely conditions needed interpret causal relationships met Yule’s data. Nevertheless, let’s run regression look results, report Table 4.1.Table 4.1:  Estimated association pauperism growth rates public assistance.words, 10-percentage-point change -relief growth rate associated 7.5-percentage-point increase pauperism growth rate, elasticity 0.75. Yule used regression crank correlation -relief pauperism, concluded public assistance increased pauper growth rates.might wrong reasoning? convinced backdoor paths pauperism -relief blocked control two covariates cross-sectional database England? unobserved determinants poverty public assistance? , control economic factors, surely affect poverty amount resources allocated -relief. Likewise, may causality backwards—perhaps increased poverty causes communities increase relief, merely way around. earliest adopters new methodology technique often ones get criticism, despite pioneers methods . ’s trivially easy beat researcher one hundred years ago, working time alternative regression ideological make-believe. Plus isn’t reply. merely want note naı̈ve use regression estimate correlations way making causal claims inform important policy questions norm long time, likely isn’t going away time soon.","code":"use https://github.com/scunning1975/mixtape/raw/master/yule.dta, clear\nregress paup outrelief old pop\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nyule <- read_data(\"yule.dta\") %>% \n  lm(paup ~ outrelief + old + pop, .)\nsummary(yule)"},{"path":"ch3.html","id":"physical-randomization","chapter":"4 Potential Outcomes Causal Model","heading":"4.1 Physical Randomization","text":"notion physical randomization foundation causal inference air nineteenth twentieth centuries, Fisher (1935) crystallized. first historically recognized randomized experiment occurred fifty years earlier psychology (Peirce Jastrow 1885). interestingly, experiment, reason randomization basis causal inference. Rather, researchers proposed randomization way fooling subjects experiments. Peirce Jastrow (1885) used several treatments, used physical randomization participants couldn’t guess happen next. Unless ’m mistaken, recommending physical randomization treatments units basis causal inference based Splawa-Neyman (1923) Fisher (1925). specifically, Splawa-Neyman (1923) developed powerful potential outcomes notation (discuss soon), proposed randomization, taken literally necessary Fisher (1925). Fisher (1925) proposed explicit use randomization experimental design causal inference.52Physical randomization largely domain agricultural experiments mid-1950s, began used medical trials. Among first major randomized experiments medicine—fact, ever attempted—Salk polio vaccine field trials. 1954, Public Health Service set determine whether Salk vaccine prevented polio. Children study assigned random receive vaccine placebo.53 Also, doctors making diagnoses polio know whether child received vaccine placebo. polio vaccine trial called double-blind, randomized controlled trial neither patient administrator vaccine knew whether treatment placebo vaccine. necessary field trial large rate polio occurred population 50 per 100,000. treatment group, contained 200,745 individuals, saw 33 polio cases. control group 201,229 individuals saw 115 cases. probability seeing big difference rates polio chance alone one billion. plausible explanation, argued, polio vaccine caused reduction risk polio.similar large-scale randomized experiment occurred economics 1970s. 1971 1982, RAND Corporation conducted large-scale randomized experiment studying causal effect health-care insurance health-care utilization. study, Rand recruited 7,700 individuals younger age 65. experiment somewhat complicated, multiple treatment arms. Participants randomly assigned one five health insurance plans: free care, three plans varying levels cost sharing, HMO plan. Participants cost sharing made fewer physician visits fewer hospitalizations free care. declines health-care utilization, fewer dental visits, also found among cost-sharing treatment groups. Overall, participants cost-sharing plans tended spend less health used fewer services. reduced use services occurred mainly participants cost-sharing treatment groups opting initiate care.54But use randomized experiments exploded since health-care experiment. multiple Nobel Prizes given use : Vernon Smith pioneering laboratory experiments 2002, recently, Abhijit Bannerjee, Esther Duflo, Michael Kremer 2019 leveraging field experiments service alleviating global poverty.55 experimental design become hallmark applied microeconomics, political science, sociology, psychology, . viewed important? randomization key element design isolating causal effects? understand , need learn powerful notation Splawa-Neyman (1923) developed, called “potential outcomes.”","code":""},{"path":"ch3.html","id":"potential-outcomes","chapter":"4 Potential Outcomes Causal Model","heading":"4.1.1 Potential outcomes","text":"potential outcomes notation goes back Splawa-Neyman (1923), got big lift broader social sciences Rubin (1974).56 book’s writing, potential outcomes less lingua franca thinking expressing causal statements, probably owe Rubin (1974) much anyone.potential outcomes tradition (Splawa-Neyman 1923; Rubin 1974), causal effect defined comparison two states world. Let illustrate simple example. first state world (sometimes called “actual” state world), man takes aspirin headache one hour later reports severity headache. second state world (sometimes called “counterfactual” state world), man takes nothing headache one hour later reports severity headache. causal effect aspirin? According potential outcomes tradition, causal effect aspirin difference severity headache two states world: one took aspirin (actual state world) one never took aspirin (counterfactual state world). difference headache severity two states world, measured otherwise point time, causal effect aspirin headache. Sounds easy!even ask questions like (let alone attempt answer ) engage storytelling. Humans always interested stories exploring counterfactuals. Bruce Wayne’s parents never murdered? waitress won lottery? friend high school never taken first drink? Matrix Neo taken blue pill? fun hypotheticals entertain, still ultimately storytelling. need Doctor Strange give us Time Stone answer questions like .can probably see going. potential outcomes notation expresses causality terms counterfactuals, since counterfactuals exist, confidence causal effects must degree unanswerable. wonder life different one single event different indulge counterfactual reasoning, counterfactuals realized history hypothetical states world. Therefore, answer requires data counterfactuals, question answered. History sequence observable, factual events, one another. don’t know happened one event changed missing data counterfactual outcome.57 Potential outcomes exist ex ante set possibilities, decision made, one outcome disappears.58To make concrete, let’s introduce notation specific concepts. simplicity, assume binary variable takes value 1 particular unit \\(\\) receives treatment 0 .59 unit two potential outcomes, one observed outcome. Potential outcomes defined \\(Y^1_i\\) unit \\(\\) received treatment \\(Y^0_i\\) unit . Notice potential outcomes \\(\\) subscript—indicates two separate states world exact person example exact moment time. ’ll call state world treatment occurred control state. unit \\(\\) exactly two potential outcomes: potential outcome state world treatment occurred (\\(Y^1\\)) potential outcome treatment occur (\\(Y^0\\)).Observable “actual” outcomes, \\(Y_i\\), distinct potential outcomes. First, notice actual outcomes superscript. potential outcomes—realized, actual, historical, empirical—however want say —outcomes unit \\(\\) experienced. Whereas potential outcomes hypothetical random variables differ across population, observable outcomes factual random variables. get potential outcomes actual outcomes major philosophical move, like good economist, ’m going make seem simpler equation. unit’s observable outcome function potential outcomes determined according switching equation:\n\\[\nY_i = D_iY^1_i + (1-D_i)Y^0_i\n\\]\n\\(D_i\\) equals 1 unit received treatment 0 . Notice logic equation. \\(D_i=1\\), \\(Y_i=Y^1_i\\) second term zeroes . \\(D_i=0\\), first term zeroes therefore \\(Y_i=Y^0_i\\). Using notation, define unit-specific treatment effect, causal effect, difference two states world:\n\\[\n\\delta_i = Y^1_i-Y^0_i\n\\]\nImmediately confronted problem. treatment effect requires knowing two states world, \\(Y^1_i\\) \\(Y^0_i\\), switching equation observe one, calculate treatment effect. Herein lies fundamental problem causal inference—certainty around causal effects requires access data always missing.","code":""},{"path":"ch3.html","id":"average-treatment-effects","chapter":"4 Potential Outcomes Causal Model","heading":"4.1.2 Average treatment effects","text":"simple definition treatment effect come three different parameters often interest researchers. population means. first called average treatment effect:\\[\\begin{align}\n   ATE & = E[\\delta_i] \\nonumber      \\\\\n       & = E[Y^1_i - Y^0_i] \\nonumber \\\\\n       & = E[Y^1_i] - E[Y^0_i]        \n\\end{align}\\]Notice, definition individual-level treatment effects, average treatment effect requires potential outcomes \\(\\) unit. Since know one switching equation, average treatment effect, ATE, inherently unknowable. Thus, ATE, like individual treatment effect, quantity can calculated. can estimated.second parameter interest average treatment effect treatment group. ’s mouthful, let explain. exist two groups people discussion ’ve : treatment group control group. average treatment effect treatment group, ATT short, simply population mean treatment effect group units assigned treatment first place according switching equation. Insofar \\(\\delta_i\\) differs across population, ATT likely differ ATE. observational data involving human beings, almost always different ATE, ’s individuals endogenously sorting treatment based gains expect . Like ATE, ATT unknowable, like ATE, also requires two observations per treatment unit \\(\\). Formally write ATT :\\[\\begin{align}\n   ATT & = E\\big[\\delta_i\\mid D_i=1\\big] \\nonumber                 \n   \\\\\n       & = E\\big[Y^1_i - E^0_i\\mid D_i = 1\\big] \\nonumber          \n   \\\\\n       & = E\\big[Y^1_i\\mid D_i=1\\big] - E\\big[Y^0_i\\mid D_i=1\\big] \n\\end{align}\\]final parameter interest called average treatment effect control group, untreated group. ’s shorthand ATU, stands average treatment effect untreated. like ATT, ATU simply population mean treatment effect units sorted control group.60 Given heterogeneous treatment effects, ’s probably case \\(ATT\\neq ATU\\), especially observational setting. formula ATU follows:\\[\\begin{align}\n   ATU & = E\\big[\\delta_i\\mid D_i = 0\\big] \\nonumber                          \n   \\\\\n       & = E\\big[Y^1_i - Y^0_i\\mid D_i = 0\\big] \\nonumber                     \n   \\\\\n       & =E\\big[Y^1_i\\mid D_i=0\\big]-E\\big[Y^0_i\\mid D_i=0\\big] \n\\end{align}\\]Depending research question, one, three, parameters interesting. two common ones interest ATE ATT.","code":""},{"path":"ch3.html","id":"simple-difference-in-means-decomposition","chapter":"4 Potential Outcomes Causal Model","heading":"4.1.3 Simple difference in means decomposition","text":"discussion somewhat abstract, let’s concrete. Let’s assume ten patients \\(\\) cancer, two medical procedures treatments. surgery intervention, \\(D_i=1\\), chemotherapy intervention, \\(D_i=0\\). patient following two potential outcomes potential outcome defined post-treatment life span years: potential outcome world received surgery potential outcome instead received chemo. use notation \\(Y^1\\) \\(Y^0\\), respectively, two states world.Table 4.2:  Potential outcomes ten patients receiving surgery \\(Y^1\\) chemo \\(Y^0\\).can calculate average treatment effect matrix data, average treatment effect simply mean difference columns 2 3. , \\(E[Y^1]=5.6\\), \\(E[Y^0]=5\\), means \\(ATE=0.6\\). words, average treatment effect surgery across specific patients 0.6 additional years (compared chemo).just average. Notice, though: everyone benefits surgery. Patient 7, instance, lives one additional year post-surgery versus ten additional years post-chemo. ATE simply average heterogeneous treatment effects.maintain fiction, let’s assume exists perfect doctor knows person’s potential outcomes chooses whichever treatment maximizes person’s post-treatment life span.61 words, doctor chooses put patient surgery chemotherapy depending whichever treatment longer post-treatment life span. makes treatment assignment, doctor observes post-treatment actual outcome according switching equation mentioned earlier.Table 4.3:  Post-treatment observed lifespans years surgery \\(D=1\\) versus chemotherapy \\(D=0\\).Table 4.3 shows observed outcome treatment control group. Table 4.3 differs Table 4.2, shows unit’s potential outcomes. treatment assigned, can calculate average treatment effect surgery group (ATT) versus chemo group (ATU). ATT equals 4.4, ATU equals \\(-3.2\\). means average post-surgery life span surgery group 4.4 additional years, whereas average post-surgery life span chemotherapy group 3.2 fewer years.62Now ATE 0.6, just weighted average ATT ATU.63 know overall effect surgery positive, although effect negative. exist heterogeneous treatment effects, words, net effect positive. simply compare average post-surgery life span two groups? simplistic estimator called simple difference means, estimate ATE equal \n\\[\nE\\big[Y^1\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big]\n\\]\ncan estimated using samples data:\\[\\begin{align}\nSDO &=E\\big[Y^1\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big] \\nonumber\n\\\\\n&= \\dfrac{1}{N_T} \\sum_{=1}^n \\big(y_i\\mid d_i=1\\big) - \\dfrac{1}{N_C} \\sum_{=1}^n \\big(y_i\\mid d_i=0\\big)\n\\end{align}\\]situation equal \\(7-7.4=-0.4\\). means treatment group lives 0.4 fewer years post-surgery chemo group perfect doctor assigned unit best treatment. statistic true, notice misleading . statistic without proper qualification easily used claim , average, surgery harmful, know ’s true. ’s biased individuals units optimally sorting best treatment option, creating fundamental differences treatment control group direct function potential outcomes . make clear can make , decompose simple difference means three parts. three parts listed :\\[\\begin{align}\n    E\\big[Y^1\\mid D=1\\big]-E\\big[Y^0\\mid D=0\\big] & =ATE \\nonumber                                              \n    \\\\\n                                & + E\\big[Y^0\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big] \\nonumber \n    \\\\\n                                & + (1-\\pi)(ATT-ATU)                                          \n\\end{align}\\]understand parts right-hand side originate, need start decompose parameter interest, \\(ATE\\), basic building blocks. ATE equal weighted sum conditional average expectations, \\(ATT\\) \\(ATU\\).\\[\\begin{align}\n   ATE & =\\pi ATT+(1-\\pi)ATU                                                    \n   \\\\\n       & =\\pi E\\big[Y^1\\mid D=1\\big]-\\pi E\\big[Y^0\\mid D=1\\big]                 \n   \\\\\n       & + (1-\\pi) E\\big[Y^1\\mid D=0\\big]-(1-\\pi) E\\big[Y^0\\mid D=0\\big]        \n   \\\\\n       & = \\Big\\{\\pi E\\big[Y^1\\mid D=1\\big]+(1-\\pi)E\\big[Y^1\\mid D=0\\big]\\Big\\} \n   \\\\\n       & -\\Big\\{\\pi E\\big[Y^0\\mid D=1\\big]+(1-\\pi) E\\big[Y^0\\mid D=0\\big]\\Big\\} \n\\end{align}\\]\\(\\pi\\) share patients received surgery \\(1-\\pi\\) share patients received chemotherapy. conditional expectation notation little cumbersome, let’s exchange term left side, \\(ATE\\), right side letters. make proof little less cumbersome:\\[\\begin{align}\n   E\\big[Y^1\\mid D=1\\big] & = \\\\\n   E\\big[Y^1\\mid D=0\\big] & = b \\\\\n   E\\big[Y^0\\mid D=1\\big] & = c \\\\\n   E\\big[Y^0\\mid D=0\\big] & = d \\\\\n   ATE  & = e \n\\end{align}\\]Now made substitutions, let’s rearrange letters redefining ATE weighted average conditional expectations\\[\\begin{align}\n   e    & =\\big\\{\\pi{}+(1-\\pi)b\\big\\}-\\big\\{\\pi{c} + (1-\\pi)d\\big\\}                                                                 \n   \\\\\n   e    & =\\pi{}+b-\\pi{b}-\\pi{c} - d + \\pi{d}                                                                                       \n   \\\\\n   e    & =\\pi{}+ b-\\pi{b}-\\pi{c} - d + \\pi{d} + (\\mathbf{} - \\mathbf{}) + (\\mathbf{c} - \\mathbf{c}) + (\\mathbf{d} - \\mathbf{d})  \n   \\\\\n   0    & =e-\\pi{} - b + \\pi{b} + \\pi{c} + d - \\pi{d} - \\mathbf{} + \\mathbf{} - \\mathbf{c} + \\mathbf{c} - \\mathbf{d} + \\mathbf{d} \n   \\\\\n   \\mathbf{}-\\mathbf{d} & =e-\\pi{} - b + \\pi{b} + \\pi{c} + d - \\pi{d} +\\mathbf{} -\\mathbf{c} +\\mathbf{c} - \\mathbf{d}                              \n   \\\\\n   \\mathbf{}-\\mathbf{d} & =e + (\\mathbf{c} -\\mathbf{d}) + \\mathbf{}-\\pi{} - b + \\pi{b} -\\mathbf{c} + \\pi{c} + d - \\pi{d}                           \n   \\\\\n   \\mathbf{}-\\mathbf{d} & =e + (\\mathbf{c} -\\mathbf{d}) + (1-\\pi)-(1-\\pi)b + (1-\\pi)d - (1-\\pi)c                                                   \n   \\\\\n   \\mathbf{}-\\mathbf{d} & =e + (\\mathbf{c} -\\mathbf{d}) + (1-\\pi)(-c) -(1-\\pi)(b-d)                                                                 \n\\end{align}\\]Now, substituting definitions, get following:\\[\\begin{align}\n   E\\big[Y^1\\mid D=1\\big]-E\\big[Y^0\\mid D=0\\big] & = ATE \\nonumber                                                       \n   \\\\\n                                & + \\Big(E\\big[Y^0\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big]\\Big) \\nonumber \n   \\\\\n                                & + (1-\\pi)(ATT - ATU)                                                  \n\\end{align}\\]decomposition ends. Now fun part—let’s think just made! left side can estimated sample data, potential outcomes become actual outcomes switching equation. ’s just simple difference mean outcomes. ’s right side interesting tells us simple difference mean outcomes definition. Let’s put labels .\\[\\begin{align}\n\\underbrace{\\dfrac{1}{N_T} \\sum_{=1}^n \\big(y_i\\mid d_i=1\\big)-\\dfrac{1}{N_C}\n   \\sum_{=1}^n \\big(y_i\\mid d_i=0\\big)}_{ \\text{Simple Difference Outcomes}}\n&= \\underbrace{E[Y^1] - E[Y^0]}_{ \\text{Average Treatment Effect}}\n\\\\\n&+ \\underbrace{E\\big[Y^0\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big]}_{ \\text{Selection bias}}\n\\\\\n& + \\underbrace{(1-\\pi)(ATT - ATU)}_{ \\text{Heterogeneous treatment effect bias}}\n\\end{align}\\]Let’s discuss turn. left side simple difference mean outcomes, already know equal \\(-0.4\\). Since decomposition, must case right side also equals \\(-0.4\\).first term average treatment effect, parameter interest, know equal 0.6. Thus, remaining two terms must source bias causing simple difference means negative.second term called selection bias, merits unpacking. case, selection bias inherent difference two groups received chemo. Usually, though, ’s just description differences two groups never treatment first place. words two groups: surgery group chemo group. potential outcomes control differ? Notice first counterfactual, whereas second observed outcome according switching equation. can calculate difference complete potential outcomes Table 4.2. difference equal \\(-4.8\\).third term lesser-known form bias, ’s interesting. Plus, focus ATE, always present.64 heterogeneous treatment effect bias simply different returns surgery two groups multiplied share population chemotherapy group . final term \\(0.5\\times (4.4-(-3.2))\\) \\(3.8\\). Note case ’s obvious reason \\(\\pi=0.5\\) 5 10 units chemotherapy group.Now three parameters right side, can see simple difference mean outcomes equal \\(-0.4\\).\n\\[\n-0.4=0.6-4.8+3.8\n\\]\nfind interesting—hopeful even—decomposition shows contrast treatment control group technically “contains” parameter interest. placed “contains” quotes clearly visible decomposition, simple difference outcomes ultimately laid sum three parts. Rather, simple difference outcomes nothing number. number sum three parts, calculate individual part data underlying counterfactual outcomes needed make calculations. problem parameter interest masked two forms bias, selection bias heterogeneous treatment effect bias. knew , just subtract , ordinarily don’t know . develop strategies negate biases, directly calculate can directly calculate ATE, biases depend unobservable counterfactuals.problem isn’t caused assuming heterogeneity either. can make strong assumption treatment effects constant, \\(\\delta_i = \\delta\\) \\(\\forall \\), cause \\(ATU=ATT\\) make \\(SDO = ATE\\) + selection bias. ’d still nasty selection bias screwing things . One argue entire enterprise causal inference developing reasonable strategy negating role selection bias playing estimated causal effects.","code":""},{"path":"ch3.html","id":"independence-assumption","chapter":"4 Potential Outcomes Causal Model","heading":"4.1.4 Independence assumption","text":"Let’s start credible situation using \\(SDO\\) estimate \\(ATE\\): treatment (e.g., surgery) assigned patients independent potential outcomes. word “independence” mean anyway? Well, notationally, means:\\[\\begin{align}\n   (Y^1,Y^0)\\perp \\!\\!\\! \\perp D \n\\end{align}\\]means surgery assigned individual reasons nothing gains surgery.65 Now example, already know violated perfect doctor specifically chose surgery chemo based potential outcomes. Specifically, patient received surgery \\(Y^1>Y^0\\) chemo \\(Y^1<Y^0\\). Thus, case, perfect doctor ensured \\(D\\) depended \\(Y^1\\ \\ Y^0\\). forms human-based sorting—probably rule honest—violate independence, main reason naı̈ve observational comparisons almost always incapable recovering causal effects.66But hadn’t done ? chosen surgery way depend \\(Y^1\\) \\(Y^0\\)? one choose surgery independent expected gains surgery? instance, maybe alphabetized last name, first five received surgery last five received chemotherapy. maybe used second hand watch assign surgery : 1 30 seconds, gave surgery, 31 60 seconds, gave chemotherapy.67 words, let’s say chose method assigning treatment depend values potential outcomes either state world. mean context? Well, mean:\\[\\begin{align}\n   E\\big[Y^1\\mid D=1\\big] - E\\big[Y^1\\mid D=0\\big]=0 \\\\\n   E\\big[Y^0\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big]=0 \n\\end{align}\\]words, mean mean potential outcome \\(Y^1\\) \\(Y^0\\) (population) either surgery group chemotherapy group. kind randomization treatment assignment eliminate selection bias heterogeneous treatment effect bias. Let’s take order. selection bias zeroes follows:\\[\\begin{align}\n   E\\big[Y^0\\mid D=1\\big] - E\\big[Y^0\\mid D=0\\big]=0\n\\end{align}\\]thus \\(SDO\\) longer suffers selection bias. randomization affect heterogeneity treatment bias third line? Rewrite definitions ATT ATU:\\[\\begin{gather}\n   ATT = E\\big[Y^1\\mid D=1\\big] - E\\big[Y^0\\mid D=1\\big]\n   \\\\\n   ATU = E\\big[Y^1\\mid D=0\\big] - E\\big[Y^0\\mid D=0\\big]\n\\end{gather}\\]Rewrite third row bias \\(1-\\pi\\):\\[\\begin{align}\n   ATT-ATU & =\\mathbf{E\\big[Y^1\\mid D=1\\big]}-E\\big[Y^0\\mid D=1\\big]    \\\\\n           & - \\mathbf{E\\big[Y^1 \\mid D=0\\big]}+ E\\big[Y^0\\mid D=0\\big] \\\\\n           & = 0                                                        \n\\end{align}\\]treatment independent potential outcomes, :\\[\\begin{align}\n   \\dfrac{1}{N_T} \\sum_{=1}^n \\big(y_i\\mid d_i=1\\big) - \\dfrac{1}{N_C} \\sum_{=1}^n \\big(y_i\\mid d_i=0\\big) & = E[Y^1] - E[Y^0] \n   \\\\\n   SDO                                                                                      & = ATE             \n\\end{align}\\]’s necessary situation simply () data observable outcomes, (b) data treatment assignment, (c) \\((Y^1,Y^0) \\perp \\!\\!\\! \\perp D\\). call (c) independence assumption. illustrate lead SDO, use following Monte Carlo simulation. Note \\(ATE\\) example equal 0.6.independence.doindependence.RThis Monte Carlo runs 10,000 times, time calculating average SDO independence—ensured random number sorting occurs. running program, ATE 0.6, SDO average equal 0.59088.68Before move SDO, let’s just emphasize something often lost students first learning independence concept notation. Independence imply \\(E[Y^1\\mid D=1] - E[Y^0\\mid D=0]=0\\). imply \\(E[Y^1\\mid D=1] - E[Y^0\\mid D=1]=0\\). Rather, implies\n\\[\nE\\big[Y^1\\mid D=1\\big] - E\\big[Y^1\\mid D=0\\big]=0\n\\]\nlarge population.69 , independence implies two groups units, surgery chemo, potential outcome average population.realistic independence observational data? Economics—maybe science—tells us independence unlikely hold observationally. Economic actors always attempting achieve optima. instance, parents putting kids perceive best school , based potential outcomes. words, people choosing interventions, likely decisions related potential outcomes, makes simple comparisons improper. Rational choice always pushing independence assumption, therefore simple comparison means approximate true causal effect. need unit randomization simple comparisons help us understand causal effects play.","code":"clear all\nprogram define gap, rclass\n\n    version 14.2\n    syntax [, obs(integer 1) mu(real 0) sigma(real 1) ]\n    clear\n    drop _all\n    set obs 10\n    gen     y1 = 7 in 1\n    replace y1 = 5 in 2\n    replace y1 = 5 in 3\n    replace y1 = 7 in 4\n    replace y1 = 4 in 5\n    replace y1 = 10 in 6\n    replace y1 = 1 in 7\n    replace y1 = 5 in 8\n    replace y1 = 3 in 9\n    replace y1 = 9 in 10\n\n    gen     y0 = 1 in 1\n    replace y0 = 6 in 2\n    replace y0 = 1 in 3\n    replace y0 = 8 in 4\n    replace y0 = 2 in 5\n    replace y0 = 1 in 6\n    replace y0 = 10 in 7\n    replace y0 = 6 in 8\n    replace y0 = 7 in 9\n    replace y0 = 8 in 10\n    drawnorm random\n    sort random\n\n    gen     d=1 in 1/5\n    replace d=0 in 6/10\n    gen     y=d*y1 + (1-d)*y0\n    egen sy1 = mean(y) if d==1\n    egen sy0 = mean(y) if d==0          \n    collapse (mean) sy1 sy0\n    gen sdo = sy1 - sy0\n    keep sdo\n    summarize sdo\n    gen mean = r(mean)\n    end\n\nsimulate mean, reps(10000): gap\nsu _sim_1 \nlibrary(tidyverse)\n\ngap <- function() \n{\n  sdo <-  tibble(\n    y1 = c(7,5,5,7,4,10,1,5,3,9),\n    y0 = c(1,6,1,8,2,1,10,6,7,8),\n    random = rnorm(10)\n  ) %>% \n    arrange(random) %>% \n    mutate(\n      d = c(rep(1,5), rep(0,5)),\n      y = d * y1 + (1 - d) * y0\n    ) %>%\n    pull(y)\n  \n  sdo <- mean(sdo[1:5]-sdo[6:10])\n  \n  return(sdo)\n}\n\nsim <- replicate(10000, gap())\nmean(sim)"},{"path":"ch3.html","id":"sutva","chapter":"4 Potential Outcomes Causal Model","heading":"4.1.5 SUTVA","text":"Rubin argues bundle assumptions behind kind calculation, calls assumptions stable unit treatment value assumption, SUTVA short. ’s mouthful, ’s means: potential outcomes framework places limits us calculating treatment effects. limits credibly hold data, come new solution. limitations unit receives sized dose, spillovers (“externalities”) units’ potential outcomes unit exposed treatment, general equilibrium effects.First, implies treatment received homogeneous doses units. ’s easy imagine violations , though—instance, doctors better surgeons others. case, just need careful defining treatment.Second, implies externalities, definition, externality spills untreated units. words, unit 1 receives treatment, externality, unit 2 different \\(Y^0\\) value unit 1 received treatment. assuming away kind spillover. spillovers, though, working social network data, need use models can explicitly account SUTVA violations, Goldsmith-Pinkham Imbens (2013).Related problem spillovers issue general equilibrium. Let’s say estimating causal effect returns schooling. increase college education general equilibrium cause change relative wages different happens partial equilibrium. kind scaling-issue common concern one considers extrapolating experimental design large-scale implementation intervention population.Replicating “demand learning HIV status.” Rebecca Thornton prolific, creative development economist. research spanned number topics development evaluated critically important questions regarding optimal HIV policy, demand learning, circumcision, education, . papers become major accomplishments. Meticulous careful, become leading expert HIV sub-Saharan Africa. ’d like discuss ambitious project undertook grad student rural Malawi concerning whether cash incentives caused people learn HIV status cascading effect learning subsequent risky sexual behavior (Thornton 2008).Thornton’s study emerges policy context people believed HIV testing used fight epidemic. idea simple: people learned HIV status, maybe learning infected cause take precautions, thus slowing rate infection. instance, might seek medical treatment, thus prolonging life quality life enjoyed. upon learning HIV status, maybe finding HIV-positive cause decrease high-risk behavior. , increased testing create frictions throughout sexual network slow epidemic. commonsense policy assumptions rested challenged Thornton (2008) ingenious field experiment rural Malawi. results , like many studies, mixture good news bad.Attempting understand demand HIV status, effect HIV status health behaviors, generally impossible without experiment. Insofar individuals optimally choosing learn type engaging health behaviors, unlikely knowledge HIV status independent potential outcomes. Almost certainly, potential outcomes shape decisions acquire information engage risky behaviors sort. Thus, field experiment needed test underlying assumptions behind commonsense policy use testing fight epidemic., though? Respondents rural Malawi offered free door--door HIV test randomly assigned voucher vouchers ranging $1–$3. vouchers redeemable visited nearby voluntary counseling testing center (VCT). encouraging news monetary incentives highly effective causing people seek results tests. average, respondents received cash-value voucher two times likely go VCT center get test results compared individuals received compensation. big incentive? Well, average incentive experiment worth day’s wage. found positive status-seeking behavior even smallest incentive, worth one-tenth day’s wage. Thornton showed even small monetary nudges used encourage people learn HIV type, obvious policy implications.second part experiment threw cold water optimism first results. Several months cash incentives given respondents, Thornton followed interviewed subsequent health behaviors. Respondents also given opportunity purchase condoms. Using randomized assignment incentives learning HIV status, able isolate causal effect learning condom purchase proxy engaging risky sex. finds conditional learning one’s HIV status randomized incentives, HIV-positive individuals increase condom usage HIV-positive individuals learned results form buying two additional condoms. study suggested kinds outreach, door--door testing, may cause people learn type—particularly bundled incentives—simply incentivized learn one’s HIV status may lead HIV-positive individuals reduce engagement high-risk sexual behaviors, sex without condom.Thorton’s experiment complex able represent , also, focus now cash-transfer aspect experiment, form vouchers. going focus purely incentive results. , let’s take look found. Table 4.4 shows findings.Since project uses randomized assignment cash transfers identifying causal effect learning, mechanically creates treatment assignment independent potential outcomes consideration. know even though directly test (.e., potential outcomes unseen) know science works. Randomization, words, design assigns treatment independent potential outcomes. result, simple differences means sufficient getting basic estimates causal effects.Thornton going estimate linear regression model controls instead using simple difference means reasons. One, allows include variety controls can reduce residual variance thus improve precision estimates. value improving precision, able rule broader range treatment effects technically contained confidence intervals. Although probably case, ’s terribly important given, see, standard errors miniscule.Table 4.4:  Impact Monetary Incentives Distance Learning HIV Results (Thornton 2008)\nColumns 1–5 represent OLS coefficients; robust standard errors clustered village (119 villages) district fixed effects parentheses. specifications also include term age-squared. “incentive” indicator respondent received nonzero monetary incentive. “HIV” indicator HIV positive. “Simulated average distance” average distance respondents’ households simulated randomized locations HIV results centers. Distance measured straight-line spherical distance respondent’s home randomly assigned VCT center geospatial coordinates measured kilometers. \\(^{***}\\)Significantly different zero 99 percent confidence level. \\(^{**}\\) Significantly different zero 95 percent confidence level. \\(^{*}\\) Significantly different zero 90 percent confidence level.\ninclusion controls value. instance, assignment conditional observables, assignment done different times, including controls (district fixed effects) technically needed isolate causal effects . finally, regression generates nice standard errors, maybe alone, give chance.70So Thornton find? uses least squares primary model, represented columns 1–5. effect sizes finds described gigantic. 34 percent control group participants went center learn HIV status, impressive receiving money caused 43-percentage-point increase learning one’s HIV status. Monetary incentives—even small ones—enough push many people hump go collect health data.Columns 2–5 also interesting, won’t belabor . short, column 2 includes control amount incentive, ranged US$0 US$3. allows us estimate linear impact additional dollar learning, relatively steep. Columns 3–5 include quadratic result see additional dollar increases learning, decreasing rate. Columns 4 5 include controls distance VCT center, studies, distance barrier types health care (Lindo et al. 2019).Thornton also produces simple graphic results, showing box plots mean confidence intervals treatment control group. continually see throughout book, best papers estimating causal effects always summarize main results smart effective pictures, study exception. figure shows, effects huge.\nFigure 4.1: Visual representation cash transfers learning HIV test results (Thornton 2008).\nlearning one’s HIV status important, particularly leads medical care, gains policies nudge learning particularly higher lead changes high-risk sexual behavior among HIV-positive individuals. fact, given multiplier effects associated introducing frictions sexual network via risk-mitigating behavior (particularly disrupts concurrent partnerships), efforts may beneficial justify many types programs otherwise may cost-effective.Thornton examines follow-survey asked individuals, regardless whether learned HIV status, effect cash transfer condom purchases. Let’s first see main results Figure 4.2.\nFigure 4.2: Visual representation cash transfers condom purchases HIV positive individuals (Thornton 2008).\ninitially encouraging see effects condom purchases large HIV-positive individuals , result incentive, got test results. bought condoms increases baseline ’s little 30 percent whopping 80 percent incentive. things get discouraging examine many additional condoms actually entailed. columns 3 4 Table 4.5, see problem.Table 4.5:  Reactions Learning HIV Results among Sexually Active Baseline (Thornton 2008)\nSample includes individuals tested HIV demographic data.\nNow Thornton wisely approaches question two ways sake reader sake accuracy. wants know effect getting results, results matter (1) got status (2) HIV-positive. effects shouldn’t matter HIV-negative. ultimately finds, going answer first? examines effect got results HIV-positive using interaction. ’s column 1: individuals got HIV status learned HIV positive 41% likely buy condoms several months later. result shrinks, though, utilizes randomization incentives instrumental variables framework, discuss later book. coefficient almost cut half confidence intervals large can’t sure effects nonexistent.let’s say reason failed find effect purchasing behavior sample size just small enough pick effect IV just asking much data. used something little information, like number condoms bought? ’s things get pessimistic. Yes, Thornton find evidence HIV-positive individuals buying condoms, see many, learn around 2 condoms follow-visit (columns 3–4). effect sex (shown) negative, small (4% reduction), precise enough say either way anyway.conclusion, Thornton’s study one studies regularly come across causal inference, mixture positive negative. ’s positive nudging people small incentives leads collecting information HIV status. enthusiasm muted learn effect actual risk behaviors large—mere two additional condoms bought several months later HIV-positive individuals likely going generate large positive externalities unless falls highest-risk HIV-positive individuals.Buy print version today:","code":""},{"path":"ch3.html","id":"randomization-inference","chapter":"4 Potential Outcomes Causal Model","heading":"4.2 Randomization Inference","text":"Athey Imbens (2017b), chapter randomized experiments, note “randomization-based inference, uncertainty estimates arises naturally random assignment treatments, rather hypothesized sampling large population” (73). Athey Imbens part growing trend economists using randomization-based methods inferring probability estimated coefficient simply result change. growing trend uses randomization-based methods construct exact \\(p\\)-values reflect likelihood chance ’ve produced estimate.randomization inference become population now? twenty years ago ? ’s clear randomization-based inference become popular recent years, possibilities explain trend. may rise randomized controlled trials within economics, availability large-scale administrative databases samples larger population rather represent “data,” may computational power improved much randomization inference become trivially simple implement working thousands observations. whatever reason, randomization inference become common way talk uncertainty around one’s estimates.least three reasons might conduct randomization inference. First, may aren’t working samples, since standard errors often justified grounds reflect sampling uncertainty, traditional methods may meaningful. core uncertainty within causal study based sampling uncertainty, rather fact know counterfactual (Abadie, Diamond, Hainmueller 2010; Abadie et al. 2020). Second, may uncomfortable appealing large sample properties estimator particular setting, working small number treatment units. situations, maybe assuming number units increases infinity stretches credibility (Buchmueller, DiNardo, Valletta 2011). can particularly problematic practice. Young (2019) shows finite samples, common observations experience concentrated leverage. Leverage causes standard errors estimates become volatile can lead overrejection. Randomization inference can robust outliers. Finally, seems aesthetic preference types placebo-based inference, many people find intuitive. sufficient reason adopt methodological procedure, nonetheless common hear someone say used randomization inference makes sense. figured worth mentioning since ’ll likely run comments like well. dig , let’s discuss history, dates back Ronald Fisher early twentieth century.","code":""},{"path":"ch3.html","id":"lady-tasting-tea","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.1 Lady tasting tea","text":"Fisher (1935) described thought experiment woman claims can discern whether milk tea poured first cup tea. give name, now know woman thought experiment Muriel Bristol thought experiment fact happen.71 Muriel Bristol PhD scientist back days women rarely able become PhD scientists. One day afternoon tea, Muriel claimed tell whether milk added cup tea. Incredulous, Fisher hastily devised experiment test self-proclaimed talent.hypothesis, properly stated, , given cup tea milk, woman can discern whether milk tea first added cup. test claim, eight cups tea prepared; four milk added first, four tea added first. many cups correctly identify convince us uncanny ability?Fisher (1935) proposed kind permutation-based inference—method now call Fisher’s exact test. woman possesses ability probabilistically, certainty, likelihood guessing four correctly sufficiently low. \\(8\\times{7}\\times{6}\\times{5}=1,680\\) ways choose first cup, second cup, third cup, fourth cup, order. \\(4\\times{3}\\times{2}\\times{1}=24\\) ways order four cups. number ways choose four cups eight \\(\\dfrac{1680}{24}=70\\). Note, woman performs experiment selecting four cups. probability correctly identify four cups \\(\\dfrac{1}{70}\\), \\(p=0.014\\).Maybe convinced method see simulation, though. let’s conduct simple combination exercise. can following code.tea.dotea.RNotice, get answer either way—0.014. , let’s return Dr. Bristol. Either ability discriminate order tea milk poured, therefore chose correct four cups random chance, (like said) ability discriminate order ingredients poured drink. Since choosing correctly highly unlikely (1 chance 70), reasonable believe talent claimed along .exactly done? Well, done provide exact probability value observed phenomenon merely product chance. can never let fundamental problem causal inference get away : never know causal effect. estimate . rely procedures give us reasons believe number calculated probably causal effect. Randomization inference, like inference, epistemological scaffolding particular kind belief—specifically, likelihood chance created observed value particular kind procedure.example, motivated Fisher develop method, experimental design wherein causal effects estimated. now ’d like move beyond . , hope, randomization inference procedure become interesting powerful tool making credible causal statements.","code":"clear\ncapture log close\n\n* Create the data. 4 cups with tea, 4 cups with milk.\n\nset obs 8\ngen cup = _n\n\n* Assume she guesses the first cup (1), then the second cup (2), and so forth\ngen     guess = 1 in 1\nreplace guess = 2 in 2\nreplace guess = 3 in 3\nreplace guess = 4 in 4\nreplace guess = 0 in 5\nreplace guess = 0 in 6\nreplace guess = 0 in 7\nreplace guess = 0 in 8\nlabel variable guess \"1: she guesses tea before milk then stops\"\n\ntempfile correct\nsave \"`correct'\", replace\n\n* ssc install percom\ncombin cup, k(4)\ngen permutation = _n\ntempfile combo\nsave \"`combo'\", replace\n\ndestring cup*, replace\ncross using `correct'\nsort permutation cup\n\ngen     correct = 0\nreplace correct = 1 if cup_1 == 1 & cup_2 == 2 & cup_3 == 3 & cup_4 == 4\n\n* Calculation p-value\ncount if correct==1\nlocal correct `r(N)'\ncount\nlocal total `r(N)'\ndi `correct'/`total'\ngen pvalue = (`correct')/(`total')\nsu pvalue\n\n* pvalue equals 0.014\n \ncapture log close\nexit\nlibrary(tidyverse)\nlibrary(utils)\n\ncorrect <- tibble(\n  cup   = c(1:8),\n  guess = c(1:4,rep(0,4))\n)\n\ncombo <- correct %$% as_tibble(t(combn(cup, 4))) %>%\n  transmute(\n    cup_1 = V1, cup_2 = V2,\n    cup_3 = V3, cup_4 = V4) %>% \n  mutate(permutation = 1:70) %>%\n  crossing(., correct) %>% \n  arrange(permutation, cup) %>% \n  mutate(correct = case_when(cup_1 == 1 & cup_2 == 2 &\n                               cup_3 == 3 & cup_4 == 4 ~ 1,\n                             TRUE ~ 0))\nsum(combo$correct == 1)\np_value <- sum(combo$correct == 1)/nrow(combo)"},{"path":"ch3.html","id":"methodology-of-fishers-sharp-null","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.2 Methodology of Fisher’s sharp null","text":"Let’s discuss mean randomization inference context easier understand—literal experiment quasi-experiment. conclude code illustrates might implement . main advantage randomization inference allows us make probability calculations revealing whether data likely draw truly random distribution .methodology can’t understood without first understanding concept Fisher’s sharp null. Fisher’s sharp null claim make wherein unit data, treated, causal effect. subtle concept maybe readily clear, much clearer work examples. value Fisher’s sharp null allows us make “exact” inference depend hypothesized distributions (e.g., Gaussian) large sample approximations. sense, nonparametric.72Some, first confronted concept randomization inference, think, “Oh, sounds like bootstrapping,” two fact completely different. Bootstrapped p-values random draws sample used conduct inference. means bootstrapping primarily uncertainty observations used sample . randomization inference \\(p\\)-values uncertainty sample; rather, based uncertainty units within sample assigned treatment .help understand randomization inference, let’s break methodological steps. say six steps randomization inference: (1) choice sharp null, (2) construction null, (3) picking different treatment vector, (4) calculation corresponding test statistic new treatment vector, (5) randomization step 3 cycle number new treatment vectors (ideally possible combinations), (6) calculation exact \\(p\\)-value.","code":""},{"path":"ch3.html","id":"steps-to-a-p-value","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.3 Steps to a p value","text":"Fisher Neyman debated first step. Fisher’s “sharp” null assertion every single unit treatment effect zero, leads easy statement ATE also zero. Neyman, hand, started direction asserted average treatment effect, unit zero treatment effect. important distinction. see , assume treatment effect 5, treatment effect \\(-5\\). \\(ATE=0\\) Neyman’s idea. Fisher’s idea say treatment effect zero, treatment effect zero. “sharp” means—means literally single unit treatment effect. Let’s express using potential outcomes notation, can help clarify mean.\n\\[\nH_0: \\delta_i = Y_i^1 - Y_i^0 = 0 \\forall \n\\]\nNow, may obvious going help us, consider —since know observed values, treatment effect, also know unit’s counterfactual. Let illustrate point using example Table 4.6.Table 4.6:  Example made-data 8 people missing counterfactuals.look closely Table 15, see unit, observe one potential outcome. sharp null, can infer missing counterfactual. information observed outcomes based switching equation. unit treated, know \\(Y^1\\) \\(Y^0\\).second step construction called “test statistic.” ? test statistic \\(t(D,Y)\\) simply known, scalar quantity calculated treatment assignments observed outcomes. often simply nothing measurement relationship \\(Y\\) values \\(D\\). rest section, build variety ways people construct test statistics, start fairly straightforward measurement—simple difference mean outcome.Test statistics ultimately help us distinguish sharp null hypothesis. want test statistic high statistical power, need test statistic take “extreme” values (.e., large absolute values) null false, need large values unlikely null true.73As said, number ways estimate test statistic, discussing several , let’s start simple difference mean outcomes. average values treatment group \\(34/4\\), average values control group \\(30/4\\), difference two averages \\(1\\). given particular treatment assignment sample—true assignment, mind —corresponding test statistic (simple difference mean outcomes) equal 1.Now, implied Fisher’s sharp null one interesting parts method. historically know unit’s counterfactual, sharp null know unit’s counterfactual. possible? none units nonzero treatment effects, must counterfactual equal observed outcome. means can fill missing counterfactuals observed values (Table 4.7).Table 4.7:  Example made-data 8 people filled-counterfactuals according Fisher’s sharp null hypothesis.missing counterfactuals replaced corresponding observed outcome, ’s treatment effect unit level therefore zero ATE. find earlier simple difference mean outcomes 1 fact average treatment effect? Simple—just noise, pure simple. simply reflection arbitrary treatment assignment Fisher’s sharp null, random chance just happens assignment generated test statistic \\(1\\)., let’s summarize. particular treatment assignment corresponding test statistic. assume Fisher’s sharp null, test statistic simply draw random process. ’s true, can shuffle treatment assignment, calculate new test statistic ultimately compare “fake” test statistic real one.key insight randomization inference sharp null, treatment assignment ultimately matter. explicitly assumes go one assignment another counterfactuals aren’t changing—always just equal observed outcomes. randomization distribution simply set possible test statistics possible treatment assignment vector. third fourth steps extend idea literally shuffling treatment assignment calculating unique test statistic assignment. repeatedly (step 5), limit eventually cycle possible combinations yield distribution test statistics sharp null.entire distribution test statistics, can calculate exact \\(p\\)-value. ? Simple—rank test statistics, fit true effect ranking, count number fake test statistics dominate real one, divide number possible combinations. Formally, :\n\\[\n\\Pr\\Big(t(D,Y)\\geq t(D,Y\\mid \\delta=0)\\Big)=\n   \\dfrac{\\sum_{D\\\\Omega} (t(D,Y) \\geq t(D,Y)}{K}\n\\]\n, see meant “exact.” \\(p\\)-values exact, approximations. rejection threshold \\(\\alpha\\)—instance, 0.05—randomization inference test falsely reject sharp null less \\(100 \\times \\alpha\\) percent time.","code":""},{"path":"ch3.html","id":"example","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.4 Example","text":"think kind abstract, things abstract, ’s easy confused, let’s work example new data. Imagine work homeless shelter cognitive behavioral therapy (CBT) program treating mental illness substance abuse. enough funding enlist four people study, eight residents. Therefore, four treatment four control. concluding CBT, residents interviewed determine severity mental illness symptoms. therapist records mental health scale 0 20. following information, can fill missing counterfactuals satisfy Fisher’s sharp null calculate corresponding test statistic based treatment assignment. test statistic absolute value simple difference mean outcomes simplicity. test statistic particular treatment assignment simply \\(|34/4-30/4|=8.5- 7.5 = 1\\), using data Table 4.8.Table 4.8:  Self-reported mental health 8 residents homeless shelter (treatment control).Now move randomization stage. Let’s shuffle treatment assignment calculate new test statistic new treatment vector. Table 4.9 shows permutation. first, one thing. going keep number treatment units fixed throughout example. treatment assignment followed random process, like Bernoulli, number treatment units random randomized treatment assignment larger . right? Neither right . Holding treatment units fixed ultimately reflection whether fixed original treatment assignment. means need know data process units assigned treatment know conduct randomization inference.Table 4.9:  First permutation holding number treatment units fixedWith shuffling treatment assignment, can calculate new test statistic, \\(|36/4 - 28/4|=9-7=2\\). Now move , look test statistic: test statistic 2 “fake” true treatment assignment. null, treatment assignment, already meaningless, since nonzero treatment effects anyway. point even null effect holds, can usually yield nonzero effect reason finite sample properties.Let’s write number 2 another permutation, mean, let’s shuffle treatment assignment . Table 4.10 shows second permutation, holding number treatment units fixed four treatment four control.Table 4.10:  First permutation holding number treatment units fixedThe test statistic associated treatment assignment \\(|36/4-27/4|=9-6.75=2.25\\). , 2.25 draw random treatment assignment unit treatment effect.time randomize treatment assignment, calculate test statistic, store test statistic somewhere, go onto next combination. repeat exhausted possible treatment assignments. Let’s look first iterations Table 4.11.Table 4.11:  first permutations randomization treatment assignments.final step calculation exact \\(p\\)-value. , couple options. can either use software , fine way , can manually . pedagogical reasons, partial manually. let’s go.ri.dori.RThis program fairly straightforward number possible combinations small. eight observations, four choose eight equals 70. just manipulate data get point, , actual calculation straighforward. can see estimated ATE reject null placebo distribution.often data sets work much larger eight observations. situations, use method, sheer volume combination grows fast \\(n\\) increases. hold now reviewing inference method \\(n\\) large ’ve chance cover ground.","code":"use https://github.com/scunning1975/mixtape/raw/master/ri.dta, clear\n\ntempfile ri\ngen id = _n\nsave \"`ri'\", replace\n\n* Create combinations\n* ssc install percom\ncombin id, k(4)\ngen permutation = _n\ntempfile combo\nsave \"`combo'\", replace\n\nforvalue i =1/4 {\n    ren id_`i' treated`i'\n}\n\n\ndestring treated*, replace\ncross using `ri'\nsort permutation name\nreplace d = 1 if id == treated1 | id == treated2 | id == treated3 | id == treated4\nreplace d = 0 if ~(id == treated1 | id == treated2 | id == treated3 | id == treated4)\n\n* Calculate true effect using absolute value of SDO\negen    te1 = mean(y) if d==1, by(permutation)\negen    te0 = mean(y) if d==0, by(permutation)\n\ncollapse (mean) te1 te0, by(permutation)\ngen     ate = te1 - te0\nkeep    ate permutation\n\nsort ate\ngen rank = _n\nsu rank if permutation==1\ngen pvalue = (`r(mean)'/70)\nlist pvalue if permutation==1\n* pvalue equals 0.6\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nri <- read_data(\"ri.dta\") %>% \n  mutate(id = c(1:8))\n\ntreated <- c(1:4)\n\ncombo <- ri %$% as_tibble(t(combn(id, 4))) %>%\n  transmute(\n    treated1 = V1, treated2 = V2,\n    treated3 = V3, treated4 = V4) %>%\n  mutate(permutation = 1:70) %>%\n  crossing(., ri) %>%\n  arrange(permutation, name) %>% \n  mutate(d = case_when(id == treated1 | id == treated2 |\n                         id == treated3 | id == treated4 ~ 1,\n                       TRUE ~ 0))\n\nte1 <- combo %>%\n  group_by(permutation) %>%\n  filter(d == 1) %>% \n  summarize(te1 = mean(y, na.rm = TRUE))\n\nte0 <- combo %>%\n  group_by(permutation) %>%\n  filter(d == 0) %>% \n  summarize(te0 = mean(y, na.rm = TRUE))\n\nn <- nrow(inner_join(te1, te0, by = \"permutation\"))\n\np_value <- inner_join(te1, te0, by = \"permutation\") %>%\n  mutate(ate = te1 - te0) %>% \n  select(permutation, ate) %>% \n  arrange(ate) %>% \n  mutate(rank = 1:nrow(.)) %>% \n  filter(permutation == 1) %>%\n  pull(rank)/n"},{"path":"ch3.html","id":"other-test-statistics","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.5 Other test statistics","text":"Recall second step methodology selection test statistic.74 chose simple difference mean outcomes (absolute value ), fine effects additive outliers data. outliers create problems test statistic variation gets introduced randomization distribution. alternative test statistics become attractive.One transformation handles outliers skewness generally log transformation. Imbens Rubin (2015) define average difference log scale treatment status, \n\\[\nT_{\\log} = \\bigg| \\dfrac{1}{N_T} \\sum_{=1}^N D_i \\ln(Y_i) - \\dfrac{1}{N_C} \\sum_{=1}^N (1-D_i)\\ln(Y_i) \\bigg |\n\\]\nmakes sense raw data skewed, happens positive values like earnings instances treatment effects multiplicative rather additive.Another test statistic seen absolute value difference quantiles. also protects outliers represented \n\\[\nT_{\\text{median}}=\\Big|\\text{median}(Y_T) - \\text{median}(Y_C)\\Big|\n\\]\nlook median, 25th quantile, 75th quantile, anything along unit interval.issue outliers also leads us consider test statistic uses ranks rather differences. useful large numbers outliers, outcomes continuous data sets small. Rank statistics transform outcomes ranks conduct analysis ranks . basic idea rank outcomes compare average rank treated control groups. Let’s illustrate example first (Table 4.12).Table 4.12:  Illustrating ranks using example data., observe one half potential outcomes given switching equation assigns potential outcomes actual outcomes. Fisher’s sharp null, can impute missing counterfactual ensure treatment effect. calculate ranks, simply count number units higher values \\(Y\\), including unit question. instances ties, simply take average tied units.instance, consider Andy. Andy value \\(10\\). Andy large (1); larger Ben (2), Daniel (3), Edith (4), Frank (5), George (6); tied Hank (7). Since tied Hank, average two, brings rank 6.5. Now consider Ben. Ben value 5. large (1), larger Daniel (2), tied Edith (3). Therefore, average Edith get 0.5, bringing us rank 2.common, though, normalize ranks mean 0, done according following formula:\n\\[\n\\widetilde{R_i} = \\widetilde{R_i}(Y_1, \\dots, Y_N) = \\sum_{j=1}^N (Y_j \\leq Y_i) - \\dfrac{N+1}{2}\n\\]\ngives us final column, now use calculate test statistic. Let’s use absolute value simple difference mean outcomes normalized rank, \n\\[\nT_{\\text{rank}}=|0-1/4|=1/4\n\\]\ncalculate exact \\(p\\)-value, simply conduct randomization process earlier, instead calculating simple difference mean outcomes, calculate absolute value simpler difference mean rank.test statistics ’ve discussing differences outcomes treatment status. considered simple differences averages, simple differences log averages, differences quantiles, differences ranks. Imbens Rubin (2015) note shortcomings come focusing solely features data (e.g., skewness), can cause us miss differences aspects. specifically can problematic variance potential outcomes treatment group differs control group. Focusing simple average differences discussed may generate \\(p\\)-values “extreme” enough reject null even null fact hold. may interested test statistic can detect differences distributions treatment control units. One test statistic Kolmogorov-Smirnov test statistic.Let’s first define empirical cumulative distribution function (CDF) :\\[\\begin{align}\n   \\widehat{F}_C(Y) & =\\dfrac{1}{N_C} \\sum_{:D_i=0} 1(Y_i \\leq Y)  \\\\\n   \\widehat{F}_T(Y) & = \\dfrac{1}{N_T} \\sum_{:D_i=1} 1(Y_i \\leq Y) \n\\end{align}\\]two distributions , empirical CDF . note, empirical CDFs functions, test statistics scalars. take differences two functions turn single scalar quantity? Easy—use maximum difference two empirical CDFs. Visually, literally greatest vertical distance two empirical CDFs. vertical distance test statistic. Formally :\\[\nT_{KS}=\\max \\Big|\\widehat{F}_T(Y_i) - \\widehat{F}_C(Y_i)\\Big|\n\\]\nFigure 4.3: Visualization distributions treatment status\nks.doks.RAnd calculate p-value, repeat earlier examples. Specifically, drop treatment variable, re-sort data, reassign new (fixed) treatment values, calculate \\(T_{KS}\\), save coefficient, repeat thousand times distribution can use calculate empirical \\(p\\)-value.","code":"clear\ninput  d y\n0    0.22         \n0   -0.87        \n0   -2.39        \n0   -1.79        \n0    0.37         \n0   -1.54        \n0    1.28         \n0   -0.31        \n0   -0.74        \n0    1.72         \n0    0.38         \n0   -0.17        \n0   -0.62        \n0   -1.10        \n0    0.30         \n0    0.15         \n0    2.30         \n0    0.19         \n0   -0.50        \n0   -0.09        \n1   -5.13 \n1   -2.19 \n1   -2.43 \n1   -3.83 \n1    0.50 \n1   -3.25 \n1    4.32 \n1    1.63 \n1    5.18 \n1   -0.43 \n1    7.11 \n1    4.87 \n1   -3.10 \n1   -5.81 \n1    3.76 \n1    6.31 \n1    2.58 \n1    0.07 \n1    5.76 \n1    3.50\nend\n\ntwoway (kdensity y if d==1) (kdensity y if d==0, lcolor(blue) lwidth(medium) lpattern(dash)), \\\\\\\ntitle(Kolmogorov-Smirnov test) legend(order(1 ``Treatment'' 2 ``Control''))\nlibrary(tidyverse)\nlibrary(stats)\n\ntb <- tibble(\n  d = c(rep(0, 20), rep(1, 20)),\n  y = c(0.22, -0.87, -2.39, -1.79, 0.37, -1.54, \n        1.28, -0.31, -0.74, 1.72, \n        0.38, -0.17, -0.62, -1.10, 0.30, \n        0.15, 2.30, 0.19, -0.50, -0.9,\n        -5.13, -2.19, 2.43, -3.83, 0.5, \n        -3.25, 4.32, 1.63, 5.18, -0.43, \n        7.11, 4.87, -3.10, -5.81, 3.76, \n        6.31, 2.58, 0.07, 5.76, 3.50)\n)\n\nkdensity_d1 <- tb %>%\n  filter(d == 1) %>% \n  pull(y)\nkdensity_d1 <- density(kdensity_d1)\n\nkdensity_d0 <- tb %>%\n  filter(d == 0) %>% \n  pull(y)\nkdensity_d0 <- density(kdensity_d0)\n\nkdensity_d0 <- tibble(x = kdensity_d0$x, y = kdensity_d0$y, d = 0)\nkdensity_d1 <- tibble(x = kdensity_d1$x, y = kdensity_d1$y, d = 1)\n\nkdensity <- full_join(kdensity_d1, kdensity_d0)\nkdensity$d <- as_factor(kdensity$d)\n\nggplot(kdensity)+\n  geom_point(size = 0.3, aes(x,y, color = d))+\n  xlim(-7, 8)+\n  labs(title = \"Kolmogorov-Smirnov Test\")+\n  scale_color_discrete(labels = c(\"Control\", \"Treatment\"))"},{"path":"ch3.html","id":"randomization-inference-with-large-n","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.6 Randomization inference with large \\(n\\)","text":"number observations large? instance, Thornton’s total sample 2,901 participants. , 2,222 received incentive . Wolfram Alpha easy use online calculator complicated calculations easy use interface. go website type “2901 choose 2222” get following truncated number combinations:6150566109498251513699280333307718471623795043419269261826403\n18266385758921095807995693142554352679783785174154933743845244\n51166052365151805051778640282428979408776709284871720118822321\n8885942515735991356144283120935017438277464692155849858790123\n68811156301154026764620799640507224864560706516078004093411306\n55445400163121511770007503391790999621671968855397259686031228\n687680364730936480933074665307…Good luck calculating combinations. clearly, exact \\(p\\)-values using combinations won’t work. instead, going estimate approximate \\(p\\)-values. , need randomly assign treatment, estimate test statistic satisfying sharp null sample, repeating thousands times, calculate \\(p\\)-value associated treatment assignment based ranked position distribution.thornton_ri.dothornton_ri.RTable 4.13:  Estimated \\(p\\)-value using different number trials.Quite impressive. Table 4.13 shows Thornton’s experiment Fisher’s sharp null 100 1,000 repeated draws yields highly significant \\(p\\)-values. fact, always highest-ranked ATE one-tailed test.done obtain approximation \\(p\\)-value associated test statistic sharp null hypothesis. practice, number draws large, \\(p\\)-value based random sample fairly accurate (Imbens Rubin 2015). wanted illustrate randomization method reality exactly time since number combinations reasonably sized data set computationally prohibitive.Now, ways, randomization exercise didn’t reveal whole lot, ’s probably Thornton’s original findings just precise begin (0.4 standard error 0.02). throw atom bombs result won’t go anywhere. purpose primarily show robustness different ways generating precious p-values, well provide map programming arguably separate intuitive way thinking significance .","code":"use https://github.com/scunning1975/mixtape/raw/master/thornton_hiv.dta, clear\n\ntempfile hiv\nsave \"`hiv'\", replace\n\n* Calculate true effect using absolute value of SDO\negen    te1 = mean(got) if any==1\negen    te0 = mean(got) if any==0\n\ncollapse (mean) te1 te0\ngen     ate = te1 - te0\nkeep    ate\ngen iteration = 1\n\ntempfile permute1\nsave \"`permute1'\", replace\n\n* Create a hundred datasets\n\nforvalues i = 2/1000 {\n\nuse \"`hiv'\", replace\n\ndrop any\nset seed `i'\ngen random_`i' = runiform()\nsort random_`i'\ngen one=_n\ndrop random*\nsort one\n\ngen     any = 0\nreplace any = 1 in 1/2222\n\n* Calculate test statistic using absolute value of SDO\negen    te1 = mean(got) if any==1\negen    te0 = mean(got) if any==0\n\ncollapse (mean) te1 te0\ngen     ate = te1 - te0\nkeep    ate\n\ngen     iteration = `i'\ntempfile permute`i'\nsave \"`permute`i''\", replace\n\n}\n\nuse \"`permute1'\", replace\nforvalues i = 2/1000 {\n    append using \"`permute`i''\"\n}\n\ntempfile final\nsave \"`final'\", replace\n\n* Calculate exact p-value\ngsort -ate\ngen rank = _n\nsu rank if iteration==1\ngen pvalue = (`r(mean)'/1000)\nlist if iteration==1\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nhiv <- read_data(\"thornton_hiv.dta\")\n\n\n# creating the permutations\n\ntb <- NULL\n\npermuteHIV <- function(df, random = TRUE){\n  tb <- df\n  first_half <- ceiling(nrow(tb)/2)\n  second_half <- nrow(tb) - first_half\n  \n  if(random == TRUE){\n    tb <- tb %>%\n      sample_frac(1) %>%\n      mutate(any = c(rep(1, first_half), rep(0, second_half)))\n  }\n  \n  te1 <- tb %>%\n    filter(any == 1) %>%\n    pull(got) %>%\n    mean(na.rm = TRUE)\n  \n  te0 <- tb %>%\n    filter(any == 0) %>%\n    pull(got) %>% \n    mean(na.rm = TRUE)\n  \n  ate <-  te1 - te0\n  \n  return(ate)\n}\n\npermuteHIV(hiv, random = FALSE)\n\niterations <- 1000\n\npermutation <- tibble(\n  iteration = c(seq(iterations)), \n  ate = as.numeric(\n    c(permuteHIV(hiv, random = FALSE), map(seq(iterations-1), ~permuteHIV(hiv, random = TRUE)))\n  )\n)\n\n#calculating the p-value\n\npermutation <- permutation %>% \n  arrange(-ate) %>% \n  mutate(rank = seq(iterations))\n\np_value <- permutation %>% \n  filter(iteration == 1) %>% \n  pull(rank)/iterations"},{"path":"ch3.html","id":"leverage","chapter":"4 Potential Outcomes Causal Model","heading":"4.2.7 Leverage","text":"conclude, ’d like go back something said earlier regarding leverage. recent provocative study Young (2019) woken us challenges may face using traditional inference estimating uncertainty point estimate, robust standard errors. finds practical problems traditional forms inference, previously known, made salient made study. problem highlights one concentrated leverage. Leverage measure degree single observation right-hand-side variable takes extreme values influential estimating slope regression line. concentration leverage even observations can make coefficients standard errors extremely volatile even bias robust standard errors towards zero, leading higher rejection rates.illustrate problem, Young (2019) went simple exercise. collected fifty experimental (lab field) articles American Economic Association’s flagship journals: American Economic Review, American Economic Journal: Applied, American Economic Journal: Economic Policy. reanalyzed papers, using authors’ models, dropping one observation cluster reestimating entire model, repeatedly. found shocking:removal just one observation, 35% 0.01-significant reported results average paper can rendered insignificant level. Conversely, 16% 0.01-insignificant reported results can found significant level. (567)evidence dependent just observations creates doubt clarity work, alternatives? randomization inference method based Fisher’s sharp null, discussed section, can improve upon problems leverage, addition aforementioned reasons consider . typical paper, randomization inference found individual treatment effects 13 22 percent fewer significant results authors’ analysis discovered. Randomization inference, appears, somewhat robust presence leverage observations.","code":""},{"path":"ch3.html","id":"conclusion-2","chapter":"4 Potential Outcomes Causal Model","heading":"4.3 Conclusion","text":"conclusion, done things chapter. ’ve introduced potential outcomes notation used define various types causal effects. showed simple difference mean outcomes equal sum average treatment effect, selection bias, weighted heterogeneous treatment effect bias. Thus simple difference--mean outcomes estimator biased unless second third terms zero . One situation zero independence treatment, treatment assigned independent potential outcomes. independence occur? commonly confronted situation physical randomization treatment units. physical randomization assigns treatment reasons independent potential outcomes, selection bias zeroes , heterogeneous treatment effect bias. now move discuss second situation two terms zero : conditional independence.Buy print version today:","code":""},{"path":"ch4.html","id":"ch4","chapter":"5 Matching and Subclassification","heading":"5 Matching and Subclassification","text":"Buy print version today:","code":""},{"path":"ch4.html","id":"subclassification","chapter":"5 Matching and Subclassification","heading":"5.1 Subclassification","text":"One main things wanted cover chapter directed acylical graphical models idea backdoor criterion. Specifically, insofar exists conditioning strategy satisfy backdoor criterion, can use strategy identify causal effect. now discuss three different kinds conditioning strategies. subclassification, exact matching, approximate matching.75Subclassification method satisfying backdoor criterion weighting differences means strata-specific weights. strata-specific weights , turn, adjust differences means distribution strata counterfactual’s strata. method implicitly achieves distributional balance treatment control terms known, observable confounder. method created statisticians like Cochran (1968), tried analyze causal effect smoking lung cancer, methods today moved beyond , include techniques implicit subclassification present throughout rest book.One concepts threaded chapter conditional independence assumption, CIA. Sometimes know randomization occurred conditional observable characteristics. instance, Krueger (1999), Tennessee randomly assigned kindergarten students teachers small classrooms, large classrooms, large classrooms aide. state conditionally—specifically, schools chosen, students randomized. Krueger therefore estimated regression models included school fixed effect knew treatment assignment conditionally random.assumption written \n\\[\n(Y^1,Y^0) \\perp \\!\\!\\! \\perp D\\mid X\n\\]\n\\(\\perp \\!\\!\\! \\perp\\) notation statistical independence \\(X\\) variable conditioning . means expected values \\(Y^1\\) \\(Y^0\\) equal treatment control group value \\(X\\). Written , means:\\[\\begin{align}\n   E\\big[Y^1\\mid D=1,X\\big]=E\\big[Y^1\\mid D=0,X\\big]\n   \\\\\n   E\\big[Y^0\\mid D=1,X\\big]=E\\big[Y^0\\mid D=0,X\\big]\n\\end{align}\\]Let link together concepts. First, insofar CIA credible, CIA means found conditioning strategy satisfies backdoor criterion. Second, treatment assignment conditional observable variables, situation selection observables. variable \\(X\\) can thought \\(n\\times k\\) matrix covariates satisfy CIA whole.","code":""},{"path":"ch4.html","id":"some-background","chapter":"5 Matching and Subclassification","heading":"5.1.1 Some background","text":"major public health problem mid- late twentieth century problem rising lung cancer. instance, mortality rate per 100,000 cancer lungs males reached 80–100 per 100,000 1980 Canada, England, Wales. 1860 1950, incidence lung cancer found cadavers autopsy grew 0% high 7%. rate lung cancer incidence appeared increasing.Studies began emerging suggested smoking cause since highly correlated incidence lung cancer. instance, studies found relationship daily smoking lung cancer males monotonically increasing number cigarettes male smoked per day. statisticians believed scientists couldn’t draw causal conclusion possible smoking independent potential health outcomes. Specifically, perhaps people smoked cigarettes differed non-smokers ways directly related incidence lung cancer. , one flipping coins deciding smoke.Thinking simple difference means decomposition earlier, know contrasting incidence lung cancer smokers non-smokers biased observational data independence assumption hold. smoking endogenous—, people choose smoke—’s entirely possible smokers differed non-smokers ways directly related incidence lung cancer.Criticisms time came prominent statisticians Joseph Berkson, Jerzy Neyman, Ronald Fisher. made several compelling arguments. First, suggested correlation spurious due non-random selection subjects. Functional form complaints also common. people’s use risk ratios odds ratios. association, argued, sensitive kinds functional form choices, fair criticism. arguments really different kinds arguments might see today people skeptical statistical association found observational data set.Probably damning, though, hypothesis existed unobservable genetic element caused people smoke independently caused people develop lung cancer. confounder meant smokers non-smokers differed one another ways directly related potential outcomes, thus independence hold. plenty evidence two groups different. instance, smokers extroverted non-smokers, also differed age, income, education, .arguments smoking cause mounted. criticisms included magnitudes relating smoking lung cancer implausibly large. , ever-present criticism observational studies: exist experimental evidence incriminate smoking cause lung cancer.76The theory smoking causes lung cancer now accepted science. wouldn’t surprised people believe flat Earth smoking causes lung cancer. can’t think well-known widely accepted causal theory, fact. Fisher others fail see ? Well, Fisher’s defense, arguments based sound causal logic. Smoking endogenous. experimental evidence. two groups differed considerably observables. decomposition simple difference means shows contrasts biased selection bias. Nonetheless, Fisher wrong, opponents right. just right wrong reasons.motivate ’re subclassification, let’s work Cochran (1968), study trying address strange patterns smoking data adjusting confounder. Cochran lays mortality rates country smoking type (Table 5.1).Table 5.1:  Death rates per 1,000 person-years (Cochran 1968)can see, highest death rate Canadians among cigar pipe smokers, considerably higher non-smokers smoke cigarettes. Similar patterns show countries, though smaller magnitude see Canada.table suggests pipes cigars dangerous cigarette smoking, , modern reader, sounds ridiculous. reason sounds ridiculous cigar pipe smokers often inhale, therefore less tar accumulates lungs cigarettes. insofar ’s tar causes lung cancer, stands reason see higher mortality rates among cigarette smokers., recall independence assumption. really believe :\\[\\begin{align}\n   E\\big[Y^1\\mid \\text{Cigarette}\\big] =\n   E\\big[Y^1\\mid \\text{Pipe}\\big] =\n   E\\big[Y^1\\mid \\text{Cigar}\\big]\n   \\\\\n   E\\big[Y^0\\mid \\text{Cigarette}\\big]=\n   E\\big[Y^0\\mid \\text{Pipe}\\big] =\n   E\\big[Y^0\\mid \\text{Cigar}\\big]\n\\end{align}\\]case factors related three states world truly independent factors determine death rates? Well, let’s assume sake argument independence assumptions held. else true across three groups? Well, mean potential outcomes type smoking category, wouldn’t expect observable characteristics smokers well? connection independence assumption characteristics groups called balance. means covariates group, say covariates balanced two groups exchangeable respect covariates.One variable appears matter age person. Older people likely time smoke cigars pipes, without stating obvious, older people likely die. Table 5.2 can see mean ages different groups.Table 5.2:  Mean ages, years (Cochran 1968).high means cigar pipe smokers probably terribly surprising. Cigar pipe smokers typically older cigarette smokers, least 1968 Cochran writing. since older people die higher rate (reasons just smoking cigars), maybe higher death rate cigar smokers ’re older average. Furthermore, maybe logic, cigarette smoking low mortality rate cigarette smokers younger average. Note, using DAG notation, simply means following DAG:\\(D\\) smoking, \\(Y\\) mortality, \\(\\) age smoker. Insofar CIA violated, backdoor path open, also means omitted variable bias. however want describe , common thing distribution age group different—mean covariate imbalance. first strategy addressing problem covariate imbalance condition age way distribution age comparable treatment control groups.77So subclassification achieve covariate balance? first step divide age strata: say, 20–40, 41–70, 71 older. can calculate mortality rate treatment group (cigarette smokers) strata (, age). Next, weight mortality rate treatment group strata-specific (age-specific) weight corresponds control group. gives us age-adjusted mortality rate treatment group. Let’s explain example looking Table 5.3. Assume age relevant confounder cigarette smoking mortality.78Table 5.3:  Subclassification example.average death rate pipe smokers without subclassification? weighted average mortality rate column weight equal \\(\\dfrac{N_t}{N}\\), \\(N_t\\) \\(N\\) number people group total number people, respectively. \n\\[\n20 \\times \\dfrac{65}{100} + 40 \\times \\dfrac{25}{100} + 60 \\times \\dfrac{10}{100}=29.\n\\]\n, mortality rate smokers population 29 per 100,000.notice age distribution cigarette smokers exact opposite (construction) pipe cigar smokers. Thus age distribution imbalanced. Subclassification simply adjusts  mortality rate cigarette smokers age distribution comparison group. words, multiply age-specific mortality rate proportion individuals age strata comparison group. \n\\[\n20 \\times \\dfrac{10}{100} + 40 \\times \\dfrac{25}{100} + 60 \\times \\dfrac{65}{100}=51\n\\]\n, adjust age distribution, age-adjusted mortality rate cigarette smokers (age distribution pipe cigar smokers) 51 per 100,000—almost twice large got taking simple naı̈ve calculation unadjusted age confounder.Cochran uses version subclassification method paper recalculates mortality rates three countries three smoking groups (see Table 5.4). can seen, adjust age distribution, cigarette smokers highest death rates among group.Table 5.4:  Adjusted mortality rates using 3 age groups (Cochran 1968).kind adjustment raises question—variable(s) use adjustment? First, recall ’ve emphasized repeatedly. backdoor criterion CIA tell us precisely need . need choose set variables satisfy backdoor criterion. backdoor criterion met, backdoor paths closed, backdoor paths closed, CIA achieved. call variable covariate. covariate usually random variable assigned individual units prior treatment. sometimes also called exogenous. Harkening back DAG chapter, variable must collider well. variable exogenous respect \\(D\\) value \\(X\\) depend value \\(D\\). Oftentimes, though always necessarily, variable time-invariant, race. Thus, trying adjust confounder using subclassification, rely credible DAG help guide selection variables. Remember—goal meet backdoor criterion.","code":""},{"path":"ch4.html","id":"identifying-assumptions","chapter":"5 Matching and Subclassification","heading":"5.1.2 Identifying assumptions","text":"Let now formalize ’ve learned. order estimate causal effect confounder, need (1) CIA (2) probability treatment 0 1 strata. formally,\\((Y^1,Y^0) \\perp \\!\\!\\! \\perp D\\mid X\\) (conditional independence)\\((Y^1,Y^0) \\perp \\!\\!\\! \\perp D\\mid X\\) (conditional independence)\\(0<Pr(D=1 \\mid X) <1\\) probability one (common support)\\(0<Pr(D=1 \\mid X) <1\\) probability one (common support)two assumptions yield following identity\\[\\begin{align}\n   E\\big[Y^1-Y^0\\mid X\\big] & = E\\big[Y^1 - Y^0 \\mid X,D=1\\big]                     \n   \\\\\n            & = E\\big[Y^1\\mid X,D=1\\big] - E\\big[Y^0\\mid X,D=0\\big] \n   \\\\\n            & = E\\big[Y\\mid X,D=1\\big] - E\\big[Y\\mid X,D=0\\big]     \n\\end{align}\\]value \\(Y\\) determined switching equation. Given common support, get following estimator:\\[\\begin{align}\n   \\widehat{\\delta_{ATE}}= \\int \\Big(E\\big[Y\\mid X,D=1\\big] - E\\big[Y\\mid X,D=0\\big]\\Big)d\\Pr(X)\n\\end{align}\\]Whereas need treatment conditionally independent potential outcomes identify ATE, need treatment conditionally independent \\(Y^0\\) identify ATT fact exist units control group treatment strata. Note, reason common support assumption weighting data; without common support, calculate relevant weights.","code":""},{"path":"ch4.html","id":"subclassification-exercise-titanic-mathrmdata-set","chapter":"5 Matching and Subclassification","heading":"5.1.3 Subclassification exercise: Titanic \\(\\mathrm{data\\ set}\\)","text":"going next, find useful move actual data. use interesting data set help us better understand subclassification. everyone knows, Titanic ocean cruiser hit iceberg sank maiden voyage. Slightly 700 passengers crew survived 2,200 people board. horrible disaster. One things notable, though, role wealth norms played passengers’ survival.Imagine wanted know whether seated first class made someone likely survive. Given cruiser contained variety levels seating wealth highly concentrated upper decks, ’s easy see wealth might leg survival. problem women children explicitly given priority boarding scarce lifeboats. women children likely seated first class, maybe differences survival first class simply picking effect social norm. Perhaps DAG might help us , DAG can help us outline sufficient conditions identifying causal effect first class survival.Now commence, let’s review DAG telling us. says female made likely first class also made likely survive lifeboats likely allocated women. Furthermore, child made likely first class made likely survive. Finally, confounders, observed unobserved.79Here one direct path (causal effect) first class (\\(D\\)) survival (\\(Y\\)) ’s \\(D \\rightarrow Y\\). , two backdoor paths. One travels variable Child (C): \\(D \\leftarrow C \\rightarrow Y\\); travels variable Woman (W): \\(D \\leftarrow W \\rightarrow Y\\). Fortunately us, data includes age gender, possible close backdoor path therefore satisfy backdoor criterion. use subclassification , , let’s calculate naı̈ve simple difference outcomes (SDO), just\n\\[\nE\\big[Y\\mid D=1\\big] - E\\big[Y\\mid D=0\\big]\n\\]\nsample.titanic.dotitanic.RUsing data set Titanic, calculate simple difference mean outcomes (SDO), finds seated first class raised probability survival 35.4%. note, since adjust observable confounders age gender, biased estimate ATE. next use subclassification weighting control confounders. steps entail:Stratify data four groups: young males, young females, old males, old females.Stratify data four groups: young males, young females, old males, old females.Calculate difference survival probabilities group.Calculate difference survival probabilities group.Calculate number people non-first-class groups divide total number non-first-class population. strata-specific weights.Calculate number people non-first-class groups divide total number non-first-class population. strata-specific weights.Calculate weighted average survival rate using strata weights.Calculate weighted average survival rate using strata weights.Let’s review code can better understand four steps actually entail.titanic_subclassification.dotitanic_subclassification.RHere find condition confounders gender age, first-class seating much lower probability survival associated (though frankly, still large). weighted ATE 16.1%, versus SDO, 35.4%.","code":"use https://github.com/scunning1975/mixtape/raw/master/titanic.dta, clear\ngen female=(sex==0)\nlabel variable female \"Female\"\ngen male=(sex==1)\nlabel variable male \"Male\"\ngen     s=1 if (female==1 & age==1)\nreplace s=2 if (female==1 & age==0)\nreplace s=3 if (female==0 & age==1)\nreplace s=4 if (female==0 & age==0)\ngen     d=1 if class==1\nreplace d=0 if class!=1\nsummarize survived if d==1\ngen ey1=r(mean)\nsummarize survived if d==0\ngen ey0=r(mean)\ngen sdo=ey1-ey0\nsu sdo\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntitanic <- read_data(\"titanic.dta\") %>% \n  mutate(d = case_when(class == 1 ~ 1, TRUE ~ 0))\n\ney1 <- titanic %>% \n  filter(d == 1) %>%\n  pull(survived) %>% \n  mean()\n\ney0 <- titanic %>% \n  filter(d == 0) %>%\n  pull(survived) %>% \n  mean()\n\nsdo <- ey1 - ey0* Subclassification\ncap n drop ey1 ey0\nsu survived if s==1 & d==1\ngen ey11=r(mean)\nlabel variable ey11 \"Average survival for male child in treatment\"\nsu survived if s==1 & d==0\ngen ey10=r(mean)\nlabel variable ey10 \"Average survival for male child in control\"\ngen diff1=ey11-ey10\nlabel variable diff1 \"Difference in survival for male children\"\nsu survived if s==2 & d==1\ngen ey21=r(mean)\nsu survived if s==2 & d==0\ngen ey20=r(mean)\ngen diff2=ey21-ey20\nsu survived if s==3 & d==1\ngen ey31=r(mean)\nsu survived if s==3 & d==0\ngen ey30=r(mean)\ngen diff3=ey31-ey30\nsu survived if s==4 & d==1\ngen ey41=r(mean)\nsu survived if s==4 & d==0\ngen ey40=r(mean)\ngen diff4=ey41-ey40\ncount if s==1 & d==0\ncount if s==2 & d==0\ncount if s==3 & d==0\ncount if s==4 & d==0\ncount\ngen wt1=425/2201\ngen wt2=45/2201\ngen wt3=1667/2201\ngen wt4=64/2201\ngen wate=diff1*wt1 + diff2*wt2 + diff3*wt3 + diff4*wt4\nsum wate sdo\nlibrary(stargazer)\nlibrary(magrittr) # for %$% pipes\nlibrary(tidyverse)\nlibrary(haven)\n\ntitanic <- read_data(\"titanic.dta\") %>% \n  mutate(d = case_when(class == 1 ~ 1, TRUE ~ 0))\n\n\ntitanic %<>%\n  mutate(s = case_when(sex == 0 & age == 1 ~ 1,\n                       sex == 0 & age == 0 ~ 2,\n                       sex == 1 & age == 1 ~ 3,\n                       sex == 1 & age == 0 ~ 4,\n                       TRUE ~ 0))\n\ney11 <- titanic %>% \n  filter(s == 1 & d == 1) %$%\n  mean(survived)\n\ney10 <- titanic %>% \n  filter(s == 1 & d == 0) %$%\n  mean(survived)\n\ney21 <- titanic %>% \n  filter(s == 2 & d == 1) %$%\n  mean(survived)\n\ney20 <- titanic %>% \n  filter(s == 2 & d == 0) %$%\n  mean(survived)\n\ney31 <- titanic %>% \n  filter(s == 3 & d == 1) %$%\n  mean(survived)\n\ney30 <- titanic %>% \n  filter(s == 3 & d == 0) %$%\n  mean(survived)\n\ney41 <- titanic %>% \n  filter(s == 4 & d == 1) %$%\n  mean(survived)\n\ney40 <- titanic %>% \n  filter(s == 4 & d == 0) %$%\n  mean(survived)\n\ndiff1 = ey11 - ey10\ndiff2 = ey21 - ey20\ndiff3 = ey31 - ey30\ndiff4 = ey41 - ey40\n\nobs = nrow(titanic)\n\nwt1 <- titanic %>% \n  filter(s == 1 & d == 0) %$%\n  nrow(.)/obs\n\nwt2 <- titanic %>% \n  filter(s == 2 & d == 0) %$%\n  nrow(.)/obs\n\nwt3 <- titanic %>% \n  filter(s == 3 & d == 0) %$%\n  nrow(.)/obs\n\nwt4 <- titanic %>% \n  filter(s == 4 & d == 0) %$%\n  nrow(.)/obs\n\nwate = diff1*wt1 + diff2*wt2 + diff3*wt3 + diff4*wt4\n\nstargazer(wate, sdo, type = \"text\")"},{"path":"ch4.html","id":"curse-of-dimensionality","chapter":"5 Matching and Subclassification","heading":"5.1.4 Curse of dimensionality","text":"’ve assuming two covariates, two possible set values. convenience. data set, instance, came us two possible values age—child adult. come us multiple values age, like specific age? condition individual age gender, ’s entirely likely information necessary calculate differences within strata, therefore unable calculate strata-specific weights need subclassification.next part, let’s assume precise data Titanic survivor ages. get incredibly laborious, let’s just focus .Table 5.5:  Subclassification example Titanic survival large \\(K\\)see example common support assumption violated. common support assumption requires strata, exist observations treatment control group, can see, 12-year-old male passengers first class. 14-year-old male passengers first class. every combination age gender, find problem quite common. Thus, estimate ATE using subclassification. problem stratifying variable many dimensions, result, sparseness cells sample small.let’s say problem always treatment group, control group. , let’s assume always someone control group given combination gender age, isn’t always treatment group. can calculate ATT. see table, two strata, 11-year-olds 13-year-olds, treatment control group values calculation. long exist controls given treatment strata, can calculate ATT. equation can compactly written :\\[\n\\widehat{\\delta}_{ATT} = \\sum_{k=1}^K\\Big(\\overline{Y}^{1,k} - \\overline{Y}^{0,k}\\Big)\\times \\bigg( \\dfrac{N^k_T}{N_T} \\bigg )\n\\]’ve seen problem arises subclassification—finite sample, subclassification becomes less feasible number covariates grows, \\(K\\) grows, data becomes sparse. likely caused sample small relative size covariate matrix. point missing values, words, \\(K\\) categories. Imagine tried add third strata, say, race (black white). ’d two age categories, two gender categories, two race categories, giving us eight possibilities. small sample, probably end many cells missing information. called curse dimensionality. sparseness occurs, means many cells may contain either treatment units control units, . happens, can’t use subclassification, common support. therefore left searching alternative method satisfy backdoor criterion.","code":""},{"path":"ch4.html","id":"exact-matching","chapter":"5 Matching and Subclassification","heading":"5.2 Exact Matching","text":"Subclassification uses difference treatment control group units achieves covariate balance using \\(K\\) probability weights weight averages. ’s simple method, aforementioned problem curse dimensionality. probably, ’s going issue research undertake may merely one variable ’re worried several—case, ’ll already running curse. thing emphasize subclassification method using raw data, weighting achieve balance. weighting differences, summing weighted differences.alternative approaches. instance, estimated \\(\\widehat{\\delta}_{ATT}\\) imputing missing potential outcomes conditioning confounding, observed covariate? Specifically, filled missing potential outcome treatment unit using control group unit “closest” treatment group unit \\(X\\) confounder? give us estimates counterfactuals simply take average differences. show, also achieve covariate balance. method called matching.two broad types matching consider: exact matching approximate matching. first start describing exact matching. Much going discussing based Abadie Imbens (2006).simple matching estimator following:\\[\n\\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1}(Y_i - Y_{j()})\n\\]\\(Y_{j()}\\) \\(j\\)th unit matched \\(\\)th unit based \\(j\\)th “closest ” \\(\\)th unit \\(X\\) covariate. instance, let’s say unit treatment group covariate value 2 find another unit control group (exactly one unit) covariate value 2. impute treatment unit’s missing counterfactual matched unit’s, take difference., ’s one variable “closest ” \\(\\)th unit? instance, say \\(\\)th unit covariate value 2 find two \\(j\\) units value 2. can ? Well, one option simply take average two units’ \\(Y\\) outcome value. found 3 close units? found 4? . However many matches \\(M\\) find, assign average outcome \\(\\left(\\dfrac{1}{M} \\right)\\) counterfactual treatment group unit.Notationally, can describe estimator \\[\n   \\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} \\bigg ( Y_i - \\bigg [\\dfrac{1}{M} \\sum_{m=1}^M Y_{j_m(1)} \\bigg ] \\bigg )\n\\]estimator really isn’t different one just ; main difference one averages several close matches opposed just picking one. approach works well can find number good matches treatment group unit. usually define \\(M\\) small, like \\(M=2\\). M greater 2, may simply randomly select two units average outcomes .ATT estimators. can tell \\(\\widehat{\\delta}_{ATT}\\) estimators summing treatment group.80 can also estimate ATE. note, estimating ATE, filling missing control group units like missing treatment group units. observation \\(\\) treated, words, need fill missing \\(Y^0_i\\) using control matches, observation \\(\\) control group unit, need fill missing \\(Y^1_i\\) using treatment group matches. estimator . looks scarier really . ’s actually compact, nicely-written-estimator equation.\\[\n   \\widehat{\\delta}_{ATE} = \\dfrac{1}{N} \\sum_{=1}^N (2D_i - 1) \\bigg [ Y_i - \\bigg ( \\dfrac{1}{M} \\sum_{m=1}^M Y_{j_m()} \\bigg ) \\bigg ]\n\\]\\(2D_i-1\\) nice little trick. \\(D_i=1\\), leading term becomes \\(1\\).81 \\(D_i=0\\), leading term becomes negative 1, outcomes reverse order treatment observation can imputed. Nice little mathematical form!Let’s see work action working example. Table 5.6 shows two samples: list participants job trainings program list non-participants, non-trainees. left-hand group treatment group right-hand group control group. matching algorithm defined earlier create third group called matched sample, consisting treatment group unit’s matched counterfactual. match age participant.Table 5.6:  Training example exact matchingBefore , though, want show ages trainees differ average ages non-trainees. can see Table 5.6—average age participants 24.3 years, average age non-participants 31.95 years. Thus, people control group older, since wages typically rise age, may suspect part reason average earnings higher ($11,075 vs. $11,101) control group older. say two groups exchangeable covariate balanced. Let’s look age distribution. illustrate , need download data first. create two histograms—distribution age treatment non-trainee group—well summarize earnings group. information also displayed Figure 5.1.training_example.dotraining_example.R\nFigure 5.1: Covariate distribution job trainings control.\ncan see Figure 5.1, two populations different means (Table 5.6); entire distribution age across samples different. let’s use matching algorithm create missing counterfactuals treatment group unit. method, since imputes missing units treatment unit, yield estimate \\(\\widehat{\\delta}_{ATT}\\).Table 5.7:  Training example exact matching (including matched sample)Now let’s move creating matched sample. exact matching, distance traveled nearest neighbor zero integers. won’t always case, note control group sample size grows, likelihood find unit covariate value one treatment group grows. ’ve created data set like . first treatment unit age 18. Searching non-trainees, find exactly one person age 18, ’s unit 14. move age earnings information new matched sample columns.continue units, always moving control group unit closest value \\(X\\) fill missing counterfactual treatment unit. run situation ’s one control group unit “close,” simply average . instance, two units non-trainees group age 30, ’s 10 18. averaged earnings matched average earnings unit 10. filled Table 5.7.Now see mean age groups. can also check overall age distribution (Figure 5.2). can see, two groups exactly balanced age. might say two groups exchangeable. difference earnings treatment group control group $1,695. , estimate causal effect program $1,695 higher earnings.\nFigure 5.2: Covariate distribution job trainings matched sample.\nLet’s summarize ’ve learned. ’ve using lot different terms, drawn different authors different statistical traditions, ’d like map onto one another. two groups different ways likely direction function potential outcomes. means independence assumption violated. Assuming treatment assignment conditionally random, matching \\(X\\) created exchangeable set observations—matched sample—characterized matched sample balance.","code":"use https://github.com/scunning1975/mixtape/raw/master/training_example.dta, clear\nhistogram age_treat, bin(10) frequency\nhistogram age_control, bin(10) frequency\nsu age_treat age_control\nsu earnings_treat earnings_control\n\nhistogram age_treat, bin(10) frequency\nhistogram age_matched, bin(10) frequency\nsu age_treat age_control\nsu earnings_matched earnings_matched\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_example <- read_data(\"training_example.dta\") %>% \n  slice(1:20)\n\nggplot(training_example, aes(x=age_treat)) +\n  stat_bin(bins = 10, na.rm = TRUE)\n\nggplot(training_example, aes(x=age_control)) +\n  geom_histogram(bins = 10, na.rm = TRUE)"},{"path":"ch4.html","id":"approximate-matching","chapter":"5 Matching and Subclassification","heading":"5.3 Approximate Matching","text":"previous example matching relatively simple—find unit collection units value covariate \\(X\\) substitute outcomes unit \\(j\\)’s counterfactuals. ’ve done , average differences estimate ATE.couldn’t find another unit exact value? ’re world approximate matching.","code":""},{"path":"ch4.html","id":"nearest-neighbor-covariate-matching","chapter":"5 Matching and Subclassification","heading":"5.3.1 Nearest neighbor covariate matching","text":"One instances exact matching can break number covariates, \\(K\\), grows large. match one variable using sub-classification approach, one first things confront concept distance. mean one unit’s covariate “close” someone else’s? Furthermore, mean multiple covariates measurements multiple dimensions?Matching single covariate straightforward distance measured terms covariate’s values. instance, distance age simply close years months days one person another person. several covariates needed matching? Say, age log income. 1-point change age different 1-point change log income, mention now measuring distance two, one, dimensions. number matching covariates one, need new definition distance measure closeness. begin simplest measure distance, Euclidean distance:\\[\\begin{align}\n   ||X_i-X_j|| & = \\sqrt{ (X_i-X_j)'(X_i-X_j) }             \n   \\\\\n            & = \\sqrt{\\sum_{n=1}^k (X_{ni} - X_{nj})^2 } \n\\end{align}\\]problem measure distance distance measure depends scale variables . reason, researchers typically use modification Euclidean distance, normalized Euclidean distance, ’ll use wholly different alternative distance. normalized Euclidean distance commonly used distance, makes different distance variable scaled variable’s variance. distance measured :\n\\[\n||X_i-X_j||=\\sqrt{(X_i-X_j)'\\widehat{V}^{-1}(X_i-X_j)}\n\\]\n\n\\[\n\\widehat{V}^{-1} =\n   \\begin{pmatrix}\n       \\widehat{\\sigma}_1^2 & 0 & \\dots  & 0                    \\\\\n       0    & \\widehat{\\sigma}_2^2 & \\dots  & 0                    \\\\\n       \\vdots           & \\vdots            & \\ddots & \\vdots               \\\\\n       0    & 0 & \\dots  & \\widehat{\\sigma}_k^2 \\\\\n   \\end{pmatrix}\n\\]\nNotice normalized Euclidean distance equal :\n\\[\n||X_i - X_j|| = \\sqrt{\\sum_{n=1}^k \\dfrac{(X_{ni} - X_{nj})}{\\widehat{\\sigma}^2_n}}\n\\]\nThus, changes scale \\(X\\), changes also affect variance, normalized Euclidean distance change.Finally, Mahalanobis distance, like normalized Euclidean distance measure, scale-invariant distance metric. :\n\\[\n||X_i-X_j||=\\sqrt{ (X_i-X_j)'\\widehat{\\Sigma}_X^{-1}(X_i - X_j) }\n\\]\n\\(\\widehat{\\Sigma}_X\\) sample variance-covariance matrix \\(X\\).Basically, one covariate creates lot headaches. create curse--dimensionality problem; also makes measuring distance harder. creates challenges finding good match data. can see distance formulas, sometimes going matching discrepancies. Sometimes \\(X_i\\neq X_j\\). mean? means unit \\(\\) matched unit \\(j\\) basis similar covariate value \\(X=x\\). Maybe unit \\(\\) age 25, unit \\(j\\) age 26. difference 1. Sometimes discrepancies small, sometimes zero, sometimes large. , move away zero, become problematic estimation introduce bias.severe bias? First, good news. know matching discrepancies tend converge zero sample size increases—one main reasons approximate matching data greedy. demands large sample size matching discrepancies trivially small. many covariates? covariates, longer takes convergence zero occur. Basically, ’s hard find good matches \\(X\\) large dimension, need lot observations result. larger dimension, greater likelihood matching discrepancies, data need. can take bank—likely, matching problem requires large data set order minimize matching discrepancies.","code":""},{"path":"ch4.html","id":"bias-correction","chapter":"5 Matching and Subclassification","heading":"5.3.2 Bias correction","text":"Speaking matching discrepancies, sorts options available us, putting aside seeking large data set lots controls? Well, enter stage left, Abadie Imbens (2011), introduced bias-correction techniques matching estimators matching discrepancies finite samples. let’s look closely, ’ll likely need work.Everything ’re getting suggesting matching biased poor matching discrepancies. let’s derive bias. First, write sample ATT estimate, subtract true ATT. :\n\\[\n\\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} (Y_i - Y_{j()})\n\\]\n\\(\\) \\(j()\\) units matched, \\(X_i \\approx X_{j()}\\) \\(D_{j()}=0\\). Next define conditional expection outcomes\\[\\begin{align}\n   \\mu^0(x) & = E\\big[Y\\mid X=x, D=0\\big] = E\\big[Y^0\\mid X=x\\big] \\\\\n   \\mu^1(x) & = E\\big[Y\\mid X=x, D=1\\big] = E\\big[Y^1\\mid X=x\\big] \n\\end{align}\\]Notice, just expected conditional outcome functions based switching equation control treatment groups.always, write observed value function expected conditional outcomes stochastic element:\\[\\begin{align}\n   Y_i = \\mu^{D_i}(X_i) + \\varepsilon_i\n\\end{align}\\]Now rewrite ATT estimator using \\(\\mu\\) terms:\\[\\begin{align}\n   \\widehat{\\delta}_{ATT}\n     & =\\dfrac{1}{N_T} \\sum_{D_i=1} \\big(\\mu^1(X_i) + \\varepsilon_i\\big) - \\big(\\mu^0(X_{j()}\\big) + \\varepsilon_{j()})                             \n   \\\\\n     & =\\dfrac{1}{N_T} \\sum_{D_i=1} \\big(\\mu^1(X_i) - \\mu^0(X_{j()})\\big) + \\dfrac{1}{N_T} \\sum_{D_i=1} \\big(\\varepsilon_i - \\varepsilon_{j()}\\big) \n\\end{align}\\]Notice, first line just ATT stochastic element included previous line. second line rearranges get two terms: estimated ATT plus average difference stochastic terms matched sample.Now compare estimator true value ATT.\n\\[\n\\widehat{\\delta}_{ATT} - \\delta_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} (\\mu^1(X_i) - \\mu^0(X_{j()}) - \\delta_{ATT}\n   + \\dfrac{1}{N_T} \\sum_{D_i=1}\\big(\\varepsilon_i - \\varepsilon_{j()}\\big)\n\\]\n, simple algebraic manipulation :\\[\\begin{align}\n   \\widehat{\\delta}_{ATT} - \\delta_{ATT}\n     & = \\dfrac{1}{N_T} \\sum_{D_i=1} \\left( \\mu^1(X_i) - {\\mu^0(X_i)} - \\delta_{ATT}\\right) \n   \\\\\n     & + \\dfrac{1}{N_T} \\sum_{D_i=1} (\\varepsilon_i - \\varepsilon_{j()})                   \n   \\\\\n     & + \\dfrac{1}{N_T} \\sum_{D_i=1} \\left( {\\mu^0(X_i)} - \\mu^0(X_{j()}) \\right).         \n\\end{align}\\]Applying central limit theorem difference, \\(\\sqrt{N_T}(\\widehat{\\delta}_{ATT} - \\delta_{ATT})\\) converges normal distribution zero mean. :\n\\[\nE\\Big[ \\sqrt{N_T} (\\widehat{\\delta}_{ATT} - \\delta_{ATT})\\Big] = E\\Big[ \\sqrt{N_T}(\\mu^0(X_i)-\\mu^0(X_{j()}) )\\mid D=1\\Big].\n\\]\nNow consider implications number covariates large. First, difference \\(X_i\\) \\(X_{j()}\\) converges zero slowly. therefore makes difference \\(\\mu^0(X_i) - \\mu(X_{j()})\\) converge zero slowly. Third, \\(E[ \\sqrt{N_T} (\\mu^0(X_i) - \\mu^0(X_{j()}))\\mid D=1]\\) may converge zero. fourth, \\(E[ \\sqrt{N_T} (\\widehat{\\delta}_{ATT} - \\delta_{ATT})]\\) may converge zero.can see, bias matching estimator can severe depending magnitude matching discrepancies. However, one piece good news discrepancies observed. can see degree unit’s matched sample severe mismatch covariates . Second, can always make matching discrepancy small using large donor pool untreated units select matches, recall, likelihood finding good match grows function sample size, content estimating ATT, increasing size donor pool can get us mess. let’s say can’t matching discrepancies large. can apply bias-correction methods minimize size bias. let’s see bias-correction method looks like. based Abadie Imbens (2011).Note total bias made bias associated individual unit \\(\\). Thus, treated observation contributes \\(\\mu^0(X_i) - \\mu^0(X_{j()})\\) overall bias. bias-corrected matching following estimator:\\[\\begin{align}\n   \\widehat{\\delta}_{ATT}^{BC} = \\dfrac{1}{N_T} \\sum_{D_i=1} \\bigg [ (Y_i - Y_{j()}) - \\Big(\\widehat{\\mu}^0(X_i) - \\widehat{\\mu}^0(X_{j()})\\Big) \\bigg ]\n\\end{align}\\]\\(\\widehat{\\mu}^0(X)\\) estimate \\(E[Y\\mid X=x,D=0]\\) using, example, OLS. , find always helpful take crack estimators concrete data. Table 5.8 contains make-believe data eight units, four treated rest functioning controls. According switching equation, observe actual outcomes associated potential outcomes treatment control, means ’re missing control values treatment group.Table 5.8:  Another matching example (time illustrate bias correction)Notice example implement exact matching none treatment group units exact match control group. ’s worth emphasizing consequence finite samples; likelihood finding exact match grows sample size control group grows faster treatment group. Instead, use nearest-neighbor matching, simply going match treatment unit control group unit whose covariate value nearest treatment group unit . , kind matching, necessarily create matching discrepancies, simply another way saying covariates perfectly matched every unit. Nonetheless, nearest-neighbor “algorithm” creates Table 5.9.Recall \n\\[\n\\widehat{\\delta}_{ATT} - \\dfrac{5-4}{4} + \\dfrac{2-0}{4} + \\dfrac{10-5}{4}+\\dfrac{6-1}{4}=3.25\n\\]\nbias correction, need estimate \\(\\widehat{\\mu}^0(X)\\). ’ll use OLS. clearer \\(\\widehat{\\mu}^0(X)\\) . fitted values regression \\(Y\\) \\(X\\). Let’s illustrate using data set shown Table 5.9.Table 5.9:  Nearest neighbor matched sampletraining_bias_reduction.dotraining_bias_reduction.RWhen regress \\(Y\\) onto \\(X\\) \\(D\\), get following estimated coefficients:\\[\\begin{align}\n   \\widehat{\\mu}^0(X) & =\\widehat{\\beta}_0 + \\widehat{\\beta}_1 X \n   \\\\\n    & = 4.42 - 0.049 X                         \n\\end{align}\\]gives us outcomes, treatment status, predicted values Table 5.10.Table 5.10:  Nearest neighbor matched sample fitted values bias correctionAnd done three simple differences, added bias-correction term based fitted values covariate values.Now, care must given using fitted values bias correction, let walk . still going taking simple differences (e.g., 5 – 4 row 1), now also subtract fitted values associated observation’s unique covariate. instance, row 1, outcome 5 covariate 11, gives fitted value 3.89, counterfactual value 10, gives predicted value 3.94. therefore use following bias correction:\n\\[\n\\widehat{\\delta}_{ATT}^{BC} = \\dfrac{ 5-4 - (3.89 - 3.94)}{4} + \\dots\n\\]\nNow see specific fitted value calculated contributes calculation ATT, let’s look entire calculation now.\\[\\begin{align}\n   \\widehat{\\delta}_{ATT}^{BC}\n     & = \\dfrac{ (5-4) - \\Big( \\widehat{\\mu^0}(11) - \\widehat{\\mu^0}(10)\\Big) }{4} + \\dfrac{ (2-0) -\\Big( \\widehat{\\mu^0}(7) - \\widehat{\\mu^0}(8)\\Big) }{4}     \n   \\\\\n     & \\quad+\\ \\dfrac{ (10-5) - \\Big( \\widehat{\\mu^0}(5) - \\widehat{\\mu^0}(4)\\Big)}{4} + \\dfrac{ (6-1) - \\Big( \\widehat{\\mu^0}(3) - \\widehat{\\mu^0}(1)\\Big)}{4} \n   \\\\\n     & = 3.28                                                                                                                                                   \n\\end{align}\\]slightly higher unadjusted ATE 3.25. Note bias-correction adjustment becomes significant matching discrepancies become common. , matching discrepancies common first place, definition, bias adjustment doesn’t change estimated parameter much.Bias arises effect large matching discrepancies. minimize discrepancies, need small number \\(M\\) (e.g., \\(M=1\\)). Larger values \\(M\\) produce large matching discrepancies. Second, need matching replacement. matching replacement can use untreated units match , matching replacement produces smaller discrepancies. finally, try match covariates large effect \\(\\mu^0(.)\\).matching estimators normal distribution large samples provided bias small. matching without replacement, usual variance estimator valid. :\\[\\begin{align}\n   \\widehat{\\sigma}^2_{ATT} = \\dfrac{1}{N_T} \\sum_{D_i=1} \\bigg ( Y_i - \\dfrac{1}{M} \\sum_{m=1}^M Y_{j_m()} - \\widehat{\\delta}_{ATT} \\bigg )^2\n\\end{align}\\]matching replacement:\\[\\begin{align}\n   \\widehat{\\sigma}^2_{ATT}\n     & = \\dfrac{1}{N_T} \\sum_{D_i=1} \\left( Y_i - \\dfrac{1}{M} \\sum_{m=1}^M Y_{j_m()} - \\widehat{\\delta}_{ATT} \\right)^2 \n   \\\\\n     & + \\dfrac{1}{N_T} \\sum_{D_i=0} \\left( \\dfrac{K_i(K_i-1)}{M^2} \\right) \\widehat{\\mathop{\\mathrm{var}}}(\\varepsilon\\mid X_i,D_i=0)     \n\\end{align}\\]\\(K_i\\) number times observation \\(\\) used match. \\(\\widehat{\\mathop{\\mathrm{var}}}(Y_i\\mid X_i, D_i=0)\\) can estimated matching. example, take two observations \\(D_i=D_j=0\\) \\(X_i \\approx X_j\\):\n\\[\n\\widehat{\\mathop{\\mathrm{var}}}(Y_i\\mid X_i,D_i=0) = \\dfrac{(Y_i-Y_j)^2}{2}\n\\]\nunbiased estimator \\(\\widehat{\\mathop{\\mathrm{var}}}(\\varepsilon_i\\mid X_i, D_i = 0)\\). bootstrap, though, doesn’t create valid standard errors (Abadie Imbens 2008).Buy print version today:","code":"use https://github.com/scunning1975/mixtape/raw/master/training_bias_reduction.dta, clear\nreg Y X\ngen muhat = _b[_cons] + _b[X]*X\nlist\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntraining_bias_reduction <- read_data(\"training_bias_reduction.dta\") %>% \n  mutate(\n    Y1 = case_when(Unit %in% c(1,2,3,4) ~ Y),\n    Y0 = c(4,0,5,1,4,0,5,1))\n\ntrain_reg <- lm(Y ~ X, training_bias_reduction)\n\ntraining_bias_reduction <- training_bias_reduction %>% \n  mutate(u_hat0 = predict(train_reg))"},{"path":"ch4.html","id":"propensity-score-methods","chapter":"5 Matching and Subclassification","heading":"5.3.3 Propensity score methods","text":"several ways achieving conditioning strategy implied backdoor criterion, ’ve discussed several. one popular one developed Donald Rubin mid-1970s early 1980s called propensity score method (Rubin 1977; Rosenbaum Rubin 1983). propensity score similar many respects nearest-neighbor covariate matching Abadie Imbens (2006) subclassification. ’s popular method, particularly medical sciences, addressing selection observables, gained use among economists well (Dehejia Wahba 2002).dig , though, couple words help manage expectations. Despite early excitement caused Dehejia Wahba (2002), subsequent enthusiasm tempered (Smith Todd 2001, 2005; King Nielsen 2019). , propensity score matching seen wide adoption among economists nonexperimental methods like regression discontinuity difference--differences. common reason given economists oftentimes skeptical CIA can achieved data set—almost article faith. many applications, economists group usually concerned selection unobservables selection observables, , reach matching methods less often. agnostic whether CIA holds doesn’t hold particular application. ’s theoretical reason dismiss procedure designed estimate causal effects ad hoc principle one holds hunch. prior knowledge deep familiarity institutional details application can tell appropriate identification strategy , insofar backdoor criterion can met, matching methods may perfectly appropriate. , matching inappropriate. , naı̈ve multivariate regression cases.’ve mentioned propensity score matching application used conditioning strategy can satisfy backdoor criterion. exactly implemented? Propensity score matching takes necessary covariates, estimates maximum likelihood model conditional probability treatment (usually logit probit ensure fitted values bounded 0 1), uses predicted values estimation collapse covariates single scalar called propensity score. comparisons treatment control group based value.subtlety propensity score practice, though. Consider scenario: two units, B, assigned treatment control, respectively. propensity score 0.6. Thus, 60% conditional probability assigned treatment, random chance, assigned treatment B assigned control. idea propensity score methods compare units , based observables, similar probabilities placed treatment group even though units differed regard actual treatment assignment. conditional \\(X\\), two units probability treated, say similar propensity scores, remaining variation treatment assignment due chance. insofar two units B propensity score 0.6, one treatment group one , conditional independence assumption credibly holds data, differences observed outcomes attributable treatment.Implicit example, though, see another assumption needed procedure, ’s common support assumption. Common support simply requires units treatment control group across estimated propensity score. common support 0.6 unit treatment group () one control group (B) 0.6. ways connected , propensity score can used check covariate balance treatment group control group two groups become observationally equivalent. walking example using real data, let’s review papers use .82","code":""},{"path":"ch4.html","id":"example-the-nsw-job-training-program","chapter":"5 Matching and Subclassification","heading":"5.3.4 Example: The NSW job training program","text":"National Supported Work Demonstration (NSW) job-training program operated Manpower Demonstration Research Corp (MRDC) mid-1970s. NSW temporary employment program designed help disadvantaged workers lacking basic job skills move labor market giving work experience counseling sheltered environment. also unique randomly assigned qualified applicants training positions. treatment group received benefits NSW program. controls basically left fend . program admitted women receiving Aid Families Dependent Children, recovering addicts, released offenders, men women sexes completed high school.Treatment group members guaranteed job nine eighteen months depending target group site. divided crews three five participants worked together met frequently NSW counselor discuss grievances program performance. Finally, paid work. NSW offered trainees lower wages ’ve received regular job, allowed earnings increase satisfactory performance attendance. participants’ terms expired, forced find regular employment. kinds jobs varied within sites—gas-station attendants, worked printer shop—men women frequently performed different kinds work.MDRC collected earnings demographic information treatment control group baseline well every nine months thereafter. MDRC also conducted four post-baseline interviews. different sample sizes study study, can confusing.NSW randomized job-training program; therefore, independence assumption satisfied. calculating average treatment effects straightforward—’s simple difference means estimator discussed potential outcomes chapter.83\n\\[\n\\dfrac{1}{N_T} \\sum_{D_i=1} Y_i - \\dfrac{1}{N_C} \\sum_{D_i=0} Y_i \\approx E[Y^1 - Y^0] \\approx ATE\n\\]\ngood news MDRC, treatment group, treatment benefited workers.84 Treatment group participants’ real earnings post-treatment 1978 earnings control group approximately $900 (Lalonde 1986) $1,800 (Dehejia Wahba 2002), depending sample researcher used.Lalonde (1986) interesting study evaluating NSW program evaluating commonly used econometric methods time. evaluated econometric estimators’ performance trading experimental control group data data non-experimental control group drawn population US citizens. used three samples Current Population Survey (CPS) three samples Panel Survey Income Dynamics (PSID) non-experimental control group data, use just one . Non-experimental data , , typical situation economist finds . difference NSW randomized experiment, therefore know average treatment effect. Since know average treatment effect, can see well variety econometric models perform. NSW program increased earnings approximately \\(\\$900\\), find econometrics estimators good job, right?Lalonde (1986) reviewed number popular econometric methods used contemporaries PSID CPS samples nonexperimental comparison groups, results consistently horrible. estimates usually different magnitude, results almost always wrong sign! paper, pessimistic conclusion, influential policy circles led greater push experimental evaluations.85 can see results following tables Lalonde (1986). Table 5.11 shows effect treatment comparing treatment group experimental control group. baseline difference real earnings two groups negligible. treatment group made $39 control group pre-treatment period without controls $21 less multivariate regression model, neither statistically significant. post-treatment difference average earnings $798 $886.86Table 5.11:  Earnings Comparisons Estimated Training Effects NSW Male Participants Using Comparison Groups PSID CPS-SSATable 5.11 also shows results got used non-experimental data comparison group. report results using one sample PSID one CPS, although original paper used three . nearly every point estimate, effect negative. one exception difference--differences model positive, small, insignificant.stark difference move NSW control group either PSID CPS? reason selection bias:\n\\[\nE\\big[Y^0\\mid D=1\\big] \\neq E\\big[Y^0\\mid D=0\\big]\n\\]\nwords, ’s highly likely real earnings NSW participants much lower non-experimental control group’s earnings. recall decomposition simple difference means estimator, second form bias selection bias, \\(E[Y^0\\mid D=1] < E[Y^0\\mid D=0]\\), bias estimate ATE downward (e.g., estimates show negative effect).show shortly, violation independence also implies covariates unbalanced across propensity score—something call balancing property. Table 5.12 illustrates showing mean values covariate treatment control groups, control 15,992 observations CPS. can see, treatment group appears different average control group CPS sample along nearly every covariate listed. NSW participants black, Hispanic, younger, less likely married, likely degree less schooling, likely unemployed 1975, likely considerably lower earnings 1975. short, two groups exchangeable observables (likely exchangeable unobservables either).Table 5.12:  Completed matching example single covariateThe first paper reevaluate Lalonde (1986) using propensity score methods Dehejia Wahba (1999). interest twofold. First, wanted examine whether propensity score matching improvement estimating treatment effects using non-experimental data. second, wanted show diagnostic value propensity score matching. authors used non-experimental control group data sets CPS PSID Lalonde (1986) .Let’s walk , learned steps. First, authors estimated propensity score using maximum likelihood modeling. estimated propensity score, compared treatment units control units within intervals propensity score . process checking whether units treatment control intervals propensity score called checking common support.One easy way check common support plot number treatment control group observations separately across propensity score histogram. Dehejia Wahba (1999) using PSID CPS samples found overlap nearly nonexistent, ’ll focus CPS sample. overlap bad opted drop 12,611 observations control group propensity scores outside treatment group range. Also, large number observations low propensity scores, evidenced fact first bin contains 2,969 comparison units. “trimming” done, overlap improved, though still wasn’t great.learn things kind diagnostic, though. learn, one, selection bias observables probably extreme reason fact units treatment control given values propensity score. considerable bunching either end propensity score distribution, suggests units differ remarkably observables respect treatment variable . Trimming around extreme values way addressing employing traditional propensity score adjustment techniques.Table 5.13:  Estimated Training Effects using Propensity ScoresWith estimated propensity score hand, Dehejia Wahba (1999) estimated treatment effect real earnings 1978 using experimental treatment group compared non-experimental control group. treatment effect differs found Lalonde Dehejia Wahba (1999) used slightly different sample. Still, using sample, find NSW program caused earnings increase $1,672 $1,794 depending whether exogenous covariates included regression. estimates highly significant.first two columns labeled “unadjusted” “adjusted” represent OLS regressions without controls. Without controls, PSID CPS estimates extremely negative precise. , , selection bias severe respect NSW program. controls included, effects become positive imprecise PSID sample though almost significant 5% CPS. effect size half size true effect.Table 5.13 shows results using propensity score weighting matching.87 can seen, results considerable improvement Lalonde (1986). won’t review every treatment effect authors calculated, note positive similar magnitude found columns 1 2 using experimental data.Finally, authors examined balance covariates treatment group (NSW) various non-experimental (matched) samples Table 5.14. next section, explain expect covariate values balance along propensity score treatment control group trimming outlier propensity score units data. Table 5.14 shows sample means characteristics matched control sample versus experimental NSW sample (first row). Trimming propensity score, effect, helped balance sample. Covariates much closer mean value NSW sample trimming propensity score.Table 5.14:  Sample Means Characteristics Matched Control Samples\nStandard error difference means NSW sample given parentheses.\nPropensity score best explained using actual data. use data Dehejia Wahba (2002) following exercises. using propensity score methods estimating treatment effects, let’s calculate average treatment effect actual experiment. Using following code, calculate NSW job-training program caused real earnings 1978 increase $1,794.343.nsw_experimental.donsw_experimental.RNext want go several examples estimate average treatment effect variants average treatment effect treatment group average treatment effect untreated group. , rather using experimental control group original randomized experiment, use non-experimental control group Current Population Survey. important stress treatment group experimental group, control group now consists random sample Americans time period. Thus, control group suffers extreme selection bias since Americans function counterfactuals distressed group workers selected NSW program. following, append CPS data experimental data estimate propensity score using logit consistent Dehejia Wahba (2002).nsw_pscore.donsw_pscore.RThe propensity score fitted values logit model. Put differently, used estimated coefficients logit regression estimate conditional probability treatment, assuming probabilities based cumulative logistic distribution:\n\\[\n\\Pr\\big(D=1\\mid X\\big) = F(\\beta_0 + \\gamma \\text{Treat} + \\alpha X)\n\\]\n\\(F()=\\dfrac{e}{(1+e)}\\) \\(X\\) exogenous covariates including model.said earlier, propensity score used fitted values maximum likelihood regression calculate unit’s conditional probability treatment regardless actual treatment status. propensity score just predicted conditional probability treatment fitted value unit. advisable use maximum likelihood estimating propensity score fitted values range \\([0,1]\\). use linear probability model, linear probability models routinely create fitted values 0 1, true probabilities since \\(0\\leq p \\leq 1\\).definition propensity score selection probability conditional confounding variables; \\(p(X)=\\Pr(D=1\\mid X)\\). Recall said two identifying assumptions propensity score methods. first assumption CIA. , \\((Y^0,Y^1) \\perp \\!\\!\\! \\perp D\\mid X\\). testable, assumption based unobservable potential outcomes. second assumption called common support assumption. , \\(0<\\Pr(D=1\\mid X) < 1\\). simply means probability, must units treatment group control group. conditional independence assumption simply means backdoor criterion met data conditioning vector \\(X\\). , put another way, conditional \\(X\\), assignment units treatment good random.88Table 5.15:  Distribution propensity score treatment group.Table 5.16:  Distribution propensity score CPS Control group.Common support required calculate particular kind defined average treatment effect, without , just get kind weird weighted average treatment effect regions common support. reason “weird” average treatment effect doesn’t correspond interesting treatment effects policymaker needed. Common support requires value \\(X\\), positive probability treated untreated, \\(0<\\Pr(D_i=1\\mid X_i) < 1\\). implies probability receiving treatment every value vector \\(X\\) strictly within unit interval. Common support ensures sufficient overlap characteristics treated untreated units find adequate matches. Unlike CIA, common support requirement testable simply plotting histograms summarizing data. two ways: looking summary statistics looking histogram. Let’s start looking distribution table form looking histogram.mean value propensity score treatment group 0.43, mean CPS control group 0.007. 50th percentile treatment group 0.4, control group doesn’t reach high number 99th percentile. Let’s look distribution propensity score two groups using histogram now.\nFigure 5.3: Histogram propensity score treatment status.\ntwo simple diagnostic tests show going problem later use inverse probability weighting. probability treatment spread across units treatment group, large mass nearly zero propensity scores CPS. interpret ? means characteristics individuals treatment group rare CPS sample. surprising given strong negative selection treatment. individuals younger, less likely married, likely uneducated minority. lesson , two groups significantly different background characteristics, propensity scores grossly different distributions treatment status. discuss greater detail later.now, let’s look treatment parameter assumptions.\\[\\begin{align}\n   E[\\delta_i(X_i)] & =E\\big[Y_i^1 - Y_i^0\\mid X_i=x\\big]                     \\\\\n    & = E\\big[Y_i^1\\mid X_i=x\\big]-E\\big[Y_i^0\\mid X_i=x\\big] \n\\end{align}\\]conditional independence assumption allows us make following substitution,\n\\[\nE\\big[Y^1_i\\mid D_i = 1, X_i = x\\big] =\n   E\\big[Y_i\\mid D_i = 1, X_i = x\\big]\n\\]\nterm. Common support means can estimate terms. Therefore, assumptions:\n\\[\n\\delta = E[\\delta(X_i)]\n\\]\nassumptions get propensity score theorem, states CIA\n\\[\n(Y^1,Y^0) \\perp \\!\\!\\! \\perp D\\mid X\n\\]\nyields\n\\[\n(Y^1,Y^0) \\perp \\!\\!\\! \\perp D \\mid p(X)\n\\]\n\\(p(X) =\\Pr(D=1\\mid X)\\), propensity score. English, means order achieve independence, assuming CIA, condition propensity score. Conditioning propensity score enough independence treatment potential outcomes.extremely valuable theorem stratifying \\(X\\) tends run sparseness-related problems (.e., empty cells) finite samples even moderate number covariates. propensity scores just scalar. stratifying across probability going reduce dimensionality problem.proof propensity score theorem fairly straightforward, ’s just application law iterated expectations nested conditioning.89 can show probability individual receives treatment conditional potential outcomes propensity score function potential outcomes, proved independence potential outcomes treatment conditional \\(X\\). diving proof, first recognize \n\\[\n\\Pr\\big(D=1\\mid Y^0, Y^1, p(X)\\big)=E\\big[D\\mid Y^0, Y^1, p(X)\\big]\n\\]\n\\[\\begin{align}\n   E\\big[D\\mid Y^0, Y^1, p(X)\\big] & =1 \\times                                     \n   \\Pr\\big(D=1\\mid Y^0, Y^1, p(X)\\big)\n   \\\\\n    & +0 \\times \\Pr\\big(D=0\\mid Y^0, Y^1, p(X)\\big) \n\\end{align}\\]second term cancels ’s multiplied zero. formal proof follows:\\[\\begin{align}\n   \\Pr\\big(D=1\\mid Y^1,Y^0, p(X)\\big) & = \\underbrace{{E\\big[D\\mid Y^1, Y^0, p(X)\\big]}}_{\\text{See previous equation}}\n   \\\\\n        & =\\underbrace{{E}                                                                           \n   \\Big[E \\big[D\\mid Y^1,Y^0,p(X),X\\big] {\\mid Y^1,Y^0,p(X)\\Big]}}_{ \\text{LIE}}\n   \\\\\n        & =\\underbrace{{E} \\Big[E                                                                    \n   \\big[D\\mid Y^1,Y^0,X\\big] {\\mid Y^1,Y^0,p(X)\\Big]}}_{\\text{Given $X$, know $p(X)$}}\n   \\\\\n        & =\\underbrace{{E}                                                                           \n   \\Big[E \\big[D\\mid X\\big] {\\mid Y^1,Y^0,p(X)\\Big]}}_{ \\text{conditional independence}}\n   \\\\\n        & = \\underbrace{{E}                                                                          \n   \\Big[p(X) {\\mid Y^1, Y^0, p(X)\\Big]}}_{\\text{propensity score definition}}\n   \\\\\n        & = p(X)                                                                                     \n\\end{align}\\]Using similar argument, obtain:\\[\\begin{align}\n   \\Pr\\big(D=1\\mid p(X)\\big) & =                                                                             \n   \\underbrace{E\\big[D\\mid p(X) \\big]}_{\\text{Previous argument}}\n   \\\\\n            & =\\underbrace{E \\Big[E\\big[D\\mid X\\big]\\mid p(X)\\Big]}_{\\text{LIE}} \n   \\\\\n            & =\\underbrace{E\\big[p(X)\\mid p(X)\\mid]}_{\\text{definition}}        \n   \\\\\n            & = p(X)                                                                        \n\\end{align}\\]\\(\\Pr(D=1\\mid Y^1, Y^0, p(X)) = \\Pr(D=1\\mid p(X))\\) CIA.Like omitted variable bias formula regression, propensity score theorem says need control covariates determine likelihood unit receives treatment. also says something . technically says covariate need condition propensity score. information \\(X\\) matrix collapsed single number: propensity score.corollary propensity score theorem, therefore, states given CIA, can estimate average treatment effects weighting appropriately simple difference means.90Because propensity score function \\(X\\), know\\[\\begin{align}\n   \\Pr\\big(D=1\\mid X, p(X)\\big) & =\\Pr\\big(D=1\\mid X\\big) \n   \\\\\n    & = p(X)                  \n\\end{align}\\]Therefore, conditional propensity score, probability \\(D=1\\) depend \\(X\\) longer. , \\(D\\) \\(X\\) independent one another conditional propensity score, \n\\[\nD \\perp \\!\\!\\! \\perp\\mid p(X)\n\\]\nalso obtain balancing property propensity score:\n\\[\n\\Pr\\big(X \\mid| D=1, p(X)\\big)=\n   \\Pr\\big(X\\mid D=0, p(X)\\big)\n\\]\nstates conditional propensity score, distribution covariates treatment control group units. See following DAG:Notice exist two paths \\(X\\) \\(D\\). ’s direct path \\(X \\rightarrow p(X) \\rightarrow D\\), ’s backdoor path \\(X \\rightarrow Y \\leftarrow D\\). backdoor path blocked collider, systematic correlation \\(X\\) \\(D\\) . systematic correlation \\(X\\) \\(D\\) first directed path. , condition \\(p(X)\\), propensity score, notice \\(D\\) \\(X\\) statistically independent. implies \\(D \\perp \\!\\!\\! \\perp X \\mid p(X)\\), implies\n\\[\n\\Pr\\big(X \\mid D=1, \\widehat{p}(X\\big)=\n   \\Pr\\big(X\\mid D=0, \\widehat{p}(X)\\big)\n\\]\nsomething can directly test, note implication: conditional propensity score, treatment control average respect \\(X\\). words, propensity score theorem implies balanced observable covariates.91","code":"use https://github.com/scunning1975/mixtape/raw/master/nsw_mixtape.dta, clear\nsu re78 if treat\ngen y1 = r(mean)\nsu re78 if treat==0\ngen y0 = r(mean)\ngen ate = y1-y0\nsu ate\ndi 6349.144 - 4554.801\n* ATE is 1794.34 \ndrop if treat==0\ndrop y1 y0 ate\ncompress\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nnsw_dw <- read_data(\"nsw_mixtape.dta\")\n\nnsw_dw %>% \n  filter(treat == 1) %>% \n  summary(re78)\n\nmean1 <- nsw_dw %>% \n  filter(treat == 1) %>% \n  pull(re78) %>% \n  mean()\n\nnsw_dw$y1 <- mean1\n\nnsw_dw %>% \n  filter(treat == 0) %>% \n  summary(re78)\n\nmean0 <- nsw_dw %>% \n  filter(treat == 0) %>% \n  pull(re78) %>% \n  mean()\n\nnsw_dw$y0 <- mean0\n\nate <- unique(nsw_dw$y1 - nsw_dw$y0)\n\nnsw_dw <- nsw_dw %>% \n  filter(treat == 1) %>% \n  select(-y1, -y0)* Reload experimental group data\nuse https://github.com/scunning1975/mixtape/raw/master/nsw_mixtape.dta, clear\ndrop if treat==0\n\n* Now merge in the CPS controls from footnote 2 of Table 2 (Dehejia and Wahba 2002)\nappend using https://github.com/scunning1975/mixtape/raw/master/cps_mixtape.dta\ngen agesq=age*age\ngen agecube=age*age*age\ngen edusq=educ*edu\ngen u74 = 0 if re74!=.\nreplace u74 = 1 if re74==0\ngen u75 = 0 if re75!=.\nreplace u75 = 1 if re75==0\ngen interaction1 = educ*re74\ngen re74sq=re74^2\ngen re75sq=re75^2\ngen interaction2 = u74*hisp\n\n* Now estimate the propensity score\nlogit treat age agesq agecube educ edusq marr nodegree black hisp re74 re75 u74 u75 interaction1 \npredict pscore\n\n* Checking mean propensity scores for treatment and control groups\nsu pscore if treat==1, detail\nsu pscore if treat==0, detail\n\n* Now look at the propensity score distribution for treatment and control groups\nhistogram pscore, by(treat) binrescale\nlibrary(tidyverse)\nlibrary(haven)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nnsw_dw_cpscontrol <- read_data(\"cps_mixtape.dta\") %>% \n  bind_rows(nsw_dw) %>% \n  mutate(agesq = age^2,\n         agecube = age^3,\n         educsq = educ*educ,\n         u74 = case_when(re74 == 0 ~ 1, TRUE ~ 0),\n         u75 = case_when(re75 == 0 ~ 1, TRUE ~ 0),\n         interaction1 = educ*re74,\n         re74sq = re74^2,\n         re75sq = re75^2,\n         interaction2 = u74*hisp)\n\n# estimating\nlogit_nsw <- glm(treat ~ age + agesq + agecube + educ + educsq + \n                   marr + nodegree + black + hisp + re74 + re75 + u74 +\n                   u75 + interaction1, family = binomial(link = \"logit\"), \n                 data = nsw_dw_cpscontrol)\n\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(pscore = logit_nsw$fitted.values)\n\n# mean pscore \npscore_control <- nsw_dw_cpscontrol %>% \n  filter(treat == 0) %>% \n  pull(pscore) %>% \n  mean()\n\npscore_treated <- nsw_dw_cpscontrol %>% \n  filter(treat == 1) %>% \n  pull(pscore) %>% \n  mean()\n\n# histogram\nnsw_dw_cpscontrol %>% \n  filter(treat == 0) %>% \n  ggplot() +\n  geom_histogram(aes(x = pscore))\n\nnsw_dw_cpscontrol %>% \n  filter(treat == 1) %>% \n  ggplot() +\n  geom_histogram(aes(x = pscore))"},{"path":"ch4.html","id":"weighting-on-the-propensity-score","chapter":"5 Matching and Subclassification","heading":"5.3.5 Weighting on the propensity score","text":"several ways researchers can estimate average treatment effects using estimated propensity score. Busso, DiNardo, McCrary (2014) examined properties various approaches found inverse probability weighting competitive several simulations. different ways weights incorporated weighting design, discuss canonical versions method inverse probability weighting associated methods inference. expansive area causal inference econometrics, consider merely overview introduction main concepts.Assuming CIA holds data, one way can estimate treatment effects use weighting procedure individual’s propensity score weight individual’s outcome (Imbens 2000). aggregated, potential identify average treatment effect. estimator based earlier work survey methodology first proposed Horvitz Thompson (1952). weight enters expression differently depending unit’s treatment status takes two different forms depending whether target parameter ATE ATT (ATU, shown ):\\[\\begin{align}\n   \\delta_{ATE} & =E[Y^1-Y^0] \\nonumber                                                      \n   \\\\\n            & =E \\left[ Y \\cdot \\dfrac{D - p(X)}{p(X) \\cdot (1-p(X))} \\right]            \n   \\\\\n   \\delta_{ATT} & =E\\big[Y^1-Y^0\\mid D=1\\big] \\nonumber                                      \n   \\\\\n            & =\\dfrac{1}{\\Pr(D=1)} \\cdot E \\left[ Y \\cdot \\dfrac{D-p(X)}{1-p(X)} \\right] \n\\end{align}\\]proof ATE provided:\\[\\begin{align}\n   E \\left[ Y \\dfrac{D-p(X)}{p(X)(1-p(X))} \\Big\\vert X \\right] & = E \\left[ \\dfrac{Y}{p(X)} \\Big\\vert X,D=1 \\right] p(X) \\nonumber      \n   \\\\\n    & + E\\left[ \\dfrac{-Y}{1-p(X)} \\Big\\vert X,D=0 \\right](1-p(X)) \\nonumber \n   \\\\\n    & = E\\big[Y\\mid X,D=1\\big] - E\\big[Y\\mid X,D=0\\big]                      \n\\end{align}\\]results follow integrating \\(P(X)\\) \\(P(X\\mid D=1)\\).sample versions ATE ATT obtained two-step estimation procedure. first step, researcher estimates propensity score using logit probit. second step, researcher uses estimated score produce sample versions one average treatment effect estimators shown . sample versions can written follows:\\[\\begin{align}\n   \\widehat{\\delta}_{ATE} & =\\dfrac{1}{N} \\sum_{=1}^N Y_i \\cdot \\dfrac{D_i - \\widehat{p}(X_i)}{\\widehat{p}(X_i) \\cdot (1-\\widehat{p}(X_i))} \n   \\\\\n   \\widehat{\\delta}_{ATT}           & =\\dfrac{1}{N_T} \\sum_{=1}^N Y_i \\cdot \\dfrac{D_i -\\widehat{p}(X_i)}{1-\\widehat{p}(X_i)}                         \n\\end{align}\\]options estimating variance estimator, one simply use bootstrapping. First created Efron (1979), bootstrapping procedure used estimate variance estimator. context inverse probability weighting, repeatedly draw (“replacement”) random sample original data use smaller sample calculate sample analogs ATE ATT. specifically, using smaller “bootstrapped” data, first estimate propensity score use estimated propensity score calculate sample analogs ATE ATT obtain distribution treatment effects corresponding different cuts data .92 1,000 10,000 times, get distribution parameter estimates can calculate standard deviation. standard deviation becomes like standard error gives us measure dispersion parameter estimate uncertainty regarding sample .93 Adudumilli (2018) Bodory et al. (2020) discuss performance various bootstrapping procedures, standard bootstrap wild bootstrap. encourage read papers closely choosing bootstrap suitable question.sensitivity inverse probability weighting extreme values propensity score led researchers propose alternative can handle extremes bit better. Hirano Imbens (2001) propose inverse probability weighting estimator average treatment effect assigns weights normalized sum propensity scores treated control groups opposed equal weights \\(\\dfrac{1}{N}\\) observation. procedure sometimes associated Hájek (1971). Millimet Tchernis (2009) refer estimator normalized estimator. weights sum one within group, tends make stable. expression normalized estimator shown :\n\\[\n\\widehat{\\delta}_{ATT}=\\bigg [ \\sum_{=1}^N \\dfrac{Y_iD_i}{\\widehat{p}} \\bigg ] / \\bigg [ \\sum_{=1}^N \\dfrac{D_i}{\\widehat{p}} \\bigg ] - \\bigg [ \\sum_{=1}^N \\dfrac{Y_i(1-D_i)}{(1-\\widehat{p})} \\bigg ] / \\bigg [ \\sum_{=1}^N \\dfrac{(1-D_i)}{(1-\\widehat{p})} \\bigg ]\n\\]\nsoftware packages programs estimate sample analog inverse probability weighted parameters use second method normalized weights. instance, Stata’s -teffects- R’s -ipw- can used. packages also generate standard errors. ’d like manually calculate point estimates can see clearly exactly use propensity score construct either non-normalized normalized weights estimate ATT.ipw.doipw.RWhen estimate treatment effect using inverse probability weighting using non-normalized weighting procedure described earlier, find estimated ATT \\(-\\$11,876\\). Using normalization weights, get \\(-\\$7,238\\). much different get using experimental data?Recall inverse probability weighting . weighting treatment control units according \\(\\widehat{p}(X)\\), causing units small values propensity score blow become unusually influential calculation ATT. Thus, need trim data. small trim eliminate mass values far-left tail. Crump et al. (2009) develop principled method addressing lack overlap. good rule thumb, note, keep observations interval [0.1,0.9], performed end program.Now let’s repeat analysis trimmed propensity score, keeping values whose scores 0.1 0.9. Now find $2,006 using non-normalized weights $1,806 using normalized weights. similar know true causal effect using experimental data, $1,794. can see normalized weights even closer. still need calculate standard errors, based bootstrapping method, leave investigate carefully reading Adudumilli (2018) Bodory et al. (2020), , mentioned, discuss performance various bootstrapping procedures standard bootstrap wild bootstrap.","code":"* Manual with non-normalized weights using all the data\ngen d1=treat/pscore\ngen d0=(1-treat)/(1-pscore)\negen s1=sum(d1)\negen s0=sum(d0)\n\ngen y1=treat*re78/pscore\ngen y0=(1-treat)*re78/(1-pscore)\ngen ht=y1-y0\n\n* Manual with normalized weights\nreplace y1=(treat*re78/pscore)/(s1/_N)\nreplace y0=((1-treat)*re78/(1-pscore))/(s0/_N)\ngen norm=y1-y0\nsu ht norm\n\n* ATT under non-normalized weights is -$11,876\n* ATT under normalized weights is -$7,238\n\ndrop d1 d0 s1 s0 y1 y0 ht norm\n\n* Trimming the propensity score\ndrop if pscore <= 0.1 \ndrop if pscore >= 0.9\n\n* Manual with non-normalized weights using trimmed data\ngen d1=treat/pscore\ngen d0=(1-treat)/(1-pscore)\negen s1=sum(d1)\negen s0=sum(d0)\n\ngen y1=treat*re78/pscore\ngen y0=(1-treat)*re78/(1-pscore)\ngen ht=y1-y0\n\n* Manual with normalized weights using trimmed data\nreplace y1=(treat*re78/pscore)/(s1/_N)\nreplace y0=((1-treat)*re78/(1-pscore))/(s0/_N)\ngen norm=y1-y0\nsu ht norm\n\n* ATT under non-normalized weights is $2,006\n* ATT under normalized weights is $1,806\nlibrary(tidyverse)\nlibrary(haven)\n\n#continuation\nN <- nrow(nsw_dw_cpscontrol)\n#- Manual with non-normalized weights using all data\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(d1 = treat/pscore,\n         d0 = (1-treat)/(1-pscore))\n\ns1 <- sum(nsw_dw_cpscontrol$d1)\ns0 <- sum(nsw_dw_cpscontrol$d0)\n\n\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(y1 = treat * re78/pscore,\n         y0 = (1-treat) * re78/(1-pscore),\n         ht = y1 - y0)\n\n#- Manual with normalized weights\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(y1 = (treat*re78/pscore)/(s1/N),\n         y0 = ((1-treat)*re78/(1-pscore))/(s0/N),\n         norm = y1 - y0)\n\nnsw_dw_cpscontrol %>% \n  pull(ht) %>% \n  mean()\n\nnsw_dw_cpscontrol %>% \n  pull(norm) %>% \n  mean()\n\n#-- trimming propensity score\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  select(-d1, -d0, -y1, -y0, -ht, -norm) %>% \n  filter(!(pscore >= 0.9)) %>% \n  filter(!(pscore <= 0.1))\n\nN <- nrow(nsw_dw_cpscontrol)\n\n#- Manual with non-normalized weights using trimmed data\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(d1 = treat/pscore,\n         d0 = (1-treat)/(1-pscore))\n\ns1 <- sum(nsw_dw_cpscontrol$d1)\ns0 <- sum(nsw_dw_cpscontrol$d0)\n\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(y1 = treat * re78/pscore,\n         y0 = (1-treat) * re78/(1-pscore),\n         ht = y1 - y0)\n\n#- Manual with normalized weights with trimmed data\nnsw_dw_cpscontrol <- nsw_dw_cpscontrol %>% \n  mutate(y1 = (treat*re78/pscore)/(s1/N),\n         y0 = ((1-treat)*re78/(1-pscore))/(s0/N),\n         norm = y1 - y0)\n\nnsw_dw_cpscontrol %>% \n  pull(ht) %>% \n  mean()\n\nnsw_dw_cpscontrol %>% \n  pull(norm) %>% \n  mean()"},{"path":"ch4.html","id":"nearest-neighbor-matching","chapter":"5 Matching and Subclassification","heading":"5.3.6 Nearest-neighbor matching","text":"alternative, popular approach inverse probability weighting matching propensity score. often done finding couple units comparable propensity scores control unit donor pool within ad hoc chosen radius distance treated unit’s propensity score. researcher averages outcomes assigns average imputation original treated unit proxy potential outcome counterfactual control. effort made enforce common support trimming.method criticized King Nielsen (2019). King Nielsen (2019) critique propensity score . instance, critique apply stratification based propensity score (Rosenbaum Rubin 1983), regression adjustment inverse probability weighting. problem focused nearest-neighbor matching related forced balance trimming well myriad common research choices made course project together ultimately amplify bias. King Nielsen (2019) write: “balanced data, balance becomes trimming observations matching, likely propensity score matching degrade inferences” (p.1).Nevertheless, nearest-neighbor matching, along inverse probability weighting, perhaps common method estimating propensity score model. Nearest-neighbor matching using propensity score pairs treatment unit \\(\\) one comparable control group units \\(j\\), comparability measured terms distance nearest propensity score. control group unit’s outcome plugged matched sample. matched sample, can calculate ATT \n\\[\n   \\widehat{ATT}=\\dfrac{1}{N_T} (Y_i - Y_{(j)})\n\\]\\(Y_{(j)}\\) matched control group unit \\(\\). focus ATT problems overlap discussed earlier.teffects_nn.doteffects_nn.RI chose match using five nearest neighbors. Nearest neighbors, words, find five nearest units control group, “nearest” measured closest propensity score . Unlike covariate matching, distance straightforward dimension reduction afforded propensity score. average actual outcome, match average outcome treatment unit. , subtract unit’s matched control treatment value, divide \\(N_T\\), number treatment units. Stata, get ATT $1,725 \\(p<0.05\\). Thus, relatively precise similar find experiment .","code":"teffects psmatch (re78) (treat age agesq agecube educ edusq marr nodegree black hisp re74 re75 u74 u75 interaction1, logit), atet gen(pstub_cps) nn(5)\nlibrary(MatchIt)\nlibrary(Zelig)\n\nm_out <- matchit(treat ~ age + agesq + agecube + educ +\n                 educsq + marr + nodegree +\n                 black + hisp + re74 + re75 + u74 + u75 + interaction1,\n                 data = nsw_dw_cpscontrol, method = \"nearest\", \n                 distance = \"logit\", ratio =5)\n\nm_data <- match.data(m_out)\n\nz_out <- zelig(re78 ~ treat + age + agesq + agecube + educ +\n               educsq + marr + nodegree +\n               black + hisp + re74 + re75 + u74 + u75 + interaction1, \n               model = \"ls\", data = m_data)\n\nx_out <- setx(z_out, treat = 0)\nx1_out <- setx(z_out, treat = 1)\n\ns_out <- sim(z_out, x = x_out, x1 = x1_out)\n\nsummary(s_out)"},{"path":"ch4.html","id":"coarsened-exact-matching","chapter":"5 Matching and Subclassification","heading":"5.3.7 Coarsened exact matching","text":"two kinds matching ’ve reviewed far. Exact matching matches treated unit control units covariate value. sometimes impossible, therefore matching discrepancies. instance, say matching continuous age continuous income. probability find another person exact value small, zero. leads therefore mismatching covariates, introduces bias.second kind matching ’ve discussed approximate matching methods, specify metric find control units “close” treated unit. requires distance metric, Euclidean, Mahalanobis, propensity score. can implemented Stata R.Iacus, King, Porro (2012) introduced kind exact matching called coarsened exact matching (CEM). idea simple. ’s based notion sometimes ’s possible exact matching coarsen data enough. coarsen data, meaning create categorical variables (e.g., 0- 10-year-olds, 11- 20-year olds), oftentimes can find exact matches. find matches, calculate weights basis person fits strata, weights used simple weighted regression.First, begin covariates \\(X\\) make copy called \\(X*\\). Next coarsen \\(X*\\) according user-defined cutpoints CEM’s automatic binning algorithm. instance, schooling becomes less high school, high school , college, college graduate, post college. create one stratum per unique observation \\(X*\\) place observation stratum. Assign strata original uncoarsened data, \\(X\\), drop observation whose stratum doesn’t contain least one treated control unit. add weights stratum size analyze without matching.trade-offs. Larger bins mean coarsening data, results fewer strata. Fewer strata result diverse observations within strata thus higher covariate imbalance. CEM prunes treatment control group units, changes parameter interest, long ’re transparent front, readers may willing give benefit doubt.94 Just know, though, estimating ATE ATT start trimming (just aren’t trim propensity scores).key benefit CEM part class matching methods called monotonic imbalance bounding (MIB). MIB methods bound maximum imbalance feature empirical distributions ex ante decision user. CEM, ex ante choice coarsening decision. choosing coarsening beforehand, users can control amount imbalance matching solution. ’s also fast.several ways measuring imbalance, focus \\(L1(f,g)\\) measure, \n\\[\nL1(f,g)=\\dfrac{1}{2} \\sum_{l_1 \\dots l_k}\n   \\Big|f_{l1 \\dots l_k} - g_{l_1 \\dots l_k}\\Big|\n\\]\n\\(f\\) \\(g\\) record relative frequencies treatment control group units. Perfect global balance indicated \\(L1=0\\). Larger values indicate larger imbalance groups, maximum \\(L1=1\\). Hence “imbalance bounding” 0 1.Now let’s get fun part: estimation. use job-training data ’ve working estimation.cem.docem.RThe estimated ATE $2,152, larger estimated experimental effect. ensured high degree balance covariates, can seen output cem command .Table 5.17:  Balance covariates coarsened exact matching.can seen Table 5.17, values \\(L1\\) close zero cases. largest \\(L1\\) gets 0.12 age squared.","code":"ssc install cem\n\n* Reload experimental group data\nuse https://github.com/scunning1975/mixtape/raw/master/nsw_mixtape.dta, clear\ndrop if treat==0\n\n* Now merge in the CPS controls from footnote 2 of Table 2 (Dehejia and Wahba 2002)\nappend using https://github.com/scunning1975/mixtape/raw/master/cps_mixtape.dta\ngen agesq=age*age\ngen agecube=age*age*age\ngen edusq=educ*edu\ngen u74 = 0 if re74!=.\nreplace u74 = 1 if re74==0\ngen u75 = 0 if re75!=.\nreplace u75 = 1 if re75==0\ngen interaction1 = educ*re74\ngen re74sq=re74^2\ngen re75sq=re75^2\ngen interaction2 = u74*hisp\n\ncem age (10 20 30 40 60) age agesq agecube educ edusq marr nodegree black hisp re74 re75 u74 u75 interaction1, treatment(treat) \nreg re78 treat [iweight=cem_weights], robust\nlibrary(cem)\nlibrary(MatchIt)\nlibrary(Zelig)\nlibrary(tidyverse)\nlibrary(estimatr)\n\n\nm_out <- matchit(treat ~ age + agesq + agecube + educ +\n                   educsq + marr + nodegree +\n                   black + hisp + re74 + re75 + \n                   u74 + u75 + interaction1,\n                 data = nsw_dw_cpscontrol, \n                 method = \"cem\", \n                 distance = \"logit\")\n\nm_data <- match.data(m_out)\n\nm_ate <- lm_robust(re78 ~ treat, \n               data = m_data,\n               weights = m_data$weights)"},{"path":"ch4.html","id":"conclusion-3","chapter":"5 Matching and Subclassification","heading":"5.3.8 Conclusion","text":"Matching methods important member causal inference arsenal. Propensity scores excellent tool check balance overlap covariates. ’s -appreciated diagnostic, one might miss ran regressions. extensions two treatments, like multinomial models, don’t cover . propensity score can make groups comparable, variables used estimate propensity score first place. area continues advance include covariate balancing (Imai Ratkovic 2013; Zubizarreta 2015; Zhao 2019) doubly robust estimators (Band Robins 2005). Consider chapter mechanics matching exact approximate matching situations.Learning propensity score particularly valuable given appears long half-life. instance, propensity scores make way contemporary designs , difference--differences (Sant’Anna Zhao 2018). investing basic understanding ideas methods likely worthwhile. never know right project comes along methods perfect solution, ’s intelligent reason write .remember, every matching solution causality problem requires credible belief backdoor criterion can achieved conditioning matrix \\(X\\), ’ve called CIA. explicitly requires unobservable variables opening backdoor paths confounders, many researchers requires leap faith great unwilling make . respects, CIA somewhat advanced requires deep institutional knowledge say confidence unobserved confounder exists. method easy compared domain-specific knowledge. good reason believe important, unobservable variables, need another tool. willing make assumption, methods others useful projects.Buy print version today:","code":""},{"path":"ch5.html","id":"ch5","chapter":"6 Regression Discontinuity","heading":"6 Regression Discontinuity","text":"Buy print version today:","code":""},{"path":"ch5.html","id":"huge-popularity-of-regression-discontinuity","chapter":"6 Regression Discontinuity","heading":"6.1 Huge Popularity of Regression Discontinuity","text":"","code":""},{"path":"ch5.html","id":"waiting-for-life","chapter":"6 Regression Discontinuity","heading":"6.1.1 Waiting for life","text":"past twenty years, interest regression-discontinuity design (RDD) increased (Figure 6.1). always popular, though. method dates back sixty years Donald Campbell, educational psychologist, wrote several studies using , beginning Thistlehwaite Campbell (1960).95 wonderful article history thought around RDD, Cook (2008) documents social evolution. Despite Campbell’s many efforts advocate usefulness understand properties, RDD catch beyond doctoral students handful papers . Eventually, Campbell moved .see growing popularity, let’s look counts papers Google Scholar year mentioned phrase “regression discontinuity design” (see Figure 6.1).96 Thistlehwaite Campbell (1960) influence broader community scholars using design, confirming Cook (2008) wrote. first time RDD appears economics community unpublished econometrics paper (Goldberger 1972). Starting 1976, RDD finally gets annual double-digit usage first time, begins slowly tick upward. part, adoption imperceptibly slow.\nFigure 6.1: Regression discontinuity time\nthings change starting 1999. ’s year couple notable papers prestigious Quarterly Journal Economics resurrected method. papers Angrist Lavy (1999) Black (1999), followed Hahn, Todd, Klaauw (2001) two years later. Angrist Lavy (1999), discuss detail later, studied effect class size pupil achievement using unusual feature Israeli public schools created smaller classes number students passed particular threshold. Black (1999) used kind RDD approach creatively exploited discontinuities geographical level created school district zoning estimate people’s willingness pay better schools. year 1999 marks watershed design’s widespread adoption. 2010 Journal Economic Literature article Lee Lemieux, nearly 4,000 cites shows year nearly 1,500 new papers mentioning method. 2019, RDD output 5,600. design today incredibly popular shows sign slowing .1972 1999 long time without much peep now considered one credible research designs observational data, gives? Cook (2008) says RDD “waiting life” time. conditions life empirical microeconomics likely growing acceptance potential outcomes framework among microeconomists (.e., -called credibility revolution led Josh Angrist, David Card, Alan Krueger, Steven Levitt, many others) well , perhaps even importantly, increased availability large digitized administrative data sets, many often captured unusual administrative rules treatment assignments. unusual rules, combined administrative data sets’ massive size, provided much-needed necessary conditions Campbell’s original design bloom thousands flowers.","code":""},{"path":"ch5.html","id":"graphical-representation-of-rdd","chapter":"6 Regression Discontinuity","heading":"6.1.2 Graphical representation of RDD","text":"’s big deal? RDD special? reason RDD appealing many ability convincingly eliminate selection bias. appeal partly due fact underlying identifying assumptions viewed many easier accept evaluate. Rendering selection bias impotent, procedure capable recovering average treatment effects given subpopulation units. method based simple, intuitive idea. Consider following DAG developed Steiner et al. (2017) illustrates method well.first graph, \\(X\\) continuous variable assigning units treatment \\(D\\) (\\(X \\rightarrow D\\)). assignment units treatment based “cutoff” score \\(c_0\\) unit score cutoff gets placed treatment group, units . example might charge driving intoxicated (impaired; DWI). Individuals blood-alcohol content 0.08 higher arrested charged DWI, whereas blood-alcohol level 0.08 (Hansen 2015). assignment variable may independently affect outcome via \\(X \\rightarrow Y\\) path may even related set variables \\(U\\) independently determine \\(Y\\). Notice moment unit’s treatment status exclusively determined assignment rule. Treatment determined \\(U\\).DAG clearly shows assignment variable \\(X\\)—often called “running variable”—observable confounder since causes \\(D\\) \\(Y\\). Furthermore, assignment variable assigns treatment basis cutoff, never able observe units treatment control value \\(X\\). Calling back matching chapter, means situation one satisfy overlap condition needed use matching methods, therefore backdoor criterion met.97However, can identify causal effects using RDD, illustrated limiting graph DAG. can identify causal effects subjects whose score close neighborhood around cutoff \\(c_0\\). Specifically, show, average causal effect subpopulation identified \\(X \\rightarrow c_0\\) limit. possible cutoff sole point treatment control subjects overlap limit.variety explicit assumptions buried graph must hold order methods review later recover average causal effect. main one discuss cutoff endogenous competing intervention occurring precisely moment cutoff triggering units \\(D\\) treatment category. assumption called continuity, formally means expected potential outcomes continuous cutoff. expected potential outcomes continuous cutoff, necessarily rules competing interventions occurring time.continuity assumption reflected graphically absence arrow \\(X \\rightarrow Y\\) second graph cutoff \\(c_0\\) cut . \\(c_0\\), assignment variable \\(X\\) longer direct effect \\(Y\\). Understanding continuity one main goals chapter. personal opinion null hypothesis always continuity discontinuity necessarily implies cause, tendency things change gradually come expect nature. Jumps unnatural see happen, beg explanation. Charles Darwin, Origin Species, summarized saying Natura non facit saltum, “nature make jumps.” use favorite phrase mine growing Mississippi, see turtle fencepost, know didn’t get .’s heart soul RDD. use knowledge selection treatment order estimate average treatment effects. Since know probability treatment assignment changes discontinuously \\(c_0\\), job simply compare people \\(c_0\\) estimate particular kind average treatment effect called local average treatment effect, LATE (Imbens Angrist 1994). overlap, “common support,” must rely extrapolation, means comparing units different values running variable. overlap limit \\(X\\) approaches cutoff either direction. methods used RDD ways handling bias extrapolation cleanly possible.","code":""},{"path":"ch5.html","id":"a-picture-is-worth-a-thousand-words","chapter":"6 Regression Discontinuity","heading":"6.1.3 A picture is worth a thousand words","text":"’ve said , say —pictures main results, including identification strategy, absolutely essential study attempting convince readers causal effect. RDD different. fact, pictures comparative advantage RDD. RDD , like many modern designs, visually intensive design. synthetic control probably two visually intensive designs ’ll ever encounter, fact. help make RDD concrete, let’s first look couple pictures. following discussion derives Hoekstra (2009).98Labor economists decades interested estimating causal effect college earnings. Hoekstra wanted crack open black box college’s returns little checking whether heterogeneous returns college. estimating causal effect attending state flagship university earnings. State flagship universities often selective public universities state. Texas, top 7% graduating high school students can select university state, modal first choice University Texas Austin. universities often environments higher research, resources strongly positive peer effects. natural wonder whether heterogeneous returns across public universities.challenge type question easy see. Let’s say compare individuals attended University Florida attended University South Florida. Insofar positive selection state flagship school, might expect individuals higher observed unobserved ability sort state flagship school. insofar ability increases one’s marginal product, expect individuals earn workforce regardless whether fact attended state flagship. basic forms selection bias confound ability estimate causal effect attending state flagship earnings. Hoekstra (2009) ingenious strategy disentangle causal effect selection bias using RDD. illustrate, let’s look two pictures associated interesting study.talking picture, want say something data. Hoekstra data applications state flagship university. get data, ’ve build relationship admissions office. involved making introductions, holding meetings explain project, convincing administrators project value well , ultimately winning approval cooperatively share data. likely ’ve involved school’s general counsel, careful plans de-identify data, agreements data storage, many assurances students’ names identities never released identified. lot trust social capital must created projects like , secret sauce RDDs—acquisition data requires far soft skills, friendship, respect, building alliances, may accustomed . isn’t straightforward simply downloading CPS IPUMS; ’s going take genuine smiles, hustle, luck. Given agencies considerable discretion release data , likely certain groups trouble others acquiring data. utmost importance approach individuals humility, genuine curiosity, , scientific integrity. ultimately ones can give data public use, don’t jerk.99\nFigure 6.2: Attending state flagship university function re-centered standardized test scores. Reprinted Hoekstra (2009).\npicture. Figure 6.2 lot going , ’s worth carefully unpacking element reader. four distinct elements picture want focus . First, notice horizontal axis. ranges negative number positive number zero around center picture. caption reads “SAT Points Admission Cutoff.” Hoekstra “recentered” university’s admissions criteria subtracting admission cutoff students’ actual score, something discuss detail later chapter. vertical line zero marks “cutoff,” university’s minimum SAT score admissions. appears binding, deterministically, students enrolled minimum SAT requirements. individuals likely qualifications compensated lower SAT scores. recentered SAT score today’s parlance called “running variable.”Second, notice dots. Hoekstra used hollow dots regular intervals along recentered SAT variable. dots represent conditional mean enrollments per recentered SAT score. administrative data set contains thousands thousands observations, shows conditional means along evenly spaced bins recentered SAT score.Third curvy lines fitting data. Notice picture two lines—curvy line fitted left zero, separate line fit right. lines least squares fitted values running variable, running variable allowed take higher-order terms. including higher-order terms regression , fitted values allowed flexibly track central tendencies data . thing really want focus attention two lines, one. fit lines separately left right cutoff.Finally, probably vivid piece information picture—gigantic jump dots zero recentered running variable. going ? Well, think probably know, let spell . probability enrolling flagship state university jumps discontinuously student just barely hits minimum SAT score required school. Let’s say score 1250. means student 1240 lower chance getting student 1250. Ten measly points go different path.Imagine two students—first student got 1240, second got 1250. two students really different one another? Well, sure: two individual students likely different. hundreds students made 1240 hundreds made 1250. Don’t think two groups probably pretty similar one another observable unobservable characteristics? , suddenly 1250 major difference characteristics students large sample? ’s question reflect . university arbitrarily picking reasonable cutoff, reasons believe also picking cutoff natural ability students jumps exact spot?said Hoekstra evaluating effect attending state flagship university future earnings. ’s study gets even intriguing. States collect data workers variety ways. One unemployment insurance tax reports. Hoekstra’s partner, state flagship university, sent university admissions data directly state office employers submit unemployment insurance tax reports. university social security numbers, matching student future worker worked quite well since social security number uniquely identifies worker. social security numbers used match quarterly earnings records 1998 second quarter 2005 university records. estimated:\n\\[\n\\ln(\\text{Earnings})=\\psi_{\\text{Year}} + \\omega_{\\text{Experience}} + \\theta_{\\text{Cohort}} + \\varepsilon\n\\]\n\\(\\psi\\) vector year dummies, \\(\\omega\\) dummy years high school earnings observed, \\(\\theta\\) vector dummies controlling cohort student applied university (e.g., 1988). residuals regression averaged applicant, resulting average residual earnings measure used implement partialled future earnings variable according Frisch-Waugh-Lovell theorem. Hoekstra takes students’ residuals natural log earnings regression collapses conditional averages bins along recentered running variable. Let’s look Figure 6.3.\nFigure 6.3: Future earnings function re-centered standardized test scores. Reprinted Hoekstra (2009).\npicture, see many elements saw Figure 6.2. instance, see recentered running variable along horizontal axis, little hollow dots representing conditional means, curvy lines fit left right cutoff zero, helpful vertical line zero. now also interesting title: “Estimated Discontinuity = 0.095 (z = 3.01).” exactly?visualization discontinuous jump zero earnings isn’t compelling prior figure, Hoekstra conducts hypothesis tests determine mean groups just just . finds : just cutoff earn 9.5% higher wages long term just . paper, experiments variety binning data (calls “bandwidth”), estimates range 7.4% 11.1%.Now let’s think second Hoekstra finding. Hoekstra finding exactly point workers experienced jump probability enrolling state flagship university, , ten fifteen years later, separate jump logged earnings around 10%. individuals just barely made state flagship university made around 10% long-term earnings individuals just barely missed cutoff., , heart soul RDD. exploiting institutional knowledge students accepted (subsequently enrolled) state flagship university, Hoekstra able craft ingenious natural experiment. insofar two groups applicants right around cutoff comparable future earnings world neither attended state flagship university, selection bias confounding comparison. see result powerful, yet simple graphs. study early one show college matter long-term earnings, sort college attend—even among public universities—matters well.","code":""},{"path":"ch5.html","id":"data-requirements-for-rdd","chapter":"6 Regression Discontinuity","heading":"6.1.4 Data requirements for RDD","text":"RDD finding “jumps” probability treatment move along running variable \\(X\\). find jumps? find discontinuities? answer humans often embed jumps rules. sometimes, lucky, someone gives us data allows us use rules study.convinced firms government agencies unknowingly sitting atop mountain potential RDD-based projects. Students looking thesis dissertation ideas might try find . encourage find topic interested begin building relationships local employers government administrators topic priority. Take coffee, get know , learn job, ask treatment assignment works. Pay close attention precisely individual units get assigned program. random? via rule? Oftentimes describe process whereby running variable used treatment assignment, won’t call . can’t promise yield pay dirt, hunch, based part experience, end describing running variable exceeds threshold, people switch intervention. Building alliances local firms agencies can pay trying find good research ideas.validity RDD doesn’t require assignment rule arbitrary. requires known, precise free manipulation. effective RDD studies involve programs \\(X\\) “hair trigger” tightly related outcome studied. Examples include probability arrested DWI jumping greater 0.08 blood-alcohol content (Hansen 2015); probability receiving health-care insurance jumping age 65, (Card, Dobkin, Maestas 2008); probability receiving medical attention jumping birthweight falls 1,500 grams (Almond et al. 2010; Barreca et al. 2011); probability attending summer school grades fall minimum level (Jacob Lefgen 2004), just saw, probability attending state flagship university jumping applicant’s test scores exceed minimum requirement (Hoekstra 2009).kinds studies, need data. specifically, need lot data around discontinuities, implies data sets useful RDD likely large. fact, large sample sizes characteristic features RDD. also face strong trends running variable, sample-size requirements get even larger. Researchers typically using administrative data settings birth records many observations.","code":""},{"path":"ch5.html","id":"estimation-using-an-rdd","chapter":"6 Regression Discontinuity","heading":"6.2 Estimation Using an RDD","text":"","code":""},{"path":"ch5.html","id":"the-sharp-rd-design","chapter":"6 Regression Discontinuity","heading":"6.2.1 The Sharp RD Design","text":"generally accepted two kinds RDD studies. designs probability treatment goes 0 1 cutoff, called “sharp” design. designs probability treatment discontinuously increases cutoff. often called “fuzzy” designs. , though, running variable \\(X\\) , upon reaching cutoff \\(c_0\\), likelihood receiving treatment flips. Let’s look diagram Figure 6.4, illustrates similarities differences two designs.\nFigure 6.4: Sharp vs. Fuzzy RDD\nSharp RDD treatment deterministic function running variable \\(X\\).100 example might Medicare enrollment, happens sharply age 65, excluding disability situations. fuzzy RDD represents discontinuous “jump” probability treatment \\(X>c_0\\). fuzzy designs, cutoff used instrumental variable treatment, like Angrist Lavy (1999), instrument class size class-size function created rules used Israeli schools construct class sizes.formally, sharp RDD, treatment status deterministic discontinuous function running variable \\(X_i\\), \n\\[\nD_i =\n   \\begin{cases} 1\n       \\text{ } & X_i\\geq{c_0} \n       \\\\ 0\n       \\text{ } & X_i < c_0    \n   \\end{cases}\n\\]\n\\(c_0\\) known threshold cutoff. know value \\(X_i\\) unit \\(\\), know treatment assignment unit \\(\\) certainty. , every value \\(X\\) can perfectly predict treatment assignment, necessarily means overlap along running variable.assume constant treatment effects, potential outcomes terms, get\\[\\begin{align}\n   Y_i^0 & = \\alpha + \\beta X_i \n   \\\\\n   Y^1_i & = Y_i^0 + \\delta     \n\\end{align}\\]Using switching equation, get\\[\\begin{align}\n   Y_i & =Y_i^0 + (Y_i^1 - Y_i^0) D_i                   \n   \\\\\n   Y_i & =\\alpha+\\beta X_i + \\delta D_i + \\varepsilon_i \n\\end{align}\\]treatment effect parameter, \\(\\delta\\), discontinuity conditional expectation function:\\[\\begin{align}\n   \\delta & =\\lim_{X_i\\rightarrow{X_0}} \n   E\\big[Y^1_i\\mid X_i=X_0\\big] - \\lim_{X_0\\leftarrow{X_i}}\n   E\\big[Y^0_i\\mid X_i=X_0\\big]\n   \\\\\n          & =\\lim_{X_i\\rightarrow{X_0}} \n   E\\big[Y_i\\mid X_i=X_0\\big]- \\lim_{X_0\\leftarrow{X_i}} E\\big[Y_i\\mid X_i=X_0\\big]\n\\end{align}\\]sharp RDD estimation interpreted average causal effect treatment running variable approaches cutoff limit, limit overlap. average causal effect local average treatment effect (LATE). discuss LATE greater detail instrumental variables, say one thing . Since identification RDD limiting case, technically identifying average causal effect units cutoff. Insofar units treatment effects differ units along rest running variable, estimated average treatment effect local range around cutoff. define local average treatment effect follows:\n\\[\n\\delta_{SRD}=E\\big[Y^1_i - Y_i^0\\mid X_i=c_0]\n\\]\nNotice role extrapolation plays estimating treatment effects sharp RDD. unit \\(\\) just \\(c_0\\), \\(D_i=0\\). unit \\(\\) just \\(c_0\\), \\(D_i=1\\). value \\(X_i\\), either units treatment group control group, . Therefore, RDD common support, one reasons rely extrapolation estimation. See Figure 6.5.\nFigure 6.5: Simulated data representing observed data points along running variable binding cutoff.\n\nNotes: Dashed lines extrapolations\n","code":""},{"path":"ch5.html","id":"continuity-assumption","chapter":"6 Regression Discontinuity","heading":"6.2.2 Continuity assumption","text":"key identifying assumption RDD called continuity assumption. states \\(E[Y^0_i\\mid X=c_0]\\) \\(E[Y_i^1\\mid X=c_0]\\) continuous (smooth) functions \\(X\\) even across \\(c_0\\) threshold. Absent treatment, words, expected potential outcomes wouldn’t jumped; ’ve remained smooth functions \\(X\\). think means moment. expected potential outcomes jumping \\(c_0\\), necessarily competing interventions occurring \\(c_0\\). Continuity, words, explicitly rules omitted variable bias cutoff . unobserved determinants \\(Y\\) continuously related running variable \\(X\\). exist omitted variable wherein outcome, jump \\(c_0\\) even disregarded treatment altogether? , continuity assumption violated methods require LATE.apologize ’m beating dead horse, continuity subtle assumption merits little discussion. continuity assumption means \\(E[Y^1\\mid X]\\) wouldn’t jumped \\(c_0\\). jumped, means something treatment caused jump \\(Y^1\\) already treatment. example might study finding large increase motor vehicle accidents age 21. ’ve reproduced figure interesting study mortality rates different types causes (Carpenter Dobkin 2009). reproduced one key figures Figure 6.6. Notice large discontinuous jump motor vehicle death rates age 21. likely explanation age 21 causes people drink , sometimes even driving.\nFigure 6.6: Mortality rates along age running variable (Carpenter Dobkin 2009).\ncausal effect motor vehicle accidents don’t jump age 21 reasons. Formally, exactly implied continuity—absence simultaneous treatments cutoff. instance, perhaps something biological happens 21-year-olds causes suddenly become bad drivers. maybe 21-year-olds graduating college age 21, celebrations, get wrecks. test , might replicate Carpenter Dobkin (2009) using data Uruguay, drinking age 18. saw jump motor vehicle accidents age 21 Uruguay, might reason believe continuity assumption hold United States. Reasonably defined placebos can help make case continuity assumption holds, even direct test per se.Sometimes abstract ideas become much easier understand data, example mean using simulation.rdd_simulate1.dordd_simulate1.RFigure 6.7 shows results simulation. Notice value \\(E[Y^1\\mid X]\\) changing continuously \\(X\\) \\(c_0\\). example continuity assumption. means absent treatment , expected potential outcomes ’ve remained smooth function \\(X\\) even passing \\(c_0\\). Therefore, continuity held, treatment, triggered \\(c_0\\), responsible discrete jumps \\(E[Y\\mid X]\\).\nFigure 6.7: Smoothness \\(Y^1\\) across cutoff illustrated using simulated data.\nnice thing simulations actually observe potential outcomes since made . real world, don’t data potential outcomes. , test continuity assumption directly. remember—switching equation, observe actual outcomes, never potential outcomes. Thus, since units switch \\(Y^0\\) \\(Y^1\\) \\(c_0\\), actually can’t directly evaluate continuity assumption. institutional knowledge goes long way, can help build case nothing else changing cutoff otherwise shift potential outcomes.Let’s illustrate using simulated data. Notice \\(Y^1\\) construction jumped 50 \\(X\\) running variable, \\(Y\\) . Let’s look output Figure 6.8. Notice jump discontinuity outcome, ’ve labeled LATE, local average treatment effect.rdd_simulate2.dordd_simulate2.R\nFigure 6.8: Estimated LATE using simulated data.\n","code":"clear\ncapture log close\nset obs 1000\nset seed 1234567\n\n* Generate running variable\ngen x = rnormal(50, 25)\nreplace x=0 if x < 0\ndrop if x > 100\nsum x, det\n\n* Set the cutoff at X=50. Treated if X > 50\ngen D = 0\nreplace D = 1 if x > 50\ngen y1 = 25 + 0*D + 1.5*x + rnormal(0, 20)\n\n* Potential outcome Y1 not jumping at cutoff (continuity)\ntwoway (scatter y1 x if D==0, msize(vsmall) msymbol(circle_hollow)) (scatter y1 x if D==1, sort mcolor(blue) msize(vsmall) msymbol(circle_hollow)) (lfit y1 x if D==0, lcolor(red) msize(small) lwidth(medthin) lpattern(solid)) (lfit y1 x, lcolor(dknavy) msize(small) lwidth(medthin) lpattern(solid)), xtitle(Test score (X)) xline(50) legend(off)\nlibrary(tidyverse)\n\n# simulate the data\ndat <- tibble(\n  x = rnorm(1000, 50, 25)\n) %>%\n  mutate(\n    x = if_else(x < 0, 0, x)\n  ) %>%\n  filter(x < 100)\n\n# cutoff at x = 50\ndat <- dat %>% \n  mutate(\n    D  = if_else(x > 50, 1, 0),\n    y1 = 25 + 0 * D + 1.5 * x + rnorm(n(), 0, 20)\n  )\n\nggplot(aes(x, y1, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = 50, colour = \"grey\", linetype = 2)+\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y1)\")* Actual outcome jumping\ngen y = 25 + 40*D + 1.5*x + rnormal(0, 20)\nscatter y x if D==0, msize(vsmall) || scatter y x if D==1, msize(vsmall) legend(off) xline(50, lstyle(foreground)) || lfit y x if D ==0, color(red) || lfit y x if D ==1, color(red) ytitle(\"Outcome (Y)\")  xtitle(\"Test Score (X)\") \n# simulate the discontinuity\ndat <- dat %>%\n  mutate(\n    y2 = 25 + 40 * D + 1.5 * x + rnorm(n(), 0, 20)\n  )\n\n# figure 36\nggplot(aes(x, y2, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.5) +\n  geom_vline(xintercept = 50, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")"},{"path":"ch5.html","id":"estimation-using-local-and-global-least-squares-regressions","chapter":"6 Regression Discontinuity","heading":"6.2.3 Estimation using local and global least squares regressions","text":"’d like now dig actual regression model use estimate LATE parameter RDD. first discuss basic modeling choices researchers often make—trivial, important. section focus primarily regression-based estimation.necessary, nonetheless quite common authors transform running variable \\(X\\) recentering \\(c_0\\):\n\\[\nY_i=\\alpha+\\beta(X_i-c_0)+\\delta D_i+\\varepsilon_i\n\\]\ndoesn’t change interpretation treatment effect—interpretation intercept. Let’s use Card, Dobkin, Maestas (2008) example. Medicare triggered person turns 65. recenter running variable (age) subtracting 65:\\[\\begin{align}\n   Y & =\\beta_0 + \\beta_1 (Age-65) + \\beta_2 Edu + \\varepsilon           \\\\\n     & =\\beta_0 + \\beta_1 Age - \\beta_1 65 + \\beta_2 Edu+ \\varepsilon    \\\\\n     & =(\\beta_0 - \\beta_1 65) + \\beta_1 Age + \\beta_2 Edu + \\varepsilon \\\\\n     & = \\alpha + \\beta_1 Age + \\beta_2 Edu+ \\varepsilon                 \n\\end{align}\\]\\(\\alpha=\\beta_0 + \\beta_1 65\\). coefficients, notice, interpretation except intercept.Another practical question relates nonlinear data-generating processes. nonlinear data-generating process easily yield false positives handle specification carefully. sometimes fitting local linear regressions around cutoff, spuriously pick effect simply reason imposed linearity model. underlying data-generating process nonlinear, may spurious result due misspecification model. Consider example nonlinearity Figure 6.9.rdd_simulate3.dordd_simulate3.R\nFigure 6.9: Simulated nonlinear data Stata.\nshow visually regression. can see Figure 6.9, data-generating process nonlinear, straight lines left right cutoff, trends running variable generate spurious discontinuity cutoff. shows regression well. fit model using least squares regression controlling running variable, estimate causal effect though isn’t one. Table 6.1, estimated effect \\(D\\) \\(Y\\) large highly significant, even though true effect zero. situation, need way model nonlinearity cutoff check whether, even given nonlinearity, jump outcome discontinuity.Table 6.1:  Estimated effect D Y using OLS controlling linear running variable.Suppose nonlinear relationships \n\\[\nE\\big[Y^0_i\\mid X_i\\big]=f(X_i)\n\\]\nreasonably smooth function \\(f(X_i)\\). case, ’d fit regression model:\n\\[\nY_i=f(X_i) + \\delta D_i + \\eta_i\n\\]\nSince \\(f(X_i)\\) counterfactual values \\(X_i>c_0\\), model nonlinearity? two ways approximating \\(f(X_i)\\). traditional approaches let \\(f(X_Be )\\) equal \\(p{th}\\)-order polynomial:\n\\[\nY_i = \\alpha + \\beta_1 x_i + \\beta_2 x_i^2 + \\dots + \\beta_p x_i^p + \\delta D_i + \\eta_i\n\\]\nHigher-order polynomials can lead overfitting found introduce bias (Gelman Imbens 2019). authors recommend using local linear regressions linear quadratic forms . Another way approximating \\(f(X_i)\\) use nonparametric kernel, discuss later.Though Gelman Imbens (2019) warn us higher-order polynomials, ’d like use example \\(p\\)th-order polynomials, mainly ’s uncommon see done today. ’d also like know history method understand better old papers . can generate function, \\(f(X_i)\\), allowing \\(X_i\\) terms differ sides cutoff including individually interacting \\(D_i\\). case, :\\[\\begin{align}\n   E\\big[Y^0_i\\mid X_i\\big] & =\\alpha + \\beta_{01} \\widetilde{X}_i + \\dots + \\beta_{0p}\\widetilde{X}_i^p           \n   \\\\\n   E\\big[Y^1_i\\mid X_i\\big] & =\\alpha + \\delta + \\beta_{11} \\widetilde{X}_i + \\dots + \\beta_{1p} \\widetilde{X}_i^p \n\\end{align}\\]\\(\\widetilde{X}_i\\) recentered running variable (.e., \\(X_i - c_0\\)). Centering \\(c_0\\) ensures treatment effect \\(X_i=X_0\\) coefficient \\(D_i\\) regression model interaction terms. Lee Lemieux (2010) note, allowing different functions sides discontinuity main results RDD paper.derive regression model, first note observed values must used place potential outcomes:\n\\[\nE[Y\\mid X]=E[Y^0\\mid X]+\\Big(E[Y^1\\mid X] - E[Y^0 \\mid X]\\Big)D\n\\]\nregression model \n\\[\nY_i= \\alpha + \\beta_{01}\\tilde{X}_i + \\dots + \\beta_{0p}\\tilde{X}_i^p +\n   \\delta D_i+ \\beta_1^*D_i \\tilde{X}_i + \\dots + \\beta_p^* D_i \\tilde{X}_i^p + \\varepsilon_i\n\\]\n\\(\\beta_1^* = \\beta_{11} - \\beta_{01}\\), \\(\\beta_p^* = \\beta_{1p} - \\beta_{0p}\\). equation looked earlier just special case equation \\(\\beta_1^*=\\beta_p^*=0\\). treatment effect \\(c_0\\) \\(\\delta\\). treatment effect \\(X_i-c_0>0\\) \\(\\delta + \\beta_1^*c + \\dots + \\beta_p^* c^p\\). Let’s see action another simulation.rdd_simulate4.dordd_simulate4.RLet’s look output exercise Figure 6.10 Table 6.2. can see, model data using quadratic (cubic ultimately unnecessary), estimated treatment effect cutoff. also effect least squares regression.\nFigure 6.10: Simulated nonlinear data Stata\nTable 6.2:  Estimated effect D Y using OLS controlling linear quadratic running variable.","code":"* Nonlinear data generating process\ndrop y y1 x* D\nset obs 1000\ngen x = rnormal(100, 50)\nreplace x=0 if x < 0\ndrop if x > 280\nsum x, det\n\n* Set the cutoff at X=140. Treated if X > 140\ngen D = 0\nreplace D = 1 if x > 140\ngen x2 = x*x\ngen x3 = x*x*x\ngen y = 10000 + 0*D - 100*x +x2 + rnormal(0, 1000)\nreg y D x\n\nscatter y x if D==0, msize(vsmall) || scatter y x ///\n  if D==1, msize(vsmall) legend(off) xline(140, ///\n  lstyle(foreground)) ylabel(none) || lfit y x ///\n  if D ==0, color(red) || lfit y x if D ==1, ///\n  color(red) xtitle(\"Test Score (X)\") ///\n  ytitle(\"Outcome (Y)\") \n\n* Polynomial estimation\ncapture drop y\ngen y = 10000 + 0*D - 100*x +x2 + rnormal(0, 1000)\nreg y D x x2 x3\npredict yhat \n\nscatter y x if D==0, msize(vsmall) || scatter y x ///\n  if D==1, msize(vsmall) legend(off) xline(140, ///\n  lstyle(foreground)) ylabel(none) || line yhat x ///\n  if D ==0, color(red) sort || line yhat x if D==1, ///\n  sort color(red) xtitle(\"Test Score (X)\") ///\n  ytitle(\"Outcome (Y)\") \n# simultate nonlinearity\ndat <- tibble(\n    x = rnorm(1000, 100, 50)\n  ) %>% \n  mutate(\n    x = case_when(x < 0 ~ 0, TRUE ~ x),\n    D = case_when(x > 140 ~ 1, TRUE ~ 0),\n    x2 = x*x,\n    x3 = x*x*x,\n    y3 = 10000 + 0 * D - 100 * x + x2 + rnorm(1000, 0, 1000)\n  ) %>% \n  filter(x < 280)\n\n\nggplot(aes(x, y3, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.2) +\n  geom_vline(xintercept = 140, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"lm\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")\n\nggplot(aes(x, y3, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.2) +\n  geom_vline(xintercept = 140, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"loess\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")* Polynomial modeling\ncapture drop y\ngen y = 10000 + 0*D - 100*x +x2 + rnormal(0, 1000)\nreg y D##c.(x x2 x3)\npredict yhat \n\nscatter y x if D==0, msize(vsmall) || scatter y x ///\n  if D==1, msize(vsmall) legend(off) xline(140, ///\n  lstyle(foreground)) ylabel(none) || line yhat x ///\n  if D ==0, color(red) sort || line yhat x if D==1, ///\n  sort color(red) xtitle(\"Test Score (X)\") ///\n  ytitle(\"Outcome (Y)\") \nlibrary(stargazer)\n\ndat <- tibble(\n  x = rnorm(1000, 100, 50)\n) %>% \n  mutate(\n    x = case_when(x < 0 ~ 0, TRUE ~ x),\n    D = case_when(x > 140 ~ 1, TRUE ~ 0),\n    x2 = x*x,\n    x3 = x*x*x,\n    y3 = 10000 + 0 * D - 100 * x + x2 + rnorm(1000, 0, 1000)\n  ) %>% \n  filter(x < 280)\n\nregression <- lm(y3 ~ D*., data = dat)\n  \nstargazer(regression, type = \"text\") \n\nggplot(aes(x, y3, colour = factor(D)), data = dat) +\n  geom_point(alpha = 0.2) +\n  geom_vline(xintercept = 140, colour = \"grey\", linetype = 2) +\n  stat_smooth(method = \"loess\", se = F) +\n  labs(x = \"Test score (X)\", y = \"Potential Outcome (Y)\")"},{"path":"ch5.html","id":"nonparametric-kernels","chapter":"6 Regression Discontinuity","heading":"6.2.4 Nonparametric kernels","text":", mentioned earlier, Gelman Imbens (2019) discouraged use higher-order polynomials estimating local linear regressions. alternative use kernel regression. nonparametric kernel method problems trying estimate regressions cutoff point, can result boundary problem (see Figure 6.11). picture, bias caused strong trends expected potential outcomes throughout running variable.\nFigure 6.11: Simulated nonlinear data Stata\ntrue effect diagram \\(AB\\), certain bandwidth rectangular kernel estimate effect \\('B'\\), can see biased estimator. systematic bias kernel method underlying nonlinear function, \\(f(X)\\), upwards-downwards-xsloping.standard solution problem run local linear nonparametric regression (Hahn, Todd, Klaauw 2001). case described , substantially reduce bias. ? Think kernel regression weighted regression restricted window (hence “local”). kernel provides weights regression.101 rectangular kernel give result taking \\(E[Y]\\) given bin \\(X\\). triangular kernel gives importance observations closest center.model version :\n\\[\n(\\widehat{},\\widehat{b})=_{,b}\n   \\sum_{=1}^n\\Big(y_i - -b(x_i-c_0)\\Big)^2K\n   \\left(\\dfrac{x_i-c_o}{h}\\right)1(x_i>c_0)\n\\]\nestimating given window width \\(h\\) around cutoff straightforward, ’s straightforward knowing large small make bandwidth. method sensitive choice bandwidth, recent work allows researcher estimate optimal bandwidths (Imbens Kalyanaraman 2011; Calonico, Cattaneo, Titiunik 2014). may even allow bandwidths vary left right cutoff.","code":""},{"path":"ch5.html","id":"medicare-and-universal-health-care","chapter":"6 Regression Discontinuity","heading":"6.2.5 Medicare and universal health care","text":"Card, Dobkin, Maestas (2008) example sharp RDD, focuses provision universal health-care insurance elderly—Medicare age 65. makes policy-relevant question? Universal insurance become highly relevant debates surrounding Affordable Care Act, well several Democratic senators supporting Medicare . also important sheer size. 2014, Medicare 14% federal budget $505 billion.Approximately 20% non-elderly adults United States lacked insurance 2005. lower-income families, nearly half African American Hispanic. Many analysts argued unequal insurance coverage contributes disparities health-care utilization health outcomes across socioeconomic status. , even among policies, heterogeneity form different copays, deductibles, features affect use. Evidence better insurance causes better health outcomes limited health insurance suffers deep selection bias. supply demand insurance depend health status, confounding observational comparisons people different insurance characteristics.situation elderly looks different, though. Less 1% elderly population uninsured. fee--service Medicare coverage. transition Medicare occurs sharply age 65—threshold Medicare eligibility.authors estimate reduced form model measuring causal effect health insurance status health-care usage:\n\\[\ny_{ija} = X_{ija} \\alpha + f_k(\\alpha ; \\beta ) + \\sum_k C_{ija}^k \\delta^k + u_{ija}\n\\]\n\\(\\) indexes individuals, \\(j\\) indexes socioeconomic group, \\(\\) indexes age, \\(u_{ija}\\) indexes unobserved error, \\(y_{ija}\\) health care usage, \\(X_{ija}\\) set covariates (e.g., gender region), \\(f_j(\\alpha ; \\beta )\\) smooth function representing age profile outcome \\(y\\) group \\(j\\), \\(C_{ija}^k\\) \\((k=1,2,\\dots ,K)\\) characteristics insurance coverage held individual copayment rates. problem estimating model, though, insurance coverage endogenous: \\(cov(u,C) \\neq 0\\). authors use identification age threshold Medicare eligibility 65, argue credibly exogenous variation insurance status.Suppose health insurance coverage can summarized two dummy variables: \\(C_{ija}^1\\) (coverage) \\(C_{ija}^2\\) (generous insurance). Card, Dobkin, Maestas (2008) estimate following linear probability models:\\[\\begin{align}\n   C_{ija}^1 & =X_{ija}\\beta_j^1 + g_j^1() + D_a \\pi_j^1 + v_{ija}^1  \n   \\\\\n   C_{ija}^2 & =X_{ija} \\beta_j^2 + g_j^2() + D_a \\pi_j^2 + v_{ija}^2 \n\\end{align}\\]\\(\\beta_j^1\\) \\(\\beta_j^2\\) group-specific coefficients, \\(g_j^1()\\) \\(g_j^2()\\) smooth age profiles group \\(j\\), \\(D_a\\) dummy respondent equal age 65. Recall reduced form model:\\[\\begin{align}\n   y_{ija} = X_{ija} \\alpha + f_k(\\alpha ; \\beta ) + \\sum_k C_{ija}^k \\delta^k + u_{ija}\n\\end{align}\\]Combining \\(C_{ija}\\) equations, rewriting reduced form model, get:\\[\\begin{align}\n   y_{ija}=X_{ija}\\Big(\\alpha_j+\\beta_j^1\\delta_j^1+ \\beta_j^2 \\delta_j^2\\Big)h_j()+D_a\\pi_j^y+ v_{ija}^y\n\\end{align}\\]\\(h()=f_j() + \\delta^1 g_j^1() + \\delta^2 g_j^2()\\) reduced form age profile group \\(j\\), \\(\\pi_j^y=\\pi_j^1\\delta^1 + \\pi_j^2 \\delta^2\\) \\(v_{ija}^y=u_{ija} + v_{ija}^1 \\delta^1 + v_{ija}^2 \\delta^2\\) error term. Assuming profiles \\(f_j()\\), \\(g_j()\\), \\(g_j^2()\\) continuous age 65 (.e., continuity assumption necessary identification), discontinuity \\(y\\) due insurance. magnitudes depend size insurance changes age 65 (\\(\\pi_j^1\\) \\(\\pi_j^2\\)) associated causal effects (\\(\\delta^1\\) \\(\\delta^2\\)).basic health-care services, routine doctor visits, may thing matters insurance. , situations, implied discontinuity \\(Y\\) age 65 group \\(j\\) proportional change insurance status experienced group. expensive elective services, generosity coverage may matter—instance, patients unwilling cover required copay managed care program won’t cover service. creates potential identification problem interpreting discontinuity \\(y\\) one group. Since \\(\\pi_j^y\\) linear combination discontinuities coverage generosity, \\(\\delta^1\\) \\(\\delta^2\\) can estimated regression across groups:\n\\[\n\\pi_j^y=\\delta^0+\\delta^1\\pi_j^1+\\delta_j^2\\pi_j^2+e_j\n\\]\n\\(e_j\\) error term reflecting combination sampling errors \\(\\pi_j^y\\), \\(\\pi_j^1\\) , \\(\\pi_j^2\\).Card, Dobkin, Maestas (2008) use couple different data sets—one standard survey administrative records hospitals three states. First, use 1992–2003 National Health Interview Survey (NHIS). NHIS reports respondents’ birth year, birth month, calendar quarter interview. Authors used construct estimate age quarters date interview. person reaches 65 interview quarter coded age 65 0 quarters. Assuming uniform distribution interview dates, one-half people 0–6 weeks younger 65 one-half 0–6 weeks older. Analysis limited people 55 75. final sample 160,821 observations.second data set hospital discharge records California, Florida, New York. records represent complete census discharges hospitals three states except federally regulated institutions. data files include information age months time admission. sample selection criteria drop records people admitted transfers institutions limit people 60 70 years age admission. Sample sizes 4,017,325 (California), 2,793,547 (Florida), 3,121,721 (New York).institutional details Medicare program may helpful. Medicare available people least 65 worked forty quarters covered employment spouse . Coverage available younger people severe kidney disease recipients Social Security Disability Insurance. Eligible individuals can obtain Medicare hospital insurance (Part ) free charge medical insurance (Part B) modest monthly premium. Individuals receive notice impending eligibility Medicare shortly turn 65 informed enroll choose whether accept Part B coverage. Coverage begins first day month turn 65.five insurance-related variables: probability Medicare coverage, health insurance coverage, private coverage, two forms coverage, individual’s primary health insurance managed care. Data drawn 1999–2003 NHIS, characteristic, authors show incidence rate age 63–64 change age 65 based version \\(C_K\\) equations include quadratic age, fully interacted post-65 dummy well controls gender, education, race/ethnicity, region, sample year. Alternative specifications also used, parametric model fit narrower age window (age 63–67) local linear regression specification using chosen bandwidth. show similar estimates change age 65.Table 6.3:  Insurance characteristics just age 65 estimated discontinuities age 65The authors present findings Table 6.3. way read table cell shows average treatment effect 65-year-old population complies treatment. can see, surprisingly, effect receiving Medicare cause large increase Medicare, well reducing coverage private managed care.Formal identification RDD relating outcome (insurance coverage) treatment (Medicare age-eligibility) depends running variable, age, relies continuity assumptions discussed earlier. , must assume conditional expectation functions potential outcomes continuous age\\(=65\\). means \\(E[Y^0\\mid ]\\) \\(E[Y^1\\mid ]\\) continuous age 65. assumption plausible, average treatment effect age 65 identified :\n\\[\n\\lim_{65 \\leftarrow }E\\big[y^1\\mid \\big] -\n   \\lim_{\\rightarrow 65}E\\big[y^0\\mid \\big]\n\\]\ncontinuity assumption requires factors, observed unobserved, affect insurance coverage trending smoothly cutoff, words. else changes age 65 Medicare eligibility? Employment changes. Typically, 65 traditional age people retire labor force. abrupt change employment lead differences health-care utilization nonworkers time visit doctors.authors need , therefore, investigate possible confounder. testing potential discontinuities age 65 confounding variables using third data set—March CPS 1996–2004. ultimately find evidence discontinuities employment age 65 (Figure 6.12).\nFigure 6.12: Investigating CPS discontinuities age 65 (Card, Dobkin, Maestas 2008).\nNext authors investigate impact Medicare access care utilization using NHIS data. Since 1997, NHIS asked four questions. :“past 12 months medical care delayed person worry cost?”“past 12 months time person needed medical care get person afford ?”“individual least one doctor visit past year?”“individual one overnight hospital stays past year?”Estimates analysis presented Table 6.4. cell measures average treatment effect complier populationat discontinuity. Standard errors parentheses. encouraging findings table. First, share relevant population delayed care previous year fell 1.8 points, similar share get care previous year. share saw doctor went slightly, share stayed hospital. large effects magnitude, important note, relatively precisely estimated. Note effects differed considerably race ethnicity well education.Table 6.4:  Measures access care just 65 estimated discontinuities age 65Having shown modest effects care utilization, authors turn examining kinds care received examining specific changes hospitalizations. Figure 6.13 shows effect Medicare hip knee replacements race. effects largest whites.\nFigure 6.13: Changes hospitalizations (Card, Dobkin, Maestas 2008)\nconclusion, authors find universal health-care coverage elderly increases care utilization well coverage. subsequent study (Card, Dobkin, Maestas 2009), authors examined impact Medicare mortality found slight decreases mortality rates (see Table 6.5).Table 6.5:  Regression discontinuity estimates changes mortality rates\nDependent variable death within interval shown column heading. Regression estimates discontinuity age 65 flexible regression models. Standard errors parenthesis.\n","code":""},{"path":"ch5.html","id":"inference","chapter":"6 Regression Discontinuity","heading":"6.2.6 Inference","text":"’ve mentioned, ’s standard practice RDD estimate causal effects using local polynomial regressions. simplest form, amounts nothing complicated fitting linear specification separately side cutoff using least squares regression. done, using observations within pre-specified window (hence “local”). true conditional expectation function probably linear window, resulting estimator likely suffers specification bias. can get window narrow enough, bias estimator probably small relative standard deviation.window narrowed enough? can happen running variable takes values, gap values closest cutoff large. result simply enough observations close cutoff local polynomial regression. also can lead heteroskedasticity-robust confidence intervals undercover average causal effect centered. ’s really bad news—probably happening lot practice.widely cited influential study, Lee Card (2008) suggested researchers cluster standard errors running variable. advice since become common practice empirical literature. Lee Lemieux (2010), survey article proper RDD methodology, recommend practice, just name one example. recent study, Kolesár Rothe (2018) provide extensive theoretical simulation-based evidence clustering running variable perhaps one worst approaches take. fact, clustering running variable can actually substantially worse heteroskedastic-robust standard errors.alternative clustering robust standard errors, authors propose two alternative confidence intervals guaranteed coverage properties various restrictions conditional expectation function. confidence intervals “honest,” means achieve correct coverage uniformly conditional expectation functions large samples. confidence intervals currently unavailable Stata time writing, can implemented R RDHonest package.102 R users encouraged use confidence intervals. Stata users encouraged switch (grudgingly) R use confidence intervals. Barring , Stata users use heteroskedastic robust standard errors. whatever , don’t cluster running variable, nearly unambiguously bad idea.separate approach may use randomization inference. noted, Hahn, Todd, Klaauw (2001) emphasized conditional expected potential outcomes must continuous across cutoff regression discontinuity design identify local average treatment effect. Cattaneo, Frandsen, Titiunik (2015) suggest alternative assumption implications inference. ask us consider perhaps around cutoff, short enough window, treatment assigned units randomly. effectively coin flip side cutoff someone small enough window around cutoff. Assuming exists neighborhood around cutoff randomization-type condition holds, assumption may viewed approximation randomized experiment around cutoff. Assuming plausible, can proceed observations closest discontinuity randomly assigned, leads naturally randomization inference methodology conducting exact approximate p-values.","code":""},{"path":"ch5.html","id":"the-fuzzy-rd-design","chapter":"6 Regression Discontinuity","heading":"6.2.7 The Fuzzy RD Design","text":"sharp RDD, treatment determined \\(X_i \\geq c_0\\). kind deterministic assignment always happen. Sometimes discontinuity, ’s entirely deterministic, though nonetheless associated discontinuity treatment assignment. increase probability treatment assignment, fuzzy RDD. earlier paper Hoekstra (2009) feature, Angrist Lavy (1999). formal definition probabilistic treatment assignment \n\\[\n\\lim_{X_i\\rightarrow{c_0}}\n   \\Pr\\big(D_i=1\\mid X_i=c_0\\big) \\ne\n   \\lim_{c_0 \\leftarrow X_i}\n   \\Pr\\big(D_i=1\\mid X_i=c_0\\big)\n\\]words, conditional probability discontinuous \\(X\\) approaches \\(c_0\\) limit. visualization presented Imbens Lemieux (2008) Figure 6.14.\nFigure 6.14: Vertical axis probability treatment value running variable.\nidentifying assumptions fuzzy designs sharp designs: continuity assumptions. identification, must assume conditional expectation potential outcomes (e.g., \\(E[Y^0|X<c_0]\\)) changing smoothly \\(c_0\\). changes \\(c_0\\) treatment assignment probability. illustration identifying assumption Figure 6.15.\nFigure 6.15: Vertical axis probability treatment value running variable.\nEstimating average treatment effect fuzzy RDD similar estimate local average treatment effect instrumental variables. cover instrumental variables detail later book, now let tell estimation fuzzy designs using IV. One can estimate several ways. One simple way type Wald estimator, estimate causal effect ratio reduced form difference mean outcomes around cutoff reduced form difference mean treatment assignment around cutoff.\n\\[\n\\delta_{\\text{Fuzzy RDD}} = \\dfrac{\\lim_{X \\rightarrow c_0}\n       E\\big[Y\\mid X = c_0\\big]-\\lim_{X_0 \\leftarrow X}\n       E\\big[Y\\mid X=c_0\\big]}{\\lim_{X \\rightarrow c_0}\n       E\\big[D\\mid X=c_0\\big]-\\lim_{X_0 \\leftarrow X}\n       E\\big[D\\mid X=c_0\\big]}\n\\]\nassumptions identification instrumental variables design: caveats exclusion restrictions, monotonicity, SUTVA, strength first stage.103But one can also estimate effect using two-stage least squares model similar appropriate model limited-information maximum likelihood. Recall now two events: first event running variable exceeds cutoff, second event unit placed treatment. Let \\(Z_i\\) indicator \\(X\\) exceeds \\(c_0\\). One can use \\(Z_i\\) interaction terms instruments treatment \\(D_i\\). one uses \\(Z_i\\) instrumental variable, “just identified” model, usually good finite sample properties.Let’s look regressions involved instrumental variables approach. three possible regressions: first stage, reduced form, second stage. Let’s look order. case just identified (meaning one instrument one endogenous variable), first stage :\n\\[\nD_i = \\gamma_0 + \\gamma_1X_i+\\gamma_2X_i^2 + \\dots + \\gamma_pX_i^p + \\pi{Z}_i + \\zeta_{1i}\n\\]\n\\(\\pi\\) causal effect \\(Z_i\\) conditional probability treatment. fitted values regression used second stage. can also use \\(Z_i\\) interaction terms instruments \\(D_i\\). used \\(Z_i\\) interactions, estimated first stage :\n\\[\nD_i= \\gamma_{00} + \\gamma_{01}\\tilde{X}_i + \\gamma_{02}\\tilde{X}_i^2 + \\dots + \\gamma_{0p}\\tilde{X}_i^p\n   + \\pi Z_i + \\gamma_1^*\\tilde{X}_iZ_i + \\gamma_2^* \\tilde{X}_i Z_i + \\dots + \\gamma_p^*Z_i + \\zeta_{1i}\n\\]\nalso construct analogous first stages \\(\\tilde{X}_iD_i, \\dots, \\tilde{X}_i^pD_i\\).wanted forgo estimating full IV model, might estimate reduced form . ’d surprised many applied people prefer simply report reduced form fully specified instrumental variables model. read Hoekstra (2009), instance, favored presenting reduced form—second figure, fact, picture reduced form. reduced form regress outcome \\(Y\\) onto instrument running variable. form fuzzy RDD reduced form :\n\\[\nY_i = \\mu + \\kappa_1X_i + \\kappa_2X_i^2 + \\dots + \\kappa_pX_i^p + \\delta \\pi Z_i + \\zeta_{2i}\n\\]\nsharp RDD case, one can allow smooth function different sides discontinuity interacting \\(Z_i\\) running variable. reduced form regression :\\[\\begin{align}\n   Y_i & =\\mu + \\kappa_{01}X_i\\tilde{X}_i + \\kappa_{02}X_i{}\\tilde{X}_i^2 + \\dots + \\kappa_{0p}X_i{}\\tilde{X}_i^p                        \n   \\\\\n       & + \\delta \\pi Z_i + \\kappa_{01}X_i^*\\tilde{X}_iZ_i + \\kappa_{02}X_i^* \\tilde{X}_i Z_i + \\dots + \\kappa_{0p}X_i^*Z_i + \\zeta_{1i} \n\\end{align}\\]let’s say wanted present estimated effect treatment outcome. requires estimating first stage, using fitted values regression, estimating second stage fitted values. , , identify causal effect treatment outcome interest. reduced form estimates causal effect instrument outcome. second-stage model interaction terms :\\[\\begin{align}\n   Y_i & =\\alpha + \\beta_{01}\\tilde{x}_i + \\beta_{02}\\tilde{x}_i^2 + \\dots + \\beta_{0p}\\tilde{x}_i^p                                                             \n   \\\\\n       & + \\delta \\widehat{D_i} + \\beta_1^*\\widehat{D_i}\\tilde{x}_i + \\beta_2^*\\widehat{D_i}\\tilde{x}_i^2 + \\dots + \\beta_p^*\\widehat{D_i}\\tilde{x}_i^p + \\eta_i \n\\end{align}\\]\\(\\tilde{x}\\) now normalized respect \\(c_0\\) also fitted values obtained first-stage regressions.Hahn, Todd, Klaauw (2001) point , one needs assumptions identification one needs IV. binary instrumental variables, fuzzy RDD estimating local average treatment effect (LATE) (Imbens Angrist 1994), average treatment effect compliers. RDD, compliers whose treatment status changed moved value \\(x_i\\) just left \\(c_0\\) just right \\(c_0\\).","code":""},{"path":"ch5.html","id":"challenges-to-identification","chapter":"6 Regression Discontinuity","heading":"6.3 Challenges to Identification","text":"requirement RDD estimate causal effect continuity assumptions. , expected potential outcomes change smoothly function running variable cutoff. words, means thing causes outcome change abruptly \\(c_0\\) treatment. , can violated practice following true:assignment rule known advance.assignment rule known advance.Agents interested adjusting.Agents interested adjusting.Agents time adjust.Agents time adjust.cutoff endogenous factors independently cause potential outcomes shift.cutoff endogenous factors independently cause potential outcomes shift.nonrandom heaping along running variable.nonrandom heaping along running variable.Examples include retaking exam, self-reporting income, . unobservable characteristic change happen threshold, direct effect outcome. words, cutoff endogenous. example age thresholds used policy, person turns 18 years old faces severe penalties crime. age threshold triggers treatment (.e., higher penalties crime), also correlated variables affect outcomes, graduating high school voting rights. Let’s tackle problems separately.","code":""},{"path":"ch5.html","id":"mccrarys-density-test","chapter":"6 Regression Discontinuity","heading":"6.3.1 McCrary’s density test","text":"challenges identification, lot work econometricians applied microeconomists gone toward trying figure solutions problems. influential density test Justin McCrary, now called McCrary density test (McCrary 2008). McCrary density test used check whether units sorting running variable. Imagine two rooms patients line life-saving treatment. Patients room receive life-saving treatment, patients room B knowingly receive nothing. room B? Like , ’d probably stand , open door, walk across hall room . natural incentives people room B get room , thing keep people room B sorting room impossible., let’s imagine people room B successfully sorted room . look like outsider? successful, room patients room B. fact, extreme, room crowded room B empty. heart McCrary density test, see things cutoff, suggestive evidence people sorting running variable. sometimes called manipulation.Remember earlier said think continuity null nature doesn’t make jumps? see turtle fencepost, probably didn’t get . Well, goes density. null continuous density cutoff, bunching density cutoff sign someone moving cutoff—probably take advantage rewards await . Sorting sorting variable testable prediction null continuous density. Assuming continuous distribution units, sorting running variable means units moving just side cutoff. Formally, assume desirable treatment \\(D\\) assignment rule \\(X\\geq c_0\\), expect individuals sort \\(D\\) choosing \\(X\\) \\(X\\geq c_0\\)—long ’re able. , imply selection bias insofar sorting function potential outcomes.kind test needed investigate whether manipulation occurring test checks whether bunching units cutoff. words, need density test. McCrary (2008) suggests formal test null, density continuous cutoff point. alternative hypothesis, density increase kink.104 ’ve always liked test ’s really simple statistical test based theory human beings optimizing constraints. optimizing, makes testable predictions—like discontinuous jump density cutoff. Statistics built behavioral theory can take us .implement McCrary density test, partition assignment variable bins calculate frequencies (.e., number observations) bin. Treat frequency counts dependent variable local linear regression. can estimate conditional expectations, data running variable, principle can always density test. recommend package rddensity,105 can install R well.106 packages based Cattaneo, Jansson, Ma (2019), based local polynomial regressions less bias border regions.high-powered test. need lot observations \\(c_0\\) distinguish discontinuity density noise. Let illustrate Figure 6.16 picture McCrary (2008) shows situation without manipulation.\nFigure 6.16: picture without discontinuity density McCrary (2008).\n","code":""},{"path":"ch5.html","id":"covariate-balance-and-other-placebos","chapter":"6 Regression Discontinuity","heading":"6.3.2 Covariate balance and other placebos","text":"become common literature provide evidence credibility underlying identifying assumptions, least degree. assumptions directly tested, indirect evidence may persuasive. ’ve already mentioned one test—McCrary density test. second test covariate balance test. RDD valid study, must observable discontinuous change average values reasonably chosen covariates around cutoff. pretreatment characteristics, invariant change treatment assignment. example Lee, Moretti, Butler (2004), evaluated impact Democratic vote share just 50%, various demographic factors (Figure 6.17).\nFigure 6.17: Panels refer (top left bottom right) district characteristics: real income, percent high school degree, percent black, percent eligible vote. Circles represent average characteristic within intervals 0.01 Democratic vote share. continuous line represents predicted values fourth-order polynomial vote share fitted separately points 50 percent threshold. dotted line represents 95 percent confidence interval. Reprinted Lee, Moretti, Butler (2004).\ntest basically sometimes called placebo test. , looking effects shouldn’t . third kind test extension —just shouldn’t effects cutoff pretreatment values, shouldn’t effects outcome interest arbitrarily chosen cutoffs. Imbens Lemieux (2008) suggest looking one side discontinuity, taking median value running variable section, pretending discontinuity, \\(c_0'\\). test whether discontinuity outcome \\(c_0'\\). want find anything.","code":""},{"path":"ch5.html","id":"nonrandom-heaping-on-the-running-variable","chapter":"6 Regression Discontinuity","heading":"6.3.3 Nonrandom heaping on the running variable","text":"Almond et al. (2010) fascinating study. authors interested estimating causal effect medical expenditures health outcomes, part many medical technologies, effective, may justify costs associated use. Determining effectiveness challenging given medical resources , hope, optimally assigned patients based patient potential outcomes. put different way, physician perceives intervention best outcome, likely treatment assigned patient. violates independence, likely, endogeneity treatment deep enough, controlling selection directly tough, impossible. saw earlier example perfect doctor, nonrandom assignment interventions can lead confusing correlations. Counterintuitive correlations may nothing selection bias.Almond et al. (2010) ingenious insight—United States, typically case babies low birth weight receive heightened medical attention. categorization called “low birth weight” range, low birth weight quite dangerous child. Using administrative hospital records linked mortality data, authors find 1-year infant mortality decreases around 1 percentage point child’s birth weight just 1,500-gram threshold compared born just . Given mean 1-year mortality 5.5%, estimate sizable, suggesting medical interventions triggered -low-birth-weight classification benefits far exceed costs.Barreca et al. (2011) Barreca, Lindo, Waddell (2016) highlight econometric issues related call “heaping” running variable. Heaping excess number units certain points along running variable. case, appeared regular 100-gram intervals likely caused tendency hospitals round nearest integer. visualization problem can seen original Almond et al. (2010), reproduce Figure 6.18. long black lines appearing regularly across birth-weight distribution excess mass children born numbers. sort event unlikely occur naturally nature, almost certainly caused either sorting rounding. due less sophisticated scales , troubling, staff rounding child’s birth weight 1,500 grams order make child eligible increased medical attention.\nFigure 6.18: Distribution births gram. Reprinted Almond et al. (2010).\nAlmond et al. (2010) attempt study carefully using conventional McCrary density test find clear, statistically significant evidence sorting running variable 1,500-gram cutoff. Satisfied, conduct main analysis, find causal effect around 1-percentage-point reduction 1-year mortality.focus Barreca et al. (2011) Barreca, Lindo, Waddell (2016) much heaping phenomenon shown Figure 6.18. Part strength work, though, illustration shortcomings conventional McCrary density test. case, data heap 1,500 grams appears babies whose mortality rates unusually high. children outliers compared units immediate left immediate right. important note events occur naturally; reason believe nature produce heaps children born outlier health defects every 100 grams. authors comment might going :heaping 1,500 grams may signal poor-quality hospitals relatively high propensities round birth weights also consistent manipulation recorded birth weights doctors, nurses, parents obtain favorable treatment children. Barreca et al. (2011) show nonrandom heaping leads one conclude “good” strictly less 100-g cutoff 1,000 3,000 grams.Since estimation RDD compares means approach threshold either side, estimates sensitive observations thresholds . solution -called “donut hole” RDD, wherein remove units vicinity 1,500 grams reestimate model. Insofar units dropped, parameter estimating cutoff become even unusual type local average treatment effect may even less informative average treatment effects policy makers desperate know. strength rule allows possibility units heap differ markedly due selection bias surrounding area. Dropping units reduces sample size around 2% large effects 1-year mortality, approximately 50% lower found Almond et al. (2010).companion papers help us better understand ways selection bias can creep RDD. Heaping end world, good news researchers facing problem. donut hole RDD can used circumvent problems. ultimately solution involves dropping observations, insofar sample size small relative number heaping units, donut hole approach infeasible. also changes parameter interest estimated ways may difficult understand explain. Caution nonrandom heaping along running variable probably good thing.","code":""},{"path":"ch5.html","id":"replicating-a-popular-design-the-close-election","chapter":"6 Regression Discontinuity","heading":"6.4 Replicating a Popular Design: The Close Election","text":"Within RDD, particular kind design become quite popular, close-election design. Essentially, design exploits feature American democracies wherein winners political races declared candidate gets minimum needed share votes. Insofar close races represent exogenous assignments party’s victory, ’ll discuss , can use close elections identify causal effect winner variety outcomes. may also able test political economy theories otherwise nearly impossible evaluate.following section two goals. First, discuss detail close election design using classic Lee, Moretti, Butler (2004). Second, show implement close-election design replicating several parts Lee, Moretti, Butler (2004).Politicians Voters Pick Policies? big question motivating Lee et al. (2004) whether way voters affect policy. two fundamentally different views role elections representative democracy: convergence theory divergence theory.convergence theory states heterogeneous voter ideology forces candidate moderate position (e.g., similar median voter theorem):Competition votes can force even partisan Republicans Democrats moderate policy choices. extreme case, competition may strong leads “full policy convergence”: opposing parties forced adopt identical policies. Lee, Moretti, Butler (2004) (p.87)Divergence theory slightly commonsense view political actors. partisan politicians credibly commit certain policies, convergence undermined result can full policy “divergence.” Divergence winning candidate, taking office, simply pursues -preferred policy. extreme case, voters unable compel candidates reach kind policy compromise, expressed two opposing candidates choosing different policies different counterfactual victory scenarios.Lee, Moretti, Butler (2004) present model, ’ve simplified. Let \\(R\\) \\(D\\) candidates congressional race. policy space single dimension \\(D\\)’s \\(R\\)’s policy preferences period quadratic loss functions, \\(u(l)\\) \\(v(l)\\), \\(l\\) policy variable. player bliss point, preferred location along unidimensional policy range. Democrats, ’s \\(l^*=c(>0)\\), Republicans ’s \\(l*=0\\). ’s means.Ex ante, voters expect candidate choose policy expect candidate win probability \\(P(x^e,y^e)\\), \\(x^e\\) \\(y^e\\) policies chosen Democrats Republicans, respectively. \\(x^>y^e\\), \\(\\dfrac{\\partial P}{\\partial x^e}>0, \\dfrac{\\partial P}{\\partial y^e}<0\\).\\(P^*\\) represents underlying popularity Democratic Party, put differently, probability \\(D\\) win policy chosen \\(x\\) equaled Democrat’s bliss point \\(c\\).solution game multiple Nash equilibria, discuss now.Partial/complete convergence: Voters affect policies.Partial/complete convergence: Voters affect policies.key result equilibrium \\(\\dfrac{\\partial x^*}{\\partial P^*}>0\\).key result equilibrium \\(\\dfrac{\\partial x^*}{\\partial P^*}>0\\).Interpretation: dropped Democrats district helicopter, exogenously increase \\(P^*\\) result candidates changing policy positions, .e., \\(\\dfrac{\\partial x^*}{\\partial P^*}>0\\).Interpretation: dropped Democrats district helicopter, exogenously increase \\(P^*\\) result candidates changing policy positions, .e., \\(\\dfrac{\\partial x^*}{\\partial P^*}>0\\).Complete divergence: Voters elect politicians fixed policies whatever want .107Complete divergence: Voters elect politicians fixed policies whatever want .107Key result popularity effect policies. , \\(\\dfrac{\\partial x^*}{\\partial P^*}=0\\).Key result popularity effect policies. , \\(\\dfrac{\\partial x^*}{\\partial P^*}=0\\).exogenous shock \\(P^*\\) (.e., dropping Democrats district) nothing equilibrium policies. Voters elect politicians whatever want fixed policy preferences.exogenous shock \\(P^*\\) (.e., dropping Democrats district) nothing equilibrium policies. Voters elect politicians whatever want fixed policy preferences.potential roll-call voting record outcomes candidate following election \n\\[\nRC_t = D_tx_t + (1-D_t)y_t\n\\]\n\\(D_t\\) indicates whether Democrat won election. , winning candidate’s policy observed. expression can transformed regression equations:\\[\\begin{align}\n   RC_t     & = \\alpha_0+\\pi_0 P_t^*+\\pi_1D_t+\\varepsilon_t                   \n   \\\\\n   RC_{t+1} & = \\beta_0 + \\pi_0 P^*_{t+1} + \\pi_1 D_{t+1} + \\varepsilon_{t+1} \n\\end{align}\\]\\(\\alpha_0\\) \\(\\beta_0\\) constants.equation can’t directly estimated never observe \\(P^*\\). suppose randomize \\(D_t\\). \\(D_t\\) independent \\(P^*_t\\) \\(\\varepsilon_t\\). taking conditional expectations respect \\(D_t\\), get:\\[\\begin{align}\n\\small\n\\underbrace{E\\big[RC_{t+1}\\mid D_t=1\\big] - E\\big[RC_{t+1}\\mid D_t=0\\big]}_{ \\text{Observable}} &= \\pi_0\\big[P^{*D}_{t+1} - P^{*R}_{t+1}\\big] \\\\\n&+ \\underbrace{\\pi_1\\big[P^D_{t+1}-P^R_{t+1}\\big]}_{\\text{Observable}} \\\\\n&=\\underbrace{\\gamma}_{ \\text{Total effect initial win future roll call votes}} \\\\\n\\end{align}\\]\\[\\begin{align}\n\\underbrace{E\\big[RC_{t}\\mid D_t=1\\big] - E\\big[RC_{t}\\mid D_t=0\\big]}_{ \\text{Observable}} = \\pi_1 \\\\\n\\underbrace{E\\big[D_{t+1}\\mid D_t=1\\big] - E\\big[D_{t+1}\\mid D_t=0\\big]}_{\\text{Observable}} = P_{t+1}^D - P_{t+1}^R\n\\end{align}\\]“elect” component \\(\\pi_1[P_{t+1}^D - P_{t+1}^R]\\) estimated difference mean voting records parties time \\(t\\). fraction districts won Democrats \\(t+1\\) estimate \\([P_{t+1}^D - P_{t+1}^R]\\). can estimate total effect, \\(\\gamma\\), Democrat victory \\(t\\) \\(RC_{t+1}\\), can net elect component implicitly get “effect” component.random assignment \\(D_t\\) crucial. without , equation reflect \\(\\pi_1\\) selection (.e., Democratic districts liberal bliss points). authors aim randomize \\(D_t\\) using RDD, ’ll now discuss detail.Buy print version today:","code":""},{"path":"ch5.html","id":"replication-exercise","chapter":"6 Regression Discontinuity","heading":"6.4.1 Replication exercise","text":"two main data sets project. first measure liberal official voted. collected Americans Democratic Action (ADA) linked House Representatives election results 1946–1995. Authors use ADA score US House representatives 1946 1995 voting record index. Congress, ADA chose twenty-five high-profile roll-call votes created index varying 0 100 representative. Higher scores correspond “liberal” voting record. running variable study vote share. share votes went Democrat. ADA scores linked election returns data period.Recall need randomization \\(D_t\\). authors clever solution. use arguably exogenous variation Democratic wins check whether convergence divergence correct. convergence true, Republicans Democrats just barely won vote almost identically, whereas divergence true, vote differently margins close race. “margins close race” crucial idea margins close race distribution voter preferences . voter preferences , policies diverge cutoff, suggests politicians voters driving policy making.exogenous shock comes discontinuity running variable. vote share just 0.5, Democratic candidate wins. argue just around cutoff, random chance determined Democratic win—hence random assignment \\(D_t\\) (Cattaneo, Frandsen, Titiunik 2015). Table 6.6 reproduction Cattaneo et al.’s main results. effect Democratic victory increases liberal voting 21 points next period, 48 points current period, probability reelection 48%. authors find evidence divergence incumbency advantage using design. Let’s dig data now see can find authors getting results. examine results around Table 6.6 playing around data different specifications.Table 6.6:  Original results based ADA Scores – Close Elections Sample\nStandard errors parentheses. unit observation district-congressional session. sample includes observations Democrat vote share time \\(t\\) strictly 48 percent 52 percent. estimated gap difference average relevant variable observations Democrat vote share time \\(t\\) strictly 50 percent 52 percent observations Democrat vote share time \\(t\\) strictly 48 percent 50 percent. Time \\(t\\) \\(t+1\\) refer congressional sessions. \\(ADA_t\\) adjusted ADA voting score. Higher ADA scores correspond liberal roll-call voting records. Sample size 915\nlmb_1.dolmb_1.RWe reproduce regression results Lee, Moretti, Butler Table 46. results close Lee, Moretti, Butler’s original table, slightly different. ignore now. main thing see used regressions limited window right around cutoff estimate effect. local regressions sense use data close cutoff. Notice window chose—using observations 0.48 0.52 vote share. regression estimating coefficient \\(D_t\\) right around cutoff. happens use data?lmb_2.dolmb_2.RTable 6.7:  Results based ADA Scores – Full Sample\nCluster robust standard errors parenthesis. \\(^{*}\\) p<0.10, \\(^{**}\\) p<0.05, \\(^{***}\\) p<0.01\nNotice use data, get somewhat different effects (Table6.7). effect future ADA scores gets larger 10 points, contemporaneous effect gets smaller. effect incumbency, though, increases considerably. see simply running regression yields different estimates include data far cutoff .Neither regressions included controls running variable though. also doesn’t use recentering running variable. let’s . simply subtract 0.5 running variable values 0 vote share equals 0.5, negative values Democratic vote shares less 0.5, positive values Democratic vote shares 0.5. , type following lines:lmb_3.dolmb_3.RTable 6.8:  Results based ADA Scores – Full Sample\nCluster robust standard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{***}\\) \\(p<0.01\\)\nreport analysis programming Table 6.8. incumbency effect falls closer Lee, Moretti, Butler (2004) find, effects still quite different.common, though, allow running variable vary either side discontinuity, exactly implement ? Think —need regression line either side, means necessarily two lines left right discontinuity. , need interaction—specifically interaction running variable treatment variable. implement Stata, can use code shown lmb_4..lmb_4.dolmb_4.RTable 6.9:  Results based ADA Scores – Full Sample linear interactions\nCluster robust standard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{***}\\) \\(p<0.01\\)\nTable 6.9, report global regression analysis running variable interacted treatment variable. pulled coefficients somewhat, remain larger found used observations within 0.02 points 0.5. Finally, let’s estimate model quadratic.lmb_5.dolmb_5.RTable 6.10:  Results based ADA Scores – Full Sample linear quadratic interactions\nCluster robust standard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{***}\\) \\(p<0.01\\)\nIncluding quadratic causes estimated effect democratic victory future voting fall considerably (see Table 6.10). effect contemporaneous voting smaller Lee, Moretti, Butler (2004) find, incumbency effect. purpose simply illustrate standard steps using global regressions.notice, still estimating global regressions. reason coefficient larger. suggests exist strong outliers data causing distance \\(c_0\\) spread widely. natural solution limit analysis smaller window. drop observations far away \\(c_0\\) omit influence outliers estimation cutoff. Since used \\(+/-\\) \\(-0.02\\) last time, ’ll use \\(+/-\\) \\(-0.05\\) time just mix things .lmb_6.dolmb_6.RTable 6.11:  Results based ADA Scores – Close election sample linear quadratic interactions\nCluster robust standard errors parenthesis. \\(^{*}\\)\\(p<0.10\\), \\(^{**}\\)\\(p<0.05\\), \\(^{**}\\)\\(^{*}\\)\\(p<0.01\\)\ncan seen Table 6.11, limit analysis \\(+/-\\) 0.05 around cutoff, using observations away cutoff used initial analysis. ’s 2,441 observations analysis opposed 915 original analysis. also see including quadratic interaction pulled estimated size future voting considerably, even using smaller sample.putting aside, let’s talk just . First fit model without controlling running variable. included running variable, introduced variety ways. instance, interacted variable Democratic vote share democratic dummy, well including quadratic. analysis, extrapolated trends lines running variable beyond support data estimate local average treatment effects right cutoff.also saw inclusion running variable form tended reduce effect victory Democrats future Democratic voting patterns, interesting. Lee, Moretti, Butler (2004) original estimate around 21 attenuated considerably include controls running variable, even go back estimating local flexible regressions. effect remains significant, considerably smaller, whereas immediate effect remains quite large.still ways explore impact treatment cutoff. instance, Hahn, Todd, Klaauw (2001) clarified assumptions RDD—specifically, continuity conditional expected potential outcomes—also framed estimation nonparametric problem emphasized using local polynomial regressions. exactly mean though practice?\nFigure 6.19: Lee, Moretti, Butler (2004), Figure \nNonparametric methods mean lot different things different people statistics, RDD contexts, idea estimate model doesn’t assume functional form relationship outcome variable \\((Y)\\) running variable \\((X)\\). model something like :\n\\[\nY=f(X) + \\varepsilon\n\\]\nbasic method calculate \\(E[Y]\\) bin \\(X\\), like histogram. Stata option called cmogram, created Christopher Robert. program lot useful options, can re-create important figures Lee, Moretti, Butler (2004). Figure 6.19 shows relationship Democratic win (function running variable, Democratic vote share) candidates, second-period ADA score.reproduce , options. manually create figure using either “twoway” command Stata “ggplot” R. ’m going show using canned cmogram routine created, ’s quick--dirty way get information data.lmb_7.dolmb_7.R\nFigure 6.20: Using cmogram quadratic fit confidence intervals. Reprinted Lee, Moretti, Butler (2004)\nFigure 6.20 shows output program. Notice similarities produced Lee, Moretti, Butler (2004) produced figure. differences subtle changes binning used two figures.options quadratic fit, though, ’s useful compare graph one fit linear model. Now, strong trends running variable, probably just want use quadratic, let’s see get use simpler straight lines.\nFigure 6.21: Using cmogram linear fit. Reprinted Lee, Moretti, Butler (2004)\nFigure 6.21 shows get use linear fit data left right cutoff. Notice influence outliers far actual cutoff play estimate causal effect cutoff. go away restricted bandwidth shorter distances cutoff, leave .Finally, can use lowess fit. lowess fit less crawls data runs small regression small cuts data. can give figure zigzag appearance. nonetheless show Figure 40.\nFigure 6.22: Using cmogram lowess fit. Reprinted Lee, Moretti, Butler (2004)\ndon’t appear trends running variable, polynomials aren’t going buy much. good papers report linear fit weren’t strong trends begin . instance, consider Carrell, Hoekstra, West (2011). authors interested causal effect drinking academic test outcomes students Air Force Academy. running variable precise age student, know student’s date birth know date every exam taken Air Force Academy. Air Force Academy restricts students’ social life, starker increase drinking age 21 campus might case typical university campus. examined causal effect drinking age normalized grades using RDD, weren’t strong trends data, presented graph linear fit. choice large part based , eyeball, best fit data.Hahn, Todd, Klaauw (2001) shown one-sided kernel estimation lowess may suffer poor properties point interest boundary (.e., discontinuity). called “boundary problem.” propose using local linear nonparametric regressions instead. regressions, weight given observations center.can also estimate kernel-weighted local polynomial regressions. Think weighted regression restricted window like ’ve (hence word “local”) chosen kernel provides weights. rectangular kernel give results \\(E[Y]\\) given bin \\(X\\), triangular kernel give importance observations closest center. method sensitive size bandwidth chosen. sense, ’s similar ’ve . Figure 6.23 shows visually.lmb_8.dolmb_8.R\nFigure 6.23: Local linear nonparametric regressions\ncouple final things. First, recall continuity assumption. continuity assumption specifically involves continuous conditional expectation functions potential outcomes throughout cutoff, therefore untestable. ’s right—’s untestable assumption. , can check whether changes conditional expectation functions exogenous covariates changing result cutoff. ’s common look things like race gender around cutoff. can use methods , . RDD paper always involve placebos; even though direct tests continuity assumption, indirect tests. Remember, publishing, readers aren’t familiar thing ’re studying, task explain readers know. Anticipate objections sources skepticism. Think like . Try put stranger’s shoes. test skepticisms best ability.Second, saw importance bandwidth selection, window, estimating causal effect using method, well importance selection polynomial length. ’s always trade-choosing bandwidth bias variance—shorter window, lower bias, less data, variance estimate increases. Recent work focused optimal bandwidth selection, Imbens Kalyanaraman (2011) Calonico, Cattaneo, Titiunik (2014). latter can implemented user-created rdrobust command. methods ultimately choose optimal bandwidths may differ left right cutoff based bias-variance trade-. Let’s repeat analysis using nonparametric method. coefficient 46.48 standard error 1.24.lmb_9.dolmb_9.RThis method, ’ve repeatedly said, data-greedy gobbles data discontinuity. ideally kinds methods used large numbers observations sample sizable number observations discontinuity. case, harmony findings across results. isn’t, may sufficient power pick effect.Finally, look implementation McCrary density test. implement test using local polynomial density estimation (Cattaneo, Jansson, Ma 2019). requires installing two files Stata. Visually inspecting graph Figure 6.24, see signs manipulation running variable cutoff.\nFigure 6.24: McCrary density test using local linear nonparametric regressions\nlmb_10.dolmb_10.R","code":"use https://github.com/scunning1975/mixtape/raw/master/lmb-data.dta, clear\n\n* Replicating Table 1 of Lee, Moretti and Butler (2004)\nreg score lagdemocrat    if lagdemvoteshare>.48 & lagdemvoteshare<.52, cluster(id)\nreg score democrat       if lagdemvoteshare>.48 & lagdemvoteshare<.52, cluster(id)\nreg democrat lagdemocrat if lagdemvoteshare>.48 & lagdemvoteshare<.52, cluster(id)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nlmb_data <- read_data(\"lmb-data.dta\")\n\nlmb_subset <- lmb_data %>% \n  filter(lagdemvoteshare>.48 & lagdemvoteshare<.52)\n\nlm_1 <- lm_robust(score ~ lagdemocrat, data = lmb_subset, clusters = id)\nlm_2 <- lm_robust(score ~ democrat, data = lmb_subset, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat, data = lmb_subset, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Use all the data\nreg score lagdemocrat, cluster(id)\nreg score democrat, cluster(id)\nreg democrat lagdemocrat, cluster(id)\n#using all data (note data used is lmb_data, not lmb_subset)\n\nlm_1 <- lm_robust(score ~ lagdemocrat, data = lmb_data, clusters = id)\nlm_2 <- lm_robust(score ~ democrat, data = lmb_data, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat, data = lmb_data, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Re-center the running variable (voteshare)\ngen demvoteshare_c = demvoteshare - 0.5\nreg score lagdemocrat demvoteshare_c, cluster(id)\nreg score democrat demvoteshare_c, cluster(id)\nreg democrat lagdemocrat demvoteshare_c, cluster(id)\nlmb_data <- lmb_data %>% \n  mutate(demvoteshare_c = demvoteshare - 0.5)\n\nlm_1 <- lm_robust(score ~ lagdemocrat + demvoteshare_c, data = lmb_data, clusters = id)\nlm_2 <- lm_robust(score ~ democrat + demvoteshare_c, data = lmb_data, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat + demvoteshare_c, data = lmb_data, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Use all the data but interact the treatment variable with the running variable\nxi: reg score i.lagdemocrat*demvoteshare_c, cluster(id)\nxi: reg score i.democrat*demvoteshare_c, cluster(id)\nxi: reg democrat i.lagdemocrat*demvoteshare_c, cluster(id)\nlm_1 <- lm_robust(score ~ lagdemocrat*demvoteshare_c, \n                  data = lmb_data, clusters = id)\nlm_2 <- lm_robust(score ~ democrat*demvoteshare_c, \n                  data = lmb_data, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c, \n                  data = lmb_data, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Use all the data but interact the treatment variable with the running variable and a quadratic\ngen demvoteshare_sq = demvoteshare_c^2\nxi: reg score lagdemocrat##c.(demvoteshare_c demvoteshare_sq), cluster(id)\nxi: reg score democrat##c.(demvoteshare_c demvoteshare_sq), cluster(id)\nxi: reg democrat lagdemocrat##c.(demvoteshare_c demvoteshare_sq), cluster(id)\nlmb_data %>% \n  mutate(demvoteshare_sq = demvoteshare_c^2)\n\nlm_1 <- lm_robust(score ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\nlm_2 <- lm_robust(score ~ democrat*demvoteshare_c + democrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Use 5 points from the cutoff\nxi: reg score lagdemocrat##c.(demvoteshare_c demvoteshare_sq) if lagdemvoteshare>.45 & lagdemvoteshare<.55, cluster(id)\nxi: reg score democrat##c.(demvoteshare_c demvoteshare_sq) if lagdemvoteshare>.45 & lagdemvoteshare<.55, cluster(id)\nxi: reg democrat lagdemocrat##c.(demvoteshare_c demvoteshare_sq) if lagdemvoteshare>.45 & lagdemvoteshare<.55, cluster(id)\nlmb_data %>% \n  filter(demvoteshare > .45 & demvoteshare < .55) %>%\n  mutate(demvoteshare_sq = demvoteshare_c^2)\n\nlm_1 <- lm_robust(score ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\nlm_2 <- lm_robust(score ~ democrat*demvoteshare_c + democrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\nlm_3 <- lm_robust(democrat ~ lagdemocrat*demvoteshare_c + lagdemocrat*demvoteshare_sq, \n                  data = lmb_data, clusters = id)\n\nsummary(lm_1)\nsummary(lm_2)\nsummary(lm_3)* Nonparametric estimation graphic\nssc install cmogram\ncmogram score lagdemvoteshare, cut(0.5) scatter line(0.5) qfitci\ncmogram score lagdemvoteshare, cut(0.5) scatter line(0.5) lfit\ncmogram score lagdemvoteshare, cut(0.5) scatter line(0.5) lowess\n#aggregating the data\ncategories <- lmb_data$lagdemvoteshare\n\ndemmeans <- split(lmb_data$score, cut(lmb_data$lagdemvoteshare, 100)) %>% \n  lapply(mean) %>% \n  unlist()\n\nagg_lmb_data <- data.frame(score = demmeans, lagdemvoteshare = seq(0.01,1, by = 0.01))\n\n#plotting\nlmb_data <- lmb_data %>% \n  mutate(gg_group = case_when(lagdemvoteshare > 0.5 ~ 1, TRUE ~ 0))\n         \nggplot(lmb_data, aes(lagdemvoteshare, score)) +\n  geom_point(aes(x = lagdemvoteshare, y = score), data = agg_lmb_data) +\n  stat_smooth(aes(lagdemvoteshare, score, group = gg_group), method = \"lm\", \n              formula = y ~ x + I(x^2)) +\n  xlim(0,1) + ylim(0,100) +\n  geom_vline(xintercept = 0.5)\n\nggplot(lmb_data, aes(lagdemvoteshare, score)) +\n  geom_point(aes(x = lagdemvoteshare, y = score), data = agg_lmb_data) +\n  stat_smooth(aes(lagdemvoteshare, score, group = gg_group), method = \"loess\") +\n  xlim(0,1) + ylim(0,100) +\n  geom_vline(xintercept = 0.5)\n\nggplot(lmb_data, aes(lagdemvoteshare, score)) +\n  geom_point(aes(x = lagdemvoteshare, y = score), data = agg_lmb_data) +\n  stat_smooth(aes(lagdemvoteshare, score, group = gg_group), method = \"lm\") +\n  xlim(0,1) + ylim(0,100) +\n  geom_vline(xintercept = 0.5)* Note kernel-weighted local polynomial regression is a smoothing method.\ncapture drop sdem* x1 x0\nlpoly score demvoteshare if democrat == 0, nograph kernel(triangle) gen(x0 sdem0) bwidth(0.1)}\nlpoly score demvoteshare if democrat == 1, nograph kernel(triangle) gen(x1 sdem1)  bwidth(0.1)}\nscatter sdem1 x1, color(red) msize(small) || scatter sdem0 x0, msize(small) color(red) xline(0.5,lstyle(dot)) legend(off) xtitle(\"Democratic vote share\") ytitle(\"ADA score\")\nlibrary(tidyverse)\nlibrary(stats)\n\nsmooth_dem0 <- lmb_data %>% \n  filter(democrat == 0) %>% \n  select(score, demvoteshare)\nsmooth_dem0 <- as_tibble(ksmooth(smooth_dem0$demvoteshare, smooth_dem0$score, \n                                 kernel = \"box\", bandwidth = 0.1))\n\n\nsmooth_dem1 <- lmb_data %>% \n  filter(democrat == 1) %>% \n  select(score, demvoteshare) %>% \n  na.omit()\nsmooth_dem1 <- as_tibble(ksmooth(smooth_dem1$demvoteshare, smooth_dem1$score, \n                                 kernel = \"box\", bandwidth = 0.1))\n\nggplot() + \n  geom_smooth(aes(x, y), data = smooth_dem0) +\n  geom_smooth(aes(x, y), data = smooth_dem1) +\n  geom_vline(xintercept = 0.5)* Local polynomial point estimators with bias correction\nssc install rdrobust, replace\nrdrobust score demvoteshare, c(0.5)\nlibrary(tidyverse)\nlibrary(rdrobust)\n\nrdr <- rdrobust(y = lmb_data$score,\n                x = lmb_data$demvoteshare, c = 0.5)\nsummary(rdr)* McCrary density test\nnet install rddensity, from(https://sites.google.com/site/rdpackages/rddensity/stata) replace\nnet install lpdensity, from(https://sites.google.com/site/nppackages/lpdensity/stata) replace\nrddensity demvoteshare, c(0.5) plot\nlibrary(tidyverse)\nlibrary(rddensity)\nlibrary(rdd)\n\nDCdensity(lmb_data$demvoteshare, cutpoint = 0.5)\n\ndensity <- rddensity(lmb_data$demvoteshare, c = 0.5)\nrdplotdensity(density, lmb_data$demvoteshare)"},{"path":"ch5.html","id":"concluding-remarks-about-close-election-designs","chapter":"6 Regression Discontinuity","heading":"6.4.2 Concluding remarks about close-election designs","text":"Let’s circle back close-election design. design since become practically cottage industry within economics political science. extended types elections outcomes. One paper like lot used close gubernatorial elections examine effect Democratic governors wage gap workers different races (Beland 2015). dozens .critique Caughey Sekhon (2011) called question validity Lee’s analysis House elections. found bare winners bare losers US House elections differed considerably pretreatment covariates, formally evaluated Lee, Moretti, Butler (2004). covariate imbalance got even worse closest elections. conclusion sorting problems got severe, less, closest House races, suggesting races used RDD.first glance, appeared criticism Caughey Sekhon (2011) threw cold water entire close-election design, since know case. appears Caughey Sekhon (2011) criticism may relevant subset House races characterize time periods types races. Eggers et al. (2014) evaluated 40,000 close elections, including House time periods, mayoral races, types races political offices US nine countries. case encountered exhibited type pattern described Caughey Sekhon (2011). Eggers et al. (2014) conclude assumptions behind RDD close-election design likely met wide variety electoral settings perhaps one best RD designs going forward.","code":""},{"path":"ch5.html","id":"regression-kink-design","chapter":"6 Regression Discontinuity","heading":"6.5 Regression Kink Design","text":"Many times, concept running variable shifting unit treatment turn causing jump outcome sufficient. instances idea “jump” doesn’t describe happens. couple papers David Card coauthors extended regression discontinuity design order handle different types situations. notable Card et al. (2015), introduced new method called regression kink design, RKD. intuition rather simple. Rather cutoff causing discontinuous jump treatment variable cutoff, changes first derivative, known kink. Kinks often embedded policy rules, thanks Card et al. (2015), can use kinks identify causal effect policy exploiting jump first derivative.Card et al. (2015) paper applies design answer question whether level unemployment benefits affects length time spent unemployed Austria. Unemployment benefits based income base period. minimum benefit level isn’t binding people low earnings. benefits 55% earnings base period. maximum benefit level adjusted every year, creates discontinuity schedule.\nFigure 6.25: RKD kinks. Reprinted Card et al. (2015).\nFigure 6.25 shows relationship base earnings unemployment benefits around discontinuity. ’s visible kink empirical relationship average benefits base earnings. can see sharp decline slope function base-year earnings pass threshold. Figure 6.26 presents similar picture, time unemployment duration. , clear kink base earnings pass threshold. authors conclude increases unemployment benefits Austrian context exert relatively large effects unemployment duration.\nFigure 6.26: Unemployment duration. Reprinted Card et al. (2015).\n","code":""},{"path":"ch5.html","id":"conclusion-4","chapter":"6 Regression Discontinuity","heading":"6.6 Conclusion","text":"regression discontinuity design often considered winning design upside credibly identifying causal effects. designs, credibility comes deep institutional knowledge, particularly surrounding relationship running variable, cutoff, treatment assignment, outcomes . Insofar one can easily find situation running variable passing threshold leads units siphoned treatment, continuity believable, ’re probably sitting great opportunity, assuming can use something theoretically interesting policy relevant others.Regression discontinuity design opportunities abound, particularly within firms government agencies, reason organizations face scarcity problems must use method ration treatment. Randomization fair way , often method used. running variable another method. Routinely, organizations simply use continuous score assign treatments arbitrarily picking cutoff everyone receives treatment. Finding can yield cheap yet powerfully informative natural experiment. chapter attempted lay basics design. area continues grow lightning pace. encourage see chapter starting point, ending point.Buy print version today:","code":""},{"path":"ch6.html","id":"ch6","chapter":"7 Instrumental Variables","heading":"7 Instrumental Variables","text":"Buy print version today:Just Archimedes said, “Give fulcrum, shall move world,” just easily say good-enough instrument, can identify causal effect. , hyperbole, reasons soon see, nonetheless case instrumental variables (IV) design potentially one important research designs ever devised. also unique one instances econometric estimator simply ripped statistics (e.g., Eicker-Huber-White standard errors) imported field (e.g., like regression discontinuity). IV invented economist, history fascinating.","code":""},{"path":"ch6.html","id":"history-of-instrumental-variables-father-and-son","chapter":"7 Instrumental Variables","heading":"7.1 History of Instrumental Variables: Father and Son","text":"Philip Wright born 1861 died 1934. received bachelor’s degree Tufts 1884 master’s degree Harvard 1887. son, Sewall Wright, born 1889 Philip 28. family moved Massachusetts Galesburg, Illinois, Philip took position professor mathematics economics Lombard College. Philip published numerous articles books economics career, published poetry, . can see vita https://scholar.harvard.edu/files/stock/files/wright_cv.jpg.108 Sewall attended Lombard College took college mathematics courses father.1913, Philip took position Harvard, Sewall entered graduate student. Philip later leave Brookings Institute, Sewall take first job Department Zoology University Chicago, eventually promoted professor 1930.Philip prolific, , given sizable teaching service requirements, impressive. published top journals Quarterly Journal Economics, Journal American Statistical Association, Journal Political Economy, American Economic Review. common theme across many publications identification problem. acutely aware intent solving .1928, Philip writing book animal vegetable oils. reason? believed recent tariff increases harming international relations. wrote damage tariffs, affected animal vegetable oils. book, turns , become classic—tariffs oils, first proof existence instrumental variables estimator.father publishing like fiend economics, Sewall Wright revolutionizing field genetics. invented path analysis, precursor Pearl’s directed acyclical graphic models, made important contributions theory evolution genetics. genius. decision follow family business (economics) created bit tension two men, evidence suggests found intellectually stimulating.book vegetable oil tariffs, appendix (entitled Appendix B) calculus instrumental variables estimator worked . Elsewhere, Philip thanked son valuable contributions written, referring path analysis Sewall taught . path analysis, turned , played key role Appendix B.Appendix B showed solution identification problem. long economist willing impose restrictions problem, system equations can identified. Specifically, one instrument supply, supply demand errors uncorrelated, elasticity demand can identified.wrote Appendix B? Either man ’ve done . chapter economics book, points Philip. used path analysis, points Sewall. Historians debated , even going far accuse Philip stealing idea son. Philip stole idea, mean published Appendix B, failed give proper attribution son, least strange oversight. come Stock Trebbi (2003) offer opinions debate authorship.Stock Trebbi (2003) tried determine authorship Appendix B using “stylometric analysis.” Stylometric analysis used applications, identify author 1996 political novel Primary Colors (Joseph Klein) unsigned Federalist Papers. Stock Trebbi (2003) easily best application stylometric analysis economics.109The method akin contemporary machine learning methods. authors collected raw data containing known original academic writings man, plus first chapter Appendix B book question. footnotes, graphs, figures excluded. Blocks 1,000 words selected files. Fifty-four blocks selected: twenty written Sewall certainty, twenty-five Philip, six Appendix B, three chapter 1. Chapter 1 always attributed Philip, Stock Trebbi (2003) treat three blocks unknown check whether model correctly predicting authorship authorship already known.stylometric indicators used included frequency occurrence block 70 function words. list taken separate study. 70 function words produced 70 numerical variables, count, per 1,000 words, individual function word block. words dropped (e.g., “things” occurred ), leaving 69 function words.second set stylometric indicators, taken another study, concerned grammatical constructions. Stock Trebbi (2003) used 18 grammatical constructions, frequency counts. included things like noun followed adverb, total occurrences prepositions, coordinating conjunction followed noun, . one dependent variable analysis, authorship. independent variables 87 covariates (69 function word counts 18 grammatical statistics).results analysis absolutely fascinating. instance, many covariates large \\(t\\)-statistics, unlikely really stylistic differences authors indicators independently distributed.find? interesting regression analysis. write:regressed authorship intercept, first two principal components grammatical statistics first two principal components function word counts, attribute authorship depending whether predicted value greater less 0.5. (p.191)find? Appendix B chapter 1 blocks assigned Philip, Sewall. robustness checks, still pointed Philip author.Writing Appendix B solving problem became Appendix B technically distinct. nonetheless love story many reasons. First, love idea econometric estimator important instrumental variables roots economics. ’m accustomed stories actual econometric estimator lifted statistics (Huber-White standard errors) educational psychology (regression discontinuity) ’s nice know economists added designs canon. part story love father-son component. ’s encouraging know father son can overcome differences intellectual collaborations . relationships important, tensions, arise, vigorously pursued tensions dissolve possible. Relationships, love generally, matter . Philip Sewall give story .","code":""},{"path":"ch6.html","id":"intuition-of-instrumental-variables","chapter":"7 Instrumental Variables","heading":"7.2 Intuition of Instrumental Variables","text":"","code":""},{"path":"ch6.html","id":"canonical-iv-dag","chapter":"7 Instrumental Variables","heading":"7.2.1 Canonical IV DAG","text":"understand instrumental variables estimator, helpful start DAG shows chain causal effects contains information needed understand instrumental variables strategy. First, notice backdoor path \\(D\\) \\(Y\\): \\(D \\leftarrow U \\rightarrow Y\\). Furthermore, note \\(U\\) unobserved econometrician, causes backdoor path remain open. kind selection unobservables, exist conditioning strategy satisfy backdoor criterion (data). , throw arms, let’s look \\(Z\\) operates pathways.First, mediated pathway \\(Z\\) \\(Y\\) via \\(D\\). \\(Z\\) varies, \\(D\\) varies, causes \\(Y\\) change. , even though \\(Y\\) varying \\(Z\\) varies, notice \\(Y\\) varying \\(D\\) varied. sometimes hear people describe “” assumption. , \\(Z\\) affects \\(Y\\) “” \\(D\\).Imagine moment though. Imagine \\(D\\) consists people making choices. Sometimes choices affect \\(Y\\), sometimes choices merely correlated changes \\(Y\\) due unobserved changes \\(U\\). along comes shock, \\(Z\\), induces people \\(D\\) make different decisions. happen?Well, one, people’s decisions change, \\(Y\\) change , causal effect. correlation \\(D\\) \\(Y\\) situation reflect causal effect. reason \\(D\\) collider along backdoor path \\(Z\\) \\(Y\\).’m done metaphor. Let’s assume \\(D\\) variable, people, people change behavior \\(D\\). ? Well, situation, \\(Z\\) causing change \\(Y\\) just subset population. instrument changes behavior women, instance, causal effect \\(D\\) \\(Y\\) reflect causal effect women’s choices, men’s choices.two ideas inherent previous paragraph want emphasize. First, heterogeneous treatment effects (e.g., men affect \\(Y\\) differently women ), \\(Z\\) shock identified causal effect \\(D\\) \\(Y\\). piece causal effect may valid population women whose behavior changed response \\(Z\\); may reflective men’s behavior affect \\(Y\\). second, \\(Z\\) inducing change \\(Y\\) via fraction change \\(D\\), ’s almost though less data identify causal effect really .see two difficulties interpreting instrumental variables identifying parameter using instrumental variables. Instrumental variables identify causal effect group units whose behaviors changed result instrument. call causal effect complier population; example, women “complied” instrument, know effect . second, instrumental variables typically going larger standard errors, , fail reject many instances reason underpowered.Moving along, let’s return DAG. Notice drew DAG \\(Z\\) independent \\(U\\). can see \\(D\\) collider along \\(Z \\rightarrow D \\leftarrow U\\) path, implies \\(Z\\) \\(U\\) independent. called “exclusion restriction,” discuss detail later. briefly, IV estimator assumes \\(Z\\) independent variables determine \\(Y\\) except \\(D\\).Second, \\(Z\\) correlated \\(D\\), correlation \\(D\\) (\\(D\\)’s effect \\(Y\\)), \\(Z\\) correlated \\(Y\\) effect \\(D\\). relationship \\(Z\\) \\(D\\) called “first stage” two-stage least squares estimator, kind IV estimator. reason correlated \\(Y\\) via \\(D\\) \\(D\\) collider along path \\(Z\\rightarrow D \\leftarrow U \\rightarrow Y\\).","code":""},{"path":"ch6.html","id":"good-instruments-should-feel-weird","chapter":"7 Instrumental Variables","heading":"7.2.2 Good instruments should feel weird","text":"know good instrument? One, require prior knowledge. ’d encourage write prior knowledge DAG use reflect feasibility design. starting point, can contemplate identifying causal effect using IV can theoretically logically defend exclusion restriction, since exclusion restriction untestable assumption. defense requires theory, since people aren’t comfortable theoretical arguments like , tend eschew use IV. applied microeconomists skeptical IV able tell limitless stories exclusion restrictions hold., let’s say think good instrument. might defend someone else? necessary sufficient condition instrument can satisfy exclusion restriction people confused tell instrument’s relationship outcome. Let explain. one likely confused tell think family size reduce labor supply women. don’t need Becker model convince women children probably employed outside home less often fewer children.think told mothers whose first two children gender employed outside home less whose two children balanced sex ratio? probably confused , , gender composition one’s first two children whether woman works outside home? ’s head scratcher. ’re confused , logically, whether first two kids gender versus gender doesn’t seem face change incentives women work outside home, based reservation wages market wages. yet, empirically true first two children boy, many families third compared boy girl first. gives?gender composition first two children matters family preferences diversity gender. Families first two children boys likely try hopes ’ll girl. two girls. Insofar parents like least one boy one girl, two boys might cause roll dice girl.see characteristics good instrument. ’s weird lay person good instrument (two boys) changes outcome first changing endogenous treatment variable (family size) thus allowing us identify causal effect family size outcome (labor supply). without knowledge endogenous variable, relationships instrument outcome don’t make much sense. ? instrument irrelevant determinants outcome except effect endogenous treatment variable. also see another quality instrument like, ’s quasi-random.moving along, ’d like illustrate “weird instrument” one way, using two favorite artists: Chance Rapper Kanye West. start chapter, posted line Kanye West’s wonderful song “Ultralight Beam” underrated Life Pablo. song, Chance Rapper sings:made “Sunday Candy,” ’m never going hell.\nmet Kanye West, ’m never going fail.Several years “Ultralight Beam,” Chance made song called “Sunday Candy.” ’s great song encourage listen . Chance makes strange argument “Ultralight Beam.” claims made “Sunday Candy,” therefore won’t go hell. Now even religious person find perplexing, nothing Christian theology eternal damnation link making song afterlife. , argue, “weird instrument” without knowing endogenous variable mediated path \\(SC \\rightarrow ? \\rightarrow H\\), two phenomena don’t seem go together.let’s say told Chance made “Sunday Candy,” got phone call old preacher. preacher loved song invited Chance come sing church. revisiting childhood church, Chance religious experience caused convert back Christianity. Now, now, statement make sense. isn’t “Sunday Candy” shaped path afterlife, much “Sunday Candy” caused particular event caused beliefs future change. line makes weird argument makes “Sunday Candy” good instrument.let’s take second line—“met Kanye West, ’m never going fail.” Unlike first line, likely good instrument. ? don’t even need know variable along mediated path \\(KW \\rightarrow ? \\rightarrow F\\) doubt exclusion restriction. musician, relationship Kanye West can possibly make break career. Kanye make career collaborating song introducing highly talented producers. shortage ways relationship Kanye West can cause successful, regardless whatever unknown endogenous variable placed mediated path. since ’s easy tell story knowing Kanye West directly causes one’s success, knowing Kanye West likely bad instrument. simply won’t satisfy exclusion restriction context.Ultimately, good instruments jarring precisely exclusion restriction—two things (gender composition work) don’t seem go together. go together, likely mean exclusion restriction violated. don’t, person confused, minimum possible candidate good instrument. commonsense explanation “” assumption.","code":""},{"path":"ch6.html","id":"homogeneous-treatment-effects","chapter":"7 Instrumental Variables","heading":"7.3 Homogeneous Treatment Effects","text":"two ways discuss instrumental variables design: one world treatment causal effect everybody (“homogeneous treatment effects”) one world treatment effects can differ across population (“heterogeneous treatment effects”). homogeneous treatment effects, depend traditional approach rather potential outcomes notation. treatment effect constant, don’t feel need potential outcomes notation much.Instrumental variables methods typically used address omitted variable bias, measurement error, simultaneity. instance, quantity price determined intersection supply demand, observational correlation price quantity uninformative elasticities associated supply demand curves. Philip Wright understood , investigated problem intensely.assume homogeneous treatment effect \\(\\delta\\) every person. means college caused wages increase 10%, also caused wages increase 10%. Let’s start illustrating problem omitted variable bias. Assume classical labor problem ’re interested causal effect schooling earnings, schooling endogenous unobserved ability. Let’s draw simple DAG illustrate setup.can represent DAG simple regression. Let true model earnings :\\[\\begin{align}\n   Y_i = \\alpha + \\delta S_i + \\gamma A_i + \\varepsilon_i\n\\end{align}\\]\\(Y\\) log earnings, \\(S\\) schooling measured years, \\(\\) individual “ability,” \\(\\varepsilon\\) error term uncorrelated schooling ability. reason \\(\\) unobserved simply surveyor either forgot collect couldn’t collect therefore ’s missing data set.110 instance, CPS tells us nothing respondents’ family background, intelligence, motivation, non-cognitive ability. Therefore, since ability unobserved, following equation instead:\\[\\begin{align}\n   Y_i = \\alpha + \\delta S_i + \\eta_i\n\\end{align}\\]\\(\\eta_i\\) composite error term equalling \\(\\gamma A_i + \\varepsilon_i\\). assume schooling correlated ability, therefore correlated \\(\\eta_i\\), making endogenous second, shorter regression. \\(\\varepsilon_i\\) uncorrelated regressors, definition.know derivation least squares operator estimated value \\(\\widehat{\\delta}\\) :\\[\\begin{align}\n   \\widehat{\\delta} = \\dfrac{C(Y,S)}{V(S)} = \\dfrac{E[YS] - E[Y]E[S]}{V(S)}\n\\end{align}\\]Plugging true value \\(Y\\) (longer model), get following:\\[\\begin{align}\n   \\widehat{\\delta} & = \\dfrac{E\\big[\\alpha S + S^2 \\delta + \\gamma SA + \\varepsilon S\\big] - E(S)E\\big[\\alpha + \\delta S + \\gamma + \\varepsilon\\big]}{V(S)} \n   \\\\\n    & = \\dfrac{ \\delta E(S^2) - \\delta E(S)^2 + \\gamma E() - \\gamma E(S)E() + E(\\varepsilon S) - E(S)E(\\varepsilon)}{V(S)}                  \n   \\\\\n    & = \\delta + \\gamma \\dfrac{C()}{V(S)}                                                                                                    \n\\end{align}\\]\\(\\gamma>0\\) \\(C(,S)>0\\), \\(\\widehat{\\delta}\\), coefficient schooling, upward biased. probably case given ’s likely ability schooling positively correlated.let’s assume found really great weird instrument \\(Z_i\\) causes people get schooling independent student ability structural error term. independent ability, means can get around endogeneity problem. ’s associated unobserved determinants earnings, basically makes weird. DAG associated set look like :can use variable, ’ll now show, estimate \\(\\delta\\). First, calculate covariance \\(Y\\) \\(Z\\):\\[\\begin{align}\n   C(Y,Z) & = C(\\alpha \\delta S+\\gamma +\\varepsilon, Z)                                                    \\\\\n          & = E\\big[(\\alpha+\\delta S+\\gamma +\\varepsilon),Z] - E(S) E(Z)                                   \n   \\\\\n          & =\\big\\{\\alpha E(Z)- \\alpha E(Z)\\big\\} + \\delta \\big\\{E(SZ) - E(S)E(Z)\\big\\}                     \\\\\n          & \\quad + \\gamma \\big\\{E(AZ) - E()E(Z)\\big\\} + \\big\\{E(\\varepsilon Z) - E(\\varepsilon)E(Z)\\big\\} \n   \\\\\n          & =\\delta C(S,Z) + \\gamma C(,Z) + C(\\varepsilon, Z)                                              \n\\end{align}\\]Notice parameter interest, \\(\\delta\\) right side. isolate ? can estimate following:\\[\\begin{align}\n   \\widehat{\\delta} = \\dfrac{C(Y,Z)}{C(S,Z)}\n\\end{align}\\]long \\(C(,Z)=0\\) \\(C(\\varepsilon,Z)=0\\).zero covariances statistical truth contained IV DAG earlier. ability independent \\(Z\\), second covariance zero. \\(Z\\) independent structural error term, \\(\\varepsilon\\), zero. , see, meant “exclusion restriction”: instrument must independent parts composite error term.exclusion restriction necessary condition IV work; sufficient condition. , needed exclusion, use random number generator instrument. Exclusion enough. also need instrument highly correlated endogenous variable schooling \\(S\\). higher better. see dividing \\(C(S,Z)\\), necessarily requires covariance zero.numerator simple ratio sometimes called “reduced form,” denominator called “first stage.” terms somewhat confusing, particularly former, “reduced form” means different things different people. IV terminology, relationship instrument outcome . first stage less confusing, gets name two-stage least squares estimator, ’ll discuss next.take probability limit expression, assuming \\(C(,Z)=0\\) \\(C(\\varepsilon , Z)=0\\) due exclusion restriction, get\n\\[\np\\lim\\ \\widehat{\\delta} = \\delta\n\\]\n\\(Z\\) independent \\(\\eta\\) (either ’s correlated \\(\\) \\(\\varepsilon\\)), correlation \\(S\\) \\(Z\\) weak, \\(\\widehat{\\delta}\\) becomes severely biased finite samples.","code":""},{"path":"ch6.html","id":"two-stage-least-squares","chapter":"7 Instrumental Variables","heading":"7.3.1 Two-stage least squares","text":"One intuitive instrumental variables estimators two-stage least squares (2SLS). Let’s review example illustrate helpful explaining IV intuition. Suppose sample data \\(Y\\), \\(S\\), \\(Z\\). observation \\(\\), assume data generated according :\\[\\begin{align}\n   Y_i & = \\alpha + \\delta S_i + \\varepsilon_i \n   \\\\\n   S_i & = \\gamma + \\beta Z_i + \\epsilon_i     \n\\end{align}\\]\\(C(Z,\\varepsilon)=0\\) \\(\\beta \\neq 0\\). former assumption exclusion restriction whereas second assumption non-zero first-stage. Now using IV expression, using result \\(\\sum_{=1}^n(x_i -\\bar{x})=0\\), can write IV estimator :\\[\\begin{align}\n   \\widehat{\\delta} & = \\dfrac{C(Y,Z)}{C(S,Z)}                                                                                                                             \n   \\\\\n    & = \\dfrac{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})(Y_i - \\overline{Y}) }{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z}) (S_i - \\overline{S})} \n   \\\\\n    & =\\dfrac{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})Y_i}{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i -\\overline{Z})S_i}                                       \n\\end{align}\\]substitute true model \\(Y\\), get following:\\[\\begin{align}\n   \\widehat{\\delta} & =\\dfrac{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})\\{\\alpha + \\delta S + \\varepsilon \\}}{\\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})S_i} \\\\\n    & =\\delta + \\dfrac{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})\\varepsilon_i}{ \\dfrac{1}{n} \\sum_{=1}^n (Z_i - \\overline{Z})S_i }             \n   \\\\\n    & =\\delta + \\text{``small $n$ large''}                                                                                                      \n\\end{align}\\], let’s return first description \\(\\widehat{\\delta}\\) ratio two covariances. simple algebraic manipulation, get following:\\[\\begin{align}\n   \\widehat{\\delta} & =\\dfrac{ C(Y,Z)}{C(S,Z)}                               \\\\\n    & =\\dfrac{ \\dfrac{C(Z,Y)}{V(Z)} }{\\dfrac{ C(Z,S)}{V(Z)}} \n\\end{align}\\]denominator equal \\(\\widehat{\\beta}\\).111 can rewrite \\(\\widehat{\\beta}\\) :\\[\\begin{align}\n   \\widehat{\\beta}     & = \\dfrac{ C(Z,S)}{V(Z)} \n   \\\\\n   \\widehat{\\beta}V(Z) & =C(Z,S)                 \n\\end{align}\\]rewrite IV estimator make substitution:\\[\\begin{align}\n   \\widehat{\\delta}_{IV} & =\\dfrac{ C(Z,Y)}{C(Z,S)}                                 \n   \\\\\n        & =\\dfrac{\\widehat{\\beta}C(Z,Y)}{\\widehat{\\beta} C(Z,S)}   \n   \\\\\n        & =\\dfrac{ \\widehat{\\beta} C(Z,Y)}{\\widehat{\\beta}^2 V(Z)} \n   \\\\\n        & = \\dfrac{C(\\widehat{\\beta}Z,Y)}{V(\\widehat{\\beta}Z)}     \n\\end{align}\\]Notice now inside parentheses: \\(\\widehat{\\beta}Z\\), fitted values schooling first-stage regression. longer, words, using \\(S\\)—using fitted values. Recall \\(S=\\gamma + \\beta Z + \\epsilon\\); \\(\\widehat{\\delta} = \\dfrac{ C(\\widehat{\\beta}ZY)}{V(\\widehat{\\beta}Z)}\\) let \\(\\widehat{S} = \\widehat{\\gamma} + \\widehat{\\beta}Z\\). two-stage least squares (2SLS) estimator :\\[\\begin{align}\n   \\widehat{\\delta}_{IV} & = \\dfrac{ C(\\widehat{\\beta}Z,Y)}{V(\\widehat{\\beta}Z)} \n   \\\\\n        & =\\dfrac{C(\\widehat{S},Y)}{V(\\widehat{S})}             \n\\end{align}\\]now show \\(\\widehat{\\beta}C(Y,Z)=C(\\widehat{S},Y)\\), leave show \\(V(\\widehat{\\beta}Z)=V(\\widehat{S})\\).\\[\\begin{align}\n   C(\\widehat{S},Y) & = E[\\widehat{S}Y] - E[\\widehat{S}]E[Y]                                                         \n   \\\\\n    & = E\\Big(Y[\\widehat{\\gamma}+\\widehat{\\beta}Z]\\Big) - E(Y)E(\\widehat{\\gamma} + \\widehat{\\beta}Z) \n   \\\\\n    & =\\widehat{\\gamma}E(Y) + \\widehat{\\beta}E(YZ) - \\widehat{\\gamma}E(Y) - \\widehat{\\beta}E(Y)E(Z)  \n   \\\\\n    & =\\widehat{\\beta}\\big[E(YZ)-E(Y)E(Z)\\big]                                                       \n   \\\\\n   C(\\widehat{S},Y) & = \\widehat{\\beta}C(Y,Z)                                                                        \n\\end{align}\\]Now let’s return something said earlier—learning 2SLS can help better understand intuition instrumental variables generally. mean exactly? First, 2SLS estimator used fitted values endogenous regressors estimation. fitted values based variables used model, including excludable instrument. instruments exogenous structural model, means fitted values become exogenous . Put differently, using variation schooling exogenous. ’s kind interesting, now ’re back world identifying causal effects exogenous changes schooling caused instrument., now less-exciting news. exogenous variation \\(S\\) driven instrument subset total variation schooling. put differently, IV reduces variation data, less information available identification, little variation left comes units responded instrument first place. , turns , critical later relax homogeneous treatment effects assumption allow heterogeneity.","code":""},{"path":"ch6.html","id":"parental-methamphetamine-abuse-and-foster-care","chapter":"7 Instrumental Variables","heading":"7.4 Parental Methamphetamine Abuse and Foster Care","text":"’s helpful occasionally stop try think real-world applications much possible; otherwise estimators feel opaque unhelpful. illustrate, ’m going review one papers Keith Finlay sought estimate effect parental methamphetamine abuse child abuse foster care admissions (Cunningham Finlay 2012).claimed substance abuse, notably illicit drug use, negative impact parenting, causing neglect, occur equilibrium, ’s possible correlation simply reflective selection bias. Maybe households parents abuse drugs ’ve negative outcomes parents used drugs. , ’s like people flipping coins deciding smoke meth. let briefly give background study better understand data-generating process.First, methamphetamine toxic poison mind body highly addictive. symptoms meth abuse increased energy alertness, decreased appetite, intense euphoria, impaired judgment, psychosis. Second, meth epidemic United States began West Coast, gradually making way eastward 1990s.interested impact growth meth abuse children. Observers law enforcement commented, without concrete causal evidence, epidemic causing growth foster care admissions. separate correlation causality? solution contained within meth produced.Meth synthesized reduction ephedrine pseudoephedrine, also active ingredient many cold medications, Sudafed. Without one two precursors, impossible produce kind meth people abuse. precursors supply chains potentially disrupted concentration pharmaceutical laboratories. 2004, nine factories manufactured bulk world’s supply ephedrine pseudoephedrine. US Drug Enforcement Agency correctly noted regulate access ephedrine pseudoephedrine, effectively interrupt production methamphetamine, turn, hypothetically reduce meth abuse associated social harms., input DEA, Congress passed Domestic Chemical Diversion Control Act August 1995, provided safeguards regulating distribution products contained ephedrine primary medicinal ingredient. new legislation’s regulations applied ephedrine, pseudoephedrine, since two precursors nearly identical, traffickers quickly substituted. 1996, pseudoephedrine found primary precursor almost half meth lab seizures.Therefore, DEA went back Congress, seeking greater control pseudoephedrine products. Comprehensive Methamphetamine Control Act 1996 went effect October December 1997. act required distributors forms pseudoephedrine subject chemical registration. Dobkin Nicosia (2009) argued precursor shocks may well largest supply shocks history drug enforcement.placed Freedom Information Act request DEA requesting undercover purchases seizures illicit drugs going back decades. data included price undercover purchase, drug’s type, weight purity, well locations purchases occurred. used data construct price series meth, heroin, cocaine. effect two interventions dramatic. first supply intervention caused retail (street) prices (adjusted purity, weight, inflation) quadruple. second intervention, still quite effective raising relative prices, large effect first. See Figure 7.1.\nFigure 7.1: Ratio Median Monthly Expected Retail Prices Meth, Heroin, Cocaine Relative Respective Values 1995, STRIDE 1995–1999. Reprinted Cunningham Finlay (2012).\nshowed two drug prices (cocaine heroin) addition meth wanted reader understand 1995 1997 shocks uniquely impacting meth markets. appear common shocks affecting drug markets, words. result, felt confident analysis able isolate effect methamphetamine, opposed substance abuse generally. two interventions simply effect cocaine heroin prices despite causing massive shortage meth raising retail price. wouldn’t surprised disrupting meth markets caused shift demand cocaine heroin turn caused prices change, yet first glance time series, ’m finding . Weird.interested causal effect meth abuse child abuse, first stage necessarily proxy meth abuse—number people entering treatment listed meth one substances used last episode substance abuse. said , since picture worth thousand words, ’m going show pictures first stage reduced form. instead going directly tables coefficients? quite frankly, likely find estimates believable can see evidence first stage reduced form raw data .112\nFigure 7.2: Visual representation equivalent first stage. Reprinted Cunningham Finlay (2012).\nFigure 7.2, show first stage. data come Treatment Episode Data Set (TEDS), includes people going treatment substance abuse federally funded clinics. Patients list last three substances used recent “episode.” mark anyone listed meth, cocaine, heroin aggregate month state. first, let’s look national aggregate Figure 7.2. can see evidence effect two interventions meth flows, particularly ephedrine intervention. Self-admitted meth admissions dropped significantly, total meth admissions, ’s effect cocaine heroin. effect pseudoephedrine dramatic, appears cause break trend growth meth admissions slows period time. summary, appears first stage , interventions, meth admissions declines.Figure 7.3, show reduced form—, effect price shocks foster care admissions. Consistent found first-stage graphic, ephedrine intervention particular profoundly negative effect foster care admissions. fell around 8,000 children removed per month around 6,000, began rising . second intervention also effect, though appears milder. reason believe second intervention modest effect first (1) effect price half size first intervention, (2) domestic meth production replaced Mexican imports meth late 1990s, precursor regulations applicable Mexico. Thus, end 1990s, domestic meth production played smaller role total output, hence effect price admissions probably smaller.\nFigure 7.3: Figure 4 Cunningham Finlay (2012) showing reduced form effect interventions children removed families placed foster care. Cunningham Finlay (2012)\n’s worth reflecting moment reduced form. rising retail prices pure gram methamphetamine cause child placed foster care? Prices don’t cause child abuse—’re just nominal pieces information world. way higher price meth reduce foster care admissions parents reduced consumption methamphetamine, turn caused reduction harm one’s child. picture key piece evidence reader going .Table 7.1, reproduce main results article Keith. pieces key information IV tables . First, OLS regression. OLS regression suffers endogeneity, want reader see something compare IV model . Let’s focus column 1, dependent variable total entry foster care. find effect, interestingly, meth foster care estimate using OLS.Table 7.1:  Log Latest Entry Foster Care\nNotes: Log latest entry foster care natural log sum new foster care admissions state, race, month. Models 3 10 denote flow children foster care via given route admission denoted column heading. Models 11 12 use natural log sum foster care exits state, race month. \\(^{***}\\), \\(^{**}\\), \\(^{*}\\) denote statistical significance 1%, 5%, 10% levels, respectively.\nsecond piece information one report 2SLS table first stage . report first stage bottom even-numbered column. can see, one-unit deviation price long-term trend, meth admissions treatment (proxy) fell \\(-0.0005\\) log points. highly significant 1% level, check strength instrument using \\(F\\) statistic (Staiger Stock 1997).113 \\(F\\) statistic 17.6, suggests instrument strong enough identification.Finally, let’s examine 2SLS estimate treatment effect . Notice using exogenous variation log meth admissions, assuming exclusion restriction holds model, able isolate causal effect log meth admissions log aggregate foster care admissions. log-log regression, can interpret coefficient elasticity. find 10% increase meth admissions treatment appears cause around 15% increase children removed homes placed foster care. effect large precise. detectable otherwise (coefficient zero).removed? data (AFCARS) lists several channels: parental incarceration, child neglect, parental drug use, physical abuse. Interestingly, find effect parental drug use parental incarceration, perhaps counterintuitive. signs negative standard errors large. Rather, find effects meth admissions removals physical abuse neglect. elastic (.e., \\(\\delta >1\\)).learn? First, learned contemporary piece applied microeconomics goes using instrumental variables identify causal effects. saw kinds graphical evidence mustered, way knowledge natural experiment policies involved helped authors argue exclusion restriction (since tested), kind evidence presented 2SLS, including first-stage tests weak instruments. Hopefully seeing paper point helpful. second thing learned concerned actual study . learned group meth users whose behavior changed result rising real prices pure gram methamphetamine (.e., complier subpopulation), meth use causing child abuse neglect severe merited removing children placing children foster care. familiar Dobkin Nicosia (2009), found effect meth crime using county-level data California 1997 ephedrine shock, might incorrectly conclude social costs associated meth abuse. , meth appear cause crime California, appear harm children meth users places strains foster care system.","code":""},{"path":"ch6.html","id":"the-problem-of-weak-instruments","chapter":"7 Instrumental Variables","heading":"7.5 The Problem of Weak Instruments","text":"trying smother papers. move back technical material , ’d like discuss one paper. paper also help better understand weak instrument literature following publication.’ve said since beginning, example example, long tradition labor economics building models can credibly identify returns schooling. goes back Becker (1994) workshop Columbia Becker ran years Jacob Mincer. study returns schooling important task given education’s growing importance distribution income wealth since latter twentieth century increasing returns skill marketplace (Juhn, Murphy, Pierce 1993).One seminal papers instrumental variables modern period Angrist Krueger (1991). idea simple clever; quirk United States educational system child enters grade basis birthday. long time, cutoff late December. children born December 31, assigned first grade. birthday January 1, assigned kindergarten. Thus two people—one born December 31 one born January 1—exogenously assigned different grades.Now ’s nothing necessarily relevant children always stay school duration necessary get high school degree, arbitrary assignment start date won’t affect high school completion. ’ll affect get high school degree. gets interesting. twentieth century, US compulsory schooling laws forced person remain high school age 16. age 16, one legally stop going school. Figure 7.4 explains visually instrumental variable.114\nFigure 7.4: Compulsory schooling start dates birthdates.\nAngrist Krueger insight small quirk exogenously assigning schooling people born later year. person born December reach age 16 education person born January, words. Thus, authors uncovered small exogenous variation schooling. Notice similar idea regression discontinuity. ’s IV RDD conceptually similar strategies.\nFigure 7.5: First stage relationship quarter birth schooling. Reprinted Angrist Krueger (1991).\nFigure 49 shows first stage, really interesting. Look 3s 4s top picture. ’s clear pattern—birthdays third fourth quarter schooling average birthdays first second quarters. relationship gets weaker move later cohorts, probably later cohorts, price higher levels schooling rising much fewer fewer people dropping finishing high school degree.\nFigure 7.6: Reduced form visualization relationship quarter birth log weekly earnings. Reprinted Angrist Krueger (1991).\nFigure 7.6 shows reduced-form relationship quarter birth log weekly earnings.115 squint little bit, can see pattern—along top jagged path 3s 4s, along bottom jagged path 1s 2s. always, ’s correlated.Remember said instruments certain ridiculousness ? , know good instrument instrument doesn’t seem relevant explaining outcome interest ’s exclusion restriction implies. quarter birth affect earnings? doesn’t make obvious, logical sense . , told people born later year got schooling less compulsory schooling, relationship instrument outcome snaps place. reason can think instrument affect earnings instrument operating schooling. Instruments explain outcome, words, understand effect endogenous variable.116Angrist Krueger use three dummies instruments: dummy first quarter, dummy second quarter, dummy third quarter. Thus, omitted category fourth quarter, group gets schooling. Now ask : regressed years schooling onto three dummies, signs magnitudes ? , expect relationship first quarter (compared fourth quarter) schooling? Let’s look first-stage results (Table 7.2).Table 7.2:  Quarter birth schooling\nStandard errors parenthesis.\nTable 7.2 shows first stage regression following form:\n\\[\nS_i=X\\pi_{10}+Z_1\\pi_{11}+Z_2\\pi_{12}+Z_3\\pi_{13}+\\eta_1\n\\]\n\\(Z_i\\) dummy first three quarters, \\(\\pi_i\\) coefficient dummy. Now look produced Table 7.2. coefficients negative significant total years education high school graduate dependent variables. Notice, , relationship gets much weaker move beyond groups bound compulsory schooling: number years schooling high school students (effect) probability college graduate (effect).Regarding college non-results. Ask question: expect quarter birth affect probability high school graduate college grad? found quarter birth predicted high school completion, college completion, post-graduate completion, total years schooling beyond high school? Wouldn’t start seem like compulsory schooling instrument thought ? , quarter birth instrument really impact high school completion; since doesn’t bind anyone beyond high school, shouldn’t affect number years beyond high school college completion probabilities. , might skeptical whole design. didn’t, makes even convincing ’re identifying compulsory high school schooling effect.117Now look second stage OLS 2SLS (authors label TSLS, means thing). Table 7.3 shows results. authors didn’t report first stage table reported earlier table just reviewed. small values, log approximates percentage change, finding 7.1% return every additional year schooling, 2SLS ’s higher (8.9%). ’s interesting, merely ability bias, ’d expect OLS estimate large, small. something mere ability bias must going .Table 7.3:  Effect schooling wages using OLS 2SLS\nStandard errors parenthesis. First stage quarter birth dummies.\nwhatever ’s worth, personally convinced point quarter birth valid instrument ’ve identified causal effect schooling earnings, Angrist Krueger (1991) want go , probably want precision estimate. get precision, load first stage even instruments. Specifically, use specifications 30 dummies (quarter birth \\(\\times\\) year) 150 dummies (quarter birth \\(\\times\\) state) instruments. idea quarter birth effect may differ state cohort.cost? Many instruments now weakly correlated schooling—locations, almost correlation, cohorts well. got flavor , fact, Table 7.3, later cohorts show less variation schooling quarter birth earlier cohorts. effect, , reducing variance estimator loading first stage bunch noise?Bound, Jaeger, Baker (1995) classic work sometimes called “weak instrument” literature. ’s paper learn basic problems created weak instruments, form 2SLS bias finite samples. Since Bound, Jaeger, Baker (1995) focused compulsory schooling application Angrist Krueger (1991) done, stick example throughout. Let’s consider model single endogenous regressor simple constant treatment effect. causal model interest :\n\\[\ny=\\beta s + \\varepsilon\n\\]\n\\(y\\) outcome \\(s\\) endogenous regressor, schooling. instrument \\(Z\\) first-stage equation :\n\\[\ns=Z' \\pi + \\eta\n\\]\nLet’s start assuming \\(\\varepsilon\\) \\(\\eta\\) correlated. estimating first equation OLS lead biased results, wherein OLS bias :\n\\[\nE\\big[\\widehat{\\beta}_{OLS}-\\beta\\big] =\n   \\dfrac{C(\\varepsilon, s)}{V(s)}\n\\]\nrename ratio \\(\\dfrac{\\sigma_{\\varepsilon \\eta}}{\\sigma^2_s}\\). Bound, Jaeger, Baker (1995) show bias 2SLS centers previously defined OLS bias weakness instrument grows. Following Angrist Pischke (2009), ’ll express bias function first-stage \\(F\\) statistic:\n\\[\nE\\big[\\widehat{\\beta}_{2SLS}-\\beta\\big] \\approx \\dfrac{\\sigma_{\\varepsilon \\eta}}{\\sigma_\\eta^2} \\dfrac{1}{F+1}\n\\]\n\\(F\\) population analogy \\(F\\)-statistic joint significance instruments first-stage regression. first stage weak, \\(F\\rightarrow 0\\), bias 2SLS approaches \\(\\dfrac{\\sigma_{\\varepsilon \\eta}}{\\sigma_\\eta^2}\\). first stage strong, \\(F \\rightarrow \\infty\\), 2SLS bias goes 0.Returning rhetorical question earlier, cost adding instruments without predictive power? Adding weak instruments causes first-stage \\(F\\) statistic approach zero increase bias 2SLS.Bound, Jaeger, Baker (1995) studied empirically, replicating Angrist Krueger (1991), using simulations. Table 7.4 shows happens start adding controls. Notice , \\(F\\) statistic excludability instruments falls 13.5 4.7 1.6. \\(F\\) statistic, already running weak instrument include 30 quarter birth \\(\\times\\) year dummies, think ’s saw, relationship quarter birth schooling got smaller later cohorts.Table 7.4:  Effect completed schooling men’s log weekly wages\nStandard errors parenthesis. First stage quarter birth dummies.\nNext, added weak instruments—180 —shown Table 7.5. see problem persists. instruments weak, therefore bias 2SLS coefficient close OLS bias.Table 7.5:  Effect completed schooling men’s log weekly wages controlling state birth\nStandard errors parenthesis.\nreally damning part Bound, Jaeger, Baker (1995) simulation. authors write:illustrate second-stage results give us indication existence quantitatively important finite-sample biases, reestimated Table 1, columns (4) (6) Table 2, columns (2) (4), using randomly generated information place actual quarter birth, following suggestion Alan Krueger. means estimated standard errors reporting last row quite close actual standard deviations 500 estimates model. . . . striking second-stage results reported Table 3 look quite reasonable even information educational attainment simulated instruments. give indication instruments randomly generated\\(\\ldots\\) hand, F statistics excluded instruments first-stage regressions always near expected value essentially 1 give clear indication estimates second-stage coefficients suffer finite-sample biases. Bound, Jaeger, Baker (1995) (p.448), can weak instruments? Unfortunately, lot. can use just-identified model strongest IV. Second, can use limited-information maximum likelihood estimator (LIML). approximately median unbiased identified constant effects models. provides asymptotic distribution 2SLS homogeneous treatment effects provides finite-sample bias reduction., let’s real second. weak instrument problem, get far using LIML estimating just-identified model. real solution weak instrument problem get better instruments. homogeneous treatment effects, ’re always identifying effect, ’s worry complier parameter. just continue searching stronger instruments simultaneously satisfy exclusion restriction.118In conclusion, think ’ve learned lot instrumental variables powerful. estimators based design capable identifying causal effects data suffer selection unobservables. Since selection unobservables believed common, useful methodology addressing . , said, also learned design’s weaknesses, hence people eschew . Let’s now move heterogeneous treatment effects can better understand limitations bit better.","code":""},{"path":"ch6.html","id":"heterogeneous-treatment-effects","chapter":"7 Instrumental Variables","heading":"7.6 Heterogeneous Treatment Effects","text":"Now turn scenario relax assumption treatment effects every unit. potential outcomes notation comes handy. Instead, allow unit unique response treatment, \n\\[\nY_i^1 - Y_i^0 = \\delta_i\n\\]\nNote treatment effect parameter now differs individual \\(\\). call heterogeneous treatment effects.main questions now : (1) IV estimating heterogeneous treatment effects, (2) assumptions IV identify causal effect heterogeneous treatment effects? reason matters introduce heterogeneous treatment effects, introduce distinction internal validity study external validity. Internal validity means strategy identified causal effect population studied. external validity means study’s finding applied different populations (study). deal homogeneous treatment effects, tension external internal validity everyone treatment effect. heterogeneous treatment effects, huge tension; tension great, fact, may even undermine meaningfulness relevance estimated causal effect despite otherwise valid IV design!119Heterogeneous treatment effects built top potential outcomes notation, modifications. Since now two arguments—\\(D\\) \\(Z\\)—modify notation slightly. say \\(Y\\) function \\(D\\) \\(Z\\) \\(Y_i(D_i=0,Z_i=1)\\), represented \\(Y_i(0,1)\\).Potential outcomes using term refers \\(Y\\) variable, now new potential variable—potential treatment status (opposed observed treatment status). characteristics:\\[\\begin{align}\n   D_i^1 & =\\text{'s treatment status }Z_i=1 \n   \\\\\n   D_i^0 & =\\text{'s treatment status }Z_i=0 \n\\end{align}\\]observed treatment status based treatment status switching equations:\\[\\begin{align}\n   D_i &=&D_i^0 + (D_i^1 - D_i^0)Z_i \\\\\n   &=&\\pi_0 + \\pi_1 Z_i + \\phi_i\n\\end{align}\\]\\(\\pi_{0i}=E[D_i^0]\\), \\(\\pi_{1i} = (D_i^1 - D_i^0)\\) heterogeneous causal effect IV \\(D_i\\), \\(E[\\pi_{1i}]=\\) average causal effect \\(Z_i\\) \\(D_i\\).considerably assumptions necessary identification introduce heterogeneous treatment effects—specifically five assumptions. now review . concrete, use repeatedly example effect military service earnings using draft lottery instrumental variable (Angrist 1990). paper, Angrist estimated returns military service using instrument person’s draft lottery number. draft lottery number generated random number generator person’s number particular range, drafted, otherwise weren’t.First, , stable unit treatment value assumption (SUTVA) states potential outcomes person \\(\\) unrelated treatment status individuals. assumption states \\(Z_i=Z_i'\\), \\(D_i(Z) = D_i(Z')\\). \\(Z_i=Z_i'\\) \\(D_i=D_i'\\), \\(Y_i(D,Z)=Y_i(D',Z')\\). violation SUTVA status person risk drafted affected draft status others risk drafted. spillovers violate SUTVA.120 knowing lot works, can’t say whether Angrist’s draft study ’ve violated SUTVA. seems like ’s safe .Second, independence assumption. independence assumption also sometimes called “good random assignment” assumption. states IV independent potential outcomes potential treatment assignments. Notationally, \n\\[\n\\Big\\{Y_i(D_i^1,1), Y_i(D_i^0,0),D_i^1,D_i^0\\Big\\} \\perp \\!\\!\\! \\perp Z_i\n\\]\nindependence assumption sufficient causal interpretation reduced form:\\[\\begin{align}\n   E\\big[Y_i\\mid Z_i=1\\big]-E\\big[Y_i\\mid Z_i=0\\big] & = E\\big[Y_i(D_i^1,1)\\mid Z_i=1\\mid]- \n   E\\big[Y_i(D_i^0,0)\\mid Z_i=0\\big]\n   \\\\\n                                    & = E[Y_i(D_i^1,1)] - E[Y_i(D_i^0,0)]  \n\\end{align}\\]many people may actually prefer work just instrument reduced form find independence satisfying acceptable. problem, though, technically instrument program ’re interested studying. may many mechanisms leading instrument outcome need think (see ). Ultimately, independence nothing nothing less assuming instrument random.Independence means first stage measures causal effect \\(Z_i\\) \\(D_i\\):\\[\\begin{align}\n   E\\big[D_i\\mid Z_i=1\\big]-E\\big[D_i\\mid Z_i=0\\big] & = E\\big[D_i^1\\mid Z_i=1\\big] - E\\big[D_i^0\\mid Z_i=0\\big] \n   \\\\\n                                    & = E[D_i^1 - D_i^0]                                        \n\\end{align}\\]example Vietnam conscription military service based randomly generated draft lottery numbers. assignment draft lottery number independent potential earnings potential military service “good random.”Third, exclusion restriction. exclusion restriction states effect \\(Z\\) \\(Y\\) must via effect \\(Z\\) \\(D\\). words, \\(Y_i(D_i,Z_i)\\) function \\(D_i\\) . formally:\n\\[\nY_i(D_i,0) = Y_i(D_i,1)\\quad \\text{$D=0,1$}\n\\]\n, Vietnam example. Vietnam draft lottery, individual’s earnings potential veteran non-veteran assumed regardless draft eligibility status. exclusion restriction violated low lottery numbers affected schooling people avoiding draft. case, lottery number correlated earnings least two cases. One, instrument’s effect military service. two, instrument’s effect schooling. implication exclusion restriction random lottery number (independence) therefore imply exclusion restriction satisfied. different assumptions.Fourth first stage. IV designs require \\(Z\\) correlated endogenous variable \n\\[\nE[D_i^1 - D_i^0] \\ne 0\n\\]\n\\(Z\\) statistically significant effect average probability treatment. example low lottery number. increase average probability military service? , satisfies first stage requirement. Note, unlike independence exclusion, first stage testable based solely \\(D\\) \\(Z\\), data .finally, monotonicity assumption. strange first glance actually quite intuitive. Monotonicity requires instrumental variable (weakly) operate direction individual units. words, instrument may effect people, affected affected direction (.e., positively negatively, ). write like :\n\\[\n\\text{Either $\\pi_{1i} \\geq 0$ $$\n       $\\pi_{1i} \\leq 0$ $=1,\\dots, N$}\n\\]\nmeans, using military draft example, draft eligibility may effect probability military service people, like patriots, people love want serve country military, effect, shifts service, service, . reason make assumption without monotonicity, IV estimators guaranteed estimate weighted average underlying causal effects affected group.five assumptions satisfied, valid IV strategy. said, valid, homogeneous treatment effects. , , IV strategy estimating heterogeneous treatment effects? Answer: local average treatment effect (LATE) \\(D\\) \\(Y\\):\\[\\begin{align}\n   \\delta_{IV,LATE} & =\\dfrac{ \\text{Effect $Z$ $Y$}}{\\text{Effect $Z$ $D$}} \n   \\\\\n    & =\\dfrac{E\\big[Y_i(D_i^1,1)-Y_i(D_i^0,0)\\big]}{ E[D_i^1 - D_i^0]}   \n   \\\\\n    & =E\\big[(Y_i^1-Y_i^0)\\mid D_i^1-D_i^0=1\\big]                        \n\\end{align}\\]LATE parameter average causal effect \\(D\\) \\(Y\\) whose treatment status changed instrument, \\(Z\\). know notice difference last line: \\(D_i^1 - D_i^0\\). , people equal 1, calculate difference potential outcomes. means averaging treatment effects \\(D_i^1 - D_i^0\\). Hence parameter estimating “local.”interpret Angrist’s estimated causal effect Vietnam draft project? Well, IV estimates average effect military service earnings subpopulations enrolled military service draft. specifically people, though, served otherwise. doesn’t identify causal effect patriots always serve, instance, \\(D_i^1 - D_i^0 = 0\\) patriots. always serve! \\(D_i^1=1\\) \\(D_i^0=1\\) patriots ’re patriots! also won’t tell us effect military service exempted military service medical reasons people \\(D_i^1=0\\) \\(D_i^0=0\\).121The LATE framework even jargon, let’s review now. LATE framework partitions population units instrument potentially four mutually exclusive groups. groups :Compliers: subpopulation whose treatment status affected instrument correct direction. , \\(D_i^1=1\\) \\(D_i^0=0\\).Compliers: subpopulation whose treatment status affected instrument correct direction. , \\(D_i^1=1\\) \\(D_i^0=0\\).Defiers: subpopulation whose treatment status affected instrument wrong direction. , \\(D_i^1=0\\) \\(D_i^0=1\\).122Defiers: subpopulation whose treatment status affected instrument wrong direction. , \\(D_i^1=0\\) \\(D_i^0=1\\).122Never takers: subpopulation units never take treatment regardless value instrument. , \\(D_i^1=D_i^0=0\\). simply never take treatment.123Never takers: subpopulation units never take treatment regardless value instrument. , \\(D_i^1=D_i^0=0\\). simply never take treatment.123Always takers: subpopulation units always take treatment regardless value instrument. , \\(D_i^1=D_i^0=1\\). simply always take instrument.124Always takers: subpopulation units always take treatment regardless value instrument. , \\(D_i^1=D_i^0=1\\). simply always take instrument.124As outlined , five assumptions satisfied, IV estimates average treatment effect compliers, parameter ’ve called local average treatment effect. ’s local sense average treatment effect compliers . Contrast traditional IV pedagogy homogeneous treatment effects. situation, compliers treatment effects non-compliers, distinction irrelevant. Without assumptions, LATE informative effects never-takers always-takers instrument affect treatment status.matter? Yes, absolutely. matters applications, mostly interested estimating average treatment effect whole population, ’s usually possible IV.125Now reviewed basic idea mechanics instrumental variables, including important tests associated , let’s get hands dirty data. ’ll work couple data sets now help better understand implement 2SLS real data.Buy print version today:","code":""},{"path":"ch6.html","id":"applications","chapter":"7 Instrumental Variables","heading":"7.7 Applications","text":"","code":""},{"path":"ch6.html","id":"college-in-the-county","chapter":"7 Instrumental Variables","heading":"7.7.1 College in the county","text":"look returns schooling since historically popular topic causal questions labor. application, simply estimate 2SLS model, calculate first-stage F statistic, compare 2SLS results OLS results. keeping simple, goal just help reader become familiarized procedure.data comes NLS Young Men Cohort National Longitudinal Survey. data began 1966 5,525 men aged 14–24 continued follow 1981. data come 1966, baseline survey, number questions related local labor-markets. One whether respondent lives county 4-year (2-year) college.Card (1995) interested estimating following regression equation:\n\\[\nY_i=\\alpha+\\delta S_i + \\gamma X_i+\\varepsilon_i\n\\]\n\\(Y\\) log earnings, \\(S\\) years schooling, \\(X\\) matrix exogenous covariates, \\(\\varepsilon\\) error term contains, among things, unobserved ability. assumption \\(\\varepsilon\\) contains ability, ability correlated schooling, \\(C(S,\\varepsilon)\\neq 0\\) therefore schooling biased. Card (1995) proposes therefore instrumental variables strategy whereby instrument schooling college---county dummy variable.worth asking presence 4-year college one’s county increase schooling. main reason can think presence 4-year college increases likelihood going college lowering costs, since student can live home. therefore means selecting group compliers whose behavior affected variable. kids, words, always go college regardless whether college county, never go despite presence nearby college. may exist group compliers go college county college, ’m right primarily picking people going can attend living home, ’s necessarily people margin attend college became slightly cheaper. , words, group people liquidity constrained. believe returns schooling group different always-takers, estimates may represent ATE. Rather, represent LATE. case, might actually interesting parameter since gets issue lowering costs attendance poorer families.simple analysis based Card (1995).card.docard.ROur results analysis arranged Table 7.6. First, report OLS results. every one year additional schooling, respondents’ earnings increase approximately 7.1%. Next estimated 2SLS using ivregress 2sls command Stata. find much larger return schooling found using OLS—around 75% larger fact. let’s look first stage. find college county associated 0.327 years schooling. highly significant (\\(p<0.001\\)). \\(F\\) statistic exceeds 15, suggesting don’t weak instrument problem. return schooling associated 2SLS estimate 0.124—, every additional year schooling, earnings increase 12.4%. covariates listed ’re interested studying well.Table 7.6:  OLS 2SLS regressions Log Earnings Schooling\nStandard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{***}\\) \\(p<0.01\\)\nreturn schooling much larger compliers general population? , showed earlier simply ability bias, ’d expect 2SLS coefficient smaller OLS coefficient, ability bias implies coefficient schooling large. Yet ’re finding opposite. couple things . First, schooling measurement error. Measurement error bias coefficient toward zero, 2SLS recover true value. find explanation unlikely, don’t foresee people really knowing accuracy many years schooling currently . leads us explanation, compliers larger returns schooling. case? Assuming exclusion restriction holds, compliers, returns much larger? ’ve already established people likely shifted schooling live parents, suggests college lowering marginal cost going college. left saying reason, higher marginal cost attending college causing people underinvest schooling; fact returns much higher.","code":"use https://github.com/scunning1975/mixtape/raw/master/card.dta, clear\n\n* OLS estimate of schooling (educ) on log wages\nreg lwage  educ  exper black south married smsa\n\n* 2SLS estimate of schooling (educ) on log wages using \"college in the county\" as an instrument for schooling\nivregress 2sls lwage (educ=nearc4) exper black south married smsa, first \n\n* First stage regression of schooling (educ) on all covariates and the college and the county variable\nreg educ nearc4 exper black south married smsa\n\n* F test on the excludability of college in the county from the first stage regression.\ntest nearc4\nlibrary(AER)\nlibrary(haven)\nlibrary(tidyverse)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ncard <- read_data(\"card.dta\")\n\n#Define variable \n#(Y1 = Dependent Variable, Y2 = endogenous variable, X1 = exogenous variable, X2 = Instrument)\n\nattach(card)\n\nY1 <- lwage\nY2 <- educ\nX1 <- cbind(exper, black, south, married, smsa)\nX2 <- nearc4\n\n#OLS\nols_reg <- lm(Y1 ~ Y2 + X1)\nsummary(ols_reg)\n\n#2SLS\niv_reg = ivreg(Y1 ~ Y2 + X1 | X1 + X2)\nsummary(iv_reg)"},{"path":"ch6.html","id":"fulton-fish-markets","chapter":"7 Instrumental Variables","heading":"7.7.2 Fulton Fish Markets","text":"second exercise ’ll based Graddy (2006). understanding Graddy collected data recording prices fish actual Fulton Fish Market. ’m sure true, like believe ’s true. Anyhow, Fulton Fish Market operated New York Fulton Street 150 years. November 2005, moved Lower Manhattan large facility building market South Bronx. time Graddy (2006) published, market called New Fulton Fish Market. ’s one world’s largest fish markets, second Tsukiji Tokyo.Fish heterogeneous, highly differentiated products. anywhere one hundred three hundred varieties fish sold market. fifteen varieties shrimp alone. Within variety, ’s small fish, large fish, medium fish, fish just caught, fish around . ’s much heterogeneity customers often want examine fish personally. get picture. fish market functions just like two-sided platform matching buyers sellers, made efficient thickness market produces. ’s surprising, therefore, Graddy found market interesting thing study.Let’s move data. want us estimate price elasticity demand fish, makes problem much like problem Philip Wright faced price quantity determined simultaneously. elasticity demand sequence quantity price pairs, one pair observed given point time. sense, demand curve sequence potential outcomes (quantity) associated different potential treatments (price). means demand curve real object, mostly unobserved. Therefore, trace elasticity, need instrument correlated supply . Graddy proposes , weather sea days fish arrived market.first instrument average maximum wave height previous two days. model interested estimating :\\[\\begin{align}\n   Q = \\alpha + \\delta P + \\gamma X + \\varepsilon \n\\end{align}\\]\\(Q\\) log quantity whiting sold pounds, \\(P\\) log average daily price per pound, \\(X\\) day week dummies time trend, \\(\\varepsilon\\) structural error term. Table 7.7 presents results estimating equation OLS (first column) 2SLS (second column). OLS estimate elasticity demand \\(-0.549\\). ’ve anything given price determined many sellers many buyers market given day. use average wave height instrument price, get \\(-0.96\\) price elasticity demand. 10% increase price causes quantity decrease 9.6%. instrument strong \\((F>22)\\). every one-unit increase wave-height, price rose 10%.Table 7.7:  OLS 2SLS regressions Log Quantity Log Price wave height instrument\nStandard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{**}\\)\\(^{*}\\) \\(p<0.01\\)\nsuppose question ask , though, exactly instrument supply. higher waves exactly? making difficult fish, also changing composition fish caught? , seem exclusion restriction violated mean wave height directly causing fish composition change, directly determine quantities bought sold.Now let’s look different instrument: wind speed (Table 59). Specifically, ’s three-day lagged maximum wind speed. present results Table 7.7. see something see , weak instrument. \\(F\\) statistic less 10 (approximately 6.5). correspondingly, estimated elasticity twice large found wave height. Thus, know earlier discussion weak instruments estimate likely severely biased, therefore less reliable previous one—even though previous one (1) may convincingly satisfy exclusion restriction (2) best LATE relevant compliers . ’ve said, think compliers’ causal effects similar broader population, LATE may informative useful.Table 7.8:  OLS 2SLS regressions Log Quantity Log Price windspeed instrument.\nStandard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{**}\\)\\(^{*}\\) \\(p<0.01\\)\n","code":""},{"path":"ch6.html","id":"popular-iv-designs","chapter":"7 Instrumental Variables","heading":"7.8 Popular IV Designs","text":"Instrumental variables strategy adopt good instrument, sense, general design can used just context. years, certain types IV strategies used many times constitute designs. repetition reflection, better understanding specific IV designs work. Let’s discuss three popular designs: lottery design, judge fixed effects design, Bartik instruments.","code":""},{"path":"ch6.html","id":"lotteries","chapter":"7 Instrumental Variables","heading":"7.8.1 Lotteries","text":"Previously, reviewed use IV identifying causal effects regressor endogenous observational data. one particular kind IV application randomized trials. many randomized trials, participation voluntary among randomly chosen treatment group. hand, persons control group usually don’t access treatment. particularly likely benefit treatment therefore probably take treatment, almost always leads positive selection bias. compare means treated untreated individuals using OLS, obtain biased treatment effects even randomized trial noncompliance. solution problems least squares application instrument Medicaid whether offered treatment estimate LATE. Thus even treatment randomly assigned, common people use randomized lottery instrument participation. modern example , see Baicker et al. (2013), used randomized lottery enrolled Oregon’s Medicaid program instrument Medicaid. Let’s discuss Oregon Medicaid studies now, excellent illustrations lottery IV design.effects expanding access public health insurance low-income adults? positive negative? large small? Surprisingly, historically reliable estimates basic questions lacked kind experiment needed make claims one way another. limited existing evidence suggestive, lot uncertainty. Observational studies confounded selection health insurance, quasi-experimental evidence tended focus elderly small children. one randomized experiment developed country, RAND health insurance experiment 1970s. important, expensive, ambitious experiment, randomized cost-sharing—coverage .2000s, Oregon chose expand Medicaid program poor adults making generous. Adults aged 19–64 income less 100% federal poverty line eligible long weren’t eligible similar programs. also uninsured fewer six months legal US resident. program called Oregon Health Plan Standard provided comprehensive coverage (dental vision) minimum cost-sharing. similar states payments management, program closed new enrollment 2004.expansion popularly known Oregon Medicaid Experiment state used lottery enroll volunteers. five weeks, people allowed sign Medicaid. state used heavy advertising make program salient. low barriers signing eligibility requirements prescreening. state March October 2008 randomly drew 30,000 people list 85,000. selected given chance apply. apply, entire household enrolled, long returned application within 45 days. original 30,000, 10,000 people enrolled.team economists became involved project early , several influential papers written. ’ll now discuss main results Finkelstein et al. (2012) Baicker et al. (2013). authors studies sought study broad range outcomes might plausibly affected health insurance—financial outcomes, health-care utilization, health outcomes. data needed outcomes meticulously collected third parties. instance, pre-randomization demographic information available lottery sign-. state administrative records Medicaid enrollment also collected became primary measure first stage (.e., insurance coverage). outcomes collected administrative sources (e.g., hospital discharge, mortality, credit), mail surveys, -person survey measurement (e.g., blood samples, body mass index, detailed questionnaires).empirical framework studies straightforward IV design. Sometimes estimated reduced form, sometimes estimated full 2SLS model. two-stages :\\[\\begin{align}\n   \\text{INSURANCE}_{ihj} & =                                                                                  \n   \\delta_0+\\delta_1\\text{ LOTTERY}_{ih} +\n   X_{ih}\\delta_2 + V_{ih}\\delta_3 + \\mu_{ihj}\n   \\\\\n   y_{ihj}                & =\\pi_0+\\pi_1 \\widehat{\\text{NSURANCE}}_{ih} + X_{ih}\\pi_2 + V_{ih}\\pi_3 + v_{ihj} \n\\end{align}\\]first equation first stage (insurance regressed onto lottery outcome plus bunch covariates), second stage regresses individual-level outcomes onto predicted insurance (plus controls). already know long first stage strong, F statistic large, finite sample bias lessens.effects winning lottery large effects enrollment. can see results first stage Table 7.9. used different samples, effect sizes similar. Winning lottery raised probability enrolled Medicaid 26% raised number months Medicaid 3.3 4 months.Table 7.9:  Effect Lottery Enrollment\nStandard errors parenthesis.\nAcross two papers, authors looked effect Medicaid’s health insurance coverage variety outcomes including financial health, mortality, health-care utilization, review . Table 7.10, authors present two regression models: column 2 intent treat estimates, reduced form model, column 3 local average treatment effect estimate, full instrumental variables specification. Interestingly, Medicaid increased number hospital admissions effect emergency room visits. effect emergency rooms, fact, significant, effect non-emergency-room admissions positive significant. interesting appears Medicaid increasing hospital admission without putting additional strain emergency rooms, already scarce resources.kinds health-care utilization observing Medicaid enrollees? Let’s look Table 7.11, five health-care utilization outcomes. , focus column 3, LATE estimates. Medicaid enrollees 34% likely usual place care, 28% personal doctor, 24% complete health-care needs, 20% likely get needed prescriptions 14% increased satisfaction quality care.Table 7.10:  Effect Medicaid Hospital admission\nHospital discharge data.\nMedicaid merely way increase access health care; also functions effectively health care insurance event catastrophic health events. one widely circulated results experiment finding Medicaid financial outcomes. Table 7.12 see one main effects reduction personal debt ($390) reducing debt going debt collection. authors also found reductions --pocket medical expenses, medical expenses, borrowing money skipping bills medical expenses, whether refused medical treatment due medical debt.Table 7.11:  Effect Medicaid healthcare Usage\nStandard errors parenthesis.\nTable 7.12:  Effect Medicaid Hospital admission\nCredit records.\neffect health outcomes little unclear study. authors find self-reported health outcomes improving, well reduction depression. also find healthy physical mental health days. effects overall small. Furthermore, ultimately find Medicaid effect mortality—result return difference--differences chapter.conclusion, see powerful use IV assignment lotteries recipients. lotteries function instruments treatment assignment, can used estimate local average treatment effect. incredibly useful experimental designs humans often refuse comply treatment assignment even participate experiment altogether!Table 7.13:  Effect Medicaid Hospital admission","code":""},{"path":"ch6.html","id":"judge-fixed-effects","chapter":"7 Instrumental Variables","heading":"7.8.2 Judge fixed effects","text":"second IV design become extremely popular recent years “judge fixed effects” design. may also hear called “leniency design,” applications often involve judges, seems former name stuck. search Google Scholar term yields 70 hits, 50 since 2018 alone.concept judge fixed effects design exists narrow pipeline individuals must pass, numerous randomly assigned decision-makers blocking individuals’ passage assign treatment individuals discretion among decision-makers. three , probably makings judge fixed effects design. reason method called judge fixed effects design traditionally exploited feature American jurisprudence jurisdictions randomly assign judges defendants. Harris County, Texas, instance, used use bingo machine assign defendants one dozens courts (Mueller-Smith 2015).\nFigure 7.7: Randomized judge assignment. Although justice supposedly blind, judges complex bundles characteristics affect judgments. Artwork Seth.\nfirst paper recognize systematic differences judge sentencing behavior article Gaudet, Harris, John (1933). authors interested better understanding , guilt, determined sentencing outcomes defendants. decided focus judge part judges randomly rotated defendants. since “chance” rotated defendants, large sample, characteristics defendants ’ve remained approximately across judges. differences sentencing outcomes, therefore, wouldn’t underlying charge even defendant’s guilt, rather, connected judge. See Figure 7.7 beautiful drawing identification strategy based 7,000 hand collected cases showing systematic differences judge sentencing behavior.\nFigure 7.8: Variation judge sentencing outcomes. figure originally appeared Gaudet, Harris, John (1933). Reprinted special permission Northwestern University Pritzker School Law, Journal Criminal Law Criminology\nFigure 7.8 pretty typical graphic paper judge fixed effects showing variation judge’s propensities; ’s just kind interesting appears beginning back 1933. can see Figure 7.8, weirdly enough lot variation sentencing propensities across six judges. Judge 2 imposed imprisonment 33.6% cases, whereas Judge 4 imposed imprisonment whopping 57.7%. since seeing average defendants, can’t Judge 4 simply seeing worse cases. Rather, appears something systematic, like tendency certain judges always judge defendants harshly. like ? Gaudet, Harris, John (1933) offer following conjecture:Perhaps interesting thing noticed graphs fact sentencing tendency judge seems fairly well determined sits bench. words determines whether judge severe lenient found environment judge subjected previous becoming administrator sentences.main takeaway authors first discover leniency severity judge, merely defendant’s guilt, plays significant role apparently final determination case defendant. authors write:authors wish point results tend show previous studies fields criminology penology based upon unreliable evidence results typical sentencing tendencies. words, type sentence received prisoner may either indication seriousness crime severity judge. (p.815)next mention explicit judge fixed effects design Imbens Angrist (1994) article decomposing IV LATE parameter using potential outcomes notation. conclusion article, provide three examples IV designs may may fit five identifying assumptions IV discussed earlier. write:Example 2 (Administrative Screening): Suppose applicants social program screened two officials. two officials likely different admission rates, even stated admission criteria identical. Since identity official probably immaterial response, seems plausible Condition 1 independence satisfied. instrument binary Condition 3 trivially satisfied. However, Condition 2 monotonicity requires official \\(\\) accepts applicants probability \\(P(0)\\), official B accepts people probability \\((P1)>P(0)\\), official B must accept applicant accepted official \\(\\). unlikely hold admission based number criteria. Therefore, example use Theorem 1 identify local average treatment effect nonparametrically despite presence instrument satisfying Condition 1 independence. (p.472)first time see method used type empirical identification Waldfogel (1995), first explicit IV strategy paper ten years later Kling (2006), used randomized judge assignment judge propensities instrument incarceration length. linked defendants employment earnings records, used estimate causal effect incarceration labor-market outcomes. ultimately finds adverse effects labor-market consequences longer sentences two states considers.question revisited Mueller-Smith (2015), used Harris County, Texas, location. Harris County dozens courts defendants randomly assigned one . Mueller-Smith linked defendant outcomes variety labor-market criminal outcomes, came opposite conclusion Kling (2006). Mueller-Smith (2015) finds incarceration generates net increases frequency severity recidivism, worsens labor-market outcomes, increases defendant’s dependence public assistance.Judicial severity causing adverse consequences defendants practically hallmark judge fixed effects literature. Just name examples, finding less allowance Chapter 13 bankruptcy worsens future financial events (Dobbie, Goldsmith-Pinkham, Yang 2017), racial bias among bail judges (Arnold, Dobbie, Yang 2018), pretrial detention higher rates guilty pleas, conviction, recidivism, worsened labor-market outcomes (Leslie Pope 2018; Dobbie, Goldin, Yang 2018; Stevenson 2018), juvenile incarceration worsening high school outcomes adult recidivism rates (Aizer Doyle 2015), foster care raising juvenile delinquency, teen pregnancy, worsening future employment (Doyle 2007), foster care increasing adult crime (Doyle 2008), countless others. exceptions. instance, Norris, Pecenco, Weaver (2020) find beneficial effects children marginal siblings parents incarcerated.three main identifying assumptions researcher’s mind attempting implement judge fixed effects design independence assumption, exclusion restriction, monotonicity assumption. Let’s discuss time , scenarios, one may credible .independence assumption seems satisfied many cases administrators question literally randomly assigned individual cases. , instrument—sometimes modeled average propensity judge excluding case question simply series judge fixed effects (, ’ll mention moment, turns equivalent)—easily passes independence test. ’s possible strategic behavior part defendant response strictness judge assigned can undermine otherwise random assignment. Consider something Gaudet, Harris, John (1933) observed original study regarding dynamics courtroom randomly assigned severe judge:individual tendencies sentencing tendencies judges evidently recognized many accustomed observe sentencing. authors told several lawyers recidivists know sentencing tendencies judges well accused frequently attempt choose judge sentence , , lawyers say frequently able . said done way. prisoner sees going sentenced Judge X, believes severe sentencing tendency, change plea “Guilty” “Non Vult” “Non Vult” “Guilty,” etc. hope way sentencing postponed hence probably sentenced another judge. (p.812)several approaches one can take assessing independence. First, checking balance pre-treatment covariates absolute must. Insofar randomized experiment, observable unobservable characteristics distributed equally across judges. check balance unobservables, can check balance observables. papers aware check covariate balance, usually actual analysis.Insofar suspect endogenous sorting, might simply use original assignment, final assignment, identification. cases, know initial judge assignment random. approach may feasible many settings initial judge court assignment available. Nevertheless, endogenous sorting response severity judge undermine design introducing separate mechanism instrument impacts final decision (via sorting lenient judge’s courtroom possible), researcher attempt ascertain conversations administrators degree practically occurs data.violation exclusion often worry, though, really evaluated case case. instance, Dobbie, Goldin, Yang (2018), authors focused pretrial detention. pretrial detention determined bail set judges subsequent interaction next level’s randomized judge, definitely don’t interaction defendant upon judicial ruling punishment rendered. case, seem like Dobbie, Goldin, Yang (2018) might credible argument exclusion holds.consider situation defendant randomly assigned severe judge. expectation, case goes trial, defendant faces higher expected penalty even given fixed probability conviction across judge reason stricter judge likely choose harsher penalty thus drive expected penalty. Facing higher expected penalty, defense attorney defendant might decide accept lesser plea response judge’s anticipated severity, violate exclusion since exclusion requires instrument effect outcome judge’s decision (sentence).even exclusion can defended, many situations monotonicity becomes difficult case make design. explicitly monotonicity made Imbens Angrist (1994) skeptical judge fixed effects used identify local average treatment effect. instrument required weakly operate across defendants. Either judge strict isn’t, can’t different circumstances. Yet humans complex bundles thoughts experiences, biases may operate non-transitive ways. instance, judge may lenient, except defendant black offense drug charge, case switch become strict. Mueller-Smith (2015) attempted overcome potential violations exclusion monotonicity parametric strategy simultaneously instrumenting observed sentencing dimensions thus allowing instruments’ effect sentencing outcomes heterogeneous defendant traits crime characteristics.Formal solutions querying plausibility assumptions appeared recent years, though. Frandsen, Lefgren, Leslie (2019) propose test exclusion monotonicity based relaxing monotonicity assumption. test requires average treatment effect among individuals violate monotonicity identical average treatment effect among subset individuals satisfy . test simultaneously tests exclusion monotonicity, one sure violation driving test’s result unless theoretically one rules one two using priori information. proposed test based two observations: average outcomes, conditional judge assignment, fit continuous function judge propensities, secondly, slope continuous function bounded magnitude width outcome variable’s support. test relatively straightforward simply requires examining whether observed outcomes averaged judges consistent function. can see picture looks like pass test top panel Figure 7.9 versus bottom panel, fails test.\nFigure 7.9: Average outcomes function judge propensities. Reprinted Frandsen, Lefgren, Leslie (2019).\nauthors made available code documentation can used implement test,126 currently available R therefore reviewed .section, ’d like accomplish two things. First, ’d like review interesting new paper Megan Stevenson examined cash bail affected case outcomes (Stevenson 2018). important policy question, felt good review excellent study. second purpose section replicate main results reader can see exactly implement instrumental variables strategy.judge fixed effects papers, Stevenson working administrative data large city. Large cities probably best context due large samples can help ameliorate finite sample bias IV. Fortunately, data often publicly available need scraped court records many locations posted online. Stevenson (2018) focuses Philadelphia, natural experiment random assignment bail judges (“magistrates”) unsurprisingly differ widely propensity set bail affordable levels. words, bail judges differ systematically price set bail, given downward-sloping demand curve, severe judges setting expensive bails see defendants unable pay bail. result, forced remain detention prior trial.Using variety IV estimators, Stevenson (2018) finds increase randomized pretrial detention leads 13% increase likelihood receiving conviction. argues caused increase guilty pleas among defendants otherwise acquitted charges dropped—particularly problematic mechanism, true. Pretrial detention also led 42% increase length incarceration sentence 41% increase amount non-bail fees owed. provides support idea cash bail contributes cycle poverty defendants unable pay court fees end trapped penal system higher rates guilt, higher court fees, likely higher rates reoffending (Dobbie, Goldin, Yang 2018).One might think judge fixed effects design “just identified” model. Can’t just use instrument average strictness judge (excluding defendant’s case)? just one instrument one endogenous variable, 2SLS seems like likely candidate, right? , one instrument unique individual individual unique judge unique average strictness average strictness calculated mean judge sentencing excluding individual consideration.problem still just high-dimension instrument. correct specification use actual judge fixed effects, depending application may anywhere eight (Stevenson’s case) hundreds judges. Insofar weak, probably , run typical kind overidentification problem finite samples begin moving point estimates back centering OLS bias discussed earlier. issue still resolved econometricians likely active area research going forward. solutions may use high-dimension reduction techniques LASSO (Gilchrist Sands 2016), instrument selection (Donald Newey 2001), perhaps combining individual judges similar strictness one instrument.Stevenson’s data contains 331,971 observations eight randomly assigned bail judges. Like many papers judge fixed effects literature, uses jackknife instrumental variables estimator (JIVE) (Angrist, Imbens, Krueger 1999). 2SLS commonly used IV estimator applied microeconomics applications, suffers finite sample problems weak instruments use many instruments showed discussion Bound, Jaeger, Baker (1995). Angrist, Imbens, Krueger (1999) proposed estimator attempts eliminate finite-sample bias 2SLS called JIVE.127 aren’t perfect, distributions larger 2SLS estimator, may advantage several instruments weak (likely occur judge fixed effects).JIVE popularly known “leave one ” estimator. Angrist, Imbens, Krueger (1999) suggest using observations estimator except \\(\\) unit. nice feature judge fixed effects ideally instrument mean strictness judge cases, excluding particular defendant’s case. JIVE nice handling finite sample bias, construction theoretical instrument generally.Given econometrics judge fixed effects many instruments potentially frontier econometrics, goal somewhat backwards looking. simply run simple exercises using JIVE can see historically researchers estimating models.bail.dobail.RThese results pretty interesting. Notice just examine using OLS, ’d conclude actually connection pre-trial detention guilty plea. either zero using time controls, raised probability 3% fuller set controls (mainly demographic controls, prior offenses, characteristics offense ). , use IV binary judge fixed effects instruments, effects change lot. end estimates ranging 15 21%, probably focused JIVE advantages, previously mentioned. can examine strength instruments regressing detention onto binary instruments see just strong instruments , strong. two statistically significant 1% level. two, one p-value 0.076 weak \\((p<0.25)\\).Table 7.14:  OLS IV Estimates Detention Guilty Plea\nFirst model includes controls time; second model controls characteristics defendant. Outcome guilty plea. Heteroskedastic robust standard errors parenthesis. \\(^{*}\\) \\(p<0.10\\), \\(^{**}\\) \\(p<0.05\\), \\(^{***}\\) \\(p<0.01\\)\njudge fixed effects design popular form instrumental variables. used whenever exists wheel randomly assigned decision makers assigning treatment kind people. Important questions answers area criminal justice examined using design. linked external administrative data sources, researchers able carefully evaluate causal effect criminal justice interventions long-term outcomes. procedure uniquely sensitive identifying assumptions related independence, exclusion, monotonicity must carefully contemplated going forward design. Nevertheless, assumptions can credibly defended, powerful estimator local average treatment effects.","code":"use https://github.com/scunning1975/mixtape/raw/master/judge_fe.dta, clear\n \nglobal judge_pre judge_pre_1 judge_pre_2 judge_pre_3 judge_pre_4 judge_pre_5 judge_pre_6 judge_pre_7 judge_pre_8\nglobal demo black age male white \nglobal off      fel mis sum F1 F2 F3 F M1 M2 M3 M \nglobal prior priorCases priorWI5 prior_felChar  prior_guilt onePrior threePriors\nglobal control2     day day2 day3  bailDate t1 t2 t3 t4 t5 t6\n\n\n* Naive OLS\n* minimum controls\nreg guilt jail3 $control2, robust\n* maximum controls\nreg guilt jail3 possess robbery DUI1st drugSell aggAss $demo $prior $off  $control2 , robust\n\n\n* First stage\nreg jail3 $judge_pre $control2, robust\nreg jail3 possess robbery DUI1st drugSell aggAss $demo $prior $off  $control2 $judge_pre, robust\n\n\n\n** Instrumental variables estimation\n* 2sls main results\n* minimum controls\nivregress 2sls guilt (jail3= $judge_pre) $control2, robust first\n* maximum controls\nivregress 2sls guilt (jail3= $judge_pre) possess robbery DUI1st drugSell aggAss $demo $prior $off $control2 , robust first\n\n* JIVE main results\n* minimum controls\njive guilt (jail3= $judge_pre) $control2, robust\n* maximum controls\njive guilt (jail3= $judge_pre) possess robbery DUI1st drugSell aggAss $demo $prior $off $control2 , robust\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\nlibrary(lfe)\nlibrary(SteinIV)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\njudge <- read_data(\"judge_fe.dta\")\n\n#grouped variable names from the data set\njudge_pre <- judge %>% \n  select(starts_with(\"judge_\")) %>% \n  colnames() %>% \n  subset(., . != \"judge_pre_8\") %>% # remove one for colinearity\n  paste(., collapse = \" + \")\n\ndemo <- judge %>% \n  select(black, age, male, white) %>% \n  colnames() %>% \n  paste(., collapse = \" + \")\n\noff <- judge %>% \n  select(fel, mis, sum, F1, F2, F3, M1, M2, M3, M) %>% \n  colnames() %>% \n  paste(., collapse = \" + \")\n\nprior <- judge %>% \n  select(priorCases, priorWI5, prior_felChar, \n         prior_guilt, onePrior, threePriors) %>% \n  colnames() %>% \n  paste(., collapse = \" + \")\n\ncontrol2 <- judge %>%\n  mutate(bailDate = as.numeric(bailDate)) %>% \n  select(day, day2, bailDate, \n         t1, t2, t3, t4, t5) %>% # all but one time period for colinearity\n  colnames() %>% \n  paste(., collapse = \" + \")\n\n#formulas used in the OLS\nmin_formula <- as.formula(paste(\"guilt ~ jail3 + \", control2))\nmax_formula <- as.formula(paste(\"guilt ~ jail3 + possess + robbery + DUI1st + drugSell + aggAss\",\n                                demo, prior, off, control2, sep = \" + \"))\n\n#max variables and min variables\nmin_ols <- lm_robust(min_formula, data = judge)\nmax_ols <- lm_robust(max_formula, data = judge)\n\n#--- Instrumental Variables Estimations\n#-- 2sls main results\n#- Min and Max Control formulas\nmin_formula <- as.formula(paste(\"guilt ~ \", control2, \" | 0 | (jail3 ~ 0 +\", judge_pre, \")\"))\nmax_formula <- as.formula(paste(\"guilt ~\", demo, \"+ possess +\", prior, \"+ robbery +\", \n                                off, \"+ DUI1st +\", control2, \"+ drugSell + aggAss | 0 | (jail3 ~ 0 +\", judge_pre, \")\"))\n#2sls for min and max\nmin_iv <- felm(min_formula, data = judge)\nsummary(min_iv)\nmax_iv <- felm(max_formula, data = judge)\nsummary(max_iv)\n\n\n\n#-- JIVE main results\n#- minimum controls\ny <- judge %>%\n  pull(guilt)\n\nX_min <- judge %>%\n  mutate(bailDate = as.numeric(bailDate)) %>%\n  select(jail3, day, day2, t1, t2, t3, t4, t5, bailDate) %>%\n  model.matrix(data = .,~.)\n\nZ_min <- judge %>%\n  mutate(bailDate = as.numeric(bailDate)) %>%\n  select(-judge_pre_8) %>%\n  select(starts_with(\"judge_pre\"), day, day2, t1, t2, t3, t4, t5, bailDate) %>%\n  model.matrix(data = .,~.)\n\njive.est(y = y, X = X_min, Z = Z_min)\n\n#- maximum controls\nX_max <- judge %>%\n  mutate(bailDate = as.numeric(bailDate)) %>%\n  select(jail3, white, age, male, black,\n         possess, robbery, prior_guilt,\n         prior_guilt, onePrior, priorWI5, prior_felChar, priorCases,\n         DUI1st, drugSell, aggAss, fel, mis, sum,\n         threePriors,\n         F1, F2, F3,\n         M, M1, M2, M3,\n         day, day2, bailDate, \n         t1, t2, t3, t4, t5) %>%\n  model.matrix(data = .,~.)\n\nZ_max <- judge %>%\n  mutate(bailDate = as.numeric(bailDate)) %>%\n  select(-judge_pre_8) %>%\n  select(starts_with(\"judge_pre\"), white, age, male, black,\n         possess, robbery, prior_guilt,\n         prior_guilt, onePrior, priorWI5, prior_felChar, priorCases,\n         DUI1st, drugSell, aggAss, fel, mis, sum,\n         threePriors,\n         F1, F2, F3,\n         M, M1, M2, M3,\n         day, day2, bailDate, \n         t1, t2, t3, t4, t5) %>%\n  model.matrix(data = .,~.)\n\njive.est(y = y, X = X_max, Z = Z_max)"},{"path":"ch6.html","id":"bartik-instruments","chapter":"7 Instrumental Variables","heading":"7.8.3 Bartik instruments","text":"Bartik instruments, also known shift-share instruments, named Timothy Bartik, used careful study regional labor-markets (Bartik 1991). Bartik’s book instrument received wider attention following year Blanchard Katz (1992). particularly influential areas migration trade, well labor, public, several fields. simple search phrase “Bartik instrument” Google Scholar reveals almost five hundred cites time writing.just Stigler’s law eponymy promises (Stigler 1980), Bartik instruments originate Bartik (1991). Goldsmith-Pinkham, Sorkin, Swift (2020) notes traces can found early Perloff (1957) showed industry shares used predict income levels. Freeman (1980) also used change industry composition instrument labor demand. due Bartik’s careful empirical analysis using instrument combined detailed exposition logic national growth shares created variation labor-market demand Appendix 4 book, design named .OLS estimates effect employment growth rates labor-market outcomes likely hopelessly biased since labor-market outcomes simultaneously determined labor supply labor demand. Bartik therefore suggested using IV resolve issue Appendix 4 describes ideal instrument.Obvious candidates instruments variables shifting MSA labor demand. book, one type demand shifter used form instrumental variables: share effect shift-share analysis metropolitan area year--year employment change. shift-share analysis decomposes MSA growth three components: national growth component, calculates growth occurred industries MSA grown -industry national average; share component, calculates extra growth occurred industry MSA grown industry’s national average; shift component, calculates extra growth occurs industries grow different rates locally nationally. (Bartik 1991)(p.202)Summarizing , idea behind Bartik instrument measure change region’s labor demand due changes national demand different industries’ products.128 make concrete, let’s assume interested estimating following wage equation:\\[\\begin{align}\n   Y_{l,t} = \\alpha + \\delta I_{l,t} + \\rho X_{l,t} + \\varepsilon_{l,t}\n\\end{align}\\]\\(Y_{l,t}\\) log wages location \\(l\\) (e.g., Detroit) time period \\(t\\) (e.g., 2000) among native workers, \\(I_{l,t}\\) immigration flows region \\(l\\) time period \\(t\\) \\(X_{l,t}\\) controls include region time fixed effects, among things. parameter \\(\\delta\\) elsewhere average treatment effect immigration flows’ effect native wages. problem almost certainly case immigration flows highly correlated disturbance term time-varying characteristics location \\(l\\) (e.g., changing amenities) (Sharpe 2019).Bartik instrument created interacting initial “shares” geographic regions, prior contemporaneous immigration flow, national growth rates. deviations region’s growth US national average explained deviations growth prediction variable US national average. deviations growth prediction variables US national average due shares national growth effect particular time period regions. can define Bartik instrument follows:\\[\\begin{align}\n   {B}_{l,t} = \\sum_{k=1}^K z_{l,k,t^0} m_{k,t}\n\\end{align}\\]\\(z_{l,k,t^0}\\) “initial” \\(t^0\\) share immigrants source country \\(k\\) (e.g., Mexico) location \\(l\\) (e.g., Detroit) \\(m_{k,t}\\) change immigration country \\(k\\) (e.g., Mexico) US whole. first term share variable second term shift variable. predicted flow immigrants, \\({B}\\), destination \\(l\\) (e.g., Detroit) just weighted average national inflow rates country weights depend initial distribution immigrants.constructed instrument, two-stage least squares estimator first regresses endogenous \\(I_{l,t}\\) onto controls Bartik instrument. Using fitted values regression, regress \\(Y_{l,t}\\) onto \\(\\widehat{}_{l,t}\\) recover impact immigration flows onto log wages.","code":""},{"path":"ch6.html","id":"shifts-vs-shares","chapter":"7 Instrumental Variables","heading":"7.8.4 Shifts vs Shares","text":"’d like now turn identifying assumptions unique design. two perspectives needed leverage Bartik design identify causal effect separately address roles exogeneity shares versus shifts. perspective take depend ex ante plausibility certain assumptions. also depend different tools.Goldsmith-Pinkham, Sorkin, Swift (2020) explain shares perspective. show shifts affect strength first stage, actually initial shares provide exogenous variation. write “Bartik instrument ‘equivalent’ using local industry shares instruments, exogeneity condition interpreted terms shares.” Insofar researcher’s application exploiting differential exogenous exposure common shocks, industry specific shocks, two-industry scenario, likely source exogeneity comes initial shares shifts. type strict exogeneity assumption initial shares exogenous conditional observables, location fixed effects. means practice burden researcher argue believe initial shares indeed exogenous.exogenous shares sufficient, turns necessary identification causal effects. Temporal shocks may provide exogeous sources variation. Borusyak, Hull, Jaravel (2019) explain shifts perspective. show exogenous independent shocks many industries allow Bartik design identify causal effects regardless whether shares exogenous long shocks uncorrelated bias shares. Otherwise, may shock creating exogenous variation, case focus excludability moves away initial shares towards national shocks (Borusyak, Hull, Jaravel 2019). authors write:Ultimately, plausibility exogenous shocks framework, alternative framework Goldsmith-Pinkham, Sorkin, Swift (2020) based exogenous shares, depends shift-share IV application. encourage practitioners use shift-share instruments based priori argument supporting plausibility either one approaches; various diagnostics tests framework suitable setting may applied. Borusyak, Hull, Jaravel (2019) develops procedures “shocks” view, Goldsmith-Pinkham, Sorkin, Swift (2020) provide different tools “shares” view.Insofar think initial shares instruments, shocks, world initial shares measuring differential exogenous exposures common shock. shares equilibrium values, based past labor supply demand, may tough justify consider exogenous structural unobserved determinants future labor-market outcome. turns critical piece. valid Bartik design can valid even shares correlated indirectly levels outcomes; just can’t correlated differential changes associated national shock , subtle distinct point.One challenge Bartik instruments sheer number shifting values. instance, almost four hundred different industries United States. Multiplied many time periods exclusion restriction becomes bit challenging defend. Goldsmith-Pinkham, Sorkin, Swift (2020) provide several suggestions evaluating central identifying assumption design. instance, pre-period, ironically design begins resemble difference--differences design discuss subsequent chapter. case, might test placebos, pre-trends, forth.Another possibility based observation Bartik instrument simply specific combination many instruments. sense, bears resemblance judge fixed effects design earlier judge’s propensity specific combination many binary fixed effects. many instruments, options become available. researcher willing assume null constant treatment effects, overidentification tests option. overidentification tests can fail treatment heterogeneity opposed exclusion holding. Similar Borusyak, Hull, Jaravel (2019), insofar one willing assume cross-sectional heterogeneity treatment effects constant within location , Goldsmith-Pinkham, Sorkin, Swift (2020) provides diagnostic aids help evaluate plausibility design .second result Goldsmith-Pinkham, Sorkin, Swift (2020) decomposition Bartik estimator weighted combination estimates share instrument. weights, called Rotemberg weights, sum one, authors note higher valued weights indicate instruments responsible identifying variation design . weights provide insight shares get weight overall estimate, helps clarify industry shares scrutinized. regions high weights pass basic specification tests, confidence overall identification strategy defensible.","code":""},{"path":"ch6.html","id":"conclusion-5","chapter":"7 Instrumental Variables","heading":"7.9 Conclusion","text":"conclusion, instrumental variables powerful design identifying causal effects data suffer selection unobservables. even mind, many limitations contemporary period caused many applied researchers eschew . First, identifies LATE heterogeneous treatment effects, may may policy relevant variable. value ultimately depends closely compliers’ average treatment effect resembles subpopulations. Second, unlike RDD, one main identifying assumption (continuity assumption), IV five assumptions! Thus, can immediately see people find IV estimation less credible—fails identify causal effect, rather ’s harder harder imagine pure instrument satisfies five conditions.say, IV important strategy sometimes opportunity use come along, prepared happens understanding implement practice. can best instruments found? Angrist Krueger (2001) note best instruments come -depth knowledge institutional details program intervention. things spend life studying time reveal good instruments. Rarely find simply downloading new data set, though. Intimate familiarity find instrumental variables, , alas, shortcut achieving .Buy print version today:","code":""},{"path":"ch7.html","id":"ch7","chapter":"8 Panel Data","heading":"8 Panel Data","text":"Buy print version today:One important tools causal inference toolkit panel data estimator. estimators designed explicitly longitudinal data—repeated observing unit time. certain situations, repeatedly observing unit time can overcome particular kind omitted variable bias, though kinds. possible observing unit time resolve bias, still many applications can, ’s method important. review first DAG describing just situation, followed discussion paper, present data set exercise R Stata.129","code":""},{"path":"ch7.html","id":"dag-example","chapter":"8 Panel Data","heading":"8.1 DAG Example","text":"dig technical assumptions estimation methodology panel data techniques, want review simple DAG illustrating assumptions. DAG comes Imai Kim (2017). Let’s say data column outcomes \\(Y_i\\), appear three time periods. words, \\(Y_{i1}\\), \\(Y_{i2}\\), \\(Y_{i3}\\) \\(\\) indexes particular unit \\(t=1,2,3\\) index time period \\(\\) unit observed. Likewise, matrix covariates, \\(D_i\\), also vary time—\\(D_{i1}\\), \\(D_{i2}\\), \\(D_{i3}\\). finally, exists single unit-specific unobserved variable, \\(u_i\\), varies across units, vary time unit. Hence reason \\(t=1,2,3\\) subscript \\(u_i\\) variable. Key variable () unobserved data set, (b) unit-specific, (c) change time given unit \\(\\). Finally exists unit-specific time-invariant variable, \\(X_i\\). Notice doesn’t change time, just \\(u_i\\), unlike \\(u_i\\) observed.busiest DAG ’ve seen far, merits discussion. First, let us note \\(D_{i1}\\) causes \\(Y_{i1}\\) well next period’s treatment value, \\(D_{i2}\\). Second, note unobserved confounder, \\(u_i\\), determines \\(Y\\) \\(D\\) variables. Consequently, \\(D\\) endogenous since \\(u_i\\) unobserved absorbed structural error term regression model. Thirdly, time-varying unobserved confounder correlated \\(D_{}\\)—confounder \\(u_i\\), call unobserved heterogeneity. Fourth, past outcomes directly affect current outcomes (.e., direct edge \\(Y_{}\\) variables). Fifth, past outcomes directly affect current treatments (.e., direct edge \\(Y_{, t-1}\\) \\(D_{}\\)). finally, past treatments, \\(D_{,t-1}\\) directly affect current outcomes, \\(Y_{}\\) (.e., direct edge \\(D_{,t-1}\\) \\(Y_{}\\)). assumptions can use particular panel method called fixed effects isolate causal effect \\(D\\) \\(Y\\).130What might example ? Let’s return story returns education. Let’s say interested effect schooling earnings, schooling partly determined unchanging genetic factors determine unobserved ability, like intelligence, contentiousness, motivation (Conley Fletcher 2017). observe people’s time-varying earnings schoolings time, situation described DAG describes directed edges missing edges, can use panel fixed effects models identify causal effect schooling earnings.","code":""},{"path":"ch7.html","id":"estimation","chapter":"8 Panel Data","heading":"8.2 Estimation","text":"use term “panel data,” mean? mean data set observe units (e.g., individuals, firms, countries, schools) one time period. Often outcome variable depends several factors, observed unobserved data, insofar unobserved variables correlated treatment variable, treatment variable endogenous correlations estimates causal effect. chapter focuses conditions correlation \\(D\\) \\(Y\\) reflects causal effect even unobserved variables correlated treatment variable. Specifically, omitted variables constant time, even heterogeneous across units, can use panel data estimators consistently estimate effect treatment variable outcomes.several different kinds estimators panel data, chapter cover two: pooled ordinary least squares (POLS) fixed effects (FE).131First need set notation. exceptions, panel methods usually based traditional notation potential outcomes notation.Let \\(Y\\) \\(D\\equiv(D_1, D_2, \\dots, D_k)\\) observable random variables \\(u\\) unobservable random variable. interested partial effects variable \\(D_j\\) population regression function:\n\\[\nE\\big[Y\\mid D_1,D_2, \\dots , D_k, u\\big]\n\\]\nobserve sample \\(=1,2,\\dots,N\\) cross-sectional units \\(t=1,2,\\dots,T\\) time periods (balanced panel). unit \\(\\), denote observable variables time periods \\(\\{(Y_{},D_{}):t=1,2,\\dots,T\\}\\).132 Let \\(D_{}\\equiv(D_{it1},D_{it2}, \\dots, D_{itk})\\) \\(1\\times K\\) vector. typically assume actual cross-sectional units (e.g., individuals panel) identical independent draws population case \\(\\{Y_i, D_i, u_i\\}^N_{=1}\\sim ..d.\\), cross-sectional independence. describe main observables, , \\(Y_i \\equiv (Y_{i1}, Y_{i2}, \\dots, Y_{})'\\) \\(D_i \\equiv (D_{i1},D_{i2}, \\dots, D_{})\\).’s helpful now illustrate actual stacking individual units across time periods. single unit \\(\\) multiple time periods \\(t\\)\n\\[\nY_i=\\left( \\begin{array}{c}\n   Y_{i1} \\\\\n   \\vdots \\\\\n   Y_{} \\\\\n   \\vdots \\\\\n   Y_{}\n   \\end{array} \\right)_{T\\times 1}\n   \\qquad\n   D_i = \\left( \\begin{array}{ccccc}\n   D_{,1,1} & D_{,1,2} & D_{,1,j} & \\dots & D_{,1,K}\n   \\\\\n   \\vdots & \\vdots & \\vdots & & \\vdots\n   \\\\\n   D_{,t,1} & D_{,t,2} & D_{,t,j} & \\dots & D_{,t,K}\n   \\\\\n   \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n   D_{,T,1} & D_{,T,2} & D_{,T,j} & \\dots & D_{,T,K}\n   \\end{array} \\right)_{T\\times K}\n\\]\nentire panel units included look like :\n\\[\nY = \\left( \\begin{array}{c}\n   Y_{1} \\\\\n   \\vdots \\\\\n   Y_{} \\\\\n   \\vdots \\\\\n   Y_{N}\n   \\end{array} \\right)_{NT\\times 1}\n   \\qquad\n   D = \\left( \\begin{array}{c}\n   D_1 \\\\\n   \\vdots \\\\\n   D_i \\\\\n   \\vdots \\\\\n   D_N\n   \\end{array} \\right)_{NT \\times K}\n\\]\nrandomly drawn cross-sectional unit \\(\\), model given \n\\[\nY_{}=\\delta D_{}+u_i+\\varepsilon_{},\n   \\quad t=1,2,\\dots,T\n\\]\nalways, use schooling-earnings example motivation. Let \\(Y_{}\\) log earnings person \\(\\) year \\(t\\). Let \\(D_{}\\) schooling person \\(\\) year \\(t\\). Let \\(\\delta\\) returns schooling. Let \\(u_i\\) sum time-invariant person-specific characteristics, unobserved ability. , said earlier, often called unobserved heterogeneity. let \\(\\varepsilon_{}\\) time-varying unobserved factors determine person’s wage given period. often called idiosyncratic error. want know happens regress \\(Y_{}\\) \\(D_{}\\).","code":""},{"path":"ch7.html","id":"pooled-ols","chapter":"8 Panel Data","heading":"8.2.1 Pooled OLS","text":"first estimator discuss pooled ordinary least squares, POLS estimator. ignore panel structure regress \\(Y_{}\\) \\(D_{}\\) get\n\\[\nY_{}=\\delta D_{} + \\eta_{};\n   \\quad\n   t=1,2,\\dots,T\n\\]\ncomposite error \\(\\eta_{} \\equiv c_i + \\varepsilon_{}\\). main assumption necessary obtain consistent estimates \\(\\delta\\) :\n\\[\nE\\big[\\eta_{}\\mid D_{i1},D_{i2}, \\dots, D_{}\\big] = E\\big[\\eta_{}\\mid D_{}\\big] = 0\n   \\quad\n   \\text{$t=1,2,\\dots, T$}\n\\]\nDAG include \\(\\varepsilon_{}\\), equivalent assuming unobserved heterogeneity, \\(c_i\\), uncorrelated \\(D_{}\\) time periods.appropriate assumption case DAG explicitly links unobserved heterogeneity outcome treatment period. using schooling-earnings example, schooling likely based unobserved background factors, \\(u_i\\), therefore without controlling , omitted variable bias \\(\\widehat{\\delta}\\) biased. correlation \\(D_{}\\) \\(\\eta_{}\\) necessarily means correlation unobserved \\(u_i\\) \\(D_{}\\) \\(t\\) just probably credible assumption. additional problem \\(\\eta_{}\\) serially correlated unit \\(\\) since \\(u_i\\) present \\(t\\) period. thus heteroskedastic robust standard errors also likely small.","code":""},{"path":"ch7.html","id":"fixed-effects-within-estimator","chapter":"8 Panel Data","heading":"8.2.2 Fixed effects (within Estimator)","text":"Let’s rewrite unobserved effects model still firmly minds:\n\\[\nY_{} = \\delta D_{} + u_i + \\varepsilon_{};\n   \\quad\n   t=1,2,\\dots,T\n\\]\ndata multiple time periods, can think \\(u_i\\) fixed effects estimated. OLS estimation fixed effects yields\n\\[\n\\big(\\widehat{\\delta}, \\widehat{u}_1, \\dots, \\widehat{u}_N\\big) = \\underset{b,m_1,\\dots,m_N}{\\arg\\min} \\sum_{=1}^N\\sum_{t=1}^T (Y_{}-D_{}b- m_i)^2\n\\]\namounts including \\(N\\) individual dummies regression \\(Y_{}\\) \\(D_{}\\).first-order conditions (FOC) minimization problem :\n\\[\n\\sum_{=1}^N \\sum_{t=1}^T D_{}'\n   \\big(Y_{} - D_{}\\widehat{\\delta} - \\widehat{u}_i\\big)=0\n\\]\n\n\\[\n\\sum_{t=1}^T\\big(Y_{} - D_{}\\widehat{\\delta} - \\widehat{u}_i\\big)=0\n\\]\n\\(=1,\\dots,N\\).Therefore, \\(=1, \\dots, N\\),\n\\[\n\\widehat{u}_i = \\dfrac{1}{T} \\sum_{t=1}^T\\big(Y_{}-D_{}\\widehat{\\delta}\\big)=\n   \\overline{Y}_i-\\overline{D}_i\\widehat{\\delta},\n\\]\n\n\\[\n\\overline{D}_i \\equiv \\dfrac{1}{T}\\sum_{t=1}^TD_{}; \\bar{Y}_i \\equiv \\dfrac{1}{T} \\sum_{t=1}^T Y_{}\n\\]\nPlug result first FOC obtain:\n\\[\n\\begin{gathered}\n   \\widehat{\\delta} = \\bigg( \\sum_{=1}^N \\sum_{t=1}^T (D_{} - \\overline{D}_i)'(D_{} - \\overline{D}_i) \\bigg)^{-1} \\bigg( \\sum_{=1}^N \\sum_{t=1}^T (D_{} - \\overline{D}_i)'(Y_{} - \\overline{Y})\\bigg)\n   \\\\\n   \\widehat{\\delta} = \\bigg(\\sum_{=1}^N \\sum_{t=1}^T \\ddot{D}_{}'\\ddot{D}_{} \\bigg)^{-1} \\bigg( \\sum_{=1}^N \\sum_{t=1}^T \\ddot{D}_{}' \\ddot{D}_{} \\bigg)\\end{gathered}\n\\]\ntime-demeaned variables \\(\\ddot{D}_{} \\equiv D_{}-\\overline{D},\\ddot{Y}_{} \\equiv Y_{} - \\overline{Y}_i\\).case isn’t clear, though, running regression time-demeaned variables \\(\\ddot{Y}_{}\\equiv Y_{} - \\overline{Y}_i\\) \\(\\ddot{D}_{} \\equiv D_{} - \\overline{D}\\) numerically equivalent regression \\(Y_{}\\) \\(D_{}\\) unit-specific dummy variables. Hence reason sometimes called “within” estimator, sometimes called “fixed effects” estimator. year fixed effects included, “twoway fixed effects” estimator. thing.133Even better, regression time-demeaned variables consistent \\(\\delta\\) even \\(C[D_{},u_i]\\ne 0\\) time-demeaning eliminates unobserved effects. Let’s see now:\\[\\begin{align}\n   Y_{}   & =\\delta D_{} + u_i + \\varepsilon_{}                                                             \n   \\\\\n   \\overline{Y}_i            & =\\delta \\overline{D}_i + u_i + \\overline{\\varepsilon}_{}                                           \n   \\\\\n   (Y_{} - \\overline{Y}_i) & =(\\delta D_{} - \\delta\\overline{D}) + (u_i - u_i) + (\\varepsilon_{} - \\overline{\\varepsilon}_i) \n   \\\\\n   \\ddot{Y}_{}             & =\\delta\\ddot{D}_{}+\\ddot{\\varepsilon}_{}                                                        \n\\end{align}\\]’d unobserved heterogeneity go?! deleted time-demeaned data. said, including individual fixed effects time demeaning automatically don’t go actual trouble manually.134So precisely form estimation? three ways implement fixed effects (within) estimator. :Demean regress \\(\\ddot{Y}_{}\\) \\(\\ddot{D}_{}\\) (need correct degrees freedom).Demean regress \\(\\ddot{Y}_{}\\) \\(\\ddot{D}_{}\\) (need correct degrees freedom).Regress \\(Y_{}\\) \\(D_{}\\) unit dummies (dummy variable regression).Regress \\(Y_{}\\) \\(D_{}\\) unit dummies (dummy variable regression).Regress \\(Y_{}\\) \\(D_{}\\) canned fixed effects routine Stata R.Regress \\(Y_{}\\) \\(D_{}\\) canned fixed effects routine Stata R.Later chapter, review example research. estimate model involving sex workers using pooled OLS, FE, demeaned OLS model. ’m hoping exercise help see similarities differences across three approaches.","code":""},{"path":"ch7.html","id":"identifying-assumptions-1","chapter":"8 Panel Data","heading":"8.2.3 Identifying Assumptions","text":"kind reviewed assumptions necessary identify \\(\\delta\\) fixed effects (within) estimator walked original DAG, let’s supplement DAG intuition formality. main identification assumptions :\\(E[\\varepsilon_{}\\mid D_{i1}, D_{i2}, \\dots, D_{}, u_i]=0; t=1,2,\\dots,T\\)\\(E[\\varepsilon_{}\\mid D_{i1}, D_{i2}, \\dots, D_{}, u_i]=0; t=1,2,\\dots,T\\)means regressors strictly exogenous conditional unobserved effect. allows \\(D_{}\\) arbitrarily related \\(u_i\\), though. concerns relationship \\(D_{}\\) \\(\\varepsilon_{}\\), \\(D_{}\\)’s relationship \\(u_i\\).means regressors strictly exogenous conditional unobserved effect. allows \\(D_{}\\) arbitrarily related \\(u_i\\), though. concerns relationship \\(D_{}\\) \\(\\varepsilon_{}\\), \\(D_{}\\)’s relationship \\(u_i\\).\\(rank\\bigg( \\sum_{t=1}^T E[\\ddot{D}_{}'\\ddot{D}_{}]\\bigg) = K\\)\\(rank\\bigg( \\sum_{t=1}^T E[\\ddot{D}_{}'\\ddot{D}_{}]\\bigg) = K\\)shouldn’t surprise point rank condition, even working simpler linear models, estimated coefficient always scaled covariance, scaling variance term. Thus regressors must vary time least \\(\\) collinear order \\(\\widehat{\\delta} \\approx \\delta\\).shouldn’t surprise point rank condition, even working simpler linear models, estimated coefficient always scaled covariance, scaling variance term. Thus regressors must vary time least \\(\\) collinear order \\(\\widehat{\\delta} \\approx \\delta\\).properties estimator assumptions 1 2 \\(\\widehat{\\delta}_{FE}\\) consistent (\\(\\underset{N\\rightarrow \\infty}{p\\lim}\\ \\widehat{\\delta}_{FE,N}=\\delta\\)) \\(\\widehat{\\delta}_{FE}\\) unbiased conditional D.briefly mention inference. standard errors framework must “clustered” panel unit (e.g., individual) allow correlation \\(\\varepsilon_{}\\) person \\(\\) time. yields valid inference long number clusters “large.”135","code":""},{"path":"ch7.html","id":"caveat-1-fixed-effects-cannot-solve-reverse-causality","chapter":"8 Panel Data","heading":"8.2.4 Caveat #1: Fixed effects cannot solve reverse causality","text":", still things fixed effects (within) estimators solve. instance, let’s say regressed crime rates onto police spending per capita. Becker (1968) argues increases probability arrest, usually proxied police per capita police spending per capita, reduce crime. time, police spending per capita function crime rates. kind reverse causality problem shows panel models regressing crime rates onto police. instance, see Cornwell Trumbull (1994). ’ve reproduced portion Table 8.1. dependent variable crime rates county North Carolina panel, find positive correlation police crime rates, opposite Becker predicts. mean police area causes higher crime rates? likely reflect reverse causality problem?Table 8.1:  Panel estimates police crime\nNorth Carolina county level data. Standard errors parenthesis.\n, one situation wouldn’t want use panel fixed effects reverse causality simultaneity bias. specifically reverse causality strong observational data. technically violate DAG, though, presented start chapter. Notice reverse causality, \\(Y \\rightarrow D\\), explicitly ruled theoretical model contained DAG. obviously, police—crime example, DAG inappropriate, amount reflection problem tell DAG inappropriate. Thus requires, ’ve said repeatedly, careful reflection, writing exactly relationship treatment variables outcome variables DAG can help develop credible identification strategy.","code":""},{"path":"ch7.html","id":"caveat-2-fixed-effects-cannot-address-time-variant-unobserved-heterogeneity","chapter":"8 Panel Data","heading":"8.2.5 Caveat #2: Fixed effects cannot address time-variant unobserved heterogeneity","text":"second situation panel fixed effects don’t buy anything unobserved heterogeneity time-varying. situation, demeaning simply demeaned unobserved time-variant variable, moved composite error term, since time-demeaned \\(\\ddot{u}_{}\\) correlated \\(\\ddot{D}_{}\\), \\(\\ddot{D}_{}\\) remains endogenous. , look carefully DAG—panel fixed effects appropriate \\(u_i\\) unchanging. Otherwise ’s just another form omitted variable bias. , said, don’t just blindly use fixed effects think solves omitted variable bias problem—way shouldn’t use matching just ’s convenient . need DAG, based actual economic model, allow build appropriate research design. Nothing substitutes careful reasoning economic theory, necessary conditions good research design.","code":""},{"path":"ch7.html","id":"returns-to-marriage-and-unobserved-heterogeneity","chapter":"8 Panel Data","heading":"8.2.6 Returns to marriage and unobserved heterogeneity","text":"might true? Let’s use example Cornwell Rupert (1997) authors attempt estimate causal effect marriage earnings. ’s well-known stylized fact married men earn unmarried men, even controlling observables. question whether correlation causal, whether reflects unobserved heterogeneity (.e., selection bias).let’s say panel data individuals. individuals \\(\\) observed four periods \\(t\\). interested following equation:136\n\\[\nY_{}=\\alpha+\\delta M_{}+\\beta X_{}+A_{} +\\gamma_i+\\varepsilon_{}\n\\]\nLet outcome wage \\(Y_{}\\) observed period, changes period. Let wages function marriage. Since people’s marital status changes time, marriage variable allowed change value time. race gender, scenarios, ordinarily change time; variables ordinarily unchanging, may sometimes hear called “time invariant.” Finally, variables \\(A_i\\) \\(\\gamma_i\\) variables unobserved, vary cross-sectionally across sample, vary time. call measures unobserved ability, may refer fixed endowment person, like fixed cognitive ability noncognitive ability “grit.” key unit-specific, unobserved, time-invariant. \\(\\varepsilon_{}\\) unobserved determinants wages assumed uncorrelated marriage covariates.Cornwell Rupert (1997) estimate feasible generalized least squares model three fixed effects models (includes different time-varying controls). authors call fixed effects regression “within” estimator, uses within unit variation eliminating confounding. estimates presented Table 8.2.Table 8.2:  Estimated wage regressions\nStandard errors parenthesis.\nNotice FGLS (column 1) finds strong marriage premium around 8.3%. , begin estimating fixed effects models, effect gets smaller less precise. inclusion marriage characteristics, years married job tenure, causes coefficient marriage fall around 60% FGLS estimate, longer statistically significant 5% level.","code":""},{"path":"ch7.html","id":"data-exercise-survey-of-adult-service-providers","chapter":"8 Panel Data","heading":"8.3 Data Exercise: Survey of Adult Service Providers","text":"Next ’d like introduce Stata exercise based data collection research: survey sex workers. may may know , Internet profound effect sex markets. moved sex work indoors simultaneously breaking traditional link sex workers pimps. increased safety anonymity, , effect causing new entrants. marginal sex worker education better outside options traditional US sex workers (Cunningham Kendall 2011, 2014, 2016). Internet, sum, caused marginal sex worker shift towards women sensitive detection, harm, arrest.2008 2009, surveyed (Todd Kendall) approximately 700 US Internet-mediated sex workers. survey basic labor-market survey; asked illicit legal labor-market experiences, demographics. survey two parts: “static” provider-specific section “panel” section. panel section asked respondents share information previous four sessions clients.137I created shortened version data set uploaded Github. includes time-invariant provider characteristics, race, age, marital status, years schooling, body mass index, well several time-variant session-specific characteristics including log hourly price, log session length (hours), characteristics client , whether condom used capacity session, whether client “regular,” etc.exercise, estimate three types models: pooled OLS model, fixed effects (FE), demeaned OLS model. model following form:\\[\\begin{align}\n   Y_{}        & =\\beta_i X_i + \\gamma_{} Z_{} + u_i + \\varepsilon_{} \n   \\\\\n   \\ddot{Y}_{} & = \\gamma_{} \\ddot{Z}_{} + \\ddot \\eta_{}              \n\\end{align}\\]\\(u_i\\) unobserved correlated \\(Z_{}\\).first regression model estimated pooled OLS second model estimated using fixed effects OLS. words, ’m going estimate model using canned routines Stata R individual fixed effects, well demean data manually estimate demeaned regression using OLS.Notice second regression different notation dependent independent variable; represents fact variables columns demeaned variables. Thus \\(\\ddot Y_{} = Y_{} - \\overline{Y}_i\\). Secondly, notice time-invariant \\(X_i\\) variables missing second equation. understand case? variables also demeaned, since demeaning across time, since time-invariant variables change time, demeaning deletes expression. Notice, also, unobserved individual specific heterogeneity, \\(u_i\\), disappeared. disappeared reason \\(X_i\\) terms gone—mean \\(u_i\\) time , thus demeaning deletes .Let’s examine models using following R Stata programs.sasp.dosasp.RA comments analysis. respondents left certain questions blank, likely due concerns anonymity privacy. dropped anyone missing values sake exercise. leaves us balanced panel. organized output Table 8.3. ’s lot interesting information three columns, may surprise novelty regressions. let’s talk statistically significant ones. pooled OLS regressions, recall, control unobserved heterogeneity, definition unobservable. potentially biased unobserved heterogeneity, kind selection bias, discuss anyhow.Table 8.3:  POLS, FE Demeaned OLS Estimates Determinants Log Hourly Price Panel Sex Workers\nHeteroskedastic robust standard errors parenthesis clustered provider level. \\(^{*}\\)\\(p<0.10\\), \\(^{**}\\)\\(p<0.05\\), \\(^{**}\\)\\(^{*}\\)\\(p<0.01\\)\nFirst, simple scan second third column show fixed effects regression included (shown) dummies individual equivalent regression demeaned data. help persuade fixed effects demeaned (within) estimators yielding coefficients.second, let’s dig results. One first things observe pooled OLS model, compensating wage differential detectable unprotected sex client.138 , notice fixed effects model, unprotected sex premium. consistent Rosen (1986) posited existence risk premia, well Gertler, Shah, Bertozzi (2005) found risk premia sex workers using panel data. Gertler, Shah, Bertozzi (2005), though, find much larger premia 20% unprotected sex, whereas finding mere 5%. large number unprotected instances fellatio, carries much lower risk infection unprotected receptive intercourse. Nevertheless, interesting unprotected sex, assumption strict exogeneity, appears cause wages rise approximately 5%, statistically significant 10% level. Given hourly wage $262, amounts mere 13 additional dollars per hour. lack finding pooled OLS model seems suggest unobserved heterogeneity masking effect.Next look session length. Note already adjusted price client paid length session outcome log wage, opposed log price. log-log regression, can interpret coefficient log length elasticity. use fixed effects, elasticity increases \\(-0.308\\) \\(-0.435\\). significance result, economic terms, though, appear “volume discounts” sex work. , longer sessions expensive, decreasing rate. Another interesting result whether client “regular,” meant seen another session. pooled OLS model, regulars paid 4.7% less, shrinks slightly fixed effects model 3.7% reductions. Economically, lower new clients pose risks repeat customers pose. Thus, expect prices move closer marginal cost, disappearance risk repeated session lower price, appears .Another factor related price attractiveness client. Interestingly, go direction may expected. One might expect attractive client, less pays. fact opposite. Given research finds beautiful people earn money (Hamermesh Biddle 1994), ’s possible sex workers price-discriminating. , see handsome client, deduce earns , therefore charge . result hold including fixed effects, though, suggesting due unobserved heterogeneity, least part.Similar unprotected sex, second provider present positive effect price, detectable fixed effects model. Controlling unobserved heterogeneity, presence second provider increases prices 11.3%. also see discriminates clients “” ethnicities, pay 14.2% White clients. ’s premium associated meeting hotel considerably smaller controlling provider fixed effects almost third. positive effect, even fixed effects model, may simply represent higher costs associated meeting hotel room. coefficients statistically significant.Many time-invariant results also interesting, though. instance, perhaps surprisingly, women higher BMI earn less. Hispanics earn less White sex workers. women schooling earn , something explored greater detail Cunningham Kendall (2016).","code":"use https://github.com/scunning1975/mixtape/raw/master/sasp_panel.dta, clear\ntsset id session\nforeach x of varlist lnw age asq bmi hispanic black other asian schooling cohab married divorced separated age_cl unsafe llength reg asq_cl appearance_cl provider_second asian_cl black_cl hispanic_cl othrace_cl hot massage_cl \ndrop if `x'==.\nbysort id: gen s=_N\nkeep if s==4\nforeach x of varlist lnw age asq bmi hispanic black other asian schooling cohab married divorced separated age_cl unsafe llength reg asq_cl appearance_cl provider_second asian_cl black_cl hispanic_cl  othrace_cl hot massage_cl \n\negen mean_`x'=mean(`x'), by(id)\ngen demean_`x'=`x' - mean_`x'\ndrop mean*\n\nxi: reg lnw  age asq bmi hispanic black other asian schooling cohab married divorced separated age_cl unsafe llength reg asq_cl appearance_cl provider_second asian_cl black_cl hispanic_cl othrace_cl hot massage_cl, robust\nxi: xtreg lnw  age asq bmi hispanic black other asian schooling cohab married divorced separated age_cl unsafe llength reg asq_cl appearance_cl provider_second asian_cl black_cl hispanic_cl othrace_cl hot massage_cl, fe i(id) robust\nreg demean_lnw demean_age demean_asq demean_bmi demean_hispanic demean_black demean_other demean_asian demean_schooling demean_cohab demean_married demean_divorced demean_separated demean_age_cl demean_unsafe demean_llength demean_reg demean_asq_cl demean_appearance_cl demean_provider_second demean_asian_cl demean_black_cl demean_hispanic_cl demean_othrace_cl demean_hot demean_massage_cl, robust cluster(id)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\nlibrary(plm)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nsasp <- read_data(\"sasp_panel.dta\")\n\n#-- Delete all NA\nsasp <- na.omit(sasp)\n\n#-- order by id and session \nsasp <- sasp %>% \n  arrange(id, session)\n\n#Balance Data\nbalanced_sasp <- make.pbalanced(sasp, \n                                balance.type = \"shared.individuals\")\n\n#Demean Data\nbalanced_sasp <- balanced_sasp %>% mutate( \n  demean_lnw = lnw - ave(lnw, id),\n  demean_age = age - ave(age, id),\n  demean_asq = asq - ave(asq, id),\n  demean_bmi = bmi - ave(bmi, id),\n  demean_hispanic = hispanic - ave(hispanic, id),\n  demean_black = black - ave(black, id),\n  demean_other = other - ave(other, id),\n  demean_asian = asian - ave(asian, id),\n  demean_schooling = schooling - ave(schooling, id),\n  demean_cohab = cohab - ave(cohab, id),\n  demean_married = married - ave(married, id),\n  demean_divorced = divorced - ave(divorced, id),\n  demean_separated = separated - ave(separated, id),\n  demean_age_cl = age_cl - ave(age_cl, id),\n  demean_unsafe = unsafe - ave(unsafe, id),\n  demean_llength = llength - ave(llength, id),\n  demean_reg = reg - ave(reg, id),\n  demean_asq_cl = asq_cl - ave(asq_cl, id),\n  demean_appearance_cl = appearance_cl - ave(appearance_cl, id),\n  demean_provider_second = provider_second - ave(provider_second, id),\n  demean_asian_cl = asian_cl - ave(asian_cl, id),\n  demean_black_cl = black_cl - ave(black_cl, id),\n  demean_hispanic_cl = hispanic_cl - ave(hispanic_cl, id),\n  demean_othrace_cl = othrace_cl - ave(lnw, id),\n  demean_hot = hot - ave(hot, id),\n  demean_massage_cl = massage_cl - ave(massage_cl, id)\n  )\n\n#-- POLS\nols <- lm_robust(lnw ~ age + asq + bmi + hispanic + black + other + asian + schooling + cohab + married + divorced + separated + \n           age_cl + unsafe + llength + reg + asq_cl + appearance_cl + provider_second + asian_cl + black_cl + hispanic_cl + \n           othrace_cl + hot + massage_cl, data = balanced_sasp)\nsummary(ols)\n\n\n#-- FE\nformula <- as.formula(\"lnw ~ age + asq + bmi + hispanic + black + other + asian + schooling + \n                      cohab + married + divorced + separated + \n                      age_cl + unsafe + llength + reg + asq_cl + appearance_cl + \n                      provider_second + asian_cl + black_cl + hispanic_cl + \n                      othrace_cl + hot + massage_cl\")\n\nmodel_fe <- lm_robust(formula = formula,\n                  data = balanced_sasp, \n                  fixed_effect = ~id, \n                  se_type = \"stata\")\n\nsummary(model_fe)\n\n#-- Demean OLS\ndm_formula <- as.formula(\"demean_lnw ~ demean_age + demean_asq + demean_bmi + \n                demean_hispanic + demean_black + demean_other +\n                demean_asian + demean_schooling + demean_cohab + \n                demean_married + demean_divorced + demean_separated +\n                demean_age_cl + demean_unsafe + demean_llength + demean_reg + \n                demean_asq_cl + demean_appearance_cl + \n                demean_provider_second + demean_asian_cl + demean_black_cl + \n                demean_hispanic_cl + demean_othrace_cl +\n                demean_hot + demean_massage_cl\")\n\nols_demean <- lm_robust(formula = dm_formula, \n                data = balanced_sasp, clusters = id,\n                se_type = \"stata\")\n\nsummary(ols_demean)"},{"path":"ch7.html","id":"conclusion-6","chapter":"8 Panel Data","heading":"8.4 Conclusion","text":"conclusion, exploring usefulness panel data estimating causal effects. noted fixed effects (within) estimator useful method addressing specific form endogeneity, caveats. First, eliminate unobserved observed time-invariant covariates correlated treatment variable. long treatment outcome varies time, strict exogeneity, fixed effects (within) estimator identify causal effect treatment outcome.came certain qualifications. one, method couldn’t handle time-variant unobserved heterogeneity. ’s thus burden researcher determine type unobserved heterogeneity problem face, face latter, panel methods reviewed unbiased consistent. Second, exists strong reverse causality pathways, panel methods biased. Thus, solve problem simultaneity, Wright faced estimating price elasticity demand, using fixed effects (within) estimator. likely, going move different framework facing kind problem.Still, many problems social sciences may credibly caused time-invariant unobserved heterogeneity problem, case fixed effects (within) panel estimator useful appropriate.Buy print version today:","code":""},{"path":"ch8.html","id":"ch8","chapter":"9 Difference-in-Differences","heading":"9 Difference-in-Differences","text":"Buy print version today:difference--differences design early quasi-experimental identification strategy estimating causal effects predates randomized experiment roughly eighty-five years. become single popular research design quantitative social sciences, , merits careful study researchers everywhere.139 chapter, explain popular important research design simplest form, group units treated time, common form, groups units treated different points time. focus identifying assumptions needed estimating treatment effects, including several practical tests robustness exercises commonly performed, point work difference--differences design (DD) done frontier research. included several replication exercises well.","code":""},{"path":"ch8.html","id":"john-snows-cholera-hypothesis","chapter":"9 Difference-in-Differences","heading":"9.1 John Snow’s Cholera Hypothesis","text":"thinking situations difference--differences design can used, one usually tries find instance consequential treatment given people units denied others “haphazardly.” sometimes called “natural experiment” based naturally occurring variation treatment variable affects units time. good difference--differences designs based kind natural experiment. one interesting natural experiments also one first difference--differences designs. story John Snow convinced world cholera transmitted water, air, using ingenious natural experiment (Snow 1855).Cholera vicious disease attacks victims suddenly, acute symptoms vomiting diarrhea. nineteenth century, usually fatal. three main epidemics hit London, like tornado, cut path devastation city. Snow, physician, watched tens thousands suffered died mysterious plague. Doctors help victims mistaken mechanism caused cholera spread people.majority medical opinion cholera transmission time miasma, said diseases spread microscopic poisonous particles infected people floating air. particles thought inanimate, microscopes time incredibly poor resolution, years microorganisms seen. Treatments, therefore, tended designed stop poisonous dirt spreading air. tried true methods like quarantining sick strangely ineffective slowing plague.John Snow worked London epidemics. Originally, Snow—like everyone—accepted miasma theory tried many ingenious approaches based theory block airborne poisons reaching people. went far cover sick burlap bags, instance, disease still spread. People kept getting sick dying. Faced theory’s failure explain cholera, good scientists —changed mind began look new explanation.Snow developed novel theory cholera active agent inanimate particle rather living organism. microorganism entered body food drink, flowed alimentary canal multiplied generated poison caused body expel water. evacuation, organism passed body , importantly, flowed England’s water supply. People unknowingly drank contaminated water Thames River, caused contract cholera. , evacuate vomit diarrhea, flow water supply , leading new infections across city. process repeated multiplier effect cholera hit city epidemic waves.Snow’s years observing clinical course disease led question usefulness miasma explain cholera. call “anecdote,” numerous observations imperfect studies nonetheless shaped thinking. ’s just observations puzzled . noticed cholera transmission tended follow human commerce. sailor ship cholera-free country arrived cholera-stricken port get sick landing taking supplies; get sick remained docked. Cholera hit poorest communities worst, people people lived crowded housing worst hygiene. might find two apartment buildings next one another, one heavily hit cholera, strangely one wouldn’t. noticed first building contaminated runoff privies water supply second building cleaner. observations weren’t impossible reconcile miasma, definitely unusual didn’t seem obviously consistent miasmis.Snow tucked away anecdotal evidence like . , evidence raised doubts mind, convinced. needed smoking gun eliminate doubt cholera spread water, air. find evidence? importantly, evidence like evenlook like?Let’s imagine following thought experiment. Snow dictator unlimited wealth power, test theory cholera waterborne? One thing flip coin household member—heads drink contaminated Thames, tails drink uncontaminated source. assignments made, Snow simply compare cholera mortality two groups. drank clean water less likely contract cholera, suggest cholera waterborne.Knowledge physical randomization used identify causal effects still eighty-five years away. issues besides ignorance kept Snow physical randomization. Experiments like one just described also impractical, infeasible, maybe even unethical—social scientists often rely natural experiments mimic important elements randomized experiments. natural experiment ? Snow needed find situation uncontaminated water distributed large number people random chance, calculate difference drink contaminated water. Furthermore, contaminated water need allocated people ways unrelated ordinary determinants cholera mortality, hygiene poverty, implying degree balance covariates groups. remembered—potential natural experiment London year earlier reallocated clean water citizens London. work?1800s, several water companies served different areas city. neighborhoods even served one company. took water Thames, polluted victims’ evacuations via runoff. 1849, Lambeth water company moved intake pipes upstream higher Thames, main sewage discharge point, thus giving customers uncontaminated water. obtain cleaner water, added benefit high Thames infected cholera runoff. Snow seized opportunity. realized given natural experiment allow test hypothesis cholera waterborne comparing households. theory right, Lambeth houses lower cholera death rates set households whose water infected runoff—might call today explicit counterfactual. found explicit counterfactual Southwark Vauxhall Waterworks Company.Unlike Lambeth, Southwark Vauxhall Waterworks Company moved intake point upstream, Snow spent entire book documenting similarities two companies’ households. instance, sometimes service cut irregular path neighborhoods houses households either side similar; difference drank different water different levels contamination runoff. Insofar kinds people company serviced observationally equivalent, perhaps similar relevant unobservables well.Snow meticulously collected data household enrollment water supply companies, going door door asking household heads name utility company. Sometimes individuals didn’t know, though, used saline test determine source (Coleman 2019). matched data city’s data cholera death rates household level. many ways advanced study might see today carefully collected, prepared, linked variety data sources show relationship water purity mortality. also displayed scientific ingenuity carefully framed research question long remained skeptical research design’s results convinced otherwise. combining everthing, able generate extremely persuasive evidence influenced policymakers city.140Snow wrote analysis manuscript entitled Mode Communication Cholera (Snow 1855). Snow’s main evidence striking, discuss results based Table XII Table IX (shown) Table 9.1. main difference version version Table XII use data estimate treatment effect using difference--differences.Table 9.1:  Modified Table XII (Snow 1854).","code":""},{"path":"ch8.html","id":"table-xii","chapter":"9 Difference-in-Differences","heading":"9.1.1 Table XII","text":"1849, 135 cases cholera per 10,000 households Southwark Vauxhall 85 Lambeth. 1854, 147 per 100,000 Southwark Vauxhall, whereas Lambeth’s cholera cases per 10,000 households fell 19.Snow explicitly calculate difference--differences, ability (Coleman 2019). difference Lambeth’s 1854 value 1849 value, followed differencing Southwark Vauxhall, can calculate estimate ATT equaling 78 fewer deaths per 10,000. Snow go produce evidence showing cholera deaths concentrated around pump Broad Street contaminated cholera, allegedly considered simple difference--differences convincing test hypothesis.importance work Snow undertook understand causes cholera London overstated. lifted ability estimate causal effects observational data, advanced science ultimately saved lives. Snow’s work cause cholera transmission, Freedman (1991) states:force Snow’s argument results clarity prior reasoning, bringing together many different lines evidence, amount shoe leather Snow willing use get data. Snow brilliant detective work nonexperimental data. impressive statistical technique handling scientific issues. made steady progress shrewd observation case studies analyze ecological data. end, found analyzed natural experiment. (p.298)","code":""},{"path":"ch8.html","id":"estimation-1","chapter":"9 Difference-in-Differences","heading":"9.2 Estimation","text":"","code":""},{"path":"ch8.html","id":"a-simple-table","chapter":"9 Difference-in-Differences","heading":"9.2.1 A simple table","text":"Let’s look example using tables, hopefully help give idea intuition behind DD, well identifying assumptions.141 Assume intervention clean water, ’ll write \\(D\\), objective estimate \\(D\\)’s causal effect cholera deaths. Let cholera deaths represented variable \\(Y\\). Can identify causal effect D just compare post-treatment 1854 Lambeth cholera death values 1854 Southwark Vauxhall values? many ways obvious choice, fact, one common naive approaches causal inference. , control group, don’t ? can’t just compare treatment group control group? Let’s look see.One things immediately must remember simple difference outcomes, , collapsed ATE treatment randomized. never randomized real world choices choices made real people endogenous potential outcomes. Let’s represent now differences Lambeth Southwark Vauxhall fixed level differences, fixed effects, represented \\(L\\) \\(SV\\). unobserved, unique company, fixed time. fixed effects mean even Lambeth hadn’t changed water source , still something determining cholera deaths, just time-invariant unique differences two companies relates cholera deathsin 1854.Compared ? Different companies.make simple comparison Lambeth Southwark Vauxhall, get estimated causal effect equalling \\(D+(L-SV)\\). Notice second term, \\(L-SV\\). ’ve seen . ’s selection bias found decomposition simple difference outcomes earlier book.Okay, say realize simply make cross-sectional comparisons two units selection bias. Surely, though, can compare unit ? sometimes called interrupted time series. Let’s consider simple --difference Lambeth now.Compared ? .procedure successfully eliminates Lambeth fixed effect (unlike cross-sectional difference), doesn’t give unbiased estimate \\(D\\) differences can’t eliminate natural changes cholera deaths time. Recall, events oscillating waves. can’t compare Lambeth (\\(T+D\\)) \\(T\\), omitted variable.intuition DD strategy remarkably simple: combine two simpler approaches selection bias effect time , turns, eliminated. Let’s look followingtable.Compared ? Difference company’s differences.first difference, \\(D_1\\), simple --difference. ultimately eliminates unit-specific fixed effects. , differences made, difference differences (hence name) get unbiased estimate \\(D\\).’s key assumption DD design, assumption discernible even table. assuming time-variant company specific unobservables. Nothing unobserved Lambeth households changing two periods also determines cholera deaths. equivalent assuming \\(T\\) units. call parallel trends assumption. discuss assumption repeatedly chapter proceeds, important assumption design’s engine. can buy parallel trends assumption, DD identify causal effect.DD powerful, yet amazingly simple design. Using repeated observations treatment control unit (usually several units), can eliminate unobserved heterogeneity provide credible estimate average treatment effect treated (ATT) transforming data specific ways. process yield correct answer? Turns , meets eye. imperative front end understand ’s hood can avoid conceptual errors design.","code":""},{"path":"ch8.html","id":"the-simple-2times-2-dd","chapter":"9 Difference-in-Differences","heading":"9.2.2 The simple \\(2\\times 2\\) DD","text":"cholera case particular kind DD design Goodman-Bacon (2019) calls \\(2\\times 2\\) DD design. \\(2\\times 2\\) DD design treatment group \\(k\\) untreated group \\(U\\). pre-period treatment group, \\(\\mathop{\\mathrm{pre}}(k)\\); post-period treatment group, \\(\\mathop{\\mathrm{post}}(k)\\); pre-treatment period untreated group, \\(\\mathop{\\mathrm{pre}}(U)\\); post-period untreated group, \\(\\mathop{\\mathrm{post}}(U)\\) :\n\\[\n  \\widehat{\\delta}^{2\\times 2}_{kU} = \\bigg ( \\overline{y}_k^{\\mathop{\\mathrm{post}}(k)} - \\overline{y}_k^{\\mathop{\\mathrm{pre}}(k)} \\bigg ) - \\bigg ( \\overline{y}_U^{\\mathop{\\mathrm{post}}(k)} - \\overline{y}_U^{\\mathop{\\mathrm{pre}}(k)} \\bigg )\n\\]\n\\(\\widehat{\\delta}_{kU}\\) estimated ATT group \\(k\\), \\(\\overline{y}\\) sample mean particular group particular time period. first paragraph differences treatment group, \\(k\\), minus , second paragraph differences untreated group, \\(U\\), minus . quantities obtained, difference second term first.simply mechanics calculations. exactly estimated parameter mapping onto? understand , must convert sample averages conditional expectations potential outcomes. easy working sample averages, see . First let’s rewrite conditional expectation.\n\\[\n\\widehat{\\delta}^{2\\times 2}_{kU} = \\bigg(E\\big[Y_k  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y_k  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]\\bigg)- \\bigg(E\\big[Y_U  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y_U  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]\\bigg)\n\\]Now let’s use switching equation, transforms historical quantities \\(Y\\) potential outcomes. ’ve done , ’ll little trick add zero right-hand side can use terms help illustrate something important.\n\\[\\begin{align}\n&\\widehat{\\delta}^{2\\times 2}_{kU} = \\bigg ( \\underbrace{E\\big[Y^1_k  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_k  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] \\bigg ) - \\bigg(E\\big[Y^0_U  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[ Y^0_U  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]}_{\\text{Switching equation}} \\bigg) \\\\\n&+ \\underbrace{E\\big[Y_k^0  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_k  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{Adding zero}}\n\\end{align}\\]Now simply rearrange terms get decomposition \\(2\\times 2\\) DD terms conditional expected potential outcomes.\n\\[\\begin{align}\n&\\widehat{\\delta}^{2\\times 2}_{kU} = \\underbrace{E\\big[Y^1_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{ATT}} \\\\\n&+\\Big[\\underbrace{E\\big[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] \\Big] - \\Big[E\\big[Y^0_U \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y_U^0 \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] }_{\\text{Non-parallel trends bias $2\\times 2$ case}} \\Big]\n\\end{align}\\]Now, let’s study last term closely. simple \\(2\\times 2\\) difference--differences isolate ATT (first term) second term zeroes . second term zero? equal zero first difference involving treatment group, \\(k\\), equaled second difference involving untreated group, \\(U\\).notice term second line. Notice anything strange ? object interest \\(Y^0\\), outcome world without treatment. ’s post period, post period, \\(Y=Y^1\\) \\(Y^0\\) switching equation. Thus, first term counterfactual. ’ve said , counterfactuals observable. bottom line often called parallel trends assumption definition untestable since observe counterfactual conditional expectation. return , now simply present consideration.","code":""},{"path":"ch8.html","id":"dd-and-the-minimum-wage","chapter":"9 Difference-in-Differences","heading":"9.2.3 DD and the Minimum Wage","text":"Now ’d like talk explicit economic content, minimum wage good topic . modern use DD brought social sciences esteemed labor economist Orley Ashenfelter (1978). study doubt influential advisee, David Card, arguably greatest labor economist generation. Card go use method several pioneering studies, Card (1990). focus one particular—now-classic minimum wage study (Card Krueger 1994).Card Krueger (1994) infamous study use explicit counterfactual estimation, study challenges many people’s common beliefs negative effects minimum wage. lionized massive back--forth minimum-wage literature continues day.142 controversial study James Buchanan, Nobel Prize winner, called influenced Card Krueger (1994) “camp following whores” letter editor Wall Street Journal (Buchanan 1996).143Suppose interested effect minimum wages employment. Theoretically, might expect competitive labor markets, increase minimum wage move us downward-sloping demand curve, causing employment fall. labor markets characterized monopsony, minimum wages can increase employment. Therefore, strong theoretical reasons believe effect minimum wage employment ultimately empirical question depending many local contextual factors. Card Krueger (1994) entered. uncover whether minimum wages ultimately harmful helpful local economy?’s always useful start questions simple thought experiment: billion dollars, complete discretion run randomized experiment, test whether minimum wages increased decreased employment? might go across hundreds local labor markets United States flip coin—heads, raise minimum wage; tails, keep status quo. ’ve done , kinds thought experiments useful clarifying research design causal question.Lacking randomized experiment, Card Krueger (1994) decided next-best solution comparing two neighboring states minimum-wage increase. essentially strategy Snow used cholera study strategy economists continue use, one form another, day (Dube, Lester, Reich 2010).New Jersey set experience increase state minimum wage $4.25 $5.05 November 1992, neighboring Pennsylvania’s minimum wage staying $4.25. Realizing opportunity evaluate effect minimum-wage increase comparing two states , fielded survey four hundred fast-food restaurants states—February 1992 () November (). responses survey used measure outcomes cared (.e., employment). saw Snow, see shoe leather important statistical technique causal inference.Let’s look whether minimum-wage hike New Jersey fact raised minimum wage examining distribution wages fast food stores surveyed. Figure 9.1 shows distribution wages November 1992 minimum-wage hike. can seen, minimum-wage hike binding, evidenced mass wages minimum wage New Jersey.caveat, notice effective convincing reader minimum wage New Jersey binding. piece data visualization trivial, even optional, strategy taken studies . Even John Snow presented carefully designed maps distribution cholera deaths throughout London. Beautiful pictures displaying “first stage” effect intervention treatment crucial rhetoric causal inference, done well Card Krueger.\nFigure 9.1: Distribution wages NJ PA November 1992. Reprinted Card Krueger (1994).\nLet’s remind ’re —average causal effect minimum-wage hike employment, ATT. Using decomposition \\(2\\times 2\\) DD earlier, can write :\n\\[\\begin{align}\n&\\widehat{\\delta}^{2\\times 2}_{NJ,PA} = \\underbrace{E\\big[Y^1_{NJ} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_{NJ} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{ATT}} \\\\\n&+ \\Big[\\underbrace{E\\big[Y^0_{NJ} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_{NJ} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] \\Big]-\\Big[E\\big[Y^0_{PA} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y_{PA}^0 \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] }_{\\text{Non-parallel trends bias}} \\Big]\n\\end{align}\\], see key assumption: parallel-trends assumption, represented first difference second line. Insofar parallel trends holds situation, second term goes zero, \\(2\\times 2\\) DD collapses ATT.\\(2\\times 2\\) DD requires differencing employment NJ PA, differencing first differences. set steps estimates true ATT long parallel-trends bias zero. true, \\(\\widehat{\\delta}^{2\\times 2}\\) equal \\(\\delta^{ATT}\\). bottom line zero, though, simple \\(2\\times 2\\) suffers unknown bias—bias upwards, bias downwards, flip sign entirely. Table @ref(tab:minwage_dd) shows results exercise Card Krueger (1994).Table 9.2:  Simple DD using sample averages full-time employment.\nStandard errors parentheses.\nsee result surprised many people. Card Krueger (1994) estimate ATT +2.76 additional mean full-time-equivalent employment, opposed negative value consistent competitive input markets. Herein get Buchanan’s frustration paper, based mainly particular model mind, rather criticism research design authors used.differences sample averages identify ATT parallel assumption, may want use multivariate regression instead. instance, need avoid omitted variable bias controlling endogenous covariates vary time, may want use regression. strategies another way saying need close known critical backdoor. Another reason equation controlling appropriate covariates, can reduce residual variance improve precision DD estimate.Using switching equation, assuming constant state fixed effect time fixed effect, can write simple regression model estimating causal effect minimum wage employment, \\(Y\\). simple \\(2\\times 2\\) estimated following equation:\n\\[\nY_{} = \\alpha + \\gamma NJ_s + \\lambda D_t + \\delta (NJ \\times D)_{st} + \\varepsilon_{}\n\\]\nNJ dummy equal 1 observation NJ, \\(D\\) dummy equal 1 observation November (post period). equation takes following values, list order according setting dummies equal one /zero:PA Pre: \\(\\alpha\\)PA Pre: \\(\\alpha\\)PA Post: \\(\\alpha + \\lambda\\)PA Post: \\(\\alpha + \\lambda\\)NJ Pre: \\(\\alpha + \\gamma\\)NJ Pre: \\(\\alpha + \\gamma\\)NJ Post: \\(\\alpha+\\gamma +\\lambda+\\delta\\)NJ Post: \\(\\alpha+\\gamma +\\lambda+\\delta\\)can visualize \\(2\\times 2\\) DD parameter Figure 9.2.\nFigure 9.2: DD regression diagram\nNow hammer parallel trends assumption billionth time, wanted point something bit subtle. see \\(\\delta\\) parameter floating air November line Figure 55? difference counterfactual level employment (bottom black circle November negatively sloped dashed line) actual level employment (black circle November positively sloped solid line) New Jersey. therefore ATT, ATT equal \n\\[ \n\\delta=E[Y^1_{NJ,\\mathop{\\mathrm{Post}}}] - E[Y^0_{NJ,\\mathop{\\mathrm{Post}}}]\n\\]\nwherein first observed (\\(Y=Y^1\\) post period) latter unobserved reason.Now ’s kicker: OLS always estimate \\(\\delta\\) line even counterfactual slope something else. ’s OLS uses Pennsylvania’s change time project point starting New Jersey’s pre-treatment value. OLS filled missing amount, parameter estimate equal difference observed post-treatment value projected value based slope Pennsylvania regardless whether Pennsylvania slope correct benchmark measuring New Jersey’s counterfactual slope. OLS always estimates effect size using slope untreated group counterfactual, regardless whether slope fact correct one., see happens Pennsylvania’s slope equal New Jersey’s counterfactual slope? Pennsylvania slope used regression mechanically estimate ATT. words, Pennsylvania slope counterfactual slope New Jersey OLS coincidentally identify true effect. Let’s see Figure 9.3.\nFigure 9.3: DD regression diagram without parallel trends\nNotice two \\(\\delta\\) listed: left true parameter \\(\\delta^{ATT}\\). right one estimated OLS, \\(\\widehat{\\delta}^{OLS}\\). falling solid line observed Pennsylvania change, whereas falling solid line labeled “observed NJ” change observed employment New Jersey two periods.true causal effect, \\(\\delta^{ATT}\\), line “observed NJ” point “counterfactual NJ” point. OLS estimate line. Instead, OLS uses falling Pennsylvania line draw parallel line February NJ point, shown thin gray. OLS simply estimates vertical line observed NJ point post NJ point, can seen underestimates true causaleffect.see importance parallel trends assumption. situation OLS estimate equals ATT counterfactual NJ just coincidentally lined gray OLS line, line parallel slope Pennsylvania line. Herein lies source understandable skepticism many paying attention: base estimation belief coincidence? , counterfactual trend, therefore unobserved, given never occurred. Maybe counterfactual ’ve gray line, maybe ’ve unknown line. ’ve anything—just don’t know.like tell people parallel trends assumption actually just restatement strict exogeneity assumption discussed panel chapter. saying appeal parallel trends found control group approximates traveling path treatment group treatment endogenous. endogenous, parallel trends always violated counterfactual treatment group ’ve diverged anyway, regardless treatment.see number tests economists devised provide reasonable confidence belief parallel trends, ’d like quickly talk standard errors DD design.","code":""},{"path":"ch8.html","id":"inference-1","chapter":"9 Difference-in-Differences","heading":"9.3 Inference","text":"Many studies employing DD strategies use data many years—just one pre-treatment one post-treatment period like Card Krueger (1994). variables interest many setups vary group level, state, outcome variables often serially correlated. Card Krueger (1994), likely instance employment state correlated within state also serially correlated. Bertrand, Duflo, Mullainathan (2004) point conventional standard errors often severely understate standard deviation estimators, standard errors biased downward, “small,” therefore overreject null hypothesis. Bertrand, Duflo, Mullainathan (2004) propose following solutions:Block bootstrapping standard errors.Block bootstrapping standard errors.Aggregating data one pre one post period.Aggregating data one pre one post period.Clustering standard errors group level.Clustering standard errors group level.","code":""},{"path":"ch8.html","id":"block-bootstrapping","chapter":"9 Difference-in-Differences","heading":"9.3.1 Block bootstrapping","text":"block state, simply sample states replacement bootstrapping. Block bootstrap straightforward requires little programming involving loops storing estimates. mechanics similar randomization inference, leave reader think might tackle .","code":""},{"path":"ch8.html","id":"aggregation","chapter":"9 Difference-in-Differences","heading":"9.3.2 Aggregation","text":"approach ignores time-series dimensions altogether, one pre post period one untreated group, ’s simple sounds. simply average groups one pre post period, conduct difference--differences aggregated. differential timing, ’s bit unusual need partial state year fixed effects turning analysis analysis involving residualization. Essentially, common situations multiple treatment time periods (discuss later greater detail), regress outcome onto panel unit time fixed effects covariates. ’d obtain residuals treatment group. divide residuals pre post period; essentially point ignoring never-treated groups. regress residuals dummy. ’s strange procedure, recover original point estimate, focus instead third.","code":""},{"path":"ch8.html","id":"clustering","chapter":"9 Difference-in-Differences","heading":"9.3.3 Clustering","text":"Correct treatment standard errors sometimes makes number groups small: Card Krueger (1994), number groups two. common , researchers use third option (clustering standard errors group). one time seen someone three ; ’s rare though. people present just clustering solution—likely requires minimal programming.clustering, programming required, software packages allow already. simply adjust standard errors clustering group level, discussed earlier chapter, level treatment. state-level panels, mean clustering state level, allows arbitrary serial correlation errors within state time. common solution employed.Inference panel setting independently interesting area. number clusters small, simple solutions like clustering standard errors longer suffice growing false positive problem. extreme case one treatment unit, -rejection rate significance 5% can high 80% simulations even using wild bootstrap technique suggested smaller numbers clusters (Cameron, Gelbach, Miller 2008; MacKinnon Webb 2017). extreme cases one treatment group, preferred use randomization inference following Buchmueller, DiNardo, Valletta (2011).","code":""},{"path":"ch8.html","id":"providing-evidence-for-parallel-trends-through-event-studies-and-parallel-leads","chapter":"9 Difference-in-Differences","heading":"9.4 Providing Evidence for Parallel Trends Through Event Studies and Parallel Leads","text":"","code":""},{"path":"ch8.html","id":"a-redundant-rant-about-parallel-pre-treatment-dd-coefficients-because-im-worried-one-was-not-enough","chapter":"9 Difference-in-Differences","heading":"9.4.1 A redundant rant about parallel pre-treatment DD coefficients (because I’m worried one was not enough)","text":"Given critical importance parallel trends assumption identifying causal effects DD design, given one observations needed evaluate parallel-trends assumption available researcher, one might throw hands despair. economists stubborn, spent decades devising ways test whether ’s reasonable believe parallel trends. now discuss obligatory test DD design—event study. Let’s rewrite decomposition \\(2 \\times 2\\) DD .\n\\[\\begin{align}\n&\\widehat{\\delta}^{2\\times 2}_{kU} =\n\\underbrace{E\\big[Y^1_{k} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_{k} \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{ATT}} \\\\\n&+\\Big[\\underbrace{E\\big[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] \\Big]-\\Big[E\\big[Y^0_U \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y_{U}^0 \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] }_{\\text{Non-parallel trends bias}} \\Big]\n\\end{align}\\]interested first term, ATT, contaminated selection bias second term equal zero. Since evaluating second term requires counterfactual, \\(E[Y^0_k \\mathop{\\mathrm{\\,\\vert\\,}}Post]\\), unable directly. economists typically , instead, compare placebo pre-treatment leads DD coefficient. DD coefficients pre-treatment periods statistically zero, difference--differences treatment control groups followed similar trend prior treatment. ’s rhetorical art design: similar , wouldn’t continue post-treatment?notice rhetoric kind proof assertion. Just similar logically require . Assuming future like past form gambler’s fallacy called “reverse position.” Just coin came heads three times row mean come heads fourth time—without assumptions. Likewise, obligated believe counterfactual trends post-treatment similar pre-treatment without assumptions predictive power pre-treatment trends. make assumptions make untestable assumptions, back started.One situation parallel trends obviously violated treatment endogenous. scenario, assignment treatment status directly dependent potential outcomes, absent treatment, potential outcomes ’ve changed regardless. traditional endogeneity requires merely lazy visualizations parallel leads. test important, technically pre-treatment similarities neither necessary sufficient guarantee parallel counterfactual trends (Kahn-Lang Lang 2019). assumption easily proven. can never stop diligent attempting determine whether groups units endogenously selected treatment, presence omitted variable biases, various sources selection bias, open backdoor paths. structural error term dynamic regression model uncorrelated treatment variable, strict exogeneity, gives parallel trends, makes able make meaningful statements estimates.","code":""},{"path":"ch8.html","id":"checking-the-pre-treatment-balance-between-treatment-and-control-groups","chapter":"9 Difference-in-Differences","heading":"9.4.2 Checking the pre-treatment balance between treatment and control groups","text":"Now pessimism way, let’s discuss event study plots though direct tests parallel trends assumption, place show two groups units comparable dynamics pre-treatment period.144 conditional independence concepts used profitably throughout book, now.Authors tried showing differences treatment control groups different ways. One way simply show raw data, can set groups received treatment point time. just visually inspect whether pre-treatment dynamics treatment group differed control group units.single treatment date? instead differential timing wherein groups units adopt treatment different points? concept pre-treatment becomes complex. New Jersey raised minimum wage 1992 New York raised minimum wage 1994, Pennsylvania never raised minimum wage, pre-treatment period defined New Jersey (1991) New York (1993), Pennsylvania. Thus, go testing pre-treatment differences case? People done variety ways.One possibility plot raw data, year year, simply eyeball. compare treatment group never-treated, instance, might require lot graphs may also awkward looking. Cheng Hoekstra (2013) took route, created separate graph comparing treatment groups untreated group different year treatment. advantage transparent display raw unadjusted data. funny business. disadvantage several-fold. First, may cumbersome number treatment groups large, making practically impossible. Second, may beautiful. third, necessarily assumes control group never-treated group, fact true given Goodman-Bacon (2019) shown. DD combination comparison treatment never treated, early treated compared late treated, late treated compared early treated. Thus showing comparison never treated actually misleading presentation underlying mechanization identification using twoway fixed-effects model differential timing.Anderson, Hansen, Rees (2013) took alternative, creative approach show comparability states legalized medical marijuana states without. said, concept pre-treatment period control state undefined pre-treatment always reference specific treatment date varies across groups. , authors construct recentered time path traffic fatality rates control states assigning random treatment dates control counties plotting average traffic fatality rates group years leading treatment beyond. approach advantages. First, plots raw data, rather coefficients regression (see next). Second, plots data controls. weakness technically, control series fact true. chosen give comparison, regressions eventually run, based series. main main shortcoming technically displaying control groups used estimation Goodman-Bacon (2019). displaying comparison treated never treated; comparison early late treated; comparison late early treated. creative attempt evaluate pre-treatment differences leads, fact technically show .current way authors evaluate pre-treatment dynamics treatment control group differential timing estimate regression model includes treatment leads lags. find always useful teach concepts context actual paper, let’s review interesting working paper Miller et al. (2019).","code":""},{"path":"ch8.html","id":"affordable-care-act-expanding-medicaid-and-population-mortality","chapter":"9 Difference-in-Differences","heading":"9.4.3 Affordable Care Act, expanding Medicaid and population mortality","text":"provocative new study Miller et al. (2019) examined expansion Medicaid Affordable Care Act. primarily interested effect expansion population mortality. Earlier work cast doubt Medicaid’s effect mortality (Finkelstein et al. 2012; Baicker et al. 2013), revisiting question larger sample size value.Like Snow , authors link data sets deaths large-scale federal survey data, thus showing shoe leather often goes hand hand good design. use data evaluate causal impact Medicaid enrollment mortality using DD design. focus near-elderly adults states without Affordable Care Act Medicaid expansions find 0.13-percentage-point decline annual mortality, 9.3% reduction sample mean, result ACA expansion. effect result reduction disease-related deaths gets larger time. Medicaid, estimation, saved non-trivial number lives.many contemporary DD designs, Miller et al. (2019) evaluate pre-treatment leads instead plotting raw data treatment control. Post-estimation, plotted regression coefficients 95% confidence intervals treatment leads lags. Including leads lags DD model allowed reader check degree post-treatment treatment effects dynamic, whether two groups comparable outcome dynamics pre-treatment. Models like one usually follow form like:\n\\[\n  Y_{} = \\gamma_s + \\lambda_t + \\sum_{\\tau=-q}^{-1}\\gamma_{\\tau}D_{s\\tau} + \\sum_{\\tau=0}^m\\delta_{\\tau}D_{s\\tau}+x_{ist}+ \\varepsilon_{ist}\n\\]\nTreatment occurs year 0. include \\(q\\) leads anticipatory effects \\(m\\) lags post-treatment effects.Miller et al. (2019) produce four event studies taken together tell main parts story paper. , quite frankly, art rhetoric causal inference—visualization key estimates, “first stages” well outcomes placebos. event study plots powerfully persuasive, make bit jealous, since oftentimes won’t nearly nice. Let’s look first three. State expansion Medicaid Affordable Care Act increased Medicaid eligibility (Figure 9.4), altogether surprising. also caused increase Medicaid coverage (Figure 9.5), consequence reduced percentage uninsured population (Figure 9.6). three simply showing ACA Medicaid expansion “bite”—people enrolled became insured.\nFigure 9.4: Estimates Medicaid expansion’s effects eligibility using leads lags event study model. Reprint Miller et al. (2019).\n\nFigure 9.5: Estimates Medicaid expansion’s effects coverage using leads lags event study model. Reprint Miller et al. (2019).\n\nFigure 9.6: Estimates Medicaid expansion’s effects uninsured state using leads lags event study model. Reprint Miller et al. (2019).\nseveral features event studies catch eye. First, look Figure 9.4. pre-treatment coefficients nearly zero line . nearly zero point estimate, standard errors small. means precisely estimated zero differences individuals two groups states prior expansion.second thing see, though, elephant room. Post-treatment, probability someone becomes eligible Medicaid immediately shoots 0.4 precise pre-treatment coefficients, authors can rule effects low 0.3 0.35. large increases eligibility, fact coefficients prior treatment basically zero, find easy believe risen coefficients post-treatment caused ACA’s expansion Medicaid states.course, say technically zeroes pre-treatment therefore mean post-treatment difference counterfactual trends observed trends zero, doesn’t seem compelling see ? Doesn’t compel , just little bit, changes enrollment insurance status probably caused Medicaid expansion? daresay table coefficients leads, lags, standard errors probably compelling even though identical information. Also, fair skeptic refuse patterns new evidence Medicaid expansion. enough merely hand wave criticism omitted variable bias; critic must engaged phenomenon authors , empiricists earn right critique someoneelse’s work.Similar graphs shown coverage—prior treatment, two groups individuals treatment control similar regards coverage uninsured rate. post-treatment, diverge dramatically. Taken together, “first stage,” means can see Medicaid expansion ACA “bite.” authors failed find changes eligibility, coverage, uninsured rates, evidence secondary outcomes doubt built . reason important examine first stage (treatment’s effect usage), well second stage (treatment’s effect outcomes interest).now let’s look main result—effect population mortality ? Recall, Miller et al. (2019) linked administrative death records large-scale federal survey. actually know Medicaid . John Snow proud design, meticulous collection high-quality data, shoeleather authors showed.event study presented Figure 9.7. graph like contemporary heart soul DD design, conveys key information regarding comparability treatment control groups dynamics just prior treatment, strong data visualization main effects powerfully persuasive. ’s quite clear looking difference trending tendencies two sets state prior treatment, making subsequent divergence striking.\nFigure 9.7: Miller et al. (2019) estimates Medicaid expansion’s effects annual mortality using leads lags event study model\npicture like important thing studying, worth summarizing Miller et al. (2019) revealed . expansion ACA Medicaid led large swaths people becoming eligible Medicaid. turn, enrolled Medicaid, caused uninsured rate drop considerably. authors find amazingly using linked administrative data death records expansion ACA Medicaid led 0.13 percentage point decline annual mortality, 9.3 percent reduction mean. go try understand mechanism (another key feature high-quality study) amazing effects may occurred, conclude Medicaid caused near-elderly individuals receive treatment life-threatening illnesses. suspect hearing study many years.","code":""},{"path":"ch8.html","id":"the-importance-of-placebos-in-dd","chapter":"9 Difference-in-Differences","heading":"9.5 The Importance of Placebos in DD","text":"several tests validity DD strategy. already discussed one—comparability treatment control groups observable pre-treatment dynamics. Next, discuss credible ways evaluate whether estimated causal effects credible emphasizing use placebo falsification.idea placebo falsification simple. Say finding negative effect minimum wage low-wage employment. hypothesis true find evidence favor? Maybe, maybe . Maybe really help, though, mind alternative hypothesis tried test alternative hypothesis. reject null alternative hypothesis, provides credibility original analysis. instance, maybe picking something spurious, like cyclical factors unobservables easily captured time state fixed effects. can ?One candidate placebo falsification might simply use data alternative type worker whose wages affected binding minimum wage. instance, minimum wages affect employment earnings low-wage workers workers literally hired based market wage. Without serious general equilibrium gymnastics, minimum wage affect employment higher wage workers, minimum wage binding high wage workers. Since high- low-wage workers employed different sectors, unlikely substitutes. reasoning might lead us consider possibility higher wage workers might function placebo.two ways can go incorporating idea analysis. Many people like straightforward simply fit DD design using high wage employment outcome. coefficient minimum wages zero using high wage worker employment outcome, coefficient minimum wages low wage workers negative, provided stronger evidence complements earlier analysis low wage workers. another method uses within-state placebo identification called difference--differences--differences (“triple differences”). discuss design now.","code":""},{"path":"ch8.html","id":"triple-differences","chapter":"9 Difference-in-Differences","heading":"9.5.1 Triple differences","text":"earlier analysis, assumed thing happened New Jersey passed minimum wage common shock, \\(T\\), state-specific time shocks \\(NJ_t\\) \\(PA_t\\)? even DD recover treatment effect. Let’s see using modification simple minimum-wage table earlier, include within-state workers hypothetically untreated minimum wage—“high-wage workers.”Triple differences design.minimum-wage increase, low- high-wage employment New Jersey determined group-specific New Jersey fixed effect (e.g., \\(NJ_h\\)). true Pennsylvania. minimum-wage hike, four things change New Jersey: national trends cause employment change \\(T\\); New Jersey-specific time shocks change employment \\(NJ_t\\); generic trends low-wage workers change employment \\(l_t\\); minimum-wage unknown effect \\(D\\). setup Pennsylvania except minimum wage, Pennsylvania experiences time shocks.Now take first differences set states, eliminate state fixed effect. first difference estimate New Jersey includes minimum-wage effect, \\(D\\), also hopelessly contaminated confounders (.e., \\(T+NJ_t+l_t\\)). take second difference state, , eliminate two confounders: \\(T\\) disappears \\(NJ_t\\) disappears. DD strategy eliminated several confounders, also introduced new ones (.e., \\((l_t-h_t)\\)). final source selection bias triple differences designed resolve. , differencing Pennsylvania’s second difference New Jersey, \\((l_t-h_t)\\) deleted minimum-wage effect isolated.Now, solution without set unique parallel-trends assumptions. one parallel trends ’d like see \\(l_t-h_t\\) term. parallel trends assumption states effect can isolated gap high- low-wage employment ’ve evolved similarly treatment state counterfactual historical control states. probably provide credible evidence true leads lags event study .","code":""},{"path":"ch8.html","id":"state-mandated-maternity-benefits","chapter":"9 Difference-in-Differences","heading":"9.5.2 State-mandated maternity benefits","text":"triple differences design first introduced Gruber (1994) study state-level policies providing maternity benefits. present main results Table @ref(tab:gruber_ddd). Notice uses treatment group married women childbearing age treatment control states, also uses set placebo units (older women single men 20–40) within-state controls. goes differences means get difference--differences set groups, calculates DDD difference two difference--differences.Table 9.3:  DDD Estimates Impact State Mandates Hourly Wages\nStandard errors parentheses.\nIdeally DDD estimate, causal effect estimate come changes treatment units, changes control units. ’s precisely see Gruber (1994): action comes changes married women age 20–40 (\\(-0.062\\)); ’s little movement among placebo units \\((-0.008)\\). Thus calculate DDD, know calculation coming first DD, much second. emphasize DDD really just another falsification exercise, just expect effect done DD placebo group, hope DDD estimate also based negligible effects among control group.done now show use sample analogs simple differences means estimate treatment effect using DDD. can also use regression control additional covariates perhaps necessary close backdoor paths forth. regression equation look like? regression , data structure upon regression based, complicated stacking different groups sheer number interactions involved. Estimating DDD model requires estimating following regression:\n\\[\\begin{align}\nY_{ijt} &= \\alpha + \\psi X_{ijt} + \\beta_1 \\tau_t + \\beta_2 \\delta_j + \\beta_3 D_i + \\beta_4(\\delta \\times \\tau)_{jt}\n\\\\\n& +\\beta_5(\\tau \\times D)_{ti} + \\beta_6(\\delta \\times D)_{ij} + \\beta_7(\\delta \\times \\tau \\times D)_{ijt}+ \\varepsilon_{ijt}\n\\end{align}\\]\nparameter interest \\(\\beta_7\\). First, notice additional subscript, \\(j\\). \\(j\\) indexes whether ’s main category interest (e.g., low-wage employment) within-state comparison group (e.g., high-wage employment). requires stacking data panel structure group, well state. Second, DDD model requires include possible interactions across group dummy \\(\\delta_j\\), post-treatment dummy \\(\\tau_t\\) treatment state dummy \\(D_i\\). regression must include dummy independently, individual interaction, triple differences interaction. One dropped due multicollinearity, include equation can visualize factors used product terms.","code":""},{"path":"ch8.html","id":"abortion-legalization-and-long-term-gonorrhea-incidence","chapter":"9 Difference-in-Differences","heading":"9.5.3 Abortion legalization and long-term gonorrhea incidence","text":"Now know little DD design, probably beneficial replicate paper. since DDD requires reshaping panel data multiple times, makes working detailed replication even important. study replicating Cunningham Cornwell (2013), one first publications third chapter dissertation. Buckle , bit roller-coaster ride.Gruber, Levine, Staiger (1999) beginning become controversial literature reproductive health. wanted know characteristics marginal child aborted child reached teen years. authors found marginal counterfactual child aborted 60% likely grow single-parent household, 50% likely live poverty, 45% likely welfare recipient. Clearly strong selection effects related early abortion whereby selected families fewer resources.finding marginal child led John Donohue Steven Levitt wonder might far-reaching effects abortion legalization given strong selection associated usage early 1970s. Donohue Levitt (2001), authors argued found evidence abortion legalization also led massive declines crime rates. interpretation results abortion legalization reduced crime removing high-risk individuals birth cohort, cohort aged, counterfactual crimes disappeared. Levitt (2004) attributed much 10% decline crime 1991 2001 abortion legalization 1970s.study , surprisingly, incredibly controversial—warranted unwarranted. instance, attacked paper ethical grounds argued paper revitalizing pseudoscience eugenics. Levitt careful focus scientific issues causal effects offer policy advice based private views, whatever may .criticism authors received legitimate precisely centered research design execution . Joyce (2004), Joyce (2009), Foote Goetz (2008) disputed abortion-crime findings—replication exercises using different data, different research designs, discovery key coding errors erroneous variable construction.One study particular challenged whole enterprise estimating longrun improvements due abortion legalization. instance, Ted Joyce, expert reproductive health, cast doubt abortion-crime hypothesis using DDD design (Joyce 2009). addition challenging Donohue Levitt (2001), Joyce also threw gauntlet. argued abortion legalization extreme negative selection claimed Gruber, Levine, Staiger (1999) Donohue Levitt (2001), shouldn’t show just crime. show everywhere. Joyce writes:abortion lowers homicide rates 20–30%, likely affected entire spectrum outcomes associated well-: infant health, child development, schooling, earnings marital status. Similarly, policy implications broader abortion. interventions affect fertility control lead fewer unwanted births—contraception sexual abstinence—huge potential payoffs. short, causal relationship legalized abortion crime significant ramifications social policy time controversial, assessment identifying assumptions robustness alternative strategies warranted. (p.112)Cunningham Cornwell (2013) took Joyce’s challenge. study estimated effects abortion legalization long-term gonorrhea incidence. gonorrhea? one, single-parent households risk factor lead earlier sexual activity unprotected sex, Levine et al. (1999) found abortion legalization caused teen childbearing fall 12%. risky outcomes found numerous authors. Charles Stephens (2006) reported children exposed utero legalized abortion regime less likely use illegal substances, correlated risky sexual behavior.research design differed Donohue Levitt (2001) used state-level lagged values abortion ratio, whereas used difference--differences. design exploited early repeal abortion five states 1970 compared states states legalized Roe v. Wade 1973. , needed cohort-specific data gonorrhea incidence state year, data collected CDC, settle second best. second best CDC’s gonorrhea data broken five-year age categories (e.g., age 15–19, age 20–24). might still useful even aggregate data, might possible test model mind.understand next part, consider best part study, must first accept basic view science good theories make specific falsifiable hypotheses. specific hypothesis, convincing theory, find evidence exactly theory predicts, Bayesian likely update beliefs towards accepting theory’s credibility. Let illustrate mean brief detour involving Albert Einstein’s theory relativity.Einstein’s theory made several falsifiable hypotheses. One involved precise prediction warping light moved past large object, star. problem testing theory involved observing distance stars night comparing measurements made day starlight moved past sun. Problem , sun bright daytime see stars, critical measurements can’t made. Andrew Crommelin Arthur Eddington realized measurements made using ingenious natural experiment. natural experiment eclipse. shipped telescopes different parts world eclipse’s path multiple chances make measurements. decided measure distances large cluster stars passing sun dark immediately eclipse (Figure 9.8). test decade Einstein’s work first published (Coles 2019). Think second—Einstein’s theory deduction making predictions phenomena one ever really observed . phenomena turned exist, couldn’t Bayesian update beliefs accept theory credible? Incredibly, Einstein right—just predicted, apparent position stars shifted moving around sun. Incredible!\nFigure 9.8: Light bending around sun, predicted Einstein, confirmed natural experiment involving eclipse. Artwork Seth Hahne (c) 2020.\nstudy abortion legalization gonorrhea? theory abortion legalization strong selection effects cohorts makes specific predictions shape observed treatment effects. found evidence shape, ’d forced take theory seriously. unusual yet testable predictions exactly?testable prediction staggered adoption abortion legalization concerned age-year-state profile gonorrhea. early repeal abortion five states three years rest country predicts lower incidence among 15- 19-year-olds repeal states 1986–1992 period relative Roe counterparts treated cohorts aged. ’s really special prediction though. Maybe something happens states fifteen nineteen years later isn’t controlled , instance. else?abortion legalization theory also predicted shape observed treatment effects particular staggered adoption. Specifically, observe nonlinear treatment effects. treatment effects increasingly negative 1986 1989, plateau 1989 1991, gradually dissipate 1992. words, abortion legalization hypothesis predicts parabolic treatment effect treated cohorts move age distribution. coefficients DD coefficients beyond 1992 zero /statistically insignificant.illustrate predictions Figure 9.9. top horizontal axis shows year panel, vertical axis shows age calendar years, cells show cohort given person certain age given year. instance, consider 15-year-old 1985. born 1970. 15-year-old 1986 born 1971. 15-year-old 1987 born 1972, forth. mark cohorts treated either repeal Roe different shades gray.\nFigure 9.9: Theoretical predictions abortion legalization age profiles gonorrhea incidence. Reprinted Cunningham Cornwell (2013).\ntheoretical predictions staggered rollout shown bottom Figure 9.9. 1986, one cohort (1971 cohort) treated repeal states. Therefore, see small declines gonorrhea incidence among 15-year-olds 1986 relative Roe states. 1987, two cohorts data treated repeal states relative Roe, see larger effects absolute value saw 1986. 1988 1991, see three net treated cohorts repeal states starting 1988, Roe state cohorts enter begin erasing differences. Starting 1992, effects get smaller absolute value 1992, beyond difference repeal Roe states.interesting something simple staggered policy rollout provide two testable hypotheses together can provide insight whether credibility negative selection abortion legalization story. find evidence negative parabola specific, narrow window, abortion legalization hypothesis one nail coffin.simple graphic gonorrhea incidence among black 15- 19-year-olds can help illustrate findings. Remember, picture worth thousand words, whether ’s RDD DD, ’s helpful show pictures like prepare reader table table regression coefficients. notice raw data looks like Figure 9.10.\nFigure 9.10: Differences black female gonorrhea incidence repeal Roe cohorts expressed coefficient plots. Reprinted Cunningham Cornwell (2013).\nFirst let’s look raw data. shaded years corresponding window expect find effects. Figure 9.10, see dynamics ultimately picked regression coefficients—Roe states experienced large sustained gonorrhea epidemic waned treated cohorts emerged overtook entire data series.Now let’s look regression coefficients. estimating equation follows:\n\\[ \nY_{st} =\\beta_1Repeals +\\beta_2 DT_t +\\beta_{3t} Repeal_s \\times DT_t +X_{st} \\psi+\\alpha_{s}DS_s + \\varepsilon_{st}\n\\]\n\\(Y\\) log number new gonorrhea cases 15- 19-year-olds (per 100,000 population); Repeal\\(_s\\) equals 1 state legalized abortion prior Roe; \\(DT_t\\) year dummy; \\(DS_s\\) state dummy; \\(t\\) time trend; \\(X\\) matrix covariates. paper, sometimes included state-specific linear trends, analysis, present simpler model. Finally, \\(\\varepsilon_{st}\\) structural error term assumed conditionally independent regressors. standard errors, furthermore, clustered state level allowing arbitrary serial correlation.present plotted coefficients regression simplicity (pictures can powerful) Figure 9.11. can seen Figure 9.11, negative effect window Roe fully caught , negative effect forms parabola—just theory predicted.\nFigure 9.11: Coefficients standard errors DD regression equation\nNow, lot people might done, reading book, revealed like lot people. Credibly identified causal effects requires finding effects, ruling alternative explanations. necessary fundamental problem causal inference keeps us blind truth. one way alleviate doubt rigorous placebo analysis. present evidence triple difference untreated cohort used within-state control.chose 25- 29-year-olds states within-state comparison groups instead 20- 24-year-olds lot thought. reasoning needed age group close enough capture common trends far enough violate SUTVA. Since 15- 19-year-olds likely 25- 29-year-olds sex 20- 24-year-olds, chose slightly older group within-stage control. ’s trade-. Choose group close get SUTVA violations. Choose group far longer can credibly soak heterogeneities ’re worried . estimating equation thisregression :\n\\[\\begin{align}\nY_{ast} &=\\beta_1\\text{~Repeal}_s + \\beta_2DT_t + \\beta_{3t}\\text{~Repeal}_s\\cdot DT_t +\\delta_1\\,DA + \\delta_2\\text{~Repeal}_s\\cdot DA\n\\\\\n&+ \\delta_{3t}\\,DA\\cdot DT_t + \\delta_{4t}\\text{~Repeal}_s\\cdot DA \\cdot DT_t + X_{st}\\xi + \\alpha_{1s}DS_s + \\alpha_{2s}DS_s\\cdot DA\n\\\\\n&+ \\gamma_1\\,t + \\gamma_{2s}DS_s\\cdot t + \\gamma_3\\,DA\\cdot t+ \\gamma_{4s}DS_s\\cdot DA \\cdot t + \\epsilon_{ast},\n\\end{align}\\]\nDDD parameter estimating \\(\\delta_{4t}\\)—full interaction. case wasn’t obvious, 7 separate dummies DDD parameter three interactions. Thus since eight combinations, drop one omitted group, control separately seven. present table coefficients. Note effect concentrated among treatment years , second, form parabola. results presented Figure 9.12.\nFigure 9.12: DDD Estimates Abortion Legalization 15-19yo Black Female Log Gonorrhea\nsee prediction start break . Though negative effects years 1986 1990, 1991 1992 coefficients positive, consistent hypothesis. Furthermore, first four coefficients statistically significant. Nevertheless, given demanding nature DDD, perhaps small victory favor Gruber, Levine, Staiger (1999) Donohue Levitt (2001). Perhaps theory abortion legalization strong selection effects cohorts validity.Putting aside whether believe results, still valuable replicate results based staggered design. Recall said DDD design requires stacking data, may seem like bit black box, ’d like examine data now.145abortion_dd.doabortion_dd.RThe second line estimates regression equation. dynamic DD coefficients captured repeal-year interactions. coefficients used create box plots Figure 9.11. can check .Note, simplicity, estimated black females (bf15==1) estimate black males (bm15==1), white females (wf15==1), white males (wm15==1). four paper, focus black females aged 15–19 purpose section help understand estimation. encourage play around model see robust effects mind using linear estimation.now want show code estimating triple difference model. reshaping done behind scenes data structure, take long post . now, simply produce commands produce black female result, encourage explore panel data structure familiarize way data organized.Notice already interactions (e.g., yr), way compactly include interactions. primarily give control variables using. encourage study data structure need estimate DDD, ’ll good handle form data must order execute many interactions.abortion_ddd.doabortion_ddd.R","code":"* DD estimate of 15-19 year olds in repeal states vs Roe states \nuse https://github.com/scunning1975/mixtape/raw/master/abortion.dta, clear\nxi: reg lnr i.repeal*i.year i.fip acc ir pi alcohol crack poverty income ur if bf15==1 [aweight=totpop], cluster(fip)\n\n* ssc install parmest, replace\n    \nparmest, label for(estimate min95 max95 %8.2f) li(parm label estimate min95 max95) saving(bf15_DD.dta, replace)\n\nuse ./bf15_DD.dta, replace\n\nkeep in 17/31\n\ngen     year=1986 in 1\nreplace year=1987 in 2\nreplace year=1988 in 3\nreplace year=1989 in 4\nreplace year=1990 in 5\nreplace year=1991 in 6\nreplace year=1992 in 7\nreplace year=1993 in 8\nreplace year=1994 in 9\nreplace year=1995 in 10\nreplace year=1996 in 11\nreplace year=1997 in 12\nreplace year=1998 in 13\nreplace year=1999 in 14\nreplace year=2000 in 15\n\nsort year\n\ntwoway (scatter estimate year, mlabel(year) mlabsize(vsmall) msize(tiny)) (rcap min95 max95 year, msize(vsmall)), ytitle(Repeal x year estimated coefficient) yscale(titlegap(2)) yline(0, lwidth(vvvthin) lcolor(black)) xtitle(Year) xline(1986 1987 1988 1989 1990 1991 1992, lwidth(vvvthick) lpattern(solid) lcolor(ltblue)) xscale(titlegap(2)) title(Estimated effect of abortion legalization on gonorrhea) subtitle(Black females 15-19 year-olds) note(Whisker plots are estimated coefficients of DD estimator from Column b of Table 2.) legend(off)\n#-- DD estimate of 15-19 year olds in repeal states vs Roe states\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nabortion <- read_data(\"abortion.dta\") %>% \n  mutate(\n    repeal = as_factor(repeal),\n    year   = as_factor(year),\n    fip    = as_factor(fip),\n    fa     = as_factor(fa),\n  )\n\nreg <- abortion %>% \n  filter(bf15 == 1) %>% \n  lm_robust(lnr ~ repeal*year + fip + acc + ir + pi + alcohol+ crack + poverty+ income+ ur,\n            data = ., weights = totpop, clusters = fip)\n\nabortion_plot <- tibble(\n  sd = reg$std.error[-1:-75],\n  mean = reg$coefficients[-1:-75],\n  year = c(1986:2000))\n\nabortion_plot %>% \n  ggplot(aes(x = year, y = mean)) + \n  geom_rect(aes(xmin=1986, xmax=1992, ymin=-Inf, ymax=Inf), fill = \"cyan\", alpha = 0.01)+\n  geom_point()+\n  geom_text(aes(label = year), hjust=-0.002, vjust = -0.03)+\n  geom_hline(yintercept = 0) +\n  geom_errorbar(aes(ymin = mean - sd*1.96, ymax = mean + sd*1.96), width = 0.2,\n                position = position_dodge(0.05))use https://github.com/scunning1975/mixtape/raw/master/abortion.dta, clear\n\n* DDD estimate for 15-19 year olds vs. 20-24 year olds in repeal vs Roe states\ngen yr=(repeal) & (younger==1)\ngen wm=(wht==1) & (male==1)\ngen wf=(wht==1) & (male==0)\ngen bm=(wht==0) & (male==1)\ngen bf=(wht==0) & (male==0)\nchar year[omit] 1985\nchar repeal[omit] 0\nchar younger[omit] 0\nchar fip[omit] 1\nchar fa[omit] 0\nchar yr[omit] 0 \nxi: reg lnr i.repeal*i.year i.younger*i.repeal i.younger*i.year i.yr*i.year i.fip*t acc pi ir alcohol crack  poverty income ur if bf==1 & (age==15 | age==25) [aweight=totpop], cluster(fip)\n    \nparmest, label for(estimate min95 max95 %8.2f) li(parm label estimate min95 max95) saving(bf15_DDD.dta, replace)\n\nuse ./bf15_DDD.dta, replace\n\nkeep in 82/96\n\ngen     year=1986 in 1\nreplace year=1987 in 2\nreplace year=1988 in 3\nreplace year=1989 in 4\nreplace year=1990 in 5\nreplace year=1991 in 6\nreplace year=1992 in 7\nreplace year=1993 in 8\nreplace year=1994 in 9\nreplace year=1995 in 10\nreplace year=1996 in 11\nreplace year=1997 in 12\nreplace year=1998 in 13\nreplace year=1999 in 14\nreplace year=2000 in 15\n\nsort year\n\ntwoway (scatter estimate year, mlabel(year) mlabsize(vsmall) msize(tiny)) (rcap min95 max95 year, msize(vsmall)), ytitle(Repeal x 20-24yo x year estimated coefficient) yscale(titlegap(2)) yline(0, lwidth(vvvthin) lcolor(black)) xtitle(Year) xline(1986 1987 1988 1989 1990 1991 1992, lwidth(vvvthick) lpattern(solid) lcolor(ltblue)) xscale(titlegap(2)) title(Estimated effect of abortion legalization on gonorrhea) subtitle(Black females 15-19 year-olds) note(Whisker plots are estimated coefficients of DDD estimator from Column b of Table 2.) legend(off)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nabortion <- read_data(\"abortion.dta\") %>% \n  mutate(\n    repeal  = as_factor(repeal),\n    year    = as_factor(year),\n    fip     = as_factor(fip),\n    fa      = as_factor(fa),\n    younger = as_factor(younger),\n    yr      = as_factor(case_when(repeal == 1 & younger == 1 ~ 1, TRUE ~ 0)),\n    wm      = as_factor(case_when(wht == 1 & male == 1 ~ 1, TRUE ~ 0)),\n    wf      = as_factor(case_when(wht == 1 & male == 0 ~ 1, TRUE ~ 0)),\n    bm      = as_factor(case_when(wht == 0 & male == 1 ~ 1, TRUE ~ 0)),\n    bf      = as_factor(case_when(wht == 0 & male == 0 ~ 1, TRUE ~ 0))\n  ) %>% \n  filter(bf == 1 & (age == 15 | age == 25))\n\nregddd <- lm_robust(lnr ~ repeal*year + younger*repeal + younger*year + yr*year + fip*t + acc + ir + pi + alcohol + crack + poverty + income + ur,\n                    data = abortion, weights = totpop, clusters = fip)\n\nabortion_plot <- tibble(\n  sd = regddd$std.error[110:124],\n  mean = regddd$coefficients[110:124],\n  year = c(1986:2000))\n\nabortion_plot %>% \n  ggplot(aes(x = year, y = mean)) + \n  geom_rect(aes(xmin=1986, xmax=1992, ymin=-Inf, ymax=Inf), fill = \"cyan\", alpha = 0.01)+\n  geom_point()+\n  geom_text(aes(label = year), hjust=-0.002, vjust = -0.03)+\n  geom_hline(yintercept = 0) +\n  geom_errorbar(aes(ymin = mean-sd*1.96, ymax = mean+sd*1.96), width = 0.2,\n                position = position_dodge(0.05))"},{"path":"ch8.html","id":"going-beyond-cunningham2013","chapter":"9 Difference-in-Differences","heading":"9.5.4 Going beyond Cunningham and Cornwell (2013)","text":"US experience abortion legalization predicted parabola 1986 1992 15- 19-year-olds, using DD design, ’s found. also estimated effect using DDD design, effects weren’t pretty found DD, appeared something going general vicinity model predicted. boom goes dynamite, right? Can’t done finally? quite.Whereas original study stopped , like go little farther. reason can seen following Figure 9.13. modified version Figure 9.9, main difference created new parabola 20- 24-year-olds.Look carefully Figure 9.13. Insofar early 1970s cohorts treated utero abortion legalization, see just parabola 15- 19-year-olds 1986 1992 also 20- 24-year-olds years 1991 1997 cohorts continuedto age.146abortion_dd2.doabortion_dd2.RI examine 20- 24-year-old cohort first wrote paper time doubted selection effects risky sex persist adulthood given youth display considerable risk-taking behavior. time come new perspectives, days don’t strong priors selection effects necessarily vanish teenage years. ’d like conduct additional analysis now first time. Let’s estimate DD model , Black females aged 20–24., focus just coefficient plots. show Figure 9.14. couple things regression output troubling. First, negative parabola showing wasn’t necessarily one predicted—1986–1992 period. Note period 15- 19-year-olds treated cohorts, suggesting 15- 19-year-old analysis picking something abortion legalization. also justification using DDD, clearly something else going repeal versus Roe states years adequately control controls fixed effects.\nFigure 9.13: Theoretical predictions abortion legalization age profiles gonorrhea incidence 20–24 year olds\nsecond thing notice parabola treatment window treatment cohort. effect sizes negative beginning, shrink absolute value growing. fact, 1991 1997 period one convergence zero, divergence two sets states.\nFigure 9.14: Coefficients standard errors DD regression equation 20–24 year olds\n, maybe strong trending unobservables groups masking abortion legalization effect. check, let’s use DDD strategy 25- 29-year-olds within-state control group. can implement using Stata code, abortion_ddd2.abortion_ddd2.R.abortion_ddd2.doabortion_ddd2.RFigure 9.15 shows DDD estimated coefficients treated cohort relative slightly older 25- 29-year-old cohort. ’s possible 25- 29-year-old cohort close age function satisfactory within-state control; age 20–24 sex age 25–29, instance, SUTVA violated. age groups, though, can try place 25- 29-year-olds, encourage experience insights might gleam.\nFigure 9.15: Coefficients standard errors DDD regression equation 20–24 year olds vs 25–29 year olds\nlet’s back remember big picture. abortion legalization hypothesis made series predictions negative parabolic treatment effects appear data. found initial support, exploited predictions, results fell apart. fair interpretation exercise analysis support abortion legalization hypothesis. Figure 9.15 shows several point estimates nearly zero, standard errors large include positive negative values interactions.included analysis wanted show power theory numerous unusual yet testable predictions. Imagine moment parabola showed age groups precisely years predicted theory. Wouldn’t update priors abortion legalization selection hypothesis? predictions narrow, else causing ? ’s precisely predictions specific, though, able reject abortion legalization hypothesis, least gonorrhea.","code":"use https://github.com/scunning1975/mixtape/raw/master/abortion.dta, clear\n\n* Second DD model for 20-24 year old black females\nchar year[omit] 1985 \nxi: reg lnr i.repeal*i.year i.fip acc ir pi alcohol crack poverty income ur if (race==2 & sex==2 & age==20) [aweight=totpop], cluster(fip) \nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nabortion <- read_data(\"abortion.dta\") %>% \n  mutate(\n    repeal = as_factor(repeal),\n    year   = as_factor(year),\n    fip    = as_factor(fip),\n    fa     = as_factor(fa),\n  )\n\nreg <- abortion %>% \n  filter(race == 2 & sex == 2 & age == 20) %>% \n  lm_robust(lnr ~ repeal*year + fip + acc + ir + pi + alcohol+ crack + poverty+ income+ ur,\n            data = ., weights = totpop, clusters = fip)use https://github.com/scunning1975/mixtape/raw/master/abortion.dta, clear\n\n* Second DDD model for 20-24 year olds vs 25-29 year olds black females in repeal vs Roe states\ngen younger2 = 0 \nreplace younger2 = 1 if age == 20\ngen yr2=(repeal==1) & (younger2==1)\ngen wm=(wht==1) & (male==1)\ngen wf=(wht==1) & (male==0)\ngen bm=(wht==0) & (male==1)\ngen bf=(wht==0) & (male==0)\nchar year[omit] 1985 \nchar repeal[omit] 0 \nchar younger2[omit] 0 \nchar fip[omit] 1 \nchar fa[omit] 0 \nchar yr2[omit] 0  \nxi: reg lnr i.repeal*i.year i.younger2*i.repeal i.younger2*i.year i.yr2*i.year i.fip*t acc pi ir alcohol crack  poverty income ur if bf==1 & (age==20 | age==25) [aweight=totpop], cluster(fip) \nlibrary(tidyverse)\nlibrary(haven)\nlibrary(estimatr)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\nabortion <- read_data(\"abortion.dta\") %>% \n  mutate(\n    repeal   = as_factor(repeal),\n    year     = as_factor(year),\n    fip      = as_factor(fip),\n    fa       = as_factor(fa),\n    younger2 = case_when(age == 20 ~ 1, TRUE ~ 0),\n    yr2      = as_factor(case_when(repeal == 1 & younger2 == 1 ~ 1, TRUE ~ 0)),\n    wm       = as_factor(case_when(wht == 1 & male == 1 ~ 1, TRUE ~ 0)),\n    wf       = as_factor(case_when(wht == 1 & male == 0 ~ 1, TRUE ~ 0)),\n    bm       = as_factor(case_when(wht == 0 & male == 1 ~ 1, TRUE ~ 0)),\n    bf       = as_factor(case_when(wht == 0 & male == 0 ~ 1, TRUE ~ 0))\n  )\n\nregddd <- abortion %>% \n  filter(bf == 1 & (age == 20 | age ==25)) %>% \n  lm_robust(lnr ~ repeal*year + acc + ir + pi + alcohol + crack + poverty + income + ur,\n            data = ., weights = totpop, clusters = fip)"},{"path":"ch8.html","id":"placebos-as-critique","chapter":"9 Difference-in-Differences","heading":"9.5.5 Placebos as critique","text":"Since fundamental problem causal inference blocks direct observation causal effects, rely many direct indirect pieces evidence establish credible causality. said previous section DDD, one indirect pieces evidence placebo analysis. reasoning goes find, using preferred research design, effects shouldn’t , maybe original findings weren’t credible first place. Using placebo analysis within work become essential part empirical work reason.another use placebo analysis evaluate credibility popular estimation strategies . kind use helps improve literature uncovering flaws research design can help stimulate creation stronger methods models. Let’s take two exemplary studies accomplished well: Auld Grootendorst (2004) Cohen-Cole Fletcher (2008).say Becker Murphy (1988) “rational addiction” model influential understatement. 4,000 cites become one common frameworks health economics. created cottage industry empirical studies persists day. Alcohol, tobacco, gambling, even sports, found “rationally addictive” commodities activities using various empirical approaches.researchers cautioned research community empirical studies. Rogeberg (2004) critiqued theory grounds, ’d like focus empirical studies based theory. Rather talk specific paper, ’d like provide quote Melberg (2008), surveyed researchers written rational addiction:majority respondents believe literature success story demonstrates power economic reasoning. time, also believe empirical evidence weak, disagree type evidence validate theory policy implications. Taken together, points interesting gap. one hand, respondents claim theory valuable real world implications. hand, believe theory received empiricalsupport. (p.1)Rational addiction held empirical standards theory. strength model always based economic reasoning, economists obviously find compelling. empirical designs flawed? know?Auld Grootendorst (2004) test rational addiction model. contrary, “anti-test” empirical rational addiction models common time. goal evaluate theoretical rational addiction model, words, rather empirical rational addiction models . ? Auld Grootendorst (2004) used empirical rational addiction model evaluate commodities plausibly considered addictive, eggs, milk, orange, apples. found empirical rational addiction model implied milk extremely addictive, perhaps one addictive commodities studied.147 credible believe eggs milk “rationally addictive” likely research designs used evaluate rational addiction model flawed? Auld Grootendorst (2004) study cast doubt empirical rational addiction model, theory.Another problematic literature peer-effects literature. Estimating peer effects notoriously hard. Manski (1993) said deep endogeneity social interactions made identification peer effects difficult possibly even impossible. called problem “mirroring” problem. “birds feather flock together,” identifying peer effects observational settings may just impossible due profound endogeneities play.Several studies found significant network effects outcomes like obesity, smoking, alcohol use, happiness. led many researchers conclude kinds risk behaviors “contagious” peer effects (Christakis Fowler 2007). studies exploit randomized social groups. peer groups purely endogenous. Cohen-Cole Fletcher (2008) showed using similar models data even attributes couldn’t transmitted peers—acne, height, headaches—appeared “contagious” observational data using Christakis Fowler (2007) model estimation. Note, Cohen-Cole Fletcher (2008) reject idea theoretical contagions. Rather, point Manski critique guide peer effect analysis social interactions endogenous. provide evidence indirectly using placebo analysis.148","code":""},{"path":"ch8.html","id":"compositional-change-within-repeated-cross-sections","chapter":"9 Difference-in-Differences","heading":"9.5.6 Compositional change within repeated cross-sections","text":"DD can applied repeated cross-sections, well panel data. one risks working repeated cross-sections unlike panel data (e.g., individual-level panel data), repeated cross-sections run risk compositional changes. Hong (2013) used repeated cross-sectional data Consumer Expenditure Survey (CEX) containing music expenditure internet use random sample households. author’s study exploited emergence immense popularity Napster, first file-sharing software widely used Internet users, June 1999 natural experiment. study compared Internet users Internet non-users emergence Napster. first glance, found Internet diffusion increased 1996 2001, spending music Internet users fell faster non-Internet users. initially evidence Napster responsible decline, investigated carefully.look Table 9.4, see evidence compositional changes. music expenditure fell treatment period, demographics two groups also changed period. instance, age Internet users grew income fell. older people less likely buy music first place, independently explain decline. kind compositional change like omitted variable bias built sample caused time-variant unobservables. Diffusion Internet appears related changing samples younger music fans early adopters. Identification causal effects need treatment exogenous changes composition.Table 9.4:  Changes Internet non-Internet users time.\nSample means Consumer Expenditure Survey.\n","code":""},{"path":"ch8.html","id":"final-thoughts","chapter":"9 Difference-in-Differences","heading":"9.5.7 Final thoughts","text":"caveats ’d like make moving . First, important remember concepts learned early DAG chapter. choosing covariates DD design, must resist temptation simply load regression kitchen sink regressors. resist , may inadvertently include collider, collider conditioned , introduces strange patterns may mislead audience. unfortunately way forward except, , deep institutional familiarity factors determined treatment assignment ground, well economic theory . Second, another issue skipped entirely question outcome modeled. little thought given exactly model outcome. Just take one example, use log levels ? use quartic root? use rates? , turns, critically important many , parallel trends assumption needed identification achieved—even though achieved unknown transformation. reason can think many DD designs parametric element must make strong commitments functional form . provide guidance , except maybe using pre-treatment leads way finding parallelism useful guide.Buy print version today:","code":""},{"path":"ch8.html","id":"twoway-fixed-effects-with-differential-timing","chapter":"9 Difference-in-Differences","heading":"9.6 Twoway Fixed Effects with Differential Timing","text":"bumper sticker car says “love Federalism (natural experiments)” (Figure 9.16). made bumper stickers students funny, illustrate United States never-ending laboratory. state federalism, US state given considerable discretion govern policies reforms. Yet, union states, US researchers access many data sets harmonized across states, making even useful causal inference.\nFigure 9.16: bumper sticker nerds.\nGoodman-Bacon (2019) calls staggered assignment treatments across geographic units time “differential timing” treatment. means unlike simple \\(2\\times 2\\) discussed earlier (e.g., New Jersey Pennsylvania), treatment units treated time, common situation one geographic units receive treatments different points time. happens United States area (state, municipality) adopt policy wants , reasons. result, adoption treatment tend differentially timed across units.introduction differential timing means basically two types DD designs. \\(2\\times 2\\) DD ’ve discussing wherein single unit group units receive treatment point time, like Snow’s cholera study Card Krueger (1994). DD differential timing groups receive treatment different points time, like Cheng Hoekstra (2013). good understanding \\(2\\times 2\\) design, works, works, works, work. Goodman-Bacon (2019) good understanding DD design differential timing. let’s get business discuss now reminding \\(2\\times 2\\) DD introduced earlier.\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{kU} =\n\\bigg(\\overline{y}_k^{\\text{post}(k)} - \\overline{y}_k^{\\text{pre}(k)} \\bigg) - \\bigg(\\overline{y}_U^{\\text{post}(k)} - \\overline{y}_U^{\\text{pre}(k)} \\bigg )\n\\end{align}\\]\n\\(k\\) treatment group, \\(U\\) never-treated group, everything else self-explanatory. Since involves sample means, can calculate differences manually. can estimate following regression:\n\\[\\begin{align}\ny_{} =\\beta D_{}+\\tau \\mathop{\\mathrm{Post}}_{t}+\\delta (D_i \\times \\mathop{\\mathrm{Post}}_t)+X_{}+\\varepsilon_{}\n\\end{align}\\]common situation ’ll encounter DD design differential timing. decomposition bit complicated, regression equation straightforward:\n\\[\\begin{align}\ny_{} =\\alpha_0 + \\delta D_{} + X_{} + \\alpha_i + \\alpha_t + \\epsilon_{}\n\\end{align}\\]\nresearchers estimate regression days, usually use linear fixed-effects model discussed previous panel chapter. linear panel models gotten nickname “twoway fixed effects” include time fixed effects unit fixed effects. Since popular estimator, ’s important understand exactly .","code":""},{"path":"ch8.html","id":"bacon-decomposition-theorem","chapter":"9 Difference-in-Differences","heading":"9.6.1 Bacon Decomposition theorem","text":"Goodman-Bacon (2019) provides helpful decomposition twoway fixed effects estimate \\(\\widehat{\\delta}\\). Given go-model implementing differential timing designs, found decomposition useful. decompositions twoway fixed effects estimators, another important paper Chaisemartin D’Haultfœuille (2019), ’ll call Bacon decomposition sake branding.punchline Bacon decomposition theorem twoway fixed effects estimator weighted average potential \\(2\\times 2\\) DD estimates weights based group sizes variance treatment. assumption variance weighted common trends (VWCT) time invariant treatment effects, variance weighted ATT weighted average possible ATTs. restrictive assumptions, estimate perfectly matches ATT. true time-varying treatment effects, time-varying treatment effects differential timing design estimated twoway fixed effects can generate bias. , twoway fixed-effects models may severely biased, echoed Chaisemartin D’Haultfœuille (2019).make concrete, let’s start simple example. Assume design three groups: early treatment group \\((k)\\), group treated later \\((l)\\), group never treated \\((U)\\). Groups \\(k\\) \\(l\\) similar treated differ \\(k\\) treated earlier \\(l\\).Let’s say 5 periods, \\(k\\) treated period 2. spends 40% time treatment, 0.4. let’s say \\(l\\) treated period 4. spends 80% time treated, 0.8. represent time spent treatment group \\(\\overline{D}_k = 0.4\\) \\(\\overline{D}_l = 0.8\\). important, length time group spends treatment determines treatment variance, turn affects weight \\(2\\times 2\\) plays final adding DD parameter . rather write \\(2\\times 2\\) DD estimator every time, just represent \\(2\\times 2\\) \\(\\widehat{\\delta}_{ab}^{2\\times 2,j}\\) \\(\\) \\(b\\) treatment groups, \\(j\\) index notation treatment group. Thus wanted know \\(2\\times 2\\) group \\(k\\) compared group \\(U\\), write \\(\\widehat{\\delta}_{kU}^{2\\times 2,k}\\) , maybe save space, just \\(\\widehat{\\delta}_{kU}^{k}\\)., let’s get started. First, single differential timing design, many \\(2\\times 2\\)s anyway? Turns lot. see, let’s make toy example. Let’s say three timing groups (\\(\\), \\(b\\), \\(c\\)) one untreated group \\((U)\\). 9 \\(2\\times 2\\) DDs. :See works? Okay, let’s return simpler example two timing groups \\(k\\) \\(l\\) one never-treated group. Groups \\(k\\) \\(l\\) get treated time periods \\(t^*_k\\) \\(t^*_l\\). earlier period anyone treated called “pre” period, period \\(k\\) \\(l\\) treated called “mid” period, period \\(l\\) treated called “post” period. much easier understand simple graphs. Let’s look Figure 9.17. Recall definition \\(2\\times 2\\) DD \n\\[\n\\widehat{\\delta}^{2\\times 2}_{kU} = \\bigg (\\overline{y}_k^{\\text{post}(k)} - \\overline{y}_k^{\\text{pre}(k)} \\bigg ) - \\bigg (\\overline{y}_U^{\\text{post}(k)} - \\overline{y}_U^{\\text{pre}(k)} \\bigg )\n\\]\n\\(k\\) \\(U\\) just place-holders groups used \\(2\\times 2\\).\nFigure 9.17: Four \\(2 \\times 2\\) DDs (Goodman-Bacon 2019). Reprinted permission authors.\nSubstituting information four panels Figure 9.17 equation enable calculate specific \\(2\\times 2\\) . can really just summarize three really important \\(2\\times 2\\)s, :\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{kU} &=\\bigg ( \\overline{y}_k^{\\text{post}(k)} - \\overline{y}_k^{\\text{pre}(k)} \\bigg ) - \\bigg ( \\overline{y}_U^{\\text{post}(k)} - \\overline{y}_U^{\\text{pre}(k)} \\bigg )\n\\\\\n\\widehat{\\delta}^{2\\times 2}_{kl} &=\\bigg ( \\overline{y}_k^{mid(k,l)} - \\overline{y}_k^{\\text{pre}(k)} \\bigg ) - \\bigg ( \\overline{y}_l^{mid(k,l)} - \\overline{y}_l^{\\text{pre}(k)} \\bigg )\n\\\\\n\\widehat{\\delta}^{2\\times 2}_{lk} &=\\bigg ( \\overline{y}_l^{\\text{post}(l)} - \\overline{y}_l^{mid(k,l)} \\bigg ) - \\bigg ( \\overline{y}_k^{\\text{post}(l)} - \\overline{y}_k^{mid(k,l)} \\bigg )\n\\end{align}\\]\nfirst \\(2\\times 2\\) timing group compared untreated group (\\(k\\) \\(l\\)), second group compared yet---treated timing group, last eventually-treated group compared already-treated controls.notation mind, DD parameter estimate can decomposed follows: \\(\\widehat{\\delta}^{DD}\\)\n\\[\\begin{align}\n\\widehat{\\delta}^{DD} = \\sum_{k \\neq U} s_{kU}\\widehat{\\delta}_{kU}^{2\\times 2} + \\sum_{k \\neq U} \\sum_{l>k} s_{kl} \\bigg [ \\mu_{kl}\\widehat{\\delta}_{kl}^{2\\times 2,k} + (1-\\mu_{kl}) \\widehat{\\delta}_{kl}^{2\\times 2,l} \\bigg]\n\\end{align}\\]\nfirst \\(2\\times 2\\) \\(k\\) compared \\(U\\) \\(l\\) compared \\(U\\) (combined make equation shorter).149 weights exactly?\n\\[\\begin{align}\ns_{ku} &=\\dfrac{ n_k n_u \\overline{D}_k (1- \\overline{D}_k ) }{ \\widehat{Var} ( \\tilde{D}_{} )} \\\\\ns_{kl} &=\\dfrac{ n_k n_l (\\overline{D}_k - \\overline{D}_{l} ) ( 1- ( \\overline{D}_k - \\overline{D}_{l} )) }{\\widehat{Var}(\\tilde{D}_{})} \\\\\n\\mu_{kl} &=\\dfrac{1 - \\overline{D}_k }{1 - ( \\overline{D}_k - \\overline{D}_{l} )}\n\\end{align}\\]\n\\(n\\) refers sample sizes, \\(\\overline{D}_k (1- \\overline{D}_k )\\) \\((\\overline{D}_k - \\overline{D}_{l} ) ( 1- ( \\overline{D}_k - \\overline{D}_{l} ))\\) expressions refer variance treatment, final equation two timing groups.150Two things immediately pop weights ’d like bring attention. First, notice “group” variation matters, opposed unit-level variation. Bacon decomposition shows ’s group variation twoway fixed effects using calculate parameter ’re seeking. states adopted law time, bigger influence final aggregate estimate .thing matters weights within-group treatment variance. appreciate subtlety ’s implied, ask —long group treated order maximize treatment variance? Define \\(X=D(1-D)=D-D^2\\), take derivative \\(V\\) respect \\(\\overline{D}\\), set \\(\\dfrac{d V}{d \\overline{D}}\\) equal zero, solve \\(\\overline{D}*\\). Treatment variance maximized \\(\\overline{D}=0.5\\). Let’s look three values \\(\\overline{D}\\) illustrate . \\[\\begin{gather}\n\\overline{D}=0.1; 0.1 \\times 0.9 = 0.09 \\\\\n\\overline{D}=0.4; 0.4 \\times 0.6 =0.24 \\\\\n\\overline{D}=0.5; 0.5 \\times 0.5 = 0.25\\end{gather}\\] learning , exactly? Well, learning treated middle panel actually directly influences numerical value get twoway fixed effects used estimate ATT. therefore means lengthening shortening panel can actually change point estimate purely changing group treatment variance nothing . Isn’t kind strange though? criteria even use determine best length?“treated treated weights,” \\(s_{kl}\\) weight. doesn’t \\(\\overline{D}(1-\\overline{D})\\) expression. Rather, \\((\\overline{D}_k - \\overline{D}_l)(1-(\\overline{D}_k - \\overline{D}_l)\\) expression. “middle” isn’t super clear. ’s isn’t middle treatment single group, rather ’s middle panel difference treatment variance. instance, let’s say \\(k\\) spends 67% time treated \\(l\\) spends 15% time treated. \\(\\overline{D}_k - \\overline{D}_l = 0.52\\) therefore \\(0.52 \\times 0.48 = 0.2496\\), showed nearly max value variance possible (e.g., 0.25). Think moment—twoway fixed effects differential timing weights 2$$2s comparing two ultimate treatment groups gap treatment time close 0.5.","code":""},{"path":"ch8.html","id":"expressing-the-decomposition-in-potential-outcomes","chapter":"9 Difference-in-Differences","heading":"9.6.2 Expressing the decomposition in potential outcomes","text":"now, just showed inside DD parameter estimate using twoway fixed effects: nothing “adding ” possible \\(2\\times 2\\)s weighted group shares treatment variance. tells us DD numerically; tell us whether parameter estimate maps onto meaningful average treatment effect. , need take sample averages use switching equations replace potential outcomes. key moving numbers estimates causal effects.Bacon’s decomposition theorem expresses DD coefficient terms sample average, making straightforward substitute potential outcomes using modified switching equation. little creative manipulation, revelatory. First, let’s define year-specific ATT \n\\[\\begin{align}\n  ATT_k(\\tau)=E\\big[Y^1_{}-Y^0_{}  \\mathop{\\mathrm{\\,\\vert\\,}}k, t=\\tau\\big]\n\\end{align}\\]\nNext, let’s define time window \\(W\\) (e.g., post-treatment window)\n\\[\\begin{align}\n  ATT_k(\\tau)=E\\big[Y^1_{}-Y^0_{}  \\mathop{\\mathrm{\\,\\vert\\,}}k,\\tau\\W\\big]\n\\end{align}\\]\nFinally, let’s define differences average potential outcomes overtime :\n\\[\\begin{align}\n  \\Delta Y^h_k(W_1,W_0) =\n  E\\big[Y^h_{}  \\mathop{\\mathrm{\\,\\vert\\,}}k, W_1\\big]-\n  E\\big[Y^h_{}  \\mathop{\\mathrm{\\,\\vert\\,}}k, W_0\\big]\n\\end{align}\\]\n\\(h=0\\) (.e., \\(Y^0\\)) \\(h=1\\) (.e., \\(Y^1\\))trends, differences mean potential outcomes non-zero. can see Figure 9.18.\nFigure 9.18: Changing average potential outcomes\n’ll return , just wanted point concrete mind return later.can move now \\(2\\times 2\\)s decomposed earlier directly ATT, ultimately main thing want know. covered earlier chapter, review maintain progress argument. first write \\(2\\times 2\\) expression, use switching equation introduce potential outcome notation, little manipulation, find ATT expression.\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{kU}\n&=\\bigg (E\\big[Y_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]-\nE\\big[Y_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] \\bigg ) -\n\\bigg( E\\big[Y_u  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]-\nE\\big[Y_u  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]\\bigg)\\\\\n&=\\bigg ( \\underbrace{E\\big[Y^1_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_j]  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]\\bigg)-\n\\bigg(E\\big[Y^0_u  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]-\nE\\big[Y^0_u  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]}_{\\text{Switching equation}} \\bigg)\\\\\n&+ \\underbrace{E\\big[Y_j^0  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{Adding zero}}\\\\\n&=\\underbrace{E\\big[Y^1_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big]}_{\\text{ATT}} \\\\\n&+\\bigg [ \\underbrace{E\\big[Y^0_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] - E\\big[Y^0_j  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big]\\bigg]-\n\\bigg [E\\big[Y^0_U  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Post}}\\big] -\nE\\big[Y_U^0  \\mathop{\\mathrm{\\,\\vert\\,}}\\mathop{\\mathrm{Pre}}\\big] }_{\\text{Non-parallel trends bias $2\\times 2$ case}} \\bigg ]\n\\end{align}\\]\ncan rewritten even compactly :\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{kU} = ATT_{\\mathop{\\mathrm{Post}},j} + \\underbrace{\\Delta Y^0_{\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}},j} -\n\\Delta Y^0_{\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}}, U}}_{\\text{Selection bias!}}\n\\end{align}\\]\n\\(2\\times 2\\) DD can expressed sum ATT plus parallel trends assumption, without parallel trends, estimator biased. Ask —two differences parallel trends assumption counterfactual, \\(\\Delta Y^0_{\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}},j}\\) \\(\\Delta Y^0_{\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}}, U}\\)? one observed, words, one observed? Look see can figure drawing Figure 9.19.\nFigure 9.19: Visualization parallel trends.\nparallel—counterfactual trend observable trend—selection bias term zero ATT identified. let’s keep looking within decomposition, aren’t done. two \\(2\\times 2\\)s need defined since appear Bacon’s decomposition also. :\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{kU} &= ATT_k{\\mathop{\\mathrm{Post}}} + \\Delta Y^0_k(\\mathop{\\mathrm{Post}}(k),\\mathop{\\mathrm{Pre}}(k)) - \\Delta Y^0_U(\\mathop{\\mathrm{Post}}(k),\\mathop{\\mathrm{Pre}})\n\\\\\n\\widehat{\\delta}^{2\\times 2}_{kl} &= ATT_k(MID) + \\Delta Y^0_k(MID,\\mathop{\\mathrm{Pre}}) - \\Delta Y^0_l(MID, \\mathop{\\mathrm{Pre}})\n\\end{align}\\]\nlook ’re always comparing treated unit untreated unit (though second case ’s just haven’t treated yet).\\(2\\times 2\\) compared late groups already-treated earlier groups? lot substitutions like get:\n\\[\\begin{align}\n\\widehat{\\delta}^{2\\times 2}_{lk} &=\nATT_{l,\\mathop{\\mathrm{Post}}(l)} \\nonumber\n\\\\\n&+ \\underbrace{\\Delta Y^0_l(\\mathop{\\mathrm{Post}}(l),MID) - \\Delta Y^0_k (\\mathop{\\mathrm{Post}}(l), MID)}_{\\text{Parallel-trends bias}} \\nonumber\n\\\\\n& - \\underbrace{(ATT_k(\\mathop{\\mathrm{Post}}) - ATT_k(Mid))}_{\\text{Heterogeneity time bias!}}\n\\end{align}\\]\nfind interesting earlier decomposition simple difference means \\(ATE\\) \\(+\\) selection bias \\(+\\) heterogeneity treatment effects bias resembles decomposition late early \\(2\\times 2\\) DD.first line \\(ATT\\) desperately hope identify. selection bias zeroes insofar \\(Y^0\\) \\(k\\) \\(l\\) parallel trends \\(mid\\) \\(post\\) period. treatment effects bias third line zeroes long constant treatment effects group time. heterogeneity time group, two \\(ATT\\) terms , therefore zero .can sign bias willing assume monotonicity, means \\(mid\\) term smaller absolute value \\(post\\) term. monotonicity, interior parentheses third line positive, therefore bias negative. positive ATT, bias effects towards zero, negative ATT, cause estimated ATT become even negative.Let’s pause collect terms. decomposition formula DD :\n\\[\\begin{align}\n\\widehat{\\delta}^{DD} = \\sum_{k \\neq U} s_{kU}\\widehat{\\delta}_{kU}^{2\\times 2} + \\sum_{k \\neq U} \\sum_{l>k} s_{kl} \\bigg[ \\mu_{kl}\\widehat{\\delta}_{kl}^{2\\times 2,k} + (1-\\mu_{kl}) \\widehat{\\delta}_{kl}^{2\\times 2,l} \\bigg]\n\\end{align}\\]\nsubstitute following three expressions formula.\n\\[\\begin{align}\n\\widehat{\\delta}_{kU}^{2\\times 2} &= ATT_k(\\mathop{\\mathrm{Post}})+\\Delta Y_l^0(\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}})-\n\\Delta Y_U^0(\\mathop{\\mathrm{Post}},\\mathop{\\mathrm{Pre}})\n\\\\\n\\widehat{\\delta}_{kl}^{2\\times 2,k} &=ATT_k(  \\mathop{\\mathrm{\\,\\vert\\,}})+\\Delta Y_l^0(  \\mathop{\\mathrm{\\,\\vert\\,}},\\mathop{\\mathrm{Pre}})-\\Delta Y_l^0(  \\mathop{\\mathrm{\\,\\vert\\,}}, \\mathop{\\mathrm{Pre}})\n\\\\\n\\widehat{\\delta}^{2\\times 2,l}_{lk} &=ATT_{l}\\mathop{\\mathrm{Post}}(l)+\\Delta Y^0_l(\\mathop{\\mathrm{Post}}(l),  \\mathop{\\mathrm{\\,\\vert\\,}})-\\Delta Y^0_k (\\mathop{\\mathrm{Post}}(l),   \\mathop{\\mathrm{\\,\\vert\\,}})\n\\\\\n&- (ATT_k(\\mathop{\\mathrm{Post}})-ATT_k(  \\mathop{\\mathrm{\\,\\vert\\,}}))\n\\end{align}\\]\nSubstituting three terms decomposition formula bit overwhelming, let’s simplify notation. estimated DD parameter equal : \\[p\\lim\\widehat{\\delta}^{DD}_{n\\\\infty} =\nVWATT + VWCT - \\Delta ATT\\] next sections, discuss individual element expression.","code":""},{"path":"ch8.html","id":"variance-weighted-att","chapter":"9 Difference-in-Differences","heading":"9.6.3 Variance weighted ATT","text":"begin discussing variance weighted average treatment effect treatment group, \\(VWATT\\). unpacked expression :\n\\[\\begin{align}\nVWATT &=\\sum_{k\\neq U}\\sigma_{kU}ATT_k(\\mathop{\\mathrm{Post}}(k))\n\\\\\n&+\\sum_{k \\neq U} \\sum_{l>k} \\sigma_{kl} \\bigg [ \\mu_{kl} ATT_k (  \\mathop{\\mathrm{\\,\\vert\\,}})+ (1-\\mu_{kl}) ATT_{l} (POST(l)) \\bigg ]\n\\end{align}\\]\n\\(\\sigma\\) like \\(s\\), population terms samples. Notice VWATT simply contains three ATTs identified , weighted weights contained decomposition formula. weights sum one, weighting irrelevant ATT identical.151When learned DD coefficient weighted average individual \\(2\\times 2\\)s, terribly surprised. may intuitively known weights based group shares treatment variance, figured probably weighted average nonetheless. experience, though, worked two terms. now turn two terms: VWCT \\(\\Delta ATT\\).","code":""},{"path":"ch8.html","id":"variance-weighted-common-trends","chapter":"9 Difference-in-Differences","heading":"9.6.4 Variance weighted common trends","text":"VWCT stands variance weighted common trends. just collection non-parallel-trends biases previously wrote , notice—identification requires variance weighted common trends hold, actually bit weaker thought identical trends. get identical trends, Goodman-Bacon (2019) shows us technically don’t need identical trends weights can make hold even don’t exact parallel trends. Unfortunately, bit pain write , since ’s important, .\n\\[\\begin{align}\nVWCT &= \\sum_{k \\neq U} \\sigma_{kU} \\bigg [ \\Delta Y_k^0(\\mathop{\\mathrm{Post}}(k),\\mathop{\\mathrm{Pre}}) - \\Delta Y_U^0(\\mathop{\\mathrm{Post}}(k),\\mathop{\\mathrm{Pre}}) \\bigg ] \\nonumber\n\\\\\n&+ \\sum_{k \\neq U} \\sum_{l>k} \\sigma_{kl} \\bigg [ \\mu_{kl} \\{ \\Delta Y^0_k(Mid,\\mathop{\\mathrm{Pre}}(k)) - \\Delta Y_l^0(  \\mathop{\\mathrm{\\,\\vert\\,}},\\mathop{\\mathrm{Pre}}(k))\\} \\nonumber\n\\\\\n&+(1-\\mu_{kl}) \\{ \\Delta Y^0_l(\\mathop{\\mathrm{Post}}(l),   \\mathop{\\mathrm{\\,\\vert\\,}}) - \\Delta Y^0_k(\\mathop{\\mathrm{Post}}(l),   \\mathop{\\mathrm{\\,\\vert\\,}}) \\} \\bigg ]\n\\end{align}\\]\nNotice VWCT term simply collects non-parallel-trend biases three \\(2\\times 2\\)s. One novelties, though, non-parallel-trend biases also weighted weights used VATT.actually new insight. one hand, lot terms need zero. hand, ’s ironically weaker identifying assumption strictly identical common trends weights can technically correct unequal trends. VWCT zero exact parallel trends situations weights adjust trends zero . good news (sort ).","code":""},{"path":"ch8.html","id":"att-heterogeneity-within-time-bias","chapter":"9 Difference-in-Differences","heading":"9.6.5 ATT heterogeneity within time bias","text":"decomposed simple difference mean outcomes sum ATE, selection bias, heterogeneous treatment effects bias, really wasn’t huge headache. ATT differed ATU, simple difference mean outcomes became sum ATT selection bias, still interesting parameter. Bacon decomposition, ATT heterogeneity time introduces bias benign. Let’s look happens time-variant within-group treatment effects.\n\\[\\begin{align}\n\\Delta ATT = \\sum_{k \\neq U} \\sum_{l>k} (1 - \\mu_{kl}) \\Big[ ATT_k(\\mathop{\\mathrm{Post}}(l) - ATT_k(  \\mathop{\\mathrm{\\,\\vert\\,}})) \\Big]\n\\end{align}\\]\nHeterogeneity ATT two interpretations: can heterogeneous treatment effects across groups, can heterogeneous treatment effects within groups time. \\(\\Delta ATT\\) concerned latter . first case heterogeneity across units within groups. heterogeneity across groups, VWATT simply average group-specific ATTs weighted function sample shares treatment variance. bias kind heterogeneity.152But ’s second case—\\(ATT\\) constant across units heterogeneous within groups time—things get little worrisome. Time-varying treatment effects, even identical across units, generate cross-group heterogeneity differing post-treatment windows, fact earlier-treated groups serving controls later-treated groups. Let’s consider case counterfactual outcomes identical, treatment effect linear break trend (Figure 9.20). instance, \\(Y^1_{} = Y^0_{} + \\theta (t-t^*_1+1)\\) similar Meer West (2016).\nFigure 9.20: Within-group heterogeneity \\(ATT\\). Reprinted Goodman-Bacon (2019)\nNotice first \\(2\\times 2\\) uses later group control middle period, late period, later-treated group using earlier treated control. problem?’s problem lot \\(2\\times 2\\)s weights large. negligible portions estimate, even exists, given weights small (group shares also important piece weighting just variance treatment) bias may small. let’s say doesn’t hold. going ? effect biased control group experiencing trend outcomes (e.g., heterogeneous treatment effects), bias feeds later \\(2\\times 2\\) according size weights, \\((1-\\mu_{kl})\\). need correct plan stick twoway fixed effects estimator.Now ’s time use ’ve learned. Let’s look interesting important paper Cheng Hoekstra (2013) learn DD paper replicate using event studies Bacon decomposition.","code":""},{"path":"ch8.html","id":"castle-doctrine-statutes-and-homicides","chapter":"9 Difference-in-Differences","heading":"9.6.6 Castle-doctrine statutes and homicides","text":"Cheng Hoekstra (2013) evaluated impact gun reform violence illustrate various principles practices regarding differential timing. ’d like discuss principles context paper. next section discuss, extend, replicate various parts study.Trayvon Benjamin Martin 17-year-old African-American young man George Zimmerman shot killed Sanford, Florida, February 26, 2012. Martin walking home alone convenience store Zimmerman spotted , followed distance, reported police. said found Martin’s behavior “suspicious,” though police officers urged Zimmerman stay back, Zimmerman stalked eventually provoked Martin. altercation occurred Zimmerman fatally shot Martin. Zimmerman claimed self-defense nonetheless charged Martin’s death. jury acquitted second-degree murder manslaughter.Zimmerman’s actions interpreted jury legal 2005, Florida reformed lethal self-defense used. Whereas lethal self-defense legal inside home, new law, “Stand Ground,” extended right public places. 2000 2010, twenty-one states explicitly expanded castle-doctrine statute extending places outside home lethal force legally used.153 states removed long-standing tradition common law placed duty retreat danger victim. reforms, though, victims longer duty retreat public places felt threatened; retaliate lethal self-defense.changes also made. states, individuals used lethal force outside home assumed reasonably afraid. Thus, prosecutor prove fear reasonable, allegedly almost impossible task. Civil liability acting expansions also removed. civil liability lower threshold guilt criminal guilt, effectively removed remaining constraint might keep someone using lethal force outside home.economic perspective, reforms lowered cost killing someone. One use lethal self-defense situations previously barred. civil liability, expected cost killing someone now lower. Thus, insofar people sensitive incentives, depending elasticities lethal self-defense respect cost, expect increase lethal violence marginal victim. reforms may , words, caused homicides rise.One can divide lethal force true false positives. true positive use lethal force situations , person used lethal force, murdered. Thus, true positive case lethal force simply transfer one life (offender) another (defender). tragic, official statistics record net increase homicides relative counterfactual—person killed. false positive causes net increase homicides relative counterfactual. arguments can escalate unnecessarily, yet common law, duty retreat defused situation spilled lethal force. Now, though, castle-doctrine reforms, safety valve removed, thus killing occurs counterfactual, leading net increase homicides.possible impact reforms—deterrence violence also possibility reforms. Lott Mustard (1997), authors found concealed-carry laws reduced violence. suggested caused deterrence—thinking someone may carrying concealed weapon, rational criminal deterred committing crime. Deterrence dates back Becker (1968) Jeremy Bentham . Expanding arenas lethal force used also deter crime. Since theoretical possibility depends crucially key elasticities, may fact zero, deterrence expanding guns can used kill someone ultimately empirical question.Cheng Hoekstra (2013) chose difference--differences design project castle doctrine law treatment timing differential across states. estimatingequation \n\\[ \nY_{}=\\alpha + \\delta D_{} + \\gamma X_{} + \\sigma_i + \\tau_t + \\varepsilon_{}\n\\]\n\\(D_{}\\) treatment parameter. estimated equation using standard twoway fixed effects model well count models. Ordinarily, treatment parameter 0 1, Cheng Hoekstra (2013), ’s variable ranging 0 1, states get law change mid-year. got law July, \\(D_{}\\) equals 0 year adoption, 0.5 year adoption 1 thereafter. \\(X_{}\\) variable included particular kind control called “region--year fixed effects,” vector dummies census region state belonged interacted year fixed effect. done explicit counterfactuals forced come within census region.154 results dramatically different twoway fixed effects count models, tend emphasize results twoway fixed effects.data used somewhat standard crime studies. used FBI Uniform Crime Reports Summary Part files 2000 2010. FBI Uniform Crime Reports harmonized data set eight “index” crimes collected voluntarily participating police agencies across country. Participation high data goes back many decades, making attractive many contemporary questions regarding crime policy. Crimes converted rates, “offenses per 100,000 population.”Cheng Hoekstra (2013) rhetorically open study series simple placebos check whether reforms spuriously correlated crime trends generally. Since oftentimes many crimes correlated unobserved factors, appeal, rules possibility laws simply adopted areas crime rates already rising. falsifications chose motor vehicle thefts larcenies, neither , reasoned, credibly connected lowering cost using lethal force public.many regression coefficients Table 9.5 applied microeconomists like report results increasingly restrictive models. case, column new regression additional controls additional fixed-effects specifications, time-varying controls, one-year lead check pre-treatment differences outcomes, state-specific trends. can see, many coefficients small, small, even large standard errors yield range estimates still large.Next look consider crimes might deterred policy created credible threat lethal retaliation public: burglary, robbery, aggravated assault.Insofar castle doctrine deterrence effect, expect negative effect law offenses. regressions shown Table 9.6 actually positive, significant even still. authors conclude detect deterrence—mean didn’t happen; just reject null large effects.Now move main results, interesting ’s much common authors lead main results. rhetoric paper somewhat original respect. point, reader seen lot null effects laws may wondering, “’s going ? law isn’t spurious isn’t causing deterrence. reading paper?”first thing authors show series figures showing raw data homicides treatment control states. always challenge working differential timing, though. instance, approximately twenty states adopted castle-doctrine law 2005 2010, time. going show visually? pre-treatment period, instance, control group differential timing? one state adoptsTable 9.5:  Falsification Tests: effect castle doctrine laws larceny motor vehicle theft.\ncolumn panel represents separate regression. unit observation state-year. Robust standard errors clustered state level. Time-varying controls include policing incarceration rates, welfare public assistance spending, median income, poverty rate, unemployment rate, demographics. \\(^{*}\\) Significant 10 percent level. \\(^{**}\\) Significant 5 percent level. \\(^{***}\\) Significant 1 percent level.\nTable 9.6:  deterrence effects castle-doctrine laws: Burglary, robbery, aggravated assault.\ncolumn panel represents separate regression. unit observation state-year. Robust standard errors clustered state level. Time-varying controls include policing incarceration rates, welfare public assistance spending, median income, poverty rate, unemployment rate, demographics. \\(^{*}\\) Significant 10 percent level. \\(^{**}\\) Significant 5 percent level. \\(^{***}\\) Significant 1 percent level.\n2005, another 2006, precisely pre- post-treatment control group? ’s bit challenge, yet stick guiding principle causal inference studies desperately need data visualization main effects, job solve creativity honesty make beautiful figures. Cheng Hoekstra (2013) ’ve presented regression coefficients leads lags, commonly done, knowing authors firsthand, preference give reader pictures raw data transparent possible. Therefore, showed multiple figures figure “treatment group” compared “never-treated” units. Figure 9.21 shows Florida case.\nFigure 9.21: Raw data log homicides per 100,000 Florida vs never treated control states.\nNotice passage law, offenses fairly flat treatment control. Obviously, ’ve emphasized, direct test parallel-trends assumption. Parallel trends pre-treatment period neither necessary sufficient. identifying assumption, recall, variance-weighted common trends, entirely based parallel counterfactual trends, pre-treatment trends. researchers use parallel pre-treatment trends like hunch counterfactual trends parallel. one sense, parallel pre-treatment rules obvious spurious factors worried , law adoption happening around timing change, even ’s simply nothing seemingly spurious factors like rising homicides. ’s clearly happening —homicides weren’t diverging controls pre-treatment. following similar trajectory Florida passed law trends converge. Notice 2005, law occurs, ’s sizable jump homicides. additional figures like , set —show treatment group time compared “never-treated” group.Table 9.7:  Effect Castle Doctrine Laws Homicide\ncolumn panel represents separate regression. unit observation state-year. Robust standard errors clustered state level. Time-varying controls include policing incarceration rates, welfare public assistance spending, median income, poverty rate, unemployment rate, demographics. \\(^{**}\\) Significant 5 percent level. \\(^{***}\\) Significant 1 percent level.\nInsofar cost committing lethal force fallen, expect see , implies positive coefficient estimated \\(\\delta\\) term assuming heterogeneity bias discussed earlier doesn’t cause twoway fixed effects estimated coefficient flip signs. different zero statistically meaningful magnitude. present four separate types specifications—three using OLS, one using negative binomial. report weighted OLS regressions sake space.’s lot information Table 9.7, let’s sure get lost. First, coefficients positive similar magnitude—8% 10% increases homicides. Second, three four panels almost entirely significant. appears bulk evidence suggests castle-doctrine statute caused increase homicides around 8%.satisfied, authors implemented kind randomization inference-based test. Specifically, moved eleven-year panel back time covering 1960–2009 estimated forty placebo “effects” passing castle doctrine one forty years earlier. , found average effect exercise essentially zero. results summarized . appears something statistically unusual actual treatment profile compared placebo profiles, actual profile yields effect sizes larger one case placebo regressions run.Randomization inference averages (Cheng Hoekstra 2013).Cheng Hoekstra (2013) found evidence castle-doctrine laws deter violent offenses, find increased homicides. 8% net increase homicide rates translates around six hundred additional homicides per year across twenty-one adopting states. Thinking back killing Trayvon Martin George Zimmerman, one left wonder whether Trayvon might still alive Florida passed Stand Ground. kind counterfactual reasoning can drive crazy, unanswerable—simply don’t know, know, never know answer counterfactual questions. fundamental problem causal inference states need know happened fateful night without Stand Ground compare happened Stand Ground know can placed feet law. know certain assumptions related DD design, homicides net around 8%–10% higher ’ve compared explicit counterfactuals. doesn’t answer every question, suggests nontrivial number deaths can blamed laws similar Stand Ground.","code":""},{"path":"ch8.html","id":"replicating-cheng2013-sort-of","chapter":"9 Difference-in-Differences","heading":"9.6.7 Replicating Cheng and Hoekstra (2013), sort of","text":"Now ’ve discussed Cheng Hoekstra (2013), want replicate , least work data set illustrate certain things ’ve discussed, like event studies Bacon decomposition. analysis slightly different , though, policy variable interval \\([0,1]\\) rather pure dummy. ’s carefully defined policy variable according month law passed (e.g., June) divided total 12 months. state passed last June, assign 0.5 first year, 1 thereafter. ’s nothing wrong approach, going use dummy makes event studies bit easier visualize, Bacon decomposition works dummy policy variables.First, replicate main homicide results Panel , column 6, Figure 9.21.castle_1.docastle_1.RHere see main result castle doctrine expansions led approximately 10% increase homicides. use post-dummy, essentially equal 0 unless state fully covered castle doctrine expansions, effect like 7.6%.now, ’d like go beyond study implement event study. First, need define pre-treatment leads lags. , use “time_til” variable, number years state received treatment. Using variable, create leads (years prior treatment) lags (years post-treatment).castle_2.docastle_2.ROur omitted category year treatment, coefficients respect year. can see coefficients leads statistically different zero prior treatment, except leads 8 9, may three states eight years prior treatment, one state nine years prior treatment. years prior treatment, leads 1 6 equal zero statistically insignificant, although technically large confidence intervals. lags, hand, positive dissimilar one another except lag 5, around 17%.Now customary plot event studies, let’s now. going show easy way longer way . longer way gives ultimately control exactly want event study look like, fast dirty method, easier way suffice. easier way, need install program Stata called coefplot, written Ben Jann, author estout.155castle_3.docastle_3.R\nFigure 9.22: Homicide event study plots using coefplot (Cheng Hoekstra 2013).\nLet’s look now command created. can see Figure 9.22, eight nine years prior treatment, treatment states significantly lower levels homicides, states even values (one \\(-9\\) three \\(-8\\)), may want disregard relevance negative effects reason units dummy know earlier can lead high overrejection rates (MacKinnon Webb 2017). Instead, notice six years prior treatment, virtually difference treatment states control states., year treatment, changes. Log murders begin rising, consistent post dummy imposed zeros pre-treatment leads required average effect post-treatment constant.promised show make graph way gave flexibility, warned, bit cumbersome.castle_4.docastle_4.RYou can see figure creates Figure 9.23. difference coefplot twoway command connects event-study coefficients lines, whereas coefplot displayed coefficients hanging air. Neither right wrong; merely wanted see differences sake code might experiment adapt needs.thing graph leads imbalanced. ’s one state, instance, ninth lead, ’s three eighth lead. ’d like two modifications . First, ’d like replace sixth lead now equal leads 6–9. words, force late adopters coefficient six years treatment. , get Figure 9.24.Next, let’s balance event study dropping states show seventh, eighth, ninth leads.156 , get Figure 9.25.\nFigure 9.23: Homicide event study plots created manually -twoway- (Cheng Hoekstra 2013).\n\nFigure 9.24: Homicide event study plots using -twoway- (Cheng Hoekstra 2013).\n\nFigure 9.25: Homicide event study plots using -twoway- (Cheng Hoekstra 2013).\nnothing else, exploring different specifications cuts data can help understand just confident prior treatment, treatment control states genuinely pretty similar. weren’t similar, behooves researcher minimum provide insight others treatment control groups dissimilar levels. —different levels, ’s entirely plausible different counterfactual trends else different first place (Kahn-Lang Lang 2019).","code":"use https://github.com/scunning1975/mixtape/raw/master/castle.dta, clear\nset scheme cleanplots\n* ssc install bacondecomp\n\n* define global macros\nglobal crime1 jhcitizen_c jhpolice_c murder homicide  robbery assault burglary larceny motor robbery_gun_r \nglobal demo blackm_15_24 whitem_15_24 blackm_25_44 whitem_25_44 //demographics\nglobal lintrend trend_1-trend_51 //state linear trend\nglobal region r20001-r20104  //region-quarter fixed effects\nglobal exocrime l_larceny l_motor // exogenous crime rates\nglobal spending l_exp_subsidy l_exp_pubwelfare\nglobal xvar l_police unemployrt poverty l_income l_prisoner l_lagprisoner $demo $spending\n\nlabel variable post \"Year of treatment\"\nxi: xtreg l_homicide i.year $region $xvar $lintrend post [aweight=popwt], fe vce(cluster sid)\nlibrary(bacondecomp)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(lfe)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ncastle <- read_data(\"castle.dta\")\n\n#--- global variables\ncrime1 <- c(\"jhcitizen_c\", \"jhpolice_c\", \n            \"murder\", \"homicide\", \n            \"robbery\", \"assault\", \"burglary\",\n            \"larceny\", \"motor\", \"robbery_gun_r\")\n\ndemo <- c(\"emo\", \"blackm_15_24\", \"whitem_15_24\", \n          \"blackm_25_44\", \"whitem_25_44\")\n\n# variables dropped to prevent colinearity\ndropped_vars <- c(\"r20004\", \"r20014\",\n                  \"r20024\", \"r20034\",\n                  \"r20044\", \"r20054\",\n                  \"r20064\", \"r20074\",\n                  \"r20084\", \"r20094\",\n                  \"r20101\", \"r20102\", \"r20103\",\n                  \"r20104\", \"trend_9\", \"trend_46\",\n                  \"trend_49\", \"trend_50\", \"trend_51\"\n)\n\nlintrend <- castle %>%\n    select(starts_with(\"trend\")) %>% \n  colnames %>% \n  # remove due to colinearity\n  subset(.,! . %in% dropped_vars) \n\nregion <- castle %>%\n  select(starts_with(\"r20\")) %>% \n  colnames %>% \n  # remove due to colinearity\n  subset(.,! . %in% dropped_vars) \n\n\nexocrime <- c(\"l_lacerny\", \"l_motor\")\nspending <- c(\"l_exp_subsidy\", \"l_exp_pubwelfare\")\n\n\nxvar <- c(\n  \"blackm_15_24\", \"whitem_15_24\", \"blackm_25_44\", \"whitem_25_44\",\n  \"l_exp_subsidy\", \"l_exp_pubwelfare\",\n  \"l_police\", \"unemployrt\", \"poverty\", \n  \"l_income\", \"l_prisoner\", \"l_lagprisoner\"\n)\n\nlaw <- c(\"cdl\")\n\ndd_formula <- as.formula(\n  paste(\"l_homicide ~ \",\n        paste(\n          paste(xvar, collapse = \" + \"),\n          paste(region, collapse = \" + \"),\n          paste(lintrend, collapse = \" + \"),\n          paste(\"post\", collapse = \" + \"), sep = \" + \"),\n        \"| year + sid | 0 | sid\"\n  )\n)\n\n#Fixed effect regression using post as treatment variable \ndd_reg <- felm(dd_formula, weights = castle$popwt, data = castle)\nsummary(dd_reg)* Event study regression with the year of treatment (lag0) as the omitted category.\nxi: xtreg l_homicide  i.year $region lead9 lead8 lead7 lead6 lead5 lead4 lead3 lead2 lead1 lag1-lag5 [aweight=popwt], fe vce(cluster sid)\ncastle <- castle %>%\n  mutate(\n    time_til = year - treatment_date,\n    lead1 = case_when(time_til == -1 ~ 1, TRUE ~ 0),\n    lead2 = case_when(time_til == -2 ~ 1, TRUE ~ 0),\n    lead3 = case_when(time_til == -3 ~ 1, TRUE ~ 0),\n    lead4 = case_when(time_til == -4 ~ 1, TRUE ~ 0),\n    lead5 = case_when(time_til == -5 ~ 1, TRUE ~ 0),\n    lead6 = case_when(time_til == -6 ~ 1, TRUE ~ 0),\n    lead7 = case_when(time_til == -7 ~ 1, TRUE ~ 0),\n    lead8 = case_when(time_til == -8 ~ 1, TRUE ~ 0),\n    lead9 = case_when(time_til == -9 ~ 1, TRUE ~ 0),\n    \n    lag0 = case_when(time_til == 0 ~ 1, TRUE ~ 0),\n    lag1 = case_when(time_til == 1 ~ 1, TRUE ~ 0),\n    lag2 = case_when(time_til == 2 ~ 1, TRUE ~ 0),\n    lag3 = case_when(time_til == 3 ~ 1, TRUE ~ 0),\n    lag4 = case_when(time_til == 4 ~ 1, TRUE ~ 0),\n    lag5 = case_when(time_til == 5 ~ 1, TRUE ~ 0)\n  )\n\nevent_study_formula <- as.formula(\n  paste(\"l_homicide ~ + \",\n        paste(\n          paste(region, collapse = \" + \"),\n          paste(paste(\"lead\", 1:9, sep = \"\"), collapse = \" + \"),\n          paste(paste(\"lag\", 1:5, sep = \"\"), collapse = \" + \"), sep = \" + \"),\n        \"| year + state | 0 | sid\"\n  ),\n)\n\nevent_study_reg <- felm(event_study_formula, weights = castle$popwt, data = castle)\nsummary(event_study_reg)* Plot the coefficients using coefplot\n* ssc install coefplot\n\ncoefplot, keep(lead9 lead8 lead7 lead6 lead5 lead4 lead3 lead2 lead1 lag1 lag2 lag3 lag4 lag5) xlabel(, angle(vertical)) yline(0) xline(9.5) vertical msymbol(D) mfcolor(white) ciopts(lwidth(*3) lcolor(*.6)) mlabel format(%9.3f) mlabposition(12) mlabgap(*2) title(Log Murder Rate) \n# order of the coefficients for the plot\nplot_order <- c(\"lead9\", \"lead8\", \"lead7\", \n                \"lead6\", \"lead5\", \"lead4\", \"lead3\", \n                \"lead2\", \"lead1\", \"lag1\", \n                \"lag2\", \"lag3\", \"lag4\", \"lag5\")\n\n# grab the clustered standard errors\n# and average coefficient estimates\n# from the regression, label them accordingly\n# add a zero'th lag for plotting purposes\nleadslags_plot <- tibble(\n  sd = c(event_study_reg$cse[plot_order], 0),\n  mean = c(coef(event_study_reg)[plot_order], 0),\n  label = c(-9,-8,-7,-6, -5, -4, -3, -2, -1, 1,2,3,4,5, 0)\n)\n\n# This version has a point-range at each\n# estimated lead or lag\n# comes down to stylistic preference at the\n# end of the day!\nleadslags_plot %>%\n  ggplot(aes(x = label, y = mean,\n             ymin = mean-1.96*sd, \n             ymax = mean+1.96*sd)) +\n  geom_hline(yintercept = 0.035169444, color = \"red\") +\n  geom_pointrange() +\n  theme_minimal() +\n  xlab(\"Years before and after castle doctrine expansion\") +\n  ylab(\"log(Homicide Rate)\") +\n  geom_hline(yintercept = 0,\n             linetype = \"dashed\") +\n  geom_vline(xintercept = 0,\n             linetype = \"dashed\")xi: xtreg l_homicide  i.year $region $xvar $lintrend post [aweight=popwt], fe vce(cluster sid)\n\nlocal DDL = _b[post]\nlocal DD : display %03.2f _b[post]\nlocal DDSE : display %03.2f _se[post]\nlocal DD1 = -0.10\n\nxi: xtreg l_homicide  i.year $region lead9 lead8 lead7 lead6 lead5 lead4 lead3 lead2 lead1 lag1-lag5 [aweight=popwt], fe vce(cluster sid)\n\noutreg2 using \"./eventstudy_levels.xls\", replace keep(lead9 lead8 lead7 lead6 lead5 lead4 lead3 lead2 lead1 lag1-lag5) noparen noaster addstat(DD, `DD', DDSE, `DDSE')\n\n\n*Pull in the ES Coefs\nxmluse \"./eventstudy_levels.xls\", clear cells(A3:B32) first\nreplace VARIABLES = subinstr(VARIABLES,\"lead\",\"\",.) \nreplace VARIABLES = subinstr(VARIABLES,\"lag\",\"\",.)  \nquietly destring _all, replace ignore(\",\")\nreplace VARIABLES = -9 in 2\nreplace VARIABLES = -8 in 4\nreplace VARIABLES = -7 in 6\nreplace VARIABLES = -6 in 8\nreplace VARIABLES = -5 in 10\nreplace VARIABLES = -4 in 12\nreplace VARIABLES = -3 in 14\nreplace VARIABLES = -2 in 16\nreplace VARIABLES = -1 in 18\nreplace VARIABLES = 1 in 20\nreplace VARIABLES = 2 in 22\nreplace VARIABLES = 3 in 24\nreplace VARIABLES = 4 in 26\nreplace VARIABLES = 5 in 28\ndrop in 1\ncompress\nquietly destring _all, replace ignore(\",\")\ncompress\n\n\n\nren VARIABLES exp\ngen b = exp<.\nreplace exp = -9 in 2 \nreplace exp = -8 in 4\nreplace exp = -7 in 6\nreplace exp = -6 in 8\nreplace exp = -5 in 10 \nreplace exp = -4 in 12\nreplace exp = -3 in 14\nreplace exp = -2 in 16\nreplace exp = -1 in 18\nreplace exp = 1 in 20\nreplace exp = 2 in 22\nreplace exp = 3 in 24\nreplace exp = 4 in 26\nreplace exp = 5 in 28\n\n* Expand the dataset by one more observation so as to include the comparison year\nlocal obs =_N+1\nset obs `obs'\nfor var _all: replace X = 0 in `obs'\nreplace b = 1 in `obs'\nreplace exp = 0 in `obs'\nkeep exp l_homicide b \nset obs 30\nforeach x of varlist exp l_homicide b {\n    replace `x'=0 in 30\n    }\nreshape wide l_homicide, i(exp) j(b)\n\n\n* Create the confidence intervals\ncap drop *lb* *ub*\ngen lb = l_homicide1 - 1.96*l_homicide0 \ngen ub = l_homicide1 + 1.96*l_homicide0 \n\n\n* Create the picture\nset scheme s2color\n#delimit ;\ntwoway (scatter l_homicide1 ub lb exp , \n        lpattern(solid dash dash dot dot solid solid) \n        lcolor(gray gray gray red blue) \n        lwidth(thick medium medium medium medium thick thick)\n        msymbol(i i i i i i i i i i i i i i i) msize(medlarge medlarge)\n        mcolor(gray black gray gray red blue) \n        c(l l l l l l l l l l l l l l l) \n        cmissing(n n n n n n n n n n n n n n n n) \n        xline(0, lcolor(black) lpattern(solid))\n        yline(0, lcolor(black)) \n        xlabel(-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 , labsize(medium))\n        ylabel(, nogrid labsize(medium))\n        xsize(7.5) ysize(5.5)           \n        legend(off)\n        xtitle(\"Years before and after castle doctrine expansion\", size(medium))\n        ytitle(\"Log Murders \", size(medium))\n        graphregion(fcolor(white) color(white) icolor(white) margin(zero))\n        yline(`DDL', lcolor(red) lwidth(thick)) text(`DD1' -0.10 \"DD Coefficient = `DD' (s.e. = `DDSE')\")\n        )\n        ;\n\n#delimit cr;\n# This version includes\n# an interval that traces the confidence intervals\n# of your coefficients\nleadslags_plot %>%\n  ggplot(aes(x = label, y = mean,\n             ymin = mean-1.96*sd, \n             ymax = mean+1.96*sd)) +\n  # this creates a red horizontal line\n  geom_hline(yintercept = 0.035169444, color = \"red\") +\n  geom_line() + \n  geom_point() +\n  geom_ribbon(alpha = 0.2) +\n  theme_minimal() +\n  # Important to have informative axes labels!\n  xlab(\"Years before and after castle doctrine expansion\") +\n  ylab(\"log(Homicide Rate)\") +\n  geom_hline(yintercept = 0) +\n  geom_vline(xintercept = 0)"},{"path":"ch8.html","id":"bacon-decomposition","chapter":"9 Difference-in-Differences","heading":"9.6.8 Bacon decomposition","text":"Recall run trouble using twoway fixed-effects model DD framework insofar heterogeneous treatment effects time. problem occurs \\(2\\times 2\\)s use late-treated units compared early-treated units. cases, issue much less problematic depending magnitudes weights size DD coefficients . now going simply evaluate frequency issue occurs using Bacon decomposition. Recall Bacon decomposition decomposes twoway fixed effects estimator DD parameter weighted averages individual \\(2\\times 2\\)s across four types \\(2\\times 2\\)s possible. Bacon decomposition uses binary treatment variable, reestimate effect castle-doctrine statutes logged homicide rates coding state “treated” portion year castle-doctrine amendment. work special case covariates simplicity, though note decomposition works inclusion covariates well (Goodman-Bacon 2019). Stata users need download -ddtiming- Thomas Goldring’s website, ’ve included first line.First, let’s estimate actual model using post dummy equaling one state covered castle-doctrine statute year. find smaller effect many Cheng Hoekstra’s estimates include state-year interaction fixed effects strategy among things. just illustrative purposes, let’s move Bacon decomposition . can decompose parameter estimate three different types \\(2\\times 2\\)s, ’ve reproduced Table 9.8Table 9.8:  Bacon Decomposition Example.Taking weights, let’s just double check indeed add regression estimate just obtained using twoway fixed-effects estimator.157\n\\[\\begin{align}\ndi (0.077 * -0.029) + (0.024 * 0.046) + (0.899 * 0.078) = 0.069\n\\end{align}\\]main estimate, thus confirms ’ve building , DD parameter estimate twoway fixed-effects estimator simply weighted average different types \\(2\\times 2\\)s differential design. Furthermore, can see Bacon decomposition 0.069 parameter estimate coming comparing treatment states group never-treated states. average DD estimate group 0.078 weight 0.899. even though later early \\(2\\times 2\\) mix, always differential timing, small terms influence ultimately pulls estimate.let’s now visualize distributing weights DD estimates, useful exercise. horizontal line Figure 9.26 shows average DD estimate obtained fixed-effects regression 0.069. graphics? Let’s review.\nFigure 9.26: Goodman-Bacon (2019) decomposition DD weights single \\(2 \\times 2\\)s.\nicon graphic represents single \\(2\\times 2\\) DD. horizontal axis shows weight , whereas vertical axis shows magnitude particular \\(2\\times 2\\). Icons right therefore influential final average DD closer zero.three kinds icons : early late group comparison (represented light \\(\\times\\)), late early (dark \\(\\times\\)), treatment compared never-treated (dark triangle). can see dark triangles zero, meaning \\(2\\times 2\\)s (correspond particular set states getting treatment year) positive. Now spread somewhat—two groups horizontal line, rest higher. appears case, though, group largest weight really pulling parameter estimate bringing closer 0.069 find regression.","code":""},{"path":"ch8.html","id":"the-future-of-dd","chapter":"9 Difference-in-Differences","heading":"9.6.9 The future of DD","text":"Bacon decomposition important phase understanding DD design implemented using twoway fixed effects linear model. Prior decomposition, metaphorical understanding necessary conditions identifying causal effects using differential timing twoway fixed-effects estimator. thought since \\(2\\times 2\\) required parallel trends, “sort ” must ’s going differential timing . weren’t far —version parallel trends identifying assumptions DD using twoway fixed effects differential timing. Goodman-Bacon (2019) also showed weights drove numerical estimates , intuitive (e.g., group shares influential) others (e.g., variance treatment influential).Bacon decomposition also highlighted unique challenges face differential timing. Perhaps problem better highlighted diagnostics Bacon decomposition problematic “late early” \\(2\\times 2\\) instance. Given heterogeneity bias, late early \\(2\\times 2\\) introduces biases even variance weighted common trends holding! , now?2018 2020, explosion work DD design. Much unpublished, yet appear real consensus among applied people handle . like outline believe map attempt navigate future DD. attempted divide new work three categories: weighting, selective choice “good” \\(2 \\times 2\\)s, matrix completion.know now two fundamental problems DD design. First, issue weighting . twoway fixed-effects estimator weights individual \\(2\\times 2\\)s ways make ton theoretical sense. instance, think groups middle panel weighted end? ’s theoretical reason believe . Goodman-Bacon (2019) revealed, ’s precisely twoway fixed effects . weird can change results simply adding subtracting years panel—just changes \\(2\\times 2\\), also changes variance treatment ! ’s weird.158But really fatal problem, might say, twoway fixed-effects estimates DD design. bigger issue saw Bacon decomposition—inevitably use past treated units controls future treated units, called “late early \\(2\\times 2\\).” happens event study designs modeling average treatment effect dummy variable. Insofar takes one period treatment fully incorporated, insofar ’s substantial weight given late early \\(2\\times 2\\)s, existence heterogeneous treatment effects skews parameter away ATT—maybe even flipping signs!159Whereas weird weighting associated twoway fixed effects issue, ’s something can least check Bacon decomposition allows separate \\(2\\times 2\\) average DD values weights. Thus, results changing adding years underlying \\(2\\times 2\\)s changing, simply need investigate Bacon decomposition. weights \\(2\\times 2\\)s, words, things can directly calculated, can source insight twoway fixed effects estimator finding finds.second issue different beast altogether. one way think emerging literature many authors attempting solve problem \\(2\\times 2\\)s (e.g., late early \\(2\\times 2\\)) problematic. Insofar problematic, can improve static twoway fixed-effects model? Let’s take issues examples growing literature.Another solution weird weighting twoway fixed-effects problem provided Callaway Sant’Anna (2019).160 Callaway Sant’Anna (2019) approach DD framework differently Goodman-Bacon (2019). Callaway Sant’Anna (2019) use approach allows estimate call group-time average treatment effect, just ATT given group point time. Assuming parallel trends conditional time-invariant covariates overlap propensity score, ’ll discuss , can calculate group ATT time (relative time like event study absolute time). One unique part authors’ approach non-parametric opposed regression-based. instance, identifying assumptions, nonparametric estimator group ATT time :\n\\[\\begin{align}\nATT(g,t)=E\\left[\\left(\\dfrac{G_g}{E[G_g]}-\n\\dfrac{\\dfrac{p_g(X)C}{1-p_g(X)}}{E \\bigg [ \\dfrac{p_g(X)C}{1-p_g(X)}\\bigg]}\\right)\n(Y_t-Y_{g-1})\\right]\n\\end{align}\\]\nweights, \\(p\\), propensity scores, \\(G\\) binary variable equal 1 individual first treated period \\(g\\), \\(C\\) binary variable equal one individuals control group. Notice time index, \\(C\\) units never-treated group. ’re still , find weights straightforward. Take observations control group well group \\(g\\), omit groups. weight observations control group characteristics similar frequently found group \\(g\\) weight observations control group characteristics rarely found group \\(g\\). kind reweighting procedure guarantees covariates group \\(g\\) control group balanced. can see principles earlier chapters making way DD estimation—namely, balance covariates create exchangeable units observables.calculating group-specific ATT time, end lot treatment effect parameters. authors address showing one can take treatment effects collapse interpretable parameters, larger ATT. done without running regression, therefore avoids unique issues created .One simple solution might estimate event-study model simply take mean lags using linear combination point estimates (Borusyak Jaravel 2018). Using method, fact find considerably larger effects nearly twice size get simpler static twoway fixed-effects model. perhaps improvement weights can large long-run effects due large effects group shares. want summary measure, ’s better estimate event study average afterthe fact.Another great example paper wrestling biases brought heterogeneous treatment effects Sun Abraham (2020). paper primarily motivated problems created event studies, can see issues brought Goodman-Bacon (2019). event study differential timing, discussed earlier, leads lags often used measure dynamics treatment . can produce causally uninterpretable results assign non-convex weights cohort-specific treatment effects. Similar Callaway Sant’Anna (2019), propose estimating group-specific dynamic effect calculate group specific estimate.way organize papers mind around idea heterogeneity time, use twoway fixed effects, differential timing. theoretical insight papers coefficients static twoway fixed-effects leads lags unintelligible heterogeneity treatment effects time. sense, back world Goodman-Bacon (2019) revealed, heterogeneity treatment effect biases create real challenges DD design using twoway fixed effects.161Their alternative estimate “saturated” model ensure heterogeneous problem never occurs first place. proposed alternative estimation technique use interacted specification saturated relative time indicators well cohort indicators. treatment effect associated design called interaction-weighted estimator, using , DD parameter equivalent difference average change outcomes given cohort periods prior treatment average changes units treated time interval. Additionally, method uses never-treated units controls, thereby avoids hairy problems noted Goodman-Bacon (2019) computing later early \\(2\\times 2\\)s.162Another paper attempts circumvent weirdness regression-based method numerous late early \\(2\\times 2\\)s Cengiz et al. (2019). bound classic study labor exhaustive search detectable repercussions minimum wage low-paying jobs. authors ultimately find little evidence support concern, come conclusion?Cengiz et al. (2019) take careful approach creating separate samples. authors want know impact minimum-wage changes low-wage jobs across 138 state-level minimum-wage changes 1979 2016. authors appendix note problems aggregating individual DD estimates single parameter, tackle problem incrementally creating 138 separate data sets associated minimum-wage event. sample treatment groups control groups, units used controls. Rather, units treated within sample window allowed controls. Insofar control treated sample window associated treatment unit, can criteria used control. 138 estimates stacked calculate average treatment effects. alternative method twoway fixed-effects DD estimator uses stringent criteria whether unit can considered control. turn circumvents heterogeneity problems Goodman-Bacon (2019) notes Cengiz et al. (2019) essentially create 138 DD situations controls always “never-treated” duration time consideration.last methodology discuss emerged last couple years radical departure regression-based methodology altogether. Rather use twoway fixed-effects estimator estimate treatment effects differential timing, Athey et al. (2018) propose machine-learning-based methodology called “matrix completion” panel data. estimator exotic bears resemblance matching imputation synthetic control. Given growing popularity placing machine learning service causal inference, suspect Stata code matrix completion introduced, see procedure used broadly.Matrix completion panel data machine-learning-based approach causal inference one working explicitly panel data differential timing. application matrix completion causal inference intuitive appeal given one ways Rubin framed causality missing data problem. Thus, missing matrix counterfactuals, might explore whether method computer science assist us recovering . Imagine create two matrices potential outcomes: matrix \\(Y^0\\) potential outcomes panel units time \\(Y^1\\). treatment occurs, unit switches \\(Y^0\\) \\(Y^1\\) switching equation, therefore missing data problem occurs. Missingness simply another way describing fundamental problem causal inference never complete set matrices enabling calculation interesting treatment parameters given switching equation assigns one reality.Say interested treatment effect parameter:\n\\[\\begin{align}\n\\widehat{\\delta_{ATT}} = \\dfrac{1}{N_T} \\sum \\big(Y_{}^1 - Z_{}^0\\big)\n\\end{align}\\]\n\\(Y^1\\) observed outcomes panel unit post-treatment period, \\(Z^0\\) estimated missing elements \\(Y^0\\) matrix post-treatment period, \\(N_T\\) number treatment units. Matrix completion uses observed elements matrix’s realized values predict missing elements \\(Y^0\\) matrix (missing due post-treatment period therefore switched \\(Y^0\\) \\(Y^1\\)).Analytically, imputation done via something called regularization-based prediction. objective approach optimally predict missing elements minimizing convex function difference observed matrix \\(Y^0\\) unknown complete matrix \\(Z^0\\) using nuclear norm regularization. Let \\(\\Omega\\) denote row column indices \\((,j)\\) observed entries outcomes, objective function can written \n\\[\\begin{align}\n\\widehat{Z^0}=\\arg\\min_{Z^0}\n\\sum_{(,j) \\\\Omega} \\dfrac{(Y^0_{} - Z^0_{})^2}{|\\Omega|}+\\Lambda ||Z^0||\n\\end{align}\\]\n\\(||Z^0||\\) nuclear norm (sum singular values \\(Z0\\)). regularization parameter \\(\\Lambda\\) chosen using tenfold cross validation. Athey et al. (2018) show procedure outperforms methods terms root mean squared prediction error.Unfortunately, present estimation using matrix completion available Stata. R packages exist, gsynth package, adapted Stata users. created, suspect adoption lag.","code":""},{"path":"ch8.html","id":"conclusion-7","chapter":"9 Difference-in-Differences","heading":"9.7 Conclusion","text":"America’s institutionalized state federalism provides constantly evolving laboratory applied researchers seeking evaluate causal effects laws interventions. reason probably become one popular forms identification among American researchers, common. Google search phrase “difference--differences” brought 45,000 hits. arguably common methodology use—IV matching even RDD, despite RDD’s greater perceived credibility. simply never-ending flow quasi-experiments created decentralized data-generating process United States made even advantageous many federal agencies responsible data collection, thus ensuring improved data quality consistency., learned chapter current set identifying assumptions practices associated DD design, differential timing introduce thorny challenges long misunderstood. Much future DD appears mounting solutions problems coming understand better, odd weighting regression problematic \\(2\\times 2\\) DDs bias aggregate ATT heterogeneity treatment effects time exists. Nevertheless, DD—specifically, regression-based DD—going away. single popular design applied researcher’s toolkit likely many years come. Thus behooves researcher study literature carefully can better protect various forms bias.Buy print version today:","code":""},{"path":"ch9.html","id":"ch9","chapter":"10 Synthetic Control","heading":"10 Synthetic Control","text":"Buy print version today:","code":""},{"path":"ch9.html","id":"introducing-the-comparative-case-study","chapter":"10 Synthetic Control","heading":"10.1 Introducing the Comparative Case Study","text":"first appearance synthetic control estimator 2003 article used estimate impact terrorism economic activity (Abadie Gardeazabal 2003). Since publication, become popular—particularly release R Stata package coinciding Abadie, Diamond, Hainmueller (2010). Google Scholar search words “synthetic control” “Abadie” yielded 3,500 hits time writing. estimator influential Athey Imbens (2017a) said “arguably important innovation policy evaluation literature last 15 years” (p.3).understand reasons might use synthetic control, let’s back broader idea comparative case study. qualitative case studies, Alexis de Tocqueville’s classic Democracy America, goal reason inductively causal effect events characteristics single unit outcome using logic historical analysis. may give satisfactory answer causal questions sometimes qualitative comparative case studies lack explicit counterfactual. , usually left description speculation causal pathways connecting various events outcomes.Quantitative comparative case studies explicitly causal designs. usually natural experiments applied single unit, single school, firm, state, country. kinds quantitative comparative case studies compare evolution aggregate outcome either single outcome, often case, chosen set similar units serve control group.Athey Imbens (2017a) point , one important contributions quantitative comparative case studies synthetic control model. synthetic control model developed Abadie Gardeazabal (2003) study terrorism’s effect aggregate income, elaborated exhaustive treatment (Abadie, Diamond, Hainmueller 2010). Synthetic controls models optimally choose set weights applied group corresponding units produce optimally estimated counterfactual unit received treatment. counterfactual, called “synthetic unit,” serves outline happened aggregate treated unit treatment never occurred. powerful, yet surprisingly simple, generalization difference--differences strategy. discuss motivating example—paper famous Mariel boatlift Card (1990).","code":""},{"path":"ch9.html","id":"cuba-miami-and-the-mariel-boatlift","chapter":"10 Synthetic Control","heading":"10.1.1 Cuba, Miami, and the Mariel Boatlift","text":"Labor economists debated effect immigration local labor-market conditions many years (Card Peri 2016). inflows immigrants depress wages employment natives local labor-markets? Card (1990), empirical question, used natural experiment evaluate .1980, Fidel Castro announced anyone wishing leave Cuba . Castro’s support, Cuban Americans helped arrange Mariel boatlift, mass exodus Cuba’s Mariel Harbor United States (primarily Miami) April October 1980. Approximately 125,000 Cubans emigrated Florida six months. emigration stopped Cuba US mutually agreed end . event increased Miami labor force 7%, largely depositing record number low-skilled workers relatively small geographic area.Card saw ideal natural experiment. arguably exogenous shift labor-supply curve, allow determine wages fell employment increased, consistent simple competitive labor-market model. used individual-level data unemployment Current Population Survey Miami chose four comparison cities (Atlanta, Los Angeles, Houston, Tampa–St. Petersburg). choice four cities delegated footnote Card argues similar based demographics economic conditions. Card estimated simple DD model found, surprisingly, effect wages native unemployment. argued Miami’s labor-market capable absorbing surge labor supply similar surges two decades earlier.paper controversial, probably much attempted answer empirically important question labor economics using natural experiment, rather result violated conventional wisdom. last word subject, don’t take stand question; rather, introduce highlight characteristics study. Notably, recent study replicated Card’s paper using synthetic control found similar results (Peri Yasenov 2018).Card’s study comparative case study strengths weaknesses. policy intervention occurred aggregate level, aggregate data available. problems study selection control group ad hoc subjective. Second, standard errors reflect sampling variance opposed uncertainty ability control group reproduce counterfactual interest. Abadie Gardeazabal (2003) Abadie, Diamond, Hainmueller (2010) introduced synthetic control estimator way addressing issues simultaneously.Abadie Gardeazabal (2003) method uses weighted average units donor pool model counterfactual. method based observation , units analysis aggregate units, combination comparison units (“synthetic control”) often better job reproducing characteristics treated unit using single comparison unit alone. comparison unit, therefore, method selected weighted average comparison units best resemble characteristics treated unit(s) pre-treatment period.Abadie, Diamond, Hainmueller (2010) argue method many distinct advantages regression-based methods. one, method precludes extrapolation. uses instead interpolation, estimated causal effect always based comparison outcome given year counterfactual year. , uses counterfactual convex hull control group units, thus counterfactual based data actually , opposed extrapolating beyond support data, can occur extreme situations regression (King Zeng 2006).second advantage processing data. construction counterfactual require access post-treatment outcomes design phase study, unlike regression. advantage helps researcher avoid “peeking” results specifying model. Care honesty must still used, ’s just easy look outcomes design phase , point hypothetically possible focus just design, estimation, method (Rubin 2007, 2008).Another advantage, oftentimes reason people object study, weights chosen make explicit unit contributing counterfactual. Now many ways strict advantage, except comes defending weights seminar. someone can see Idaho contributing 0.3 modeling Florida, now able argue ’s absurd think Idaho anything like Florida. contrast regression, also weights data, blindly. reason one objects regression produces weight see weights. implicit rather explicit. see explicit production weights distinct advantage makes synthetic control transparent regression-based designs (even likely require fights audience reader wouldn’t otherwise).fourth advantage, think often unappreciated, bridges gap qualitative quantitative types. Qualitative researchers often ones focused describing single unit, country prison (Perkinson 2010), great detail. usually experts histories surrounding institutions. usually ones comparative case studies first place. Synthetic control places valuable tool hands enables choose counterfactuals—process principle can improve work insofar interested evaluating particular intervention.","code":""},{"path":"ch9.html","id":"picking-synthetic-controls","chapter":"10 Synthetic Control","heading":"10.1.2 Picking synthetic controls","text":"Abadie, Diamond, Hainmueller (2010) argue synthetic control removes subjective researcher bias, turns somewhat complicated. frontier method grown considerably recent years, along different margins, one via model-fitting exercise . new ways trying choose principled models appeared, particularly efforts fit data synthetic control pre-treatment period imperfect. Ferman Pinto (2019) Powell (2017), instance, propose alternative solutions problem. Ferman Pinto (2019) examine properties using de-trended data. find can advantages, even dominate DD, terms bias variance.transitory shocks, common practice, fit deteriorates, thus introducing bias. Powell (2017) provides parametric solution, however, cleverly exploits information procedure may help reconstruct treatment unit. Assume Georgia receives treatment whatever reason convex hull assumption hold data (.e., Georgia unusual). Powell (2017) shows Georgia appears synthetic control state, possible recover treatment effect kind backdoor procedure. Using appearance Georgia control placebos can used reconstruct counterfactual.still remain questions regarding selection covariates used matching. repeated iterations changes matching formula, person can potentially reintroduce bias endogenous selection covariates used specification search. weights optimally chosen minimize distance function, choice covariates , researcher can principle select different weights. just doesn’t lot control , ultimately weights optimal given set covariates, selecting models suit one’s priors still possible.Ferman, Pinto, Possebom (2020) addressed gap literature providing guidance principled covariate selection. consider variety commonly used synthetic control specifications (e.g., pre-treatment outcome values, first three quarters pre-treatment outcome values). run randomization inference test calculate empirical \\(p\\)-values. find probability falsely rejecting null least one specification 5% significance test can high 14% pre-treatment periods. possibilities specification searching remain high even number pre-treatment periods large, . consider sample four hundred pre-treatment periods still find false-positive probability around 13% least one specification significant 5% level. Thus, even large number pre-treatment periods, theoretically possible “hack” analysis order find statistical significance suits one’s priors.Given broad discretion available researcher search countless specifications using covariates pretreatment combinations, one might conclude fewer time periods better reason limits ability conduct endogenous specification search. Using Monte Carlo simulations, though, find models use pre-treatment outcome lags predictors—consistent statements made Abadie, Diamond, Hainmueller (2010) originally—better job controlling unobserved confounders, whereas limit number pre-treatment outcome lags substantially misallocate weights considered synthetic control applications.Thus, one main takeaways Ferman, Pinto, Possebom (2020) , despite hope synthetic control remove subjective researcher bias creating weights based data-driven optimization algorithm, may somewhat overstated practice. Whereas remains true weights optimal uniquely minimize distance function, point Ferman, Pinto, Possebom (2020) note distance function still, end day, endogenously chosen researcher., given risk presenting results may cherry picked, ? Ferman, Pinto, Possebom (2020) suggest presenting multiple results variety commonly specified specifications. regularly robust, reader may sufficient information check , opposed seeing one specification may cherry-picked result.","code":""},{"path":"ch9.html","id":"formalization","chapter":"10 Synthetic Control","heading":"10.1.3 Formalization","text":"Let \\(Y_{jt}\\) outcome interest unit \\(j\\) \\(J+1\\) aggregate units time \\(t\\), treatment group \\(j=1.\\) synthetic control estimator models effect intervention time \\(T_0\\) treatment group using linear combination optimally chosen units synthetic control. post-intervention period, synthetic control estimator measures causal effect \\(Y_{1t}- \\sum_{j=2}^{J+1}w_j^*Y_{jt}\\) \\(w_j^*\\) vector optimally chosen weights.Matching variables, \\(X_1\\) \\(X_0,\\) chosen predictors post-intervention outcomes must unaffected intervention. weights chosen minimize norm, \\(||X_1 - X_0W||\\) subject weight constraints. two weight constraints. First, let \\(W=(w_2, \\dots, w_{J+1})'\\) \\(w_j \\geq 0\\) \\(j=2, \\dots, J+1\\). Second, let \\(w_2 + \\dots + w_{J+1}=1\\). words, unit receives negative weight, can receive zero weight.163 sum weights must equal one.said, Abadie, Diamond, Hainmueller (2010) consider\\[\\begin{align}\n||X_1 - X_0W|| = \\sqrt{(X_1 - X_0W)'V(X_1 - X_0W)}\n\\end{align}\\]\\(V\\) \\((k \\times k)\\) symmetric positive semidefinite matrix. Let \\(X_{jm}\\) value \\(m\\)th covariates unit \\(j\\). Typically, \\(V\\) diagonal main diagonal \\(v_1, \\dots, v_k\\). synthetic control weights minimize:\n\\[\n\\sum_{m=1}^k v_m \\bigg(X_{1m} - \\sum_{j=2}^{J+1}w_jX_{jm} \\bigg)^2\n\\]\n\\(v_m\\) weight reflects relative importance assign \\(m\\)th variable measure discrepancy treated unit synthetic control.choice \\(V\\), seen now, important \\(W^*\\) depends one’s choice \\(V\\). synthetic control \\(W^*(V)\\) meant reproduce behavior outcome variable treated unit absence treatment. Therefore, weights \\(v_1, \\dots, v_k\\) reflect predictive value covariates.Abadie, Diamond, Hainmueller (2010) suggests different choices \\(V\\), ultimately appears practice people choose \\(V\\) minimizes mean squared prediction error:\n\\[\n\\sum_{t=1}^{T_0} \\bigg (Y_{1t} - \\sum_{j=2}^{J+1}w_j^*(V)Y_{jt}\\bigg )^2\n\\]\nunobserved factors? Comparative case studies complicated unmeasured factors affecting outcome interest well heterogeneity effect observed unobserved factors. Abadie, Diamond, Hainmueller (2010) note number pre-intervention periods data “large,” matching pre-intervention outcomes can allow us control heterogeneous responses multiple unobserved factors. intuition units alike unobservables observables follow similar trajectory pre-treatment.","code":""},{"path":"ch9.html","id":"californias-proposition-99","chapter":"10 Synthetic Control","heading":"10.1.4 California’s Proposition 99","text":"Abadie Gardeazabal (2003) developed synthetic control estimator evaluate impact terrorism Basque region Spain. Abadie, Diamond, Hainmueller (2010) expound method using cigarette tax California called Proposition 99. example uses placebo-based method inference, let’s look closely paper.\nFigure 10.1: California cigarette sales vs rest country\n1988, California passed comprehensive tobacco control legislation called Proposition 99. Proposition 99 increased cigarette taxes $0.25 pack, spurred clean-air ordinances throughout state, funded anti-smoking media campaigns, earmarked tax revenues health anti-smoking budgets, produced $100 million year anti-tobacco projects. states similar control programs, dropped analysis.Figure 10.1 shows changes cigarette sales California rest United States annually 1970 2000. can seen, cigarette sales fell Proposition 99, already falling, ’s clear effect—particularly since falling rest country time.Using method, though, select optimal set weights applied rest country produces figure shown Figure 10.2. Notice pre-treatment, set weights produces nearly identical time path California real California , post-treatment two series diverge. appears first glance effect program cigarette sales.\nFigure 10.2: California cigarette sales vs synthetic California\nvariables used distance minimization listed Table 10.1. Notice analysis produces values treatment group control group facilitate simple investigation balance. technical test, one value per variable per treatment category, ’s best can method. appears variables used matching similar across two groups, particularly lagged values.Table 10.1:  Balance table\nvariables except lagged cigarette sales averaged 1980–1988 period. Beer consumption averaged 1984–1988.\nLike RDD, synthetic control picture-intensive estimator. estimator basically picture two series , causal effect, diverge another post-treatment, resemble pre-treatment. common therefore see picture just showing difference two series (Figure 10.3).\nFigure 10.3: Gap cigarette sales estimation pre post treatment\nfar, covered estimation. determine whether observed difference two series statistically significant difference? , two observations per year. Maybe divergence two series nothing prediction error, model chosen ’ve done , even treatment effect. Abadie, Diamond, Hainmueller (2010) suggest use old-fashioned method construct exact \\(p\\)-values based Fisher (1935). Firpo Possebom (2018) call null hypothesis used test “treatment effect whatsoever,” common null used literature. Whereas propose alternative null inference, focus original null proposed Abadie, Diamond, Hainmueller (2010) exercise. discussed earlier chapter, randomization inference assigns treatment every untreated unit, recalculates model’s key coefficients, collects distribution used inference. Abadie, Diamond, Hainmueller (2010) recommend calculating set root mean squared prediction error (RMSPE) values pre- post-treatment period test statistic used inference.164 proceed follows:Iteratively apply synthetic control method country/state donor pool obtain distribution placebo effects.Iteratively apply synthetic control method country/state donor pool obtain distribution placebo effects.Calculate RMSPE placebo pre-treatment period:\n\\[\nRMSPE = \\bigg (\\dfrac{1}{T-T_0} \\sum_{t=T_0+t}^T \\bigg (Y_{1t} - \\sum_{j=2}^{J+1} w_j^* Y_{jt} \\bigg )^2 \\bigg )^{\\tfrac{1}{2}}\n\\]Calculate RMSPE placebo pre-treatment period:\n\\[\nRMSPE = \\bigg (\\dfrac{1}{T-T_0} \\sum_{t=T_0+t}^T \\bigg (Y_{1t} - \\sum_{j=2}^{J+1} w_j^* Y_{jt} \\bigg )^2 \\bigg )^{\\tfrac{1}{2}}\n\\]Calculate RMSPE placebo post-treatment period (similar equation post-treatment period).Calculate RMSPE placebo post-treatment period (similar equation post-treatment period).Compute ratio post- pre-treatment RMSPE.Compute ratio post- pre-treatment RMSPE.Sort ratio descending order greatest highest.Sort ratio descending order greatest highest.Calculate treatment unit’s ratio distribution \\(p=\\dfrac{RANK}{TOTAL}\\).Calculate treatment unit’s ratio distribution \\(p=\\dfrac{RANK}{TOTAL}\\).words, want know whether California’s treatment effect extreme, relative concept compared donor pool’s placebo ratios.several different ways represent . first overlay California placebos using Stata twoway command, ’ll show later. Figure 10.4 shows looks like. think ’ll agree, tells nice story. Clearly, California tails distribution treatment effects.\nFigure 10.4: Placebo distribution using units donor pool\nAbadie, Diamond, Hainmueller (2010) recommend iteratively dropping states whose pre-treatment RMSPE considerably different California’s can see, ’re kind blowing scale making hard see ’s going . several steps, ’ll just skip last step (Figure 10.5). , ’ve dropped state unit graph whose pre-treatment RMSPE two times California’s. therefore limits picture just units whose model fit, pre-treatment, pretty good, like California’s.\nFigure 10.5: Pre-Proposition 99 RMSPE$$2 times Pre-Pop 99 RMSPE CA\n, ultimately, inference based exact \\(p\\)-values. way simply create histogram ratios, less mark treatment group distribution reader can see exact \\(p\\)-value associated model. produce Figure 10.6.can seen, California ranked first thirty-eight state units.165 gives exact \\(p\\)-value 0.026, less conventional 5% journals want (arbitrarily) see statistical significance.\nFigure 10.6: Histogram post/pre RMSPE units.\n","code":""},{"path":"ch9.html","id":"falsifications","chapter":"10 Synthetic Control","heading":"10.1.5 Falsifications","text":"Abadie, Diamond, Hainmueller (2015), authors studied effect reunification Germany gross domestic product. One contributions paper makes, though, recommendation testing validity estimator falsification exercise. illustrate , let review study. 1990 reunification Germany brought together East Germany West Germany, years separation developed vastly different cultures, economies, political systems. authors interested evaluating effect reunification economic output, smoking study, thought countries simply dissimilar one country make compelling comparison group, used synthetic control create composite comparison group based optimally chosen countries.One things authors study provide guidance check whether model chose reasonable one. authors specifically recommend rewinding time date treatment estimating model earlier (placebo) date. Since placebo dates effect output, provides assurances deviations found 1990 might due structural breaks caused reunification . fact don’t find effect using 1975 placebo date, suggesting model good sample predictive properties.include second paper primarily illustrate synthetic control methods increasingly expected pursue numerous falsification exercises addition simply estimating causal effect . sense, researchers pushed others hold level scrutiny skepticism methodologies RDD IV. Authors using synthetic control must merely run synth command comparative case studies. must find exact \\(p\\)-values placebo-based inference, check quality pre-treatment fit, investigate balance covariates used matching, check validity model placebo estimation (e.g., rolling back treatment date).","code":""},{"path":"ch9.html","id":"prison-construction-and-black-male-incarceration","chapter":"10 Synthetic Control","heading":"10.2 Prison Construction and Black Male Incarceration","text":"project ’ll replicating project working several coauthors last years.166 ’s backdrop.1980, Texas Department Corrections (TDC) lost major civil action lawsuit, Ruiz v. Estelle; Ruiz prisoner brought case, Estelle warden. case argued TDC engaging unconstitutional practices related overcrowding prison conditions. Texas lost case, result, forced enter series settlements. amend issue overcrowding, courts placed constraints number inmates placed cells. ensure compliance, TDC put court supervision 2003.Given constraints, construction new prisons way Texas keep arresting many people police departments wanted without release TDC already imprisoned. didn’t build prisons, state forced increase number people granted parole. precisely happened; following Ruiz v. Estelle, Texas used parole intensively., late 1980s, Texas Governor Bill Clements began building prisons. Later, 1993, Texas Governor Ann Richards began building even prisons. Richards, state legislators approved $1 billion prison construction, double state’s ability imprison people within three years. can seen Figure 10.7.\nFigure 10.7: Prison capacity (operational capacity) expansion\ncan seen, Clements’ prison capacity expansion projects relatively small compared Richards. Richards’s investments “operational capacity,” ability house prisoners, gigantic. number prison beds available state keep filling prisoners grew 30% three years, meaning number prison beds doubled just short period time.effect building many prisons? Just prison capacity expands doesn’t mean incarceration grow. , among reasons, state intensively using paroles handle flow, ’s precisely happen. analysis follows show effect prison-building boom state Texas incarceration African American men.\nFigure 10.8: African-American male incarceration\ncan see Figure 10.8, incarceration rate black men doubled three years. Texas basically went typical, modal state came incarceration one severe short period.now analyze effect prison construction Governor Ann Richards incarceration black men using synthetic control. R file much straightforward synthetic control file, broken several parts. therefore posted Github texassynth.file run seamlessly, well “Read ” document help understand directories subdirectories needed . Let’s begin.first step create figure showing effect 1993 prison construction incarceration black men. ’ve chosen set covariates pre-treatment outcome variables matching; encourage , though, play around different models. can already see Figure 10.8 prior 1993, Texas Black male incarceration pretty similar rest country. going mean analysis every reason believe convex hull likely exists application.synth_1.dosynth_1.RRegarding Stata syntax file: personally prefer make delimiter semicolon want syntax synth screen. ’m visual person, helps . Next synth syntax. syntax goes like : call synth, call outcome variable (bmprison), variables want match . Notice can choose either match entire pre-treatment average, can choose particular years. choose . Also recall Abadie, Diamond, Hainmueller (2010) notes importance controlling pre-treatment outcomes soak heterogeneity; well. ’ve listed covariates, use comma move Stata options. first specify treatment unit. FIPS code Texas 48, hence 48. specify treatment period, 1993. list period time used minimize mean squared prediction error, well years display. Stata produce figure well data set information used create figure. also list \\(V\\) matrix. Finally, change delimiter back carriage return, save figure /Figures subdirectory. Let’s look lines made (Figure 10.9).\nFigure 10.9: African-American male incarceration\nsynth_2.dosynth_2.RThis kind outcome ideally want specifically, similar pre-treatment trend synthetic Texas group compared actual Texas group, divergence post-treatment period. now plot gap two lines using programming commands accompanying code.\nFigure 10.10: Gap actual Texas synthetic Texas\nfigure makes shown Figure 10.10. essentially nothing “gap” Texas synthetic Texas values, per year, Figure 10.9.finally, show weights used construct synthetic Texas.Synthetic control weightsNow estimates causal effect, move calculation exact \\(p\\)-value, based assigning treatment every state reestimating model. Texas always thrown back donor pool time. next part contain multiple Stata programs, efficiency R package, produce one R program. exposition henceforth focus Stata commands.synth_3.dosynth_3_7.RThis loop cycle every state estimate model. save data associated model ../data/synth/synth_bmcrate_‘’.dta data file ‘’ one state FIPS codes listed local statelist. Now files, can calculate post--pre RMSPE.synth_4.doNotice going first create gap treatment state counterfactual state merging single data file.synth_5.doIn part, calculating post-RMSPE, pre-RMSPE, ratio two. information, can compute histogram. following commands .synth_6.\nFigure 10.11: Histogram distribution ratios post-RMSPE pre-RMSPE. Texas one ones far right tail.\nlooping take moments run, done, produce histogram distribution ratios post-RMSPE pre-RMSPE. can see \\(p\\)-value, Texas second-highest ratio forty-six state units, giving \\(p\\)-value 0.04. can see Figure 10.11.Notice addition figure, created Excel spreadsheet containing information pre-RMSPE, post-RMSPE, ratio, rank. want use limit display next states whose pre-RMSPE similar Texas.Now want create characteristic placebo graph state placebos laid top Texas. , can use simple syntax contained Stata code:synth_7.doHere display main picture placebos, though one show several cuts data drop states whose pre-treatment fit compared Texas rather poor.\nFigure 10.12: Placebo distribution. Texas black line.\nNow seen use .file estimate synthetic control model, ready play around data . analysis far used black male (total counts) incarceration dependent variable, perhaps results different used black male incarceration. information contained data set. like analysis using black male incarceration rate variable dependent variable. need find new model fit pattern, ’s unlikely one used levels good job describing rates levels. addition, implement placebo-date falsification exercise mentioned Abadie, Diamond, Hainmueller (2015). Choose 1989 treatment date 1992 end sample, check whether model shows treatment effect found used correct year, 1993, treatment date. encourage use data file learn ins outs procedure , well think deeply synthetic control best use research.","code":"cd /users/scott\\_cunningham/downloads/texas/do\n* Estimation 1: Texas model of black male prisoners (per capita) \nuse https://github.com/scunning1975/mixtape/raw/master/texas.dta, clear\nssc install synth \nssc install mat2txt\n#delimit; \nsynth   bmprison  \n            bmprison(1990) bmprison(1992) bmprison(1991) bmprison(1988)\n            alcohol(1990) aidscapita(1990) aidscapita(1991) \n            income ur poverty black(1990) black(1991) black(1992) \n            perc1519(1990)\n            ,       \n        trunit(48) trperiod(1993) unitnames(state) \n        mspeperiod(1985(1)1993) resultsperiod(1985(1)2000)\n        keep(../data/synth/synth\\_bmprate.dta) replace fig;\n        mat list e(V_matrix);\n        #delimit cr\n        graph save Graph ../Figures/synth\\_tx.gph, replace}\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(Synth)\nlibrary(devtools)\nif(!require(SCtools)) devtools::install_github(\"bcastanho/SCtools\")\nlibrary(SCtools)\n\nread_data <- function(df)\n{\n  full_path <- paste(\"https://raw.github.com/scunning1975/mixtape/master/\", \n                     df, sep = \"\")\n  df <- read_dta(full_path)\n  return(df)\n}\n\ntexas <- read_data(\"texas.dta\") %>%\n  as.data.frame(.)\n\ndataprep_out <- dataprep(\n  foo = texas,\n  predictors = c(\"poverty\", \"income\"),\n  predictors.op = \"mean\",\n  time.predictors.prior = 1985:1993,\n  special.predictors = list(\n    list(\"bmprison\", c(1988, 1990:1992), \"mean\"),\n    list(\"alcohol\", 1990, \"mean\"),\n    list(\"aidscapita\", 1990:1991, \"mean\"),\n    list(\"black\", 1990:1992, \"mean\"),\n    list(\"perc1519\", 1990, \"mean\")),\n  dependent = \"bmprison\",\n  unit.variable = \"statefip\",\n  unit.names.variable = \"state\",\n  time.variable = \"year\",\n  treatment.identifier = 48,\n  controls.identifier = c(1,2,4:6,8:13,15:42,44:47,49:51,53:56),\n  time.optimize.ssr = 1985:1993,\n  time.plot = 1985:2000\n)\n\nsynth_out <- synth(data.prep.obj = dataprep_out)\n\npath.plot(synth_out, dataprep_out)* Plot the gap in predicted error\nuse ../data/synth/synth_bmprate.dta, clear\nkeep _Y_treated _Y_synthetic _time\ndrop if _time==.\nrename _time year\nrename _Y_treated  treat\nrename _Y_synthetic counterfact\ngen gap48=treat-counterfact\nsort year\n#delimit ; \ntwoway (line gap48 year,lp(solid)lw(vthin)lcolor(black)), yline(0, lpattern(shortdash) lcolor(black)) \n    xline(1993, lpattern(shortdash) lcolor(black)) xtitle(\"\",si(medsmall)) xlabel(#10) \n    ytitle(\"Gap in black male prisoner prediction error\", size(medsmall)) legend(off); \n    #delimit cr\n    save ../data/synth/synth_bmprate_48.dta, replace}\ngaps.plot(synth_out, dataprep_out)* Inference 1 placebo test  \n#delimit; \nset more off; \nuse ../data/texas.dta, replace; \nlocal statelist  1 2 4 5 6 8 9 10 11 12 13 15 16 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32  \n    33 34 35 36 37 38 39 40 41 42 45 46 47 48 49 51 53 55; \nforeach i of local statelist {;\nsynth   bmprison  \n        bmprison(1990) bmprison(1992) bmprison(1991) bmprison(1988) \n        alcohol(1990) aidscapita(1990) aidscapita(1991)  \n        income ur poverty black(1990) black(1991) black(1992)  \n        perc1519(1990) \n        ,        \n            trunit(`i') trperiod(1993) unitnames(state)  \n            mspeperiod(1985(1)1993) resultsperiod(1985(1)2000) \n            keep(../data/synth/synth\\_bmprate\\_`i'.dta) replace; \n            matrix state`i' = e(RMSPE); /* check the V matrix*/ \n\nforeach i of local statelist {; \nmatrix rownames state`i'=`i'; \nmatlist state`i', names(rows); \n};\n#delimit cr\nplacebos <- generate.placebos(dataprep_out, synth_out, Sigf.ipop = 3)\n\nplot_placebos(placebos)\n\nmspe.plot(placebos, discard.extreme = TRUE, mspe.limit = 1, plot.hist = TRUE)local statelist  1 2 4 5 6 8 9 10 11 12 13 15 16 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32 \n    33 34 35 36 37 38 39 40 41 42 45 46 47 48 49 51 53 55\n foreach i of local statelist {\n    use ../data/synth/synth_bmprate_`i' ,clear\n    keep _Y_treated _Y_synthetic _time\n    drop if _time==.\n    rename _time year\n    rename _Y_treated  treat`i'\n    rename _Y_synthetic counterfact`i'\n    gen gap`i'=treat`i'-counterfact`i'\n    sort year \n    save ../data/synth/synth_gap_bmprate`i', replace\n    }\nuse ../data/synth/synth_gap_bmprate48.dta, clear\nsort year\nsave ../data/synth/placebo_bmprate48.dta, replace\n\nforeach i of local statelist {\n        merge year using ../data/synth/synth_gap_bmprate`i' \n        drop _merge \n        sort year \n    save ../data/synth/placebo_bmprate.dta, replace \n    }\n    ** Inference 2: Estimate the pre- and post-RMSPE and calculate the ratio of the\n*  post-pre RMSPE   \nset more off\nlocal statelist  1 2 4 5 6 8 9 10 11 12 13 15 16 17 18 20 21 22 23 24 25 26 27 28 29 30 31 32 \n    33 34 35 36 37 38 39 40 41 42 45 46 47 48 49 51 53 55\nforeach i of local statelist {\n\n    use ../data/synth/synth_gap_bmprate`i', clear\n    gen gap3=gap`i'*gap`i'\n    egen postmean=mean(gap3) if year>1993\n    egen premean=mean(gap3) if year<=1993\n    gen rmspe=sqrt(premean) if year<=1993\n    replace rmspe=sqrt(postmean) if year>1993\n    gen ratio=rmspe/rmspe[_n-1] if 1994\n    gen rmspe_post=sqrt(postmean) if year>1993\n    gen rmspe_pre=rmspe[_n-1] if 1994\n    mkmat rmspe_pre rmspe_post ratio if 1994, matrix (state`i')* show post/pre-expansion RMSPE ratio for all states, generate histogram\n    foreach i of local statelist {\n        matrix rownames state`i'=`i'\n        matlist state`i', names(rows)\n                                    }\n#delimit ;\nmatstate=state1/state2/state4/state5/state6/state8/state9/state10/state11/state12/state13/state15/state16/state17/state18/state20/state21/state22/state23/state24/state25/state26/state27/state28/state29/state30/state31/state32/state33/state34/state35/state36/state37/state38/state39/state40/state41/state42/state45/state46/state47/state48/state49/state51/state53/state55; \n#delimit cr\n* ssc install mat2txt\n    mat2txt, matrix(state) saving(../inference/rmspe_bmprate.txt) replace\n    insheet using ../inference/rmspe_bmprate.txt, clear\n    ren v1 state\n    drop v5\n    gsort -ratio\n    gen rank=_n\n    gen p=rank/46\n    export excel using ../inference/rmspe_bmprate, firstrow(variables) replace\n    import excel ../inference/rmspe_bmprate.xls, sheet(\"Sheet1\") firstrow clear\n    histogram ratio, bin(20) frequency fcolor(gs13) lcolor(black) ylabel(0(2)6) \n    xtitle(Post/pre RMSPE ratio) xlabel(0(1)5)\n* Show the post/pre RMSPE ratio for all states, generate the histogram.\n    list rank p if state==48* Inference 3: all the placeboes on the same picture\nuse ../data/synth/placebo_bmprate.dta, replace\n* Picture of the full sample, including outlier RSMPE\n#delimit;   \ntwoway \n(line gap1 year ,lp(solid)lw(vthin)) \n(line gap2 year ,lp(solid)lw(vthin)) \n(line gap4 year ,lp(solid)lw(vthin)) \n(line gap5 year ,lp(solid)lw(vthin))\n(line gap6 year ,lp(solid)lw(vthin)) \n(line gap8 year ,lp(solid)lw(vthin)) \n(line gap9 year ,lp(solid)lw(vthin)) \n(line gap10 year ,lp(solid)lw(vthin)) \n(line gap11 year ,lp(solid)lw(vthin)) \n(line gap12 year ,lp(solid)lw(vthin)) \n(line gap13 year ,lp(solid)lw(vthin)) \n(line gap15 year ,lp(solid)lw(vthin)) \n(line gap16 year ,lp(solid)lw(vthin)) \n(line gap17 year ,lp(solid)lw(vthin))\n(line gap18 year ,lp(solid)lw(vthin)) \n(line gap20 year ,lp(solid)lw(vthin)) \n(line gap21 year ,lp(solid)lw(vthin)) \n(line gap22 year ,lp(solid)lw(vthin)) \n(line gap23 year ,lp(solid)lw(vthin)) \n(line gap24 year ,lp(solid)lw(vthin)) \n(line gap25 year ,lp(solid)lw(vthin)) \n(line gap26 year ,lp(solid)lw(vthin))\n(line gap27 year ,lp(solid)lw(vthin))\n(line gap28 year ,lp(solid)lw(vthin)) \n(line gap29 year ,lp(solid)lw(vthin)) \n(line gap30 year ,lp(solid)lw(vthin)) \n(line gap31 year ,lp(solid)lw(vthin)) \n(line gap32 year ,lp(solid)lw(vthin)) \n(line gap33 year ,lp(solid)lw(vthin)) \n(line gap34 year ,lp(solid)lw(vthin))\n(line gap35 year ,lp(solid)lw(vthin))\n(line gap36 year ,lp(solid)lw(vthin))\n(line gap37 year ,lp(solid)lw(vthin)) \n(line gap38 year ,lp(solid)lw(vthin)) \n(line gap39 year ,lp(solid)lw(vthin))\n(line gap40 year ,lp(solid)lw(vthin)) \n(line gap41 year ,lp(solid)lw(vthin)) \n(line gap42 year ,lp(solid)lw(vthin)) \n(line gap45 year ,lp(solid)lw(vthin)) \n(line gap46 year ,lp(solid)lw(vthin)) \n(line gap47 year ,lp(solid)lw(vthin))\n(line gap49 year ,lp(solid)lw(vthin)) \n(line gap51 year ,lp(solid)lw(vthin)) \n(line gap53 year ,lp(solid)lw(vthin)) \n(line gap55 year ,lp(solid)lw(vthin)) \n(line gap48 year ,lp(solid)lw(thick)lcolor(black)), /*treatment unit, Texas*/\nyline(0, lpattern(shortdash) lcolor(black)) xline(1993, lpattern(shortdash) lcolor(black))\nxtitle(\"\",si(small)) xlabel(#10) ytitle(\"Gap in black male prisoners prediction error\", size(small))\n    legend(off);\n#delimit cr"},{"path":"ch9.html","id":"conclusion-8","chapter":"10 Synthetic Control","heading":"10.2.1 Conclusion","text":"conclusion, seen estimate synthetic control models Stata. model currently active area research, decided wait subsequent editions dive new material many questions unsettled. chapter therefore good foundation understanding model practices around implementing , including code \\(R\\) Stata . hope find useful.Buy print version today:","code":""},{"path":"ch10.html","id":"ch10","chapter":"11 Conclusion","heading":"11 Conclusion","text":"Causal inference important fun area. ’s fun potential outcomes model intuitive philosophically stimulating way think causal effects. model also proved quite powerful helping us better understand assumptions needed identify causal effects using exotic quasi-experimental research designs beyond randomized control trial. Pearl’s directed acyclic graphical models also helpful moving theoretical model understanding phenomenon strategy identify causal effect care . DAGs, can learn whether ’s even possible design identification strategy data set. although can disappointing, disciplined truthful approach estimation. DAGs , experience, empowering, extremely useful design phase project, adored students.methods ’ve outlined merely common research designs currently employed applied microeconomics. tried selectively navigate research bring readers close frontier possible. leave things . instance, nothing bounding partial identification. perhaps love book enough, can second edition includes important topic.Even topics cover, areas constantly changing, encourage read many articles provided bibliography learn . also encourage just use links provided software code throughout book download data files . Play around programs, explore data, improve intuition use R Stata tackle causal inference problems using designs. hope found book valuable. Good luck research. wish best.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Abadie, Alberto, Susan Athey, Guido W. Imbens, Jeffrey M. Wooldridge. 2020. “Sampling-Based Versus Design-Based Uncertainty Regression Analysis.” Econometrica 88 (0): 265–96.Abadie, Alberto, Alexis Diamond, Jens Hainmueller. 2010. “Synthetic Control Methods Comparative Case Studies: Estimating Effect California’s Tobacco Control Program.” Journal American Statistical Association 105 (490): 493–505.———. 2015. “Comparative Politics Synthetic Control Method.” American Journal Political Science 59 (2): 495–510.Abadie, Alberto, Javier Gardeazabal. 2003. “Economic Costs Conflict: Case Study Basque Country.” American Economic Review 93 (1): 113–32.Abadie, Alberto, Guido Imbens. 2006. “Large Sample Properties Matching Estimators Average Treatment Effects.” Econometrica 74 (1): 235–67.———. 2011. “Bias-Corrected Matching Estimators Average Treatment Effects.” Journal Business Economic Statistics 29: 1–11.Abadie, Alberto, Guido W. Imbens. 2008. “Failure Bootstrap Matching Estimators.” Econometrica 76 (6): 1537–57.Adudumilli, Karun. 2018. “Bootstrap Inference Propensity Score Matching.”Aizer, Anna, Joseph J. Doyle. 2015. “Juvenile Incarceration, Human Capital, Future Crime: Evidence Randomly Assigned Judges.” Quarterly Journal Economics 130 (2): 759–803.Almond, Douglas, Joseph J. Doyle, Amanda Kowalski, Heidi Williams. 2010. “Estimating Returns Medical Care: Evidence -Risk Newborns.” Quarterly Journal Economics 125 (2): 591–634.Anderson, D. Mark, Benjamin Hansen, Dan . Rees. 2013. “Medical Marijuana Laws, Traffic Fatalities, Alcohol Consumption.” Journal Law Economics 56 (May).Angrist, Joshua D. 1990. “Lifetime Earnings Vietnam Era Draft Lottery: Evidence Social Security Administrative Records.” American Economic Review 80 (3): 313–36.Angrist, Joshua D., Guido W. Imbens, Alan B. Krueger. 1999. “Jacknnife Instrumental Variables Estimation.” Journal Applied Econometrics 14: 57–67.Angrist, Joshua D., Guido W. Imbens, Donald B. Rubin. 1996. “Identification Causal Effects Using Instrumental Variables.” Journal American Statistical Association 87: 328–36.Angrist, Joshua D., Alan B. Krueger. 1991. “Compulsory School Attendance Affect Schooling Earnings?” Quarterly Journal Economics 106 (4): 979–1014.———. 2001. “Instrumental Variables Search Identification: Supply Demand Natural Experiments.” Journal Economic Perspectives 15 (4): 69–85.Angrist, Joshua D., Victor Lavy. 1999. “Using Maimonides’ Rule Estimate Effect Class Size Scholastic Achievement.” Quarterly Journal Economics 114 (2): 533–75.Angrist, Joshua D., Jorn-Steffen Pischke. 2009. Mostly Harmless Econometrics. 1st ed. Princeton University Press.Arnold, David, Dobbie, Crystal S. Yang. 2018. “Racial Bias Bail Decisions.” Quarterly Journal Economics 133 (4): 1885–1932.Ashenfelter, Orley. 1978. “Estimating Effect Training Programs Earnings.” Review Economics Statistics 60: 47–57.Athey, Susan, Mohsen Bayati, Nikolay Doudchenko, Guido W. Imbens, Khashayar Khosravi. 2018. “Matrix Completion Methods Causal Panel Data Models.”Athey, Susan, Guide W. Imbens. 2017a. “State Applied Econometrics: Causality Policy Evaluation.” Journal Economic Perspectives 31 (2): 3–32.Athey, Susan, Guido W. Imbens. 2017b. “Econometrics Randomized Experiments.” , 1:73–140. Elsevier.Auld, M. Christopher, Paul Grootendorst. 2004. “Empirical Analysis Milk Addiction.” Journal Health Economics 23 (6): 1117–33.Baicker, Katherine, Sarah L. Taubman, Heidi L. Allen, Mira Bernstein, Jonathan Gruber, Joseph Newhouse, Eric Schneider, Bill Wright, Alam Zaslavsky, Amy Finkelstein. 2013. “Oregon Experiment – Effects Medicaid Clinical Outcomes.” New England Journal Medicine 368 (May): 1713–22.Band, Heejung, James M. Robins. 2005. “Doubly Robust Estimation Missing Data Causal Inference Models.” Biometrics 61: 962–72.Barnow, Burt S., Glen G. Cain, Arthur Goldberger. 1981. “Selection Observables.” Evaluation Studies Review Annual 5: 43–59.Barreca, Alan ., Melanie Guldi, Jason M. Lindo, Glen R. Waddell. 2011. “Saving Babies? Revisiting Effect Low Birth Weight Classification.” Quarterly Journal Economics 126 (4): 2117–23.Barreca, Alan ., Jason M. Lindo, Glen R. Waddell. 2016. “Heaping-Induced Bias Regression-Discontinuity Designs.” Economic Inquiry 54 (1): 268–93.Bartik, Timothy J. 1991. Benefits State Local Economic Development Policies? Kalamazoo, Michigan: W.E. Upjohn Institute Employment Research.Becker, Gary. 1968. “Crime Punishment: Economic Approach.” Journal Political Economy 76: 169–217.———. 1994. Human Capital: Theoretical Empirical Analysis Special Reference Education. 3rd ed. University Chicago Press.Becker, Gary S. 1993. “Economic Way Looking Life.”Becker, Gary S., Michael Grossman, Kevin M. Murphy. 2006. “Market Illegal Gods: Case Drugs.” Journal Political Economy 114 (1): 38–60.Becker, Gary S., Kevin M. Murphy. 1988. “Theory Rational Addiction.” Journal Political Economy 96 (4).Beland, Louis-Philippe. 2015. “Political Parties Labor-Market Outcomes: Evidence Us States.” American Economic Journal: Applied Economics 7 (4): 198–220.Bertrand, Marianne, Esther Duflo, Sendhil Mullainathan. 2004. “Much Trust Differences--Differences Estimates?” Quarterly Journal Economics 119 (1): 249–75.Binder, John. 1998. “Event Study Methodology Since 1969.” Review Quantitative Finance Accounting 11: 111–37.Black, Sandra E. 1999. “Better Schools Matter? Parental Valuation Elementary Education.” Quarterly Journal Economics 114 (2): 577–99.Blanchard, Olivier Jean, Lawrence F. Katz. 1992. “Regional Evolutions.” Brookings Papers Economic Activity 1: 1–75.Bodory, Hugo, Lorenzo Camponovo, Martin Huber, Michael Lechner. 2020. “Finite Sample Performance Inference Methods Propensity Score Matching Weighting Estimators.” Journal Business Economic Statistics 38 (1).Borusyak, Kirill, Peter Hull, Xavier Jaravel. 2019. “Quasi-Experimental Shift-Share Research Designs.”Borusyak, Kirill, Xavier Jaravel. 2018. “Revisiting Event Study Designs.”Bound, John, David . Jaeger, Regina M. Baker. 1995. “Problems Instrumental Variables Estimation Correlation Instruments Endogenous Explanatory Variable Weak.” Journal American Statistical Association 90 (430).Brooks, John M., Robert L. Ohsfeldt. 2013. “Squeezing Balloon: Propensity Scores Unmeasured Covariate Balance.” Health Services Research 48 (4): 1487–1507.Buchanan, James. 1996. “Letter Editor.” Wall Street Journal.Buchmueller, Thomas C., John DiNardo, Robert G. Valletta. 2011. “Effect Employer Health Insurance Mandate Health Insurance Coverage Demand Labor: Evidence Hawaii.” American Economic Journal: Economic Policy 3 (4): 25–51.Buckles, Kasey, Daniel Hungerman. 2013. “Season Birth Later Outcomes: Old Questions, New Answers.” Review Economics Statistics 95 (3): 711–24.Busso, Matias, John DiNardo, Justin McCrary. 2014. “New Evidence Finite Sample Properties Propensity Score Reweighting Matching Estimators.” Review Economics Statistics 96 (5): 885–97.Callaway, Brantly, Pedro H. C. Sant’Anna. 2019. “Difference--Differences Multiple Time Periods.”Calonico, Sebastian, Matis D. Cattaneo, Rocio Titiunik. 2014. “Robust Nonparametric Confidence Intervals Regression-Discontinuity Designs.” Econometrica 82 (6): 2295–2326.Cameron, . Colin, Jonah B. Gelbach, Douglas L. Miller. 2008. “Bootstrap-Based Improvements Inference Clustered Errors.” Review Economics Statistics 90 (3): 414–27.———. 2011. “Robust Inference Multiway Clustering.” Journal Business Economic Statistics 29 (2): 238–49.Card, David. 1990. “Impact Mariel Boatlift Miami Labor Market.” Industrial Labor Relations Review 43 (2): 245–57.———. 1995. “Aspects Labour Economics: Essays Honour John Vanderkamp.” . University Toronto Press.Card, David, Carlos Dobkin, Nicole Maestas. 2008. “Impact Nearly Universal Insurance Coverage Health Care Utilization: Evidence Medicare.” American Economic Review 98 (5): 2242–58.———. 2009. “Medicare Save Lives?” Quarterly Journal Economics 124 (2): 597–636.Card, David, Alan Krueger. 1994. “Minimum Wages Employment: Case Study Fast-Food Industry New Jersey Pennsylvania.” American Economic Review 84: 772–93.Card, David, David S. Lee, Zhuan Pei, Andrea Weber. 2015. “Inference Causal Effects Generalized Regression Kink Design.” Econometrica 84 (6): 2453–83.Card, David, Giovanni Peri. 2016. “Immigration Economics: Review.”Carpenter, Christopher, Carlos Dobkin. 2009. “Effect Alcohol Consumption Mortality: Regression Discontinuity Evidence Minimum Drinking Age.” American Economic Journal: Applied Economics 1 (1): 164–82.Carrell, Scott E., Mark Hoekstra, James E. West. 2011. “Drinking Impair College Performance? Evidence Regression Discontinuity Approach.” Journal Public Economics 95: 54–62.———. 2019. “Impact College Diversity Behavior Toward Minorities.” American Economic Journal: Economic Policy Forthcoming.Cattaneo, Matias D., Brigham R. Frandsen, Rocio Titiunik. 2015. “Randomization Inference Regression Discontinuity Design: Application Party Advantages U.s. Senate.” Journal Causal Inference 3 (1): 1–24.Cattaneo, Matias D., Michael Jansson, Xinwei Ma. 2019. “Simply Local Polynomial Density Estimators.” Journal American Statistical Association 00 (0): 1–7.Caughey, Devin, Jasjeet S. Sekhon. 2011. “Elections Regression Discontinuity Design: Lessons Close U.s. House Races, 1942-2008.” Political Analysis 19: 385–408.Cengiz, Doruk, Arindrajit Dube, Attila Lindner, Ben Zipperer. 2019. “Effect Minimum Wages Low-Wage Jobs.” Quarterly Journal Economics 134 (3): 1405–54.Chaisemartin, Clément de, Xavier D’Haultfœuille. 2019. “Two-Way Fixed Effects Estimators Heterogeneous Treatment Effects.”Charles, Kerwin Kofi, Melvin Stephens. 2006. “Abortion Legalization Adolescent Substance Use.” Journal Law Economics 49: 481–505.Cheng, Cheng, Mark Hoekstra. 2013. “Strengthening Self-Defense Law Deter Crime Escalate Violence? Evidence Expansions Castle Doctrine.” Journal Human Resources 48 (3): 821–54.Christakis, Nicholas ., James H. Fowler. 2007. “Spread Obesity Large Social Network 32 Years.” New England Journal Medicine 357 (4): 370–79.Cochran, W. G. 1968. “Effectiveness Adjustment Subclassification Removing Bias Observational Studies.” Biometrics 24 (2): 295–313.Cohen-Cole, Ethan, Jason Fletcher. 2008. “Deteching Implausible Social Network Effects Acne, Height, Headaches: Longtiudinal Analysis.” British Medical Journal 337 (a2533).Coleman, Thomas S. 2019. “Causality Time Cholera: John Snow Prototype Causal Inference.”Coles, Peter. 2019. “Einstein, Eddington 1919 Eclipse.” Nature 568 (7752): 306–7.Conley, Dalton, Jason Fletcher. 2017. Genome Factor: Social Genomics Revolution Reveals , History, Future. Princeton University Press.Cook, Thomas D. 2008. “‘Waiting Life Arrive’: History Regression-Discontinuity Design Psychology, Statistics Economics.” Journal Econometrics 142: 636–54.Cornwell, Christopher, Peter Rupert. 1997. “Unobservable Individual Effects, Marriage Earnings Young Men.” Economic Inquiry 35 (2): 1–8.Cornwell, Christopher, William N. Trumbull. 1994. “Estimating Economic Model Crime Panel Data.” Review Economics Statistics 76 (2): 360–66.Craig, Michael. 2006. Professor, Banker Suicide King: Inside Richest Poker Game Time. Grand Central Publishing.Crump, Richard K., V. Joseph Hotz, Guido W. Imbens, Oscar . Mitnik. 2009. “Dealing Limited Overlap Estimation Average Treatment Effects.” Biometrika 96 (1): 187–1999.Cunningham, Scott, Christopher Cornwell. 2013. “Long-Run Effect Abortion Sexually Transmitted Infections.” American Law Economics Review 15 (1): 381–407.Cunningham, Scott, Keith Finlay. 2012. “Parental Substance Abuse Foster Care: Evidence Two Methamphetamine Supply Shocks?” Economic Inquiry 51 (1): 764–82.Cunningham, Scott, Todd D. Kendall. 2011. “Prostitution 2.0: Changing Face Sex Work.” Journal Urban Economics 69: 273–87.———. 2014. “Examining Role Client Reviews Reputation Within Online Prostitution.” , edited Scott Cunningham Manisha Shah. Vol. Handbook Economics Prostitution. Oxford University Press.———. 2016. “Prostitution Labor Supply Education.” Review Economics Household Forthcoming.Dale, Stacy Berg, Alan B. Krueger. 2002. “Estimating Payoff Attending Selective College: Application Selection Observables Unobservables.” Quarterly Journal Economics 117 (4): 1491–1527.Dehejia, Rajeev H., Sadek Wahba. 1999. “Causal Effects Nonexperimental Studies: Reevaluating Evaluation Training Programs.” Journal American Statistical Association 94 (448): 1053–62.———. 2002. “Propensity Score-Matching Methods Nonexperimental Causal Studies.” Review Economics Statistics 84 (1): 151–61.Dobbie, , Jaconb Goldin, Crystal S. Yang. 2018. “Effects Pretrial Detention Conviction, Future Crime, Employment: Evidence Randomly Assigned Judges.” American Economic Review 108 (2): 201–40.Dobbie, , Paul Goldsmith-Pinkham, Crystal Yang. 2017. “Consumer Bankruptcy Financial Health.” Review Economics Statistics 99 (5): 853–69.Dobkin, Carlos, Nancy Nicosia. 2009. “War Drugs: Methamphetamine, Public Health Crime.” American Economic Review 99 (1): 324–49.Donald, Stephen G., Whitney K. Newey. 2001. “Choosing Number Instruments.” Econometrica 69 (5): 1161–91.Donohue, John J., Steven D. Levitt. 2001. “Impact Legalized Abortion Crime.” Quarterly Journal Economics 116 (2): 379–420.Doudchenko, Nikolay, Guido Imbens. 2016. “Balancing, Regression, Difference--Differences Synthetic Control Methods: Synthesis.”Doyle, Joseph J. 2007. “Child Protection Adult Crime: Using Investigator Assignment Estimate Causal Effects Foster Care.”———. 2008. “Child Protection Child Outcomes: Measuring Effects Foster Care.” American Economic Review Forthcoming.Dube, Arindrajit, T. William Lester, Michael Reich. 2010. “Minimum Wage Effects Across State Borders: Estimates Using Contiguous Counties.” Review Economics Statistics 92 (4): 945–64.Efron, Bradley. 1979. “Bootstrap Methods: Another Look Jackknife.” Annals Statistics 7 (1): 1–26.Eggers, Andrew C., Anthony Fowler, Jens Hainmueller, Andrew B. Hall, James M. Snyder Jr. 2014. “Validity Regression Discontinuity Design Estimating Electoral Effects: New Evidence 40,000 Close Races.” American Journal Political Science 59 (1).Elwert, Felix, Christopher Winship. 2014. “Endogenous Selection Bias: Problem Conditioning Collider Variable.” Annual Review Sociology 40: 31–53.Ferman, Bruno, Cristine Pinto. 2019. “Synthetic Controls Imperfect Pre-Treatment Fit.”Ferman, Bruno, Cristine Pinto, Vitor Possebom. 2020. “Cherry Picking Synthetic Controls.” Journal Policy Analysis Management Forthcoming.Finkelstein, Amy, Sarah Taubman, Bill Wright, Mira Bernstein, Jonathan Gruber, Joseph P. Newhouse, Heidi Allen, Katherine Baicker. 2012. “Oregon Health Insurance Experiment: Evidence First Year.” Quarterly Journal Economics 127 (3): 1057–1106.Firpo, Sergio, Vitor Possebom. 2018. “Synthetic Control Method: Inference, Sensitivity Analysis Confidence Sets.” Journal Causal Inference 6 (2).Fisher, R. . 1935. Design Experiments. Edinburgh: Oliver; Boyd.Fisher, Roland . 1925. Statistical Methods Research Workers. Oliver; Boyd, Edinburg.Foote, Christopher L., Christopher F. Goetz. 2008. “Impact Legalized Abortion Crime: Comment.” Quarterly Journal Economics 123 (1): 407–23.Frandsen, Brigham R., Lars J. Lefgren, Emily C. Leslie. 2019. “Judging Judge Fixed Effects.”Freedman, David . 1991. “Statistical Models Shoe Leather.” Sociological Methodology 21: 291–313.Freeman, Richard B. 1980. “Empirical Analysis Fixed Coefficient ‘Manpower Requirement’ Mode, 1960-1970.” Journal Human Resources 15 (2): 176–99.Frisch, Ragnar, Frederick V. Waugh. 1933. “Partial Time Regressions Compared Individuals Trends.” Econometrica 1 (4): 387–401.Fryer, Roland. 2019. “Empirical Analysis Racial Differences Police Use Force.” Journal Political Economy 127 (3).Gaudet, Frederick J., George S. Harris, Charles W. St. John. 1933. “Individual Differences Sentencing Tendencies Judges.” Journal Criminal Law Criminology 23 (5): 811–18.Gauss, Carl Friedrich. 1809. Theoria Motus Corporum Coelestium. Perthes et Besser, Hamburg.Gelman, Andrew, Guido Imbens. 2019. “Higher-Order Polynomials Used Regression Discontinuity Designs.” Journal Business Economic Statistics 37 (3): 447–56.Gertler, Paul, Manisha Shah, Stefano M. Bertozzi. 2005. “Risky Business: Market Unprotected Commercial Sex.” Journal Political Economy 113 (3): 518–50.Gilchrist, Duncan Sheppard, Emily Glassberg Sands. 2016. “Something Talk : Social Spillovers Movie Consumption.” Journal Political Economy 124 (5): 1339–82.Goldberger, . S. 1972. “Selection Bias Evaluating Treatment Effects: Formal Illustrations.”Goldsmith-Pinkham, Paul, Guido W. Imbens. 2013. “Social Networks Identification Peer Effects.” Journal Business Economic Statistics 31 (3).Goldsmith-Pinkham, Paul, Isaac Sorkin, Henry Swift. 2020. “Bartik Instruments: , , , .” American Economic Review Forthcoming.Goodman-Bacon, Andrew. 2019. “Difference--Differences Variation Treatment Timing.”Graddy, Kathryn. 2006. “Fulton Fish Market.” Journal Economic Perspectives 20 (2): 207–20.Gruber, Jonathan. 1994. “Incidence Mandated Maternity Benefits.” American Economic Review 84 (3): 622–41.Gruber, Jonathan, Phillip B. Levine, Douglas Staiger. 1999. “Abortion Legalization Child Living Circumstances: ‘Marginal Child’?” Quarterly Journal Economics 114 (1): 263–91.Haavelmo, Trygve. 1943. “Statistical Implications System Simultaneous Equations.” Econometrica 11 (1): 1–12.Hahn, Jinyong, Petra Todd, Wilbert van der Klaauw. 2001. “Identification Estimation Treatment Effects Regression-Discontinuity Design.” Econometrica 69 (1): 201–9.Hamermesh, Daniel S., Jeff E. Biddle. 1994. “Beauty Labor Market.” American Economic Review 84 (5): 1174–94.Hansen, Ben. 2015. “Punishment Deterrence: Evidence Drunk Driving.” American Economic Review 105 (4): 1581–1617.Hájek, J. 1971. “Comment ‘Essay Logical Foundations Survey Sampling, Part One’.” . Holt, Rinehart; Winston.Heckman, James J. 1979. “Sample Selection Bias Specificaiton Error.” Econometrica 47 (1): 153–61.Heckman, James J., Edward J. Vytlacil. 2007. “Econometric Evaluation Social Programs, Part : Causal Models, Structural Models Econometric Policy Evaluation.” , 6B:4779–4874. Elsevier.Heckman, James, Rodrigo Pinto. 2015. “Causal Analysis Haavelmo.” Econometric Theory 31 (1): 115–51.Hirano, Keisuke, Guido W. Imbens. 2001. “Estimation Causal Effects Using Propensity Score Weighting: Application Data Right Heart Catheterization.” Health Services Outcomes Research Methodology 2: 259–78.Hoekstra, Mark. 2009. “Effect Attending Flagship State University Earnings: Discontinuity-Based Approach.” Review Economics Statistics 91 (4): 717–24.Holtzman, Wayne H. 1950. “Unbiased Estimate Population Variance Standard Deviation.” American Journal Psychology 63 (4): 615–17.Hong, Seung Hyun. 2013. “Measuring Effect Napster Recorded Music Sales: Difference--Differences Estimates Compositional Changes.” Journal Applied Econometrics 28 (2): 297–324.Horvitz, D. G., D. J. Thompson. 1952. “Generalization Sampling Without Replacement Finite Universe.” Journal American Statistical Association 47 (260): 663–85.Hume, David. 1993. Enquiry Concerning Human Understanding: Hume’s Abstract Treatise Human Nature Letter Gentleman Friend Edinburgh. 2nd ed. Hackett Publishing Company.Iacus, Stefano M., Gary King, Giuseppe Porro. 2012. “Causal Inference Without Balance Checking: Coarsened Exact Matching.” Political Analysis 20 (1): 1–24.Imai, Kosuke, Song Kim. 2017. “Use Fixed Effects Regression Models Causal Inference Longitudinal Data.”Imai, Kosuke, Marc Ratkovic. 2013. “Covariate Balancing Propensity Score.” Journal Royal Statistical Society Statistical Methodology Series B 76 (1): 243–63.Imbens, Guideo W., Joshua D. Angrist. 1994. “Identification Estimation Local Average Treatment Effects.” Econometrica 62 (2): 467–75.Imbens, Guide W., Donald B. Rubin. 2015. Causal Inference Statistics, Social Biomedical Sciences: Introduction. 1st ed. Cambridge University Press.Imbens, Guido, Karthik Kalyanaraman. 2011. “Optimal Bandwidth Choice Regression Discontinuity Estimator.” Review Economic Studies 79 (3): 933–59.Imbens, Guido W. 2000. “Role Propensity Score Estimating Dose-Response Functions.” Biometrika 87 (3): 706–10.———. 2019. “Potential Outcome Directed Acyclic Graph Approaches Causality: Relevance Empirical Practices Economics.”Imbens, Guido W., Thomas Lemieux. 2008. “Regression Discontinuity Designs: Guide Practice.” Journal Econometrics 142: 615–35.Jacob, Brian ., Lars Lefgen. 2004. “Remedial Education Student Achivement: Regression-Discontinuity Analysis.” Review Economics Statistics 86 (1): 226–44.Joyce, Ted. 2004. “Legalized Abortion Lower Crime?” Journal Human Resources 39 (1): 1–28.———. 2009. “Simple Test Abortion Crime.” Review Economics Statistics 91 (1): 112–23.Juhn, Chinhui, Kevin M. Murphy, Brooks Pierce. 1993. “Wage Inequality Rise Returns Skill.” Journal Political Economy 101 (3): 410–42.Kahn-Lang, Ariella, Kevin Lang. 2019. “Promise Pitfalls Differences--Differences: Reflections 16 Pregnant Applications.” Journal Business Economic Statistics forthcoming: 1–14.King, Gary, Richard Nielsen. 2019. “Propensity Scores Used Matching.” Political Analysis 27 (4).King, Gary, Langche Zeng. 2006. “Dangers Extreme Counterfactuals.” Political Analysis 14 (2): 131–59.Klaauw, Wilbert van der. 2002. “Estimating Effect Financial Aid Offers College Enrollment: Regression-Discontinuity Approach.” International Economic Review 43 (4): 1249–87.Kling, Jeffrey R. 2006. “Incarceration Length, Employment, Earnings.” American Economic Review 96 (3): 863–76.Knox, Dean, Lowe, Jonathan Mummolo. 2020. “Administrative Records Mask Racially Biased Policing.” American Political Science Review Forthcoming.Kofoed, Michael S., Elizabeth McGovney. 2019. “Effect -Gender -Race Role Models Occupation Choice: Evidence Randomly Assigned Mentors West Point.” Journal Human Resources 54 (2).Kolesár, Michal, Christoph Rothe. 2018. “Inference Regression Discontinuity Designs Discrete Running Variable.” American Economic Review 108 (8): 2277–2304.Krueger, Alan. 1999. “Experimental Estimates Education Production Functions.” Quarterly Journal Economics 114 (2): 497–532.Lalonde, Robert. 1986. “Evaluating Econometric Evaluations Training Programs Experimental Data.” American Economic Review 76 (4): 604–20.Lee, David S., David Card. 2008. “Regression Discontinuity Inference Specification Error.” Journal Econometrics 142 (2): 655–74.Lee, David S., Thomas Lemieux. 2010. “Regresion Discontinuity Designs Economics.” Journal Economic Literature 48: 281–355.Lee, David S., Enrico Moretti, Matthew J. Butler. 2004. “Voters Affect Elect Policies: Evidence U.s. House.” Quarterly Journal Economics 119 (3): 807–59.Leslie, Emily, Nolan G. Pope. 2018. “Unintended Impact Pretrial Detention Case Outcomes: Evidence New York City Arraignments.” Journal Law Economics 60 (3): 529–57.Levine, Phillip B. 2004. Sex Consequences: Abortion, Public Policy, Economics Fertility. 1st ed. Princeton University Press.Levine, Phillip B., Douglas Staiger, Thomas J. Kane, David J. Zimmerman. 1999. “Roe V. Wade American Fertility.” American Journal Public Health 89 (2): 199–203.Levitt, Steven D. 2004. “Understanding Crime Fell 1990s: Four Factors Explain Decline Six .” Journal Economic Perspectives 18 (1): 163–90.Lewis, David. 1973. “Causation.” Journal Philosophy 70 (17): 556–67.Lindo, Jason, Caitlyn Myers, Andrea Schlosser, Scott Cunningham. 2019. “Far Far? New Evidence Abortion Clinic Closures, Access Abortions.” Journal Human Resources forthcoming.Lott, John R., David B. Mustard. 1997. “Crime, Deterrence Right--Carry Concealed Handguns.” Journal Legal Studies 26: 1–68.Lovell, Michael C. 1963. “Seasonal Adjustment Economic Time Series Multiple Regression Analysis.” Journal American Statistical Association 58 (304): 991–1010.———. 2008. “Simple Proof Fwl Theorem.” Journal Economic Education 39 (1): 88–91.Lyle, David S. 2009. “Effects Peer Group Heterogeneity Production Human Capital West Point.” American Economic Journal: Applied Economics 1 (4): 69–84.MacKinnon, James G., Matthew D. Webb. 2017. “Wild Bootstrap Inference Wildly Different Cluster Sizes.” Journal Applied Econometrics 32 (2): 233–54.Manski, Charles F. 1993. “Identification Endogenous Social Effects: Reflection Problem.” Review Economic Studies 60: 531–42.Manski, Charles F., John V. Pepper. 2018. “Right--Carry Laws Affect Crime Rates? Coping Ambiguity Using Bounded-Variation Assumptions.” Review Economics Statistics 100 (2): 232–44.Matsueda, Ross L. 2012. “Handbook Structural Equation Modeling.” . Guilford Press.McCrary, Justin. 2008. “Manipulation Running Variable Regression Discontinuity Design: Design Test.” Journal Econometrics 142: 698–714.Mcgrayne, Sharon Bertsch. 2012. Theory Die: Bayes’ Rule Cracked Enigma Code, Hunted Russian Submarines, Emerged Triumphant Two Centuries Controversy. Yale University Press.Meer, Jonathan, Jeremy West. 2016. “Effects Minimum Wage Employment Dynamics.” Journal Human Resources 51 (2): 500–522.Melberg, H. O. 2008. “Rational Addiction Theory - Survey Opinions.”Mill, John Stuart. 2010. System Logic, Ratiocinative Inductive. FQ Books.Miller, Sarah, Sean Altekruse, Norman Johnson, Laura R. Wherry. 2019. “Medicaid Mortality: New Evidence Linked Survey Administrative Data.”Millimet, Daniel L., Rusty Tchernis. 2009. “Specification Propensity Scores, Applications Analysis Trade Policies.” Journal Business Economic Statistics 27 (3): 397–415.Morgan, Mary S. 1991. History Econometric Ideas. Cambridge University Press.Morgan, Stephen L., Christopher Winship. 2014. Counterfactuals Causal Inference: Methods Principles Social Research. 2nd ed. Cambridge University Press.Mueller-Smith, Michael. 2015. “Criminal Labor Market Impacts Incarceration.”Needleman, Martin, Carolyn Needleman. 1969. “Marx Problem Causation.” Science Society 33 (3): 322–39.Neumark, David, J. M. Ian Salas, William Wascher. 2014. “Revisting Minimum Wage-Employment Debate: Throwing Baby Bathwater?” Industrial Labor Relations Review 67 (2.5): 608–48.Newhouse, Joseph P. 1993. Free ? Lessons Rand Health Experiment. Harvard University Press.Norris, Samuel, Matthew Pecenco, Jeffrey Weaver. 2020. “Effects Parental Sibling Incarceration: Evidence Ohio.”Pearl, Judea. 2009. Causality. 2nd ed. Cambridge University Press.Peirce, Charles Sanders, Joseph Jastrow. 1885. “Small Differences Sensation.” Memoirs National Academy Sciences 3: 73–83.Peri, Giovanni, Vasil Yasenov. 2018. “Labor Market Effects Refugee Wave: Synthetic Control Method Meets Mariel Boatlift.” Journal Human Resources doi: 10.3368/jhr.54.2.0217.8561R1 (2018).Perkinson, Robert. 2010. Texas Tough: Rise America’s Prison Empire. First. Picador.Perloff, Harvey S. 1957. “Interrelations State Income Industrial Structure.” Review Economics Statistics 39 (2): 162–71.Piazza, Jo. 2009. “Megan Fox Voted Worst - Sexiest - Actress 2009.” https://marquee.blogs.cnn.com/2009/12/30/megan-fox-voted-worst--sexiest-actress--2009/.Powell, David. 2017. “Imperfect Synthetic Controls: Massachusetts Health Care Reform Save Lives?”Rilke, Ranier Maria. 2012. Letters Young Poet. Merchant Books.Rogeberg, Ole. 2004. “Taking Absurd Theories Seriously: Economics Case Rational Addiction Theories.” Philosophy Science 71: 263–85.Rosen, Sherwin. 1986. “Handbook Labor Economics.” . Vol. 1. Amsterdam: North-Holland.Rosenbaum, Paul R., Donald B. Rubin. 1983. “Central Role Propensity Score Observational Studies Causal Effects.” Biometrika 70 (1): 41–55.Rubin, Donald. 1974. “Estimating Causal Effects Treatments Randominzed Nonrandomized Studies.” Journal Educational Psychology 66 (5): 688–701.Rubin, Donald B. 1977. “Assignment Treatment Group Basis Covariate.” Journal Educational Statistics 2: 1–26.———. 2005. “Causal Inference Using Potential Outcomes: Design, Modeling, Decisions.” Journal American Statistical Association 100 (469): 322–31.———. 2007. “Design Versus Analysis Observational Studies Causal Effects: Parallels Design Randomized Trials.” Statistics Medicine 26 (1): 20–36.———. 2008. “Objective Causal Inference, Design Trumps Analysis.” Annals Applied Statistics 2 (3): 808–40.Sacerdote, Bruce. 2001. “Peer Effects Random Assignment: Results Dartmouth Roommates.” Quarterly Journal Economics, May, 681–704.Sant’Anna, Pedro H. C., Jun B. Zhao. 2018. “Doubly Robust Difference--Differences Estimators.”Sharpe, Jamie. 2019. “Re-Evaluating Impact Immigration Us Rental Housing Market.” Journal Urban Economics 111 (C): 14–34.Smith, Adam. 2003. Inquiry Nature Causes Wealth Nations. Bantam Classics.Smith, Jeffrey ., Petra E. Todd. 2005. “Matching Overcome Lalonde’s Critique Nonexperimental Estimators?” Journal Econometrics 125 (1-2): 305–53.———. 2001. “Reconciling Conflicting Evidence Performance Propensity-Score Matching Methods.” American Economic Review 91 (2): 112–18.Snow, John. 1855. Mode Communication Cholera. 2nd ed. John Churchill.Splawa-Neyman, Jerzy. 1923. “Application Probability Theory Agricultural Experiments. Essay Principles.” Annals Agricultural Sciences, 1–51.Staiger, Douglas, James H. Stock. 1997. “Instrumental Variables Regression Weak Instruments.” Econometrica 65 (3): 557–86.Steiner, Peter M., Yongnam Kim, Courtney E. Hall, Dan Su. 2017. “Graphical Models Quasi-Experimental Designs.” Sociological Methods Research 46 (2): 155–88.Stevenson, Megan T. 2018. “Distortion Justice: Inability Pay Bail Affects Case Outcomes.” Journal Law, Economics Organization 34 (4): 511–42.Stigler, Stephen M. 1980. “Stigler’s Law Eponymy.” Transactions New York Academy Sciences 39: 147–58.Stock, James H., Francesco Trebbi. 2003. “Invented Instrumental Variable Regression?” Journal Economic Perspectives 17 (3): 177–94.Sun, Liyang, Sarah Abraham. 2020. “Estimating Dynamic Treatment Effects Event Studies Heterogenous Treatment Effects.”Thistlehwaite, Donald, Donald Campbell. 1960. “Regression-Discontinuity Analysis: Alternative Ex-Post Facto Experiment.” Journal Educational Psychology 51: 309–17.Thornton, Rebecca L. 2008. “Demand , Impact , Learning Hiv Status.” American Economic Review 98 (5): 1829–63.Waldfogel, Joel. 1995. “Selection Hypotehsis Relationship Trial Plaintiff Victory.” Journal Political Economy 103 (2): 229–60.White, Halbert. 1980. “Heteroskedasticity-Consistent Covariance Matrix Estimator Direct Test Heteroskedasticity.” Econometrica 48 (4): 817–38.Wolpin, Kenneth . 2013. Limits Inference Without Theory. MIT Press.Wooldridge, Jeffrey. 2010. Econometric Analysis Cross Section Panel Data. 2nd ed. MIT Press.———. 2015. Introductory Econometrics: Modern Approach. 6th ed. South-Western College Pub.Wright, Phillip G. 1928. Tariff Animal Vegetable Oils. Macmillan Company.Young, Alwyn. 2019. “Chanelling Fisher: Randomization Tests Statistical Insignificance Seemingly Significant Experimental Results.” Quarterly Journal Economics 134 (2): 557–98.Yule, G. Udny. 1899. “Investigation Causes Changes Pauperism England, Chiefly Last Two Interensal Decades.” Journal Royal Statistical Society 62: 249–95.Zhao, Qingyuan. 2019. “Covariate Balancing Propensity Score Tailored Loss Functions.” Annals Statistics 47 (2): 965–93.Zubizarreta, Jose R. 2015. “Stable Weights Balance Covariates Estimation Incomplete Outcome Data.” Journal American Statistical Association 110 (511).","code":""}]
